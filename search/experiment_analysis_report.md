# 训练实验分析报告

## 1. 总体概述

本次分析涵盖了128次独立的训练实验。实验旨在通过调整一系列超参数来优化模型的性能。分析报告基于训练日志，重点评估了不同参数组合在**最终平均奖励、稳定性、收敛速度和综合性能**等多个维度上的表现。

**核心发现**:
- 实验 `exp_80` 在综合性能上表现最佳，取得了稳定性和奖励之间的良好平衡。
- 实验 `exp_7` 获得了最高的最终平均奖励，但在稳定性上稍逊一筹。
- 关键超参数如学习率 (`lrA`, `lrC`), 折扣因子 (`g`), 和批量大小 (`bs`) 对模型性能有显著影响。

## 2. 关键发现分析

### 2.1. 最佳实验配置

根据不同的评估指标，以下实验表现突出：

- **综合性能最佳**:
  - **`exp_80_lrA0.0005_lrC0.001_g0.99_tau0.01_bs64_uf100_rd200`**
  - **特点**: 该实验在综合评分中排名第一，具有高最终奖励（52635.21）和优秀的稳定性（稳定性得分0.212），收敛速度也较快（28回合）。这表明较低的Actor学习率、较高的Gamma值和较小的批处理大小组合可能有助于实现稳健且高效的训练。

- **最终奖励最高**:
  - **`exp_7_lrA0.001_lrC0.001_g0.95_tau0.01_bs128_uf200_rd300`**
  - **特点**: 该实验获得了最高的最终平均奖励（56699.74）。这表明较高的学习率和较大的批处理大小可能有助于模型探索并达到更高的奖励峰值，但可能以牺牲部分稳定性为代价（其稳定性评分为0.251，低于 `exp_80`）。

### 2.2. 超参数影响分析

- **学习率 (lrA, lrC)**:
  - 较低的Actor学习率 (`lrA=0.0005`) 与较高的Critic学习率 (`lrC=0.001`) 的组合（如 `exp_80`）在综合性能上表现优异，这可能有助于策略（Actor）更稳定地更新。
  - 相同的学习率 (`lrA=0.001`, `lrC=0.001` in `exp_7`) 能够达到最高的奖励值，但可能需要更大的批处理大小来维持稳定性。

- **折扣因子 (g)**:
  - 较高的 `g=0.99` (如 `exp_80`) 在综合推荐和稳定性方面表现良好，表明模型更关注长期回报，有助于制定更具远见的策略。
  - `g=0.95` 的实验占据了性能榜单的多个位置，表明也能取得非常好的结果，但可能更侧重于短期奖励。

- **批量大小 (bs)**:
  - `bs=64` (如 `exp_80`) 似乎与更好的稳定性相关。
  - `bs=128` (如 `exp_7`) 似乎与更高的峰值奖励相关。这可能是因为更大的批量提供了更稳定的梯度估计，允许使用更高的学习率。

- **更新参数 (tau, uf, rd)**:
  - **`tau`**: `0.01` 是大多数顶级实验的选择，表明较慢的目标网络更新有助于稳定学习过程。
  - **`uf` (Update Frequency)**: 效果似乎不明确，`100`和`200`在优秀实验中均有出现。
  - **`rd` (Replay Duration)**: `rd=300` 在多个高奖励实验中出现（如 `exp_7`, `exp_77`），表明更大的经验回放池可能有助于找到更好的策略。

### 2.3. 性能权衡

- **奖励与稳定性**: 追求最高奖励（如`exp_7`）的配置不一定是整体最稳定的。综合得分最高的`exp_80`在最终奖励上略低于`exp_7`，但稳定性更好。
- **收敛速度**: 最快收敛的实验 (`exp_108`) 并非奖励最高或最稳定的实验，表明过早收敛可能陷入局部最优。

## 3. 结论与建议

基于以上分析，我们提出以下建议：

1.  **首选推荐配置**:
    - 为了获得平衡的性能，推荐使用 `exp_80` 的参数配置作为基线：
      - `lrA=0.0005`, `lrC=0.001`, `g=0.99`, `tau=0.01`, `bs=64`, `uf=100`, `rd=200`

2.  **进一步探索方向**:
    - **探索混合配置**: 尝试将 `exp_80` 的稳定配置（如`g=0.99`, `bs=64`）与 `exp_7` 的高奖励配置（如`rd=300`）相结合，可能产生更优的结果。例如，可以测试 `g=0.99` 和 `rd=300` 的组合。
    - **微调学习率**: `lrA` 和 `lrC` 的相对大小似乎很重要。可以进一步探索 `lrA < lrC` 的设置。
    - **检测率优化**: 当前检测率最高的实验 (`exp_75`) 在奖励和稳定性方面并不突出。如果检测率是关键指标，需要专门针对其进行优化，分析其参数 `lrA0.0005_lrC0.001_g0.95_tau0.05_bs64_uf200_rd300` 的特点（例如 `tau=0.05`, `uf=200`）。

