import os
import re
import pandas as pd
import numpy as np
from collections import defaultdict
import matplotlib.pyplot as plt
import seaborn as sns

def extract_log_data(log_file):
    """ä»æ—¥å¿—æ–‡ä»¶ä¸­æå–è®­ç»ƒæ•°æ®"""
    data = {
        'episodes': [],
        'steps': [],
        'avg_rewards': [],
        'total_rewards': [],
        'detection_rates': [],
        'detection_counts': [],
        'episode_times': [],
        'termination_reasons': []
    }
    
    with open(log_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–Episode Summaryä¿¡æ¯
    episode_summaries = re.findall(
        r'Episode (\d+) Summary:\s*\n\s*Total Reward: ([\d.-]+)\s*\n\s*Targets Detected: (\d+)/(\d+) \(([\d.]+)%\)\s*\n\s*Steps: (\d+)\s*\n\s*Episode Time: ([\d.]+)s\s*\n\s*Termination Reason: (\w+)',
        content
    )
    
    for match in episode_summaries:
        episode_num, total_reward, detected, total_targets, detection_rate, steps, episode_time, termination = match
        
        data['episodes'].append(int(episode_num))
        data['total_rewards'].append(float(total_reward))
        data['detection_rates'].append(float(detection_rate))
        data['detection_counts'].append(int(detected))
        data['steps'].append(int(steps))
        data['episode_times'].append(float(episode_time))
        data['avg_rewards'].append(float(total_reward) / int(steps))
        data['termination_reasons'].append(termination)
    
    # æå–è®­ç»ƒè¿‡ç¨‹ä¸­çš„rewardå˜åŒ–
    step_rewards = re.findall(
        r'Step (\d+), Episode Steps: (\d+), Avg Reward: ([-\d.]+), Episode Reward: ([-\d.]+)',
        content
    )
    
    training_progress = []
    for match in step_rewards:
        step, episode_steps, avg_reward, episode_reward = match
        training_progress.append({
            'step': int(step),
            'episode_steps': int(episode_steps),
            'avg_reward': float(avg_reward),
            'episode_reward': float(episode_reward)
        })
    
    return data, training_progress

def analyze_single_log(log_file, exp_name):
    """åˆ†æå•ä¸ªæ—¥å¿—æ–‡ä»¶"""
    try:
        episode_data, training_progress = extract_log_data(log_file)
        
        if not episode_data['episodes']:
            return None
            
        analysis = {
            'exp_name': exp_name,
            'total_episodes': len(episode_data['episodes']),
            'final_avg_reward': np.mean(episode_data['total_rewards'][-10:]) if len(episode_data['total_rewards']) >= 10 else np.mean(episode_data['total_rewards']),
            'best_episode_reward': max(episode_data['total_rewards']) if episode_data['total_rewards'] else 0,
            'worst_episode_reward': min(episode_data['total_rewards']) if episode_data['total_rewards'] else 0,
            'reward_std': np.std(episode_data['total_rewards']) if episode_data['total_rewards'] else 0,
            'avg_detection_rate': np.mean(episode_data['detection_rates']) if episode_data['detection_rates'] else 0,
            'best_detection_rate': max(episode_data['detection_rates']) if episode_data['detection_rates'] else 0,
            'avg_episode_time': np.mean(episode_data['episode_times']) if episode_data['episode_times'] else 0,
            'avg_steps': np.mean(episode_data['steps']) if episode_data['steps'] else 0,
            'convergence_episode': None,  # æ”¶æ•›çš„å›åˆæ•°
            'improvement_trend': None,    # æ”¹å–„è¶‹åŠ¿
            'stability_score': None       # ç¨³å®šæ€§å¾—åˆ†
        }
        
        # åˆ†ææ”¶æ•›æ€§
        if len(episode_data['total_rewards']) >= 10:
            # è®¡ç®—æ»‘åŠ¨å¹³å‡
            window_size = min(10, len(episode_data['total_rewards']))
            moving_avg = pd.Series(episode_data['total_rewards']).rolling(window=window_size).mean().tolist()
            
            # å¯»æ‰¾æ”¶æ•›ç‚¹ï¼ˆè¿ç»­5ä¸ªepisodeçš„å¹³å‡å¥–åŠ±å˜åŒ–å°äºæ€»ä½“æ ‡å‡†å·®çš„10%ï¼‰
            threshold = analysis['reward_std'] * 0.1
            for i in range(len(moving_avg) - 5):
                if i >= window_size - 1:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
                    recent_values = moving_avg[i:i+5]
                    if max(recent_values) - min(recent_values) < threshold:
                        analysis['convergence_episode'] = i + 1
                        break
        
        # åˆ†ææ”¹å–„è¶‹åŠ¿
        if len(episode_data['total_rewards']) >= 20:
            first_half = episode_data['total_rewards'][:len(episode_data['total_rewards'])//2]
            second_half = episode_data['total_rewards'][len(episode_data['total_rewards'])//2:]
            improvement = (np.mean(second_half) - np.mean(first_half)) / np.mean(first_half) * 100
            analysis['improvement_trend'] = improvement
        
        # è®¡ç®—ç¨³å®šæ€§å¾—åˆ† (å30%episodeçš„æ ‡å‡†å·®)
        if len(episode_data['total_rewards']) >= 10:
            stable_episodes = episode_data['total_rewards'][int(len(episode_data['total_rewards']) * 0.7):]
            analysis['stability_score'] = np.std(stable_episodes) / np.mean(stable_episodes) if np.mean(stable_episodes) > 0 else float('inf')
        
        return analysis, episode_data, training_progress
    
    except Exception as e:
        print(f"Error analyzing {log_file}: {e}")
        return None

def analyze_all_logs():
    """åˆ†ææ‰€æœ‰æ—¥å¿—æ–‡ä»¶"""
    logs_dir = "logs"
    all_analysis = []
    detailed_data = {}
    
    print("å¼€å§‹åˆ†æè®­ç»ƒæ—¥å¿—...")
    print("=" * 80)
    
    for filename in sorted(os.listdir(logs_dir)):
        if filename.endswith('.txt') and filename.startswith('exp_'):
            exp_name = filename[:-4]  # å»æ‰.txt
            log_path = os.path.join(logs_dir, filename)
            
            result = analyze_single_log(log_path, exp_name)
            if result:
                analysis, episode_data, training_progress = result
                all_analysis.append(analysis)
                detailed_data[exp_name] = {
                    'episode_data': episode_data,
                    'training_progress': training_progress
                }
                print(f"âœ“ å·²åˆ†æ: {exp_name}")
    
    if not all_analysis:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ—¥å¿—æ•°æ®")
        return
    
    df = pd.DataFrame(all_analysis)
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n" + "=" * 80)
    print("è®­ç»ƒæ—¥å¿—åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    # 1. åŸºç¡€ç»Ÿè®¡
    print(f"\nğŸ“Š åŸºç¡€ç»Ÿè®¡:")
    print(f"  æ€»å®éªŒæ•°é‡: {len(df)}")
    print(f"  å¹³å‡è®­ç»ƒå›åˆæ•°: {df['total_episodes'].mean():.1f}")
    print(f"  æœ€å¤§å•å›åˆå¥–åŠ±: {df['best_episode_reward'].max():.1f}")
    print(f"  æœ€å°å•å›åˆå¥–åŠ±: {df['worst_episode_reward'].min():.1f}")
    
    # 2. æ€§èƒ½æ’å
    print(f"\nğŸ† æ€§èƒ½è¡¨ç°TOP10:")
    top_performers = df.nlargest(10, 'final_avg_reward')[['exp_name', 'final_avg_reward', 'best_episode_reward', 'avg_detection_rate', 'reward_std']]
    print(top_performers.to_string(index=False))
    
    # 3. æ”¶æ•›æ€§åˆ†æ
    converged = df[df['convergence_episode'].notna()]
    if len(converged) > 0:
        print(f"\nâš¡ æ”¶æ•›æ€§åˆ†æ:")
        print(f"  æ”¶æ•›å®éªŒæ•°é‡: {len(converged)}/{len(df)} ({len(converged)/len(df)*100:.1f}%)")
        print(f"  å¹³å‡æ”¶æ•›å›åˆ: {converged['convergence_episode'].mean():.1f}")
        print(f"  æœ€å¿«æ”¶æ•›: {converged['convergence_episode'].min():.0f} å›åˆ")
        
        fastest_converge = df.loc[df['convergence_episode'].idxmin()]
        print(f"  æœ€å¿«æ”¶æ•›å®éªŒ: {fastest_converge['exp_name']} (ç¬¬{fastest_converge['convergence_episode']:.0f}å›åˆ)")
    
    # 4. ç¨³å®šæ€§åˆ†æ
    stable = df[df['stability_score'].notna() & (df['stability_score'] != float('inf'))]
    if len(stable) > 0:
        print(f"\nğŸ“ˆ ç¨³å®šæ€§åˆ†æ:")
        stable_top10 = stable.nsmallest(10, 'stability_score')[['exp_name', 'stability_score', 'final_avg_reward', 'reward_std']]
        print(f"  ç¨³å®šæ€§æœ€å¥½çš„10ä¸ªå®éªŒ:")
        print(stable_top10.to_string(index=False))
    
    # 5. æ”¹å–„è¶‹åŠ¿åˆ†æ
    improved = df[df['improvement_trend'].notna()]
    if len(improved) > 0:
        print(f"\nğŸ“Š å­¦ä¹ æ”¹å–„åˆ†æ:")
        print(f"  æ˜¾ç¤ºæ”¹å–„çš„å®éªŒ: {len(improved[improved['improvement_trend'] > 0])}/{len(improved)} ({len(improved[improved['improvement_trend'] > 0])/len(improved)*100:.1f}%)")
        print(f"  å¹³å‡æ”¹å–„å¹…åº¦: {improved['improvement_trend'].mean():.1f}%")
        
        best_improvement = improved.loc[improved['improvement_trend'].idxmax()]
        print(f"  æœ€å¤§æ”¹å–„: {best_improvement['exp_name']} ({best_improvement['improvement_trend']:.1f}%)")
    
    # 6. æ£€æµ‹æ€§èƒ½åˆ†æ
    print(f"\nğŸ¯ æ£€æµ‹æ€§èƒ½åˆ†æ:")
    detection_top10 = df.nlargest(10, 'avg_detection_rate')[['exp_name', 'avg_detection_rate', 'best_detection_rate', 'final_avg_reward']]
    print(f"  æ£€æµ‹ç‡æœ€é«˜çš„10ä¸ªå®éªŒ:")
    print(detection_top10.to_string(index=False))
    
    # 7. è®­ç»ƒæ•ˆç‡åˆ†æ
    print(f"\nâ±ï¸ è®­ç»ƒæ•ˆç‡åˆ†æ:")
    print(f"  å¹³å‡æ¯å›åˆç”¨æ—¶: {df['avg_episode_time'].mean():.1f}s")
    print(f"  å¹³å‡æ¯å›åˆæ­¥æ•°: {df['avg_steps'].mean():.0f}")
    efficiency = df['final_avg_reward'] / (df['avg_episode_time'] * df['total_episodes'])
    efficiency_analysis = pd.DataFrame({
        'exp_name': df['exp_name'],
        'efficiency_score': efficiency,
        'final_avg_reward': df['final_avg_reward'],
        'total_training_time': df['avg_episode_time'] * df['total_episodes']
    }).nlargest(10, 'efficiency_score')
    
    print(f"  è®­ç»ƒæ•ˆç‡æœ€é«˜çš„10ä¸ªå®éªŒ (å¥–åŠ±/è®­ç»ƒæ—¶é—´):")
    print(efficiency_analysis.to_string(index=False))
    
    # 8. ç»¼åˆæ¨è
    print(f"\nğŸŒŸ ç»¼åˆæ¨èåˆ†æ:")
    
    # ç»¼åˆè¯„åˆ†ï¼šæ€§èƒ½ + ç¨³å®šæ€§ + æ”¶æ•›æ€§
    df['comprehensive_score'] = df['final_avg_reward'] * 0.4
    
    # ç¨³å®šæ€§åŠ åˆ†ï¼ˆç¨³å®šæ€§è¶Šå¥½åˆ†æ•°è¶Šé«˜ï¼‰
    if 'stability_score' in df.columns and df['stability_score'].notna().sum() > 0:
        df.loc[df['stability_score'].notna() & (df['stability_score'] != float('inf')), 'comprehensive_score'] += \
            (1 / df.loc[df['stability_score'].notna() & (df['stability_score'] != float('inf')), 'stability_score']) * 5000
    
    # æ”¶æ•›æ€§åŠ åˆ†
    if 'convergence_episode' in df.columns and df['convergence_episode'].notna().sum() > 0:
        max_convergence = df['convergence_episode'].max()
        df.loc[df['convergence_episode'].notna(), 'comprehensive_score'] += \
            (max_convergence - df.loc[df['convergence_episode'].notna(), 'convergence_episode']) * 100
    
    comprehensive_top10 = df.nlargest(10, 'comprehensive_score')[['exp_name', 'comprehensive_score', 'final_avg_reward', 'stability_score', 'convergence_episode']]
    print(f"  ç»¼åˆè¡¨ç°æœ€ä½³çš„10ä¸ªå®éªŒ:")
    print(comprehensive_top10.to_string(index=False))
    
    return df, detailed_data

if __name__ == "__main__":
    results = analyze_all_logs()