# test_optimizations.py - éªŒè¯ä¼˜åŒ–æ•ˆæœçš„æµ‹è¯•è„šæœ¬
import numpy as np
import pygame
from environment import UsvUavEnv
from ippo import PPOAgent
import config

def test_boundary_detection():
    """æµ‹è¯•è¾¹ç•Œç›®æ ‡æ£€æµ‹ä¼˜åŒ–"""
    print("=== æµ‹è¯•è¾¹ç•Œç›®æ ‡æ£€æµ‹å¢å¼º ===")
    
    env = UsvUavEnv(action_type='discrete')
    obs, _ = env.reset()
    
    # æ‰‹åŠ¨æ·»åŠ è¾¹ç•Œç›®æ ‡è¿›è¡Œæµ‹è¯•
    from agents import Target
    boundary_target = Target("test_boundary", [100, 100], 0)  # è¾¹ç•Œé™„è¿‘
    boundary_target.velocity = np.array([2.0, 1.0])  # é«˜é€Ÿç›®æ ‡
    env.targets.append(boundary_target)
    
    center_target = Target("test_center", [4000, 4000], 0)  # ä¸­å¿ƒåŒºåŸŸ
    center_target.velocity = np.array([1.0, 0.5])  # ä½é€Ÿç›®æ ‡
    env.targets.append(center_target)
    
    # æµ‹è¯•æ¢æµ‹èŒƒå›´å¢å¼º
    agent = env.agents[0]
    boundary_detected = env._is_target_in_agent_range(agent, boundary_target)
    center_detected = env._is_target_in_agent_range(agent, center_target)
    
    print(f"è¾¹ç•Œç›®æ ‡æ£€æµ‹: {boundary_detected}")
    print(f"ä¸­å¿ƒç›®æ ‡æ£€æµ‹: {center_detected}")
    print("è¾¹ç•Œç›®æ ‡åº”è¯¥æœ‰æ›´å¤§çš„æ£€æµ‹æ¦‚ç‡")

def test_reward_system():
    """æµ‹è¯•æ–°çš„å¥–åŠ±ç³»ç»Ÿ"""
    print("\n=== æµ‹è¯•å¥–åŠ±ç³»ç»Ÿä¼˜åŒ– ===")
    
    env = UsvUavEnv(action_type='discrete')
    obs, _ = env.reset()
    
    # åˆ›å»ºä¸åŒç±»å‹çš„ç›®æ ‡
    from agents import Target
    
    # è¾¹ç•Œé«˜é€Ÿç›®æ ‡
    boundary_fast = Target("boundary_fast", [100, 100], 0)
    boundary_fast.velocity = np.array([6.0, 3.0])  # >10èŠ‚
    boundary_fast.spawn_time = env.current_time - 100  # 100ç§’å‰ç”Ÿæˆ
    boundary_fast.is_detected = True
    boundary_fast.detection_completed = True
    env.targets.append(boundary_fast)
    
    # ä¸­å¿ƒä½é€Ÿç›®æ ‡
    center_slow = Target("center_slow", [4000, 4000], 0)
    center_slow.velocity = np.array([1.0, 0.5])  # <5èŠ‚
    center_slow.spawn_time = env.current_time - 50   # 50ç§’å‰ç”Ÿæˆ
    center_slow.is_detected = True
    center_slow.detection_completed = True
    env.targets.append(center_slow)
    
    # è®¡ç®—å¥–åŠ±
    rewards, events = env._calculate_rewards_and_detections()
    
    print(f"è¾¹ç•Œé«˜é€Ÿç›®æ ‡æ£€æµ‹å¥–åŠ±åº”è¯¥æ›´é«˜")
    print(f"å½“å‰å¥–åŠ±åˆ†é…: {rewards}")
    print(f"æ£€æµ‹äº‹ä»¶: {events}")

def test_observation_space():
    """æµ‹è¯•å¢å¼ºçš„è§‚æµ‹ç©ºé—´"""
    print("\n=== æµ‹è¯•è§‚æµ‹ç©ºé—´å¢å¼º ===")
    
    env = UsvUavEnv(action_type='discrete')
    obs, _ = env.reset()
    
    print(f"è§‚æµ‹ç©ºé—´ç»´åº¦: {env.observation_space.shape}")
    print("åº”è¯¥æ˜¯ (57,) ç»´åº¦")
    
    # æ£€æŸ¥è§‚æµ‹æ•°æ®ç»“æ„
    agent_id = list(obs.keys())[0]
    observation = obs[agent_id]
    
    print(f"å®é™…è§‚æµ‹ç»´åº¦: {observation.shape}")
    print(f"è§‚æµ‹æ•°æ®èŒƒå›´: [{observation.min():.3f}, {observation.max():.3f}]")
    
    # è§£æè§‚æµ‹æ•°æ®
    print("è§‚æµ‹æ•°æ®ç»“æ„:")
    print("  è‡ªèº«çŠ¶æ€: 0-5 (6ç»´)")
    print("  ç›®æ ‡ä¿¡æ¯: 6-20 (15ç»´)")
    print("  å…¶ä»–æ™ºèƒ½ä½“: 21-40 (20ç»´)")
    print("  æ¢ç´¢çŠ¶æ€: 41-49 (9ç»´)")
    print("  ç›®æ ‡ä¼˜å…ˆçº§: 50-52 (3ç»´)")
    print("  ååŒä¿¡æ¯: 53-56 (4ç»´)")

def test_coordination():
    """æµ‹è¯•ååŒæœºåˆ¶"""
    print("\n=== æµ‹è¯•ååŒæœºåˆ¶ ===")
    
    env = UsvUavEnv(action_type='discrete')
    obs, _ = env.reset()
    
    # æ·»åŠ é«˜ä¼˜å…ˆçº§ç›®æ ‡
    from agents import Target
    high_priority_target = Target("high_priority", [200, 200], 0)
    high_priority_target.velocity = np.array([7.0, 4.0])  # é«˜é€Ÿç›®æ ‡
    env.targets.append(high_priority_target)
    
    # æ›´æ–°ååŒä¿¡æ¯
    for agent in env.agents:
        agent.update_coordination_info(env.agents, env.targets, env.current_time)
        agent.get_coordination_role(env.targets, env.agents)
    
    # æ£€æŸ¥è§’è‰²åˆ†é…
    roles = [agent.coordination_role for agent in env.agents]
    shared_info = [len(agent.shared_target_info) for agent in env.agents]
    
    print(f"æ™ºèƒ½ä½“è§’è‰²åˆ†é…: {roles}")
    print(f"å…±äº«ç›®æ ‡ä¿¡æ¯æ•°é‡: {shared_info}")
    print("åº”è¯¥æœ‰æ™ºèƒ½ä½“åˆ‡æ¢åˆ°trackeræˆ–interceptorè§’è‰²")

def test_curriculum_learning():
    """æµ‹è¯•è¯¾ç¨‹å­¦ä¹ """
    print("\n=== æµ‹è¯•è¯¾ç¨‹å­¦ä¹  ===")
    
    # å¯¼å…¥è¯¾ç¨‹å­¦ä¹ å‡½æ•°
    from main import adjust_difficulty
    
    # æµ‹è¯•ä¸åŒé˜¶æ®µ
    print("åˆæœŸé˜¶æ®µ (Episode 50):")
    adjust_difficulty(50)
    print(f"  è¾¹ç•Œç›®æ ‡æ¦‚ç‡: {getattr(config, 'TARGET_BOUNDARY_PROB', 'æœªè®¾ç½®')}")
    print(f"  é€Ÿåº¦èŒƒå›´: {getattr(config, 'TARGET_SPEED_RANGE', 'æœªè®¾ç½®')}")
    
    print("\nä¸­æœŸé˜¶æ®µ (Episode 200):")
    adjust_difficulty(200)
    print(f"  è¾¹ç•Œç›®æ ‡æ¦‚ç‡: {getattr(config, 'TARGET_BOUNDARY_PROB', 'æœªè®¾ç½®')}")
    print(f"  é€Ÿåº¦èŒƒå›´: {getattr(config, 'TARGET_SPEED_RANGE', 'æœªè®¾ç½®')}")
    
    print("\nåæœŸé˜¶æ®µ (Episode 400):")
    adjust_difficulty(400)
    print(f"  è¾¹ç•Œç›®æ ‡æ¦‚ç‡: {getattr(config, 'TARGET_BOUNDARY_PROB', 'æœªè®¾ç½®')}")
    print(f"  é€Ÿåº¦èŒƒå›´: {getattr(config, 'TARGET_SPEED_RANGE', 'æœªè®¾ç½®')}")

def run_quick_training_test():
    """è¿è¡Œå¿«é€Ÿè®­ç»ƒæµ‹è¯•"""
    print("\n=== å¿«é€Ÿè®­ç»ƒæµ‹è¯• ===")
    
    env = UsvUavEnv(action_type='discrete')
    obs, _ = env.reset()
    
    # åˆå§‹åŒ–PPOæ™ºèƒ½ä½“
    state_dim = env.observation_space.shape[0]
    action_dim = env.action_space.n
    
    ppo_agents = {}
    for agent in env.agents:
        ppo_agents[agent.id] = PPOAgent(
            state_dim, action_dim, 
            config.LR_ACTOR, config.LR_CRITIC, 
            config.GAMMA, config.K_EPOCHS, config.EPS_CLIP, 
            'discrete'
        )
    
    print(f"æˆåŠŸåˆ›å»º {len(ppo_agents)} ä¸ªPPOæ™ºèƒ½ä½“")
    print(f"è§‚æµ‹ç»´åº¦: {state_dim}, åŠ¨ä½œç»´åº¦: {action_dim}")
    
    # è¿è¡Œå‡ æ­¥æµ‹è¯•
    total_reward = 0
    for step in range(10):
        actions = {}
        for agent_id, observation in obs.items():
            action = ppo_agents[agent_id].select_action(observation)
            actions[agent_id] = action
        
        obs, rewards, terminated, truncated, info = env.step(actions)
        step_reward = sum(rewards.values())
        total_reward += step_reward
        
        if step % 5 == 0:
            print(f"  æ­¥éª¤ {step}: å¥–åŠ± = {step_reward:.2f}")
        
        if terminated or truncated:
            break
    
    print(f"10æ­¥æµ‹è¯•å®Œæˆï¼Œæ€»å¥–åŠ±: {total_reward:.2f}")

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹éªŒè¯ä¼˜åŒ–æ•ˆæœ...")
    
    try:
        test_boundary_detection()
        test_reward_system()
        test_observation_space()
        test_coordination()
        test_curriculum_learning()
        run_quick_training_test()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼ä¼˜åŒ–éªŒè¯æˆåŠŸï¼")
        print("\nä¸»è¦æ”¹è¿›æ€»ç»“:")
        print("âœ… è¾¹ç•Œç›®æ ‡æ£€æµ‹å¢å¼º - æé«˜è¾¹ç•Œå’Œé«˜é€Ÿç›®æ ‡çš„æ¢æµ‹èƒ½åŠ›")
        print("âœ… å¥–åŠ±å‡½æ•°é‡æ–°è®¾è®¡ - é‡ç‚¹å¥–åŠ±è¾¹ç•Œã€é«˜é€Ÿã€æ—©æœŸæ£€æµ‹ç›®æ ‡")
        print("âœ… è§‚æµ‹ç©ºé—´å¢å¼º - å¢åŠ ç›®æ ‡ä¼˜å…ˆçº§å’ŒååŒä¿¡æ¯")
        print("âœ… ååŒæœºåˆ¶ä¼˜åŒ– - æ™ºèƒ½ä½“è§’è‰²åˆ†é…å’Œä¿¡æ¯å…±äº«")
        print("âœ… è¯¾ç¨‹å­¦ä¹ æ”¹è¿› - æ¸è¿›å¼éš¾åº¦è°ƒæ•´ï¼Œç¬¦åˆæ¯”èµ›ç‰¹ç‚¹")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()