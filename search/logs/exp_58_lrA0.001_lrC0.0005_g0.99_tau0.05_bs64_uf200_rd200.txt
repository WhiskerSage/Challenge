D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: 2.505, Episode Reward: 2504.6
    æ£€æµ‹è¿›åº¦: 1/13 (7.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(311,3121)'), ('usv_1', '(293,4095)'), ('usv_2', '(255,5072)')]...
    Recent rewards sample: {'usv_0': np.float64(0.39050489957894174), 'usv_1': np.float64(-0.5191934245814916)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 4.517, Episode Reward: 9034.0
    æ£€æµ‹è¿›åº¦: 2/26 (7.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(398,3128)'), ('usv_1', '(266,4035)'), ('usv_2', '(209,5055)')]...
    Recent rewards sample: {'usv_0': np.float64(1.421634530050814), 'usv_1': np.float64(-2.52019527447343)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 3000, Avg Reward: 5.928, Episode Reward: 17785.2
    æ£€æµ‹è¿›åº¦: 2/40 (5.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(483,3172)'), ('usv_1', '(210,4097)'), ('usv_2', '(209,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(2.4474258797955777), 'usv_1': np.float64(-3.5337853639710284)}
    Episode time: 300.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 17792.1
  Targets Detected: 3/40 (5.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.93
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 999, Avg Reward: 11.696, Episode Reward: 11684.6
    æ£€æµ‹è¿›åº¦: 3/20 (15.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(314,3138)'), ('usv_1', '(282,4071)'), ('usv_2', '(221,5070)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3967045801886377), 'usv_1': np.float64(3.480543851194322)}
    Episode time: 99.9s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.14799494 -0.09735204] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 1999, Avg Reward: 15.305, Episode Reward: 30594.0
    æ£€æµ‹è¿›åº¦: 3/28 (10.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(404,3155)'), ('usv_1', '(249,3990)'), ('usv_2', '(201,5070)')]...
    Recent rewards sample: {'usv_0': np.float64(4.415864206328388), 'usv_1': np.float64(1.473225299282296)}
    Episode time: 199.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 34849.0
  Targets Detected: 4/28 (10.7%)
  Steps: 2235
  Episode Time: 223.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.59
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 764, Avg Reward: -0.717, Episode Reward: -548.0
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(268,3161)'), ('usv_1', '(301,4119)'), ('usv_2', '(263,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3729605190030344), 'usv_1': np.float64(-0.521487199730096)}
    Episode time: 76.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 1764, Avg Reward: 9.976, Episode Reward: 17598.1
    æ£€æµ‹è¿›åº¦: 3/25 (12.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(355,3215)'), ('usv_1', '(332,4042)'), ('usv_2', '(239,5026)')]...
    Recent rewards sample: {'usv_0': np.float64(4.389830597190794), 'usv_1': np.float64(3.478787062081996)}
    Episode time: 176.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 29482.5
  Targets Detected: 3/33 (9.1%)
  Steps: 2349
  Episode Time: 234.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.55
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 415, Avg Reward: 1.695, Episode Reward: 703.6
    æ£€æµ‹è¿›åº¦: 1/13 (7.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3126)'), ('usv_1', '(265,4107)'), ('usv_2', '(246,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(0.37950746984488415), 'usv_1': np.float64(1.475210063740907)}
    Episode time: 41.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 1415, Avg Reward: 8.083, Episode Reward: 11437.9
    æ£€æµ‹è¿›åº¦: 2/23 (8.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(325,3192)'), ('usv_1', '(296,4029)'), ('usv_2', '(274,5077)')]...
    Recent rewards sample: {'usv_0': np.float64(2.394614755860408), 'usv_1': np.float64(3.4748586378252027)}
    Episode time: 141.5s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.21819788 -0.22801487] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 2415, Avg Reward: 12.506, Episode Reward: 30202.3
    æ£€æµ‹è¿›åº¦: 3/41 (7.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(334,3294)'), ('usv_1', '(206,3972)'), ('usv_2', '(207,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(4.379882253180929), 'usv_1': np.float64(3.4788296425931176)}
    Episode time: 241.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 34300.5
  Targets Detected: 3/41 (7.3%)
  Steps: 2633
  Episode Time: 263.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.03
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 782, Avg Reward: 5.702, Episode Reward: 4459.3
    æ£€æµ‹è¿›åº¦: 2/8 (25.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(297,3137)'), ('usv_1', '(283,4098)'), ('usv_2', '(236,5088)')]...
    Recent rewards sample: {'usv_0': np.float64(4.38509571729697), 'usv_1': np.float64(1.4717176347747505)}
    Episode time: 78.2s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 1782, Avg Reward: 14.316, Episode Reward: 25511.4
    æ£€æµ‹è¿›åº¦: 3/18 (16.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(400,3167)'), ('usv_1', '(243,4009)'), ('usv_2', '(202,5031)')]...
    Recent rewards sample: {'usv_0': np.float64(4.410148154677536), 'usv_1': np.float64(1.4778429836289022)}
    Episode time: 178.2s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 29666.2
  Targets Detected: 3/21 (14.3%)
  Steps: 1999
  Episode Time: 199.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.84
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 783, Avg Reward: -3.415, Episode Reward: -2674.1
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3130)'), ('usv_1', '(269,4102)'), ('usv_2', '(249,5087)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6150336079513666), 'usv_1': np.float64(-1.52319787550866)}
    Episode time: 78.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 1783, Avg Reward: 5.399, Episode Reward: 9626.3
    æ£€æµ‹è¿›åº¦: 5/29 (17.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(373,3159)'), ('usv_1', '(285,4015)'), ('usv_2', '(228,5004)')]...
    Recent rewards sample: {'usv_0': np.float64(4.4053943662846375), 'usv_1': np.float64(1.4796017095955571)}
    Episode time: 178.3s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.00351939 0.25735268] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 2783, Avg Reward: 10.076, Episode Reward: 28041.3
    æ£€æµ‹è¿›åº¦: 5/45 (11.1%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(459,3145)'), ('usv_1', '(208,3992)'), ('usv_2', '(209,5008)')]...
    Recent rewards sample: {'usv_0': np.float64(4.4239705948500205), 'usv_1': np.float64(1.4703785909566855)}
    Episode time: 278.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 32657.8
  Targets Detected: 7/46 (13.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.88
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 782, Avg Reward: -3.255, Episode Reward: -2545.7
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(296,3143)'), ('usv_1', '(300,4091)'), ('usv_2', '(271,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6117297624628527), 'usv_1': np.float64(-1.5113013083108673)}
    Episode time: 78.2s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 1782, Avg Reward: 3.217, Episode Reward: 5733.3
    æ£€æµ‹è¿›åº¦: 2/26 (7.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(362,3220)'), ('usv_1', '(340,4017)'), ('usv_2', '(240,5056)')]...
    Recent rewards sample: {'usv_0': np.float64(4.391859613636517), 'usv_1': np.float64(3.482994541324099)}
    Episode time: 178.2s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 2782, Avg Reward: 9.806, Episode Reward: 27281.5
    æ£€æµ‹è¿›åº¦: 5/37 (13.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(394,3305)'), ('usv_1', '(266,3971)'), ('usv_2', '(205,5069)')]...
    Recent rewards sample: {'usv_0': np.float64(4.389445996924696), 'usv_1': np.float64(3.4825218225042534)}
    Episode time: 278.2s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 31382.3
  Targets Detected: 5/39 (12.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.46
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 781, Avg Reward: 2.286, Episode Reward: 1785.6
    æ£€æµ‹è¿›åº¦: 1/8 (12.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(284,3134)'), ('usv_1', '(299,4109)'), ('usv_2', '(268,5106)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3805791367963263), 'usv_1': np.float64(0.475553551999486)}
    Episode time: 78.1s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.07371198 0.10385757] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 1781, Avg Reward: 12.364, Episode Reward: 22020.7
    æ£€æµ‹è¿›åº¦: 5/29 (17.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(346,3157)'), ('usv_1', '(377,4040)'), ('usv_2', '(265,5031)')]...
    Recent rewards sample: {'usv_0': np.float64(4.397157998308216), 'usv_1': np.float64(1.4821656804735581)}
    Episode time: 178.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 2781, Avg Reward: 13.067, Episode Reward: 36338.3
    æ£€æµ‹è¿›åº¦: 3/46 (6.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(427,3217)'), ('usv_1', '(374,3935)'), ('usv_2', '(210,5031)')]...
    Recent rewards sample: {'usv_0': np.float64(4.413432162985148), 'usv_1': np.float64(-3.515827327999202)}
    Episode time: 278.1s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 37357.7
  Targets Detected: 6/47 (6.4%)
  Steps: 2896
  Episode Time: 289.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.90
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 885, Avg Reward: 1.518, Episode Reward: 1343.8
    æ£€æµ‹è¿›åº¦: 1/12 (8.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(291,3135)'), ('usv_1', '(277,4084)'), ('usv_2', '(259,5080)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3923756327680743), 'usv_1': np.float64(-0.524576127932828)}
    Episode time: 88.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 1885, Avg Reward: 6.057, Episode Reward: 11417.7
    æ£€æµ‹è¿›åº¦: 3/29 (10.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(393,3145)'), ('usv_1', '(252,4008)'), ('usv_2', '(209,5083)')]...
    Recent rewards sample: {'usv_0': np.float64(2.4171983215765582), 'usv_1': np.float64(1.472372663045408)}
    Episode time: 188.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 2885, Avg Reward: 9.789, Episode Reward: 28241.2
    æ£€æµ‹è¿›åº¦: 3/38 (7.9%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(469,3156)'), ('usv_1', '(207,3990)'), ('usv_2', '(223,5169)')]...
    Recent rewards sample: {'usv_0': np.float64(2.4303812487832954), 'usv_1': np.float64(1.4690671418669483)}
    Episode time: 288.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 30192.2
  Targets Detected: 3/38 (7.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.06
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.2048384  -0.06093215] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 884, Avg Reward: 11.405, Episode Reward: 10081.8
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(300,3156)'), ('usv_1', '(292,4087)'), ('usv_2', '(285,5085)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3817197242367194), 'usv_1': np.float64(2.4785470226034474)}
    Episode time: 88.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 1884, Avg Reward: 16.697, Episode Reward: 31456.7
    æ£€æµ‹è¿›åº¦: 3/26 (11.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(340,3221)'), ('usv_1', '(284,4013)'), ('usv_2', '(294,5016)')]...
    Recent rewards sample: {'usv_0': np.float64(4.38839718215951), 'usv_1': np.float64(3.4822540140005565)}
    Episode time: 188.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 2884, Avg Reward: 18.273, Episode Reward: 52700.7
    æ£€æµ‹è¿›åº¦: 5/33 (15.2%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(291,3311)'), ('usv_1', '(212,4044)'), ('usv_2', '(250,5034)')]...
    Recent rewards sample: {'usv_0': np.float64(4.371433673228781), 'usv_1': np.float64(3.467475816366224)}
    Episode time: 288.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 54884.2
  Targets Detected: 7/33 (15.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.29

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 33256.4
Last 10 episodes average detections: 4.4
Best episode reward so far: 54884.2
Best detection count so far: 7
Buffer size: 27117
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 883, Avg Reward: 1.829, Episode Reward: 1614.6
    æ£€æµ‹è¿›åº¦: 1/25 (4.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3140)'), ('usv_1', '(286,4067)'), ('usv_2', '(256,5075)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33259935211537184), 'usv_1': np.float64(-0.5710425038764688)}
    Episode time: 88.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 7630.6
  Targets Detected: 2/44 (2.3%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_147s
  Average Reward/Step: 4.24
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 82, Avg Reward: -4.411, Episode Reward: -361.7
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3131)'), ('usv_1', '(223,4130)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6793274786258063), 'usv_1': np.float64(-1.5709423676227188)}
    Episode time: 8.2s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.09494618 -0.18931164] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 1082, Avg Reward: 4.403, Episode Reward: 4764.1
    æ£€æµ‹è¿›åº¦: 1/24 (4.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(322,3126)'), ('usv_1', '(326,4091)'), ('usv_2', '(236,5095)')]...
    Recent rewards sample: {'usv_0': np.float64(0.34972678094314325), 'usv_1': np.float64(-0.5749448549369562)}
    Episode time: 108.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 2082, Avg Reward: 10.798, Episode Reward: 22481.8
    æ£€æµ‹è¿›åº¦: 6/47 (12.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(401,3124)'), ('usv_1', '(354,3993)'), ('usv_2', '(232,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(4.363677053736933), 'usv_1': np.float64(1.438020263839967)}
    Episode time: 208.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 39886.9
  Targets Detected: 7/61 (8.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.29
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 81, Avg Reward: -3.476, Episode Reward: -281.5
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3130)'), ('usv_1', '(228,4129)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3232067267527502), 'usv_1': np.float64(1.4236810429629165)}
    Episode time: 8.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 1081, Avg Reward: 4.112, Episode Reward: 4445.6
    æ£€æµ‹è¿›åº¦: 1/20 (5.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(326,3136)'), ('usv_1', '(324,4099)'), ('usv_2', '(209,5075)')]...
    Recent rewards sample: {'usv_0': np.float64(0.34514384679316257), 'usv_1': np.float64(1.4248694661692793)}
    Episode time: 108.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 2081, Avg Reward: 6.835, Episode Reward: 14223.3
    æ£€æµ‹è¿›åº¦: 2/39 (5.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(410,3148)'), ('usv_1', '(328,4010)'), ('usv_2', '(200,5069)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3695545643650338), 'usv_1': np.float64(0.42944797931863543)}
    Episode time: 208.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 32323.6
  Targets Detected: 4/64 (6.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.77
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.06944818 0.10101211] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 80, Avg Reward: -3.511, Episode Reward: -280.9
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(217,4130)'), ('usv_2', '(229,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6854932974522562), 'usv_1': np.float64(-1.58233504787439)}
    Episode time: 8.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 1080, Avg Reward: 13.570, Episode Reward: 14656.1
    æ£€æµ‹è¿›åº¦: 3/43 (7.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(338,3145)'), ('usv_1', '(290,4074)'), ('usv_2', '(276,5082)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3515947862893025), 'usv_1': np.float64(3.422550566614535)}
    Episode time: 108.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 32130.4
  Targets Detected: 5/57 (5.3%)
  Steps: 1902
  Episode Time: 190.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.89
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 178, Avg Reward: -3.565, Episode Reward: -634.6
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3130)'), ('usv_1', '(224,4127)'), ('usv_2', '(232,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6730224619384872), 'usv_1': np.float64(-1.5819603072013086)}
    Episode time: 17.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 1178, Avg Reward: 1.419, Episode Reward: 1671.3
    æ£€æµ‹è¿›åº¦: 2/9 (22.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(304,3179)'), ('usv_1', '(293,4050)'), ('usv_2', '(266,5057)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33025144373884285), 'usv_1': np.float64(-0.5619679946039222)}
    Episode time: 117.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 5487.6
  Targets Detected: 2/26 (7.7%)
  Steps: 2168
  Episode Time: 216.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 2.53
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 10, Avg Reward: -2.693, Episode Reward: -26.9
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(213,4130)'), ('usv_2', '(212,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6680946194351366), 'usv_1': np.float64(-1.5688204500674174)}
    Episode time: 1.0s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.01247509 -0.23849078] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 1010, Avg Reward: 7.995, Episode Reward: 8075.3
    æ£€æµ‹è¿›åº¦: 2/23 (8.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(333,3153)'), ('usv_1', '(307,4072)'), ('usv_2', '(267,5106)')]...
    Recent rewards sample: {'usv_0': np.float64(3.34538811680784), 'usv_1': np.float64(0.42444917512774927)}
    Episode time: 101.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 11739.3
  Targets Detected: 2/36 (2.8%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_140s
  Average Reward/Step: 6.52
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 209, Avg Reward: -3.584, Episode Reward: -749.0
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3130)'), ('usv_1', '(244,4129)'), ('usv_2', '(226,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6828221301382347), 'usv_1': np.float64(-1.5760357201724444)}
    Episode time: 20.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 1209, Avg Reward: 7.924, Episode Reward: 9580.0
    æ£€æµ‹è¿›åº¦: 2/31 (6.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(313,3137)'), ('usv_1', '(317,4099)'), ('usv_2', '(243,5043)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3457027253534526), 'usv_1': np.float64(1.4262917107345694)}
    Episode time: 120.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 2209, Avg Reward: 11.812, Episode Reward: 26092.8
    æ£€æµ‹è¿›åº¦: 3/47 (6.4%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(398,3171)'), ('usv_1', '(305,4033)'), ('usv_2', '(209,5001)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3598167734289484), 'usv_1': np.float64(-6.566956526152577)}
    Episode time: 220.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 26725.7
  Targets Detected: 6/49 (8.2%)
  Steps: 2490
  Episode Time: 249.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.73
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 719, Avg Reward: -0.894, Episode Reward: -642.5
    æ£€æµ‹è¿›åº¦: 1/16 (6.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(287,3129)'), ('usv_1', '(269,4106)'), ('usv_2', '(244,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33619023399949544), 'usv_1': np.float64(-0.5753676117447122)}
    Episode time: 71.9s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.39761168 0.05568756] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 1719, Avg Reward: 3.751, Episode Reward: 6448.7
    æ£€æµ‹è¿›åº¦: 1/30 (3.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(384,3185)'), ('usv_1', '(278,4007)'), ('usv_2', '(214,5039)')]...
    Recent rewards sample: {'usv_0': np.float64(2.363086528281384), 'usv_1': np.float64(1.4289199326650692)}
    Episode time: 171.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 2719, Avg Reward: 9.370, Episode Reward: 25475.7
    æ£€æµ‹è¿›åº¦: 2/49 (4.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(457,3287)'), ('usv_1', '(230,3924)'), ('usv_2', '(205,5061)')]...
    Recent rewards sample: {'usv_0': np.float64(2.364562174866199), 'usv_1': np.float64(1.4349248862013781)}
    Episode time: 271.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 30433.3
  Targets Detected: 4/54 (3.7%)
  Steps: 2997
  Episode Time: 299.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.15
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 722, Avg Reward: 3.808, Episode Reward: 2749.4
    æ£€æµ‹è¿›åº¦: 2/11 (18.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(283,3143)'), ('usv_1', '(277,4096)'), ('usv_2', '(239,5082)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3380678529661967), 'usv_1': np.float64(2.4331692094880104)}
    Episode time: 72.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 1722, Avg Reward: 11.100, Episode Reward: 19114.6
    æ£€æµ‹è¿›åº¦: 3/27 (11.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(390,3134)'), ('usv_1', '(338,4001)'), ('usv_2', '(209,5022)')]...
    Recent rewards sample: {'usv_0': np.float64(2.365491369117553), 'usv_1': np.float64(1.4387739093414234)}
    Episode time: 172.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 25465.0
  Targets Detected: 4/32 (9.4%)
  Steps: 2161
  Episode Time: 216.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 11.78
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 561, Avg Reward: -3.589, Episode Reward: -2013.7
    æ£€æµ‹è¿›åº¦: 0/19 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3136)'), ('usv_1', '(279,4120)'), ('usv_2', '(239,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6674869302543459), 'usv_1': np.float64(-1.5786710937181758)}
    Episode time: 56.1s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.02183413  0.06916587] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 1561, Avg Reward: -2.305, Episode Reward: -3597.7
    æ£€æµ‹è¿›åº¦: 1/38 (2.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(362,3180)'), ('usv_1', '(298,4051)'), ('usv_2', '(206,5064)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3499384736585505), 'usv_1': np.float64(-0.575431459540264)}
    Episode time: 156.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 2561, Avg Reward: -3.918, Episode Reward: -10032.9
    æ£€æµ‹è¿›åº¦: 1/56 (1.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(393,3261)'), ('usv_1', '(259,3952)'), ('usv_2', '(204,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(2.341141121614743), 'usv_1': np.float64(-8.5734251573308)}
    Episode time: 256.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: -15300.2
  Targets Detected: 3/62 (3.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: -5.10

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 19652.2
Last 10 episodes average detections: 3.9
Best episode reward so far: 54884.2
Best detection count so far: 7
Learning trend: Declining (19652.2 vs 33256.4)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 560, Avg Reward: 10.050, Episode Reward: 5628.1
    æ£€æµ‹è¿›åº¦: 2/15 (13.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(262,3139)'), ('usv_1', '(251,4124)'), ('usv_2', '(253,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3323822953867426), 'usv_1': np.float64(0.42982537663975995)}
    Episode time: 56.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 1560, Avg Reward: 15.690, Episode Reward: 24475.9
    æ£€æµ‹è¿›åº¦: 3/30 (10.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(322,3194)'), ('usv_1', '(303,4072)'), ('usv_2', '(269,5060)')]...
    Recent rewards sample: {'usv_0': np.float64(4.335672267864334), 'usv_1': np.float64(1.4381368624341824)}
    Episode time: 156.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 31169.9
  Targets Detected: 5/45 (4.4%)
  Steps: 2352
  Episode Time: 235.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.25
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 208, Avg Reward: -2.284, Episode Reward: -475.0
    æ£€æµ‹è¿›åº¦: 1/2 (50.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3125)'), ('usv_1', '(241,4129)'), ('usv_2', '(224,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6818111104237792), 'usv_1': np.float64(-1.5720457941334611)}
    Episode time: 20.8s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.02628446 -0.03839112] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 1208, Avg Reward: -0.075, Episode Reward: -91.0
    æ£€æµ‹è¿›åº¦: 2/28 (7.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(306,3149)'), ('usv_1', '(333,4097)'), ('usv_2', '(319,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33564085500135954), 'usv_1': np.float64(-0.5723479666257922)}
    Episode time: 120.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 1657.8
  Targets Detected: 2/41 (2.4%)
  Steps: 1897
  Episode Time: 189.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 0.87
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 311, Avg Reward: -3.589, Episode Reward: -1116.3
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3131)'), ('usv_1', '(246,4132)'), ('usv_2', '(231,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6805053070259243), 'usv_1': np.float64(-1.5758749382711348)}
    Episode time: 31.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 1311, Avg Reward: 6.449, Episode Reward: 8454.3
    æ£€æµ‹è¿›åº¦: 3/29 (10.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(325,3128)'), ('usv_1', '(350,4103)'), ('usv_2', '(240,5043)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3518580500561486), 'usv_1': np.float64(3.428804186611643)}
    Episode time: 131.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 2311, Avg Reward: 9.391, Episode Reward: 21701.6
    æ£€æµ‹è¿›åº¦: 3/41 (7.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(402,3183)'), ('usv_1', '(361,4009)'), ('usv_2', '(203,5049)')]...
    Recent rewards sample: {'usv_0': np.float64(2.356982640862267), 'usv_1': np.float64(-6.564976207508689)}
    Episode time: 231.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 21490.2
  Targets Detected: 3/41 (7.3%)
  Steps: 2502
  Episode Time: 250.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 8.59
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 809, Avg Reward: 4.706, Episode Reward: 3806.8
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3146)'), ('usv_1', '(291,4099)'), ('usv_2', '(267,5095)')]...
    Recent rewards sample: {'usv_0': np.float64(1.322716424669855), 'usv_1': np.float64(0.4223605204377936)}
    Episode time: 80.9s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.04426415 0.03469205] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 1809, Avg Reward: 13.325, Episode Reward: 24105.4
    æ£€æµ‹è¿›åº¦: 5/36 (13.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(322,3171)'), ('usv_1', '(293,4036)'), ('usv_2', '(220,5068)')]...
    Recent rewards sample: {'usv_0': np.float64(4.337702493451086), 'usv_1': np.float64(3.4361321045711257)}
    Episode time: 180.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 2809, Avg Reward: 16.177, Episode Reward: 45439.9
    æ£€æµ‹è¿›åº¦: 8/60 (13.3%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(361,3245)'), ('usv_1', '(212,4047)'), ('usv_2', '(206,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3430773789943276), 'usv_1': np.float64(1.4207863325635883)}
    Episode time: 280.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 50408.7
  Targets Detected: 9/64 (14.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.80
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 808, Avg Reward: -3.570, Episode Reward: -2884.6
    æ£€æµ‹è¿›åº¦: 0/16 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3132)'), ('usv_1', '(291,4118)'), ('usv_2', '(238,5070)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6705621784340988), 'usv_1': np.float64(-1.5761003069818265)}
    Episode time: 80.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: -4280.4
  Targets Detected: 0/42 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -2.38
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 7, Avg Reward: -2.598, Episode Reward: -18.2
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3130)'), ('usv_1', '(211,4130)'), ('usv_2', '(211,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6779492520098556), 'usv_1': np.float64(-1.5744436632757237)}
    Episode time: 0.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 1007, Avg Reward: -3.633, Episode Reward: -3658.3
    æ£€æµ‹è¿›åº¦: 1/26 (3.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3161)'), ('usv_1', '(254,4050)'), ('usv_2', '(217,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6690605991058827), 'usv_1': np.float64(-1.5769515130009915)}
    Episode time: 100.7s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.40626647 -0.08546298] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 2007, Avg Reward: -2.083, Episode Reward: -4180.7
    æ£€æµ‹è¿›åº¦: 3/48 (6.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(338,3223)'), ('usv_1', '(208,3991)'), ('usv_2', '(204,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(1.332751387494909), 'usv_1': np.float64(0.4190971246927171)}
    Episode time: 200.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 12917.0
  Targets Detected: 7/63 (7.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 4.30
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 6, Avg Reward: -2.427, Episode Reward: -14.6
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3130)'), ('usv_1', '(211,4130)'), ('usv_2', '(211,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6770011184306008), 'usv_1': np.float64(-1.56935122619254)}
    Episode time: 0.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 1006, Avg Reward: 3.277, Episode Reward: 3296.6
    æ£€æµ‹è¿›åº¦: 1/29 (3.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(297,3139)'), ('usv_1', '(285,4081)'), ('usv_2', '(242,5068)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3364490490422711), 'usv_1': np.float64(0.42671758316695385)}
    Episode time: 100.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 13399.3
  Targets Detected: 2/44 (2.3%)
  Steps: 1969
  Episode Time: 196.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 6.81
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 37, Avg Reward: -3.382, Episode Reward: -125.1
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(213,4130)'), ('usv_2', '(214,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.685423269389272), 'usv_1': np.float64(-1.5830347965391907)}
    Episode time: 3.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 1037, Avg Reward: 9.083, Episode Reward: 9419.5
    æ£€æµ‹è¿›åº¦: 4/27 (14.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3165)'), ('usv_1', '(303,4072)'), ('usv_2', '(222,5078)')]...
    Recent rewards sample: {'usv_0': np.float64(2.325928094223425), 'usv_1': np.float64(3.424158095137627)}
    Episode time: 103.7s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.25129721 0.03820683] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 2037, Avg Reward: 13.537, Episode Reward: 27574.7
    æ£€æµ‹è¿›åº¦: 4/41 (9.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(340,3217)'), ('usv_1', '(239,4005)'), ('usv_2', '(207,5090)')]...
    Recent rewards sample: {'usv_0': np.float64(4.336689099526456), 'usv_1': np.float64(3.4274253120011267)}
    Episode time: 203.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 50789.9
  Targets Detected: 8/61 (13.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.92
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 36, Avg Reward: -3.364, Episode Reward: -121.1
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(217,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6844143631353893), 'usv_1': np.float64(-1.5791110621785478)}
    Episode time: 3.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 1036, Avg Reward: -3.072, Episode Reward: -3183.0
    æ£€æµ‹è¿›åº¦: 0/18 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(314,3123)'), ('usv_1', '(252,4045)'), ('usv_2', '(256,5075)')]...
    Recent rewards sample: {'usv_0': np.float64(2.345673702293987), 'usv_1': np.float64(-0.5687039267122269)}
    Episode time: 103.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 2036, Avg Reward: 1.514, Episode Reward: 3082.2
    æ£€æµ‹è¿›åº¦: 2/37 (5.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(416,3152)'), ('usv_1', '(206,3975)'), ('usv_2', '(206,5059)')]...
    Recent rewards sample: {'usv_0': np.float64(1.361809556055067), 'usv_1': np.float64(-7.57443785921294)}
    Episode time: 203.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 12572.4
  Targets Detected: 5/60 (6.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 4.19
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 35, Avg Reward: 2.490, Episode Reward: 87.1
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3130)'), ('usv_1', '(216,4130)'), ('usv_2', '(214,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31273260284930215), 'usv_1': np.float64(-0.5747403918694379)}
    Episode time: 3.5s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.23217182 -0.15869653] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 1035, Avg Reward: 7.260, Episode Reward: 7513.9
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(298,3169)'), ('usv_1', '(327,4089)'), ('usv_2', '(260,5089)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3334403386647362), 'usv_1': np.float64(0.43130723459089326)}
    Episode time: 103.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 2035, Avg Reward: 11.550, Episode Reward: 23503.6
    æ£€æµ‹è¿›åº¦: 6/46 (13.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(369,3219)'), ('usv_1', '(369,3999)'), ('usv_2', '(209,5078)')]...
    Recent rewards sample: {'usv_0': np.float64(2.345015154220064), 'usv_1': np.float64(1.4309075550880896)}
    Episode time: 203.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: 40624.3
  Targets Detected: 9/65 (10.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.54

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 23074.9
Last 10 episodes average detections: 5.0
Best episode reward so far: 54884.2
Best detection count so far: 9
Learning trend: Improving (23074.9 vs 19652.2)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 34, Avg Reward: -3.857, Episode Reward: -131.1
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(217,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7283346785738107), 'usv_1': np.float64(-1.6255228897188885)}
    Episode time: 3.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 1034, Avg Reward: 15.190, Episode Reward: 15706.1
    æ£€æµ‹è¿›åº¦: 5/32 (15.6%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(292,3180)'), ('usv_1', '(302,4087)'), ('usv_2', '(213,5075)')]...
    Recent rewards sample: {'usv_0': np.float64(4.277190194015393), 'usv_1': np.float64(1.3827191849866813)}
    Episode time: 103.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 2034, Avg Reward: 17.494, Episode Reward: 35582.8
    æ£€æµ‹è¿›åº¦: 8/61 (13.1%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(386,3220)'), ('usv_1', '(233,4032)'), ('usv_2', '(201,5064)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2948536335336005), 'usv_1': np.float64(1.3719255826480579)}
    Episode time: 203.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 55393.1
  Targets Detected: 11/97 (9.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.46
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.16847524 -0.15630669] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 33, Avg Reward: 3.534, Episode Reward: 116.6
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3130)'), ('usv_1', '(219,4130)'), ('usv_2', '(214,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2680896622412208), 'usv_1': np.float64(-0.6200435346658549)}
    Episode time: 3.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 1033, Avg Reward: 13.976, Episode Reward: 14437.0
    æ£€æµ‹è¿›åº¦: 4/32 (12.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(290,3151)'), ('usv_1', '(245,4051)'), ('usv_2', '(271,5078)')]...
    Recent rewards sample: {'usv_0': np.float64(4.286722914570012), 'usv_1': np.float64(3.3711542978435887)}
    Episode time: 103.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 2033, Avg Reward: 18.360, Episode Reward: 37325.5
    æ£€æµ‹è¿›åº¦: 5/60 (8.3%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(380,3211)'), ('usv_1', '(202,4001)'), ('usv_2', '(208,5076)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2944035663501), 'usv_1': np.float64(3.373291451483241)}
    Episode time: 203.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 43543.6
  Targets Detected: 7/69 (7.2%)
  Steps: 2485
  Episode Time: 248.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 17.52
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 548, Avg Reward: 15.574, Episode Reward: 8534.8
    æ£€æµ‹è¿›åº¦: 4/21 (19.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3126)'), ('usv_1', '(280,4125)'), ('usv_2', '(250,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2824060235531087), 'usv_1': np.float64(1.3795244877843897)}
    Episode time: 54.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 1548, Avg Reward: 17.005, Episode Reward: 26323.7
    æ£€æµ‹è¿›åº¦: 3/37 (8.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(373,3129)'), ('usv_1', '(353,4059)'), ('usv_2', '(282,5039)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3070036185501257), 'usv_1': np.float64(1.3847670006865598)}
    Episode time: 154.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 33423.2
  Targets Detected: 6/53 (7.5%)
  Steps: 1912
  Episode Time: 191.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 17.48
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.3439321 0.0539661] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 636, Avg Reward: 6.286, Episode Reward: 3997.8
    æ£€æµ‹è¿›åº¦: 4/21 (19.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3146)'), ('usv_1', '(298,4128)'), ('usv_2', '(274,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2846190492648808), 'usv_1': np.float64(0.37423768686346826)}
    Episode time: 63.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 1636, Avg Reward: 17.211, Episode Reward: 28157.6
    æ£€æµ‹è¿›åº¦: 9/59 (15.3%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(338,3204)'), ('usv_1', '(314,4071)'), ('usv_2', '(295,5056)')]...
    Recent rewards sample: {'usv_0': np.float64(4.286109974417639), 'usv_1': np.float64(3.3838260838703658)}
    Episode time: 163.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 36093.0
  Targets Detected: 10/75 (12.0%)
  Steps: 2385
  Episode Time: 238.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.13
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 251, Avg Reward: -3.292, Episode Reward: -826.2
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3132)'), ('usv_1', '(228,4127)'), ('usv_2', '(226,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2675880895169125), 'usv_1': np.float64(-0.6276761391953144)}
    Episode time: 25.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 1251, Avg Reward: 10.147, Episode Reward: 12693.5
    æ£€æµ‹è¿›åº¦: 3/37 (8.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(305,3183)'), ('usv_1', '(272,4058)'), ('usv_2', '(269,5069)')]...
    Recent rewards sample: {'usv_0': np.float64(4.286299607124871), 'usv_1': np.float64(3.3748110564692553)}
    Episode time: 125.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 2251, Avg Reward: 13.901, Episode Reward: 31290.6
    æ£€æµ‹è¿›åº¦: 4/62 (6.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(387,3247)'), ('usv_1', '(218,4018)'), ('usv_2', '(206,5027)')]...
    Recent rewards sample: {'usv_0': np.float64(4.293431006791052), 'usv_1': np.float64(3.3716733197438087)}
    Episode time: 225.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 40815.1
  Targets Detected: 7/75 (5.3%)
  Steps: 2711
  Episode Time: 271.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.06
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.06928506  0.30157329] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 540, Avg Reward: 4.531, Episode Reward: 2446.9
    æ£€æµ‹è¿›åº¦: 1/19 (5.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3154)'), ('usv_1', '(276,4120)'), ('usv_2', '(261,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27451993795884344), 'usv_1': np.float64(-0.6200034685521668)}
    Episode time: 54.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 1540, Avg Reward: 12.242, Episode Reward: 18852.5
    æ£€æµ‹è¿›åº¦: 4/46 (8.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(328,3211)'), ('usv_1', '(378,4088)'), ('usv_2', '(270,5039)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2939915396368877), 'usv_1': np.float64(1.385152523107672)}
    Episode time: 154.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 2540, Avg Reward: 16.134, Episode Reward: 40980.1
    æ£€æµ‹è¿›åº¦: 9/73 (12.3%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(398,3295)'), ('usv_1', '(342,3997)'), ('usv_2', '(204,5007)')]...
    Recent rewards sample: {'usv_0': np.float64(4.301893947235561), 'usv_1': np.float64(3.3819419833171853)}
    Episode time: 254.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 51400.7
  Targets Detected: 10/87 (10.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.13
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 539, Avg Reward: 5.639, Episode Reward: 3039.4
    æ£€æµ‹è¿›åº¦: 1/14 (7.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3130)'), ('usv_1', '(267,4111)'), ('usv_2', '(238,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(1.275150409327963), 'usv_1': np.float64(2.382644805992304)}
    Episode time: 53.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 1539, Avg Reward: 15.822, Episode Reward: 24350.4
    æ£€æµ‹è¿›åº¦: 6/46 (13.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(342,3125)'), ('usv_1', '(319,4043)'), ('usv_2', '(209,5062)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2993953682770116), 'usv_1': np.float64(3.3804128506044524)}
    Episode time: 153.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.1535806  0.20217883] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 2539, Avg Reward: 16.930, Episode Reward: 42985.9
    æ£€æµ‹è¿›åº¦: 7/69 (10.1%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(441,3093)'), ('usv_1', '(245,3988)'), ('usv_2', '(204,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3315120556512974), 'usv_1': np.float64(3.3726464693344917)}
    Episode time: 253.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 56250.7
  Targets Detected: 13/90 (12.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.74
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 538, Avg Reward: 19.912, Episode Reward: 10712.8
    æ£€æµ‹è¿›åº¦: 4/22 (18.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3131)'), ('usv_1', '(248,4119)'), ('usv_2', '(229,5107)')]...
    Recent rewards sample: {'usv_0': np.float64(4.280793753352357), 'usv_1': np.float64(1.3741452262633875)}
    Episode time: 53.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 1538, Avg Reward: 19.227, Episode Reward: 29570.6
    æ£€æµ‹è¿›åº¦: 6/52 (11.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(361,3136)'), ('usv_1', '(290,4044)'), ('usv_2', '(208,5083)')]...
    Recent rewards sample: {'usv_0': np.float64(4.302723582631382), 'usv_1': np.float64(3.3766150048523507)}
    Episode time: 153.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 2538, Avg Reward: 13.200, Episode Reward: 33502.4
    æ£€æµ‹è¿›åº¦: 8/76 (10.5%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(448,3156)'), ('usv_1', '(248,3970)'), ('usv_2', '(200,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(4.323127419034444), 'usv_1': np.float64(1.3794082626040018)}
    Episode time: 253.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 41947.0
  Targets Detected: 9/79 (10.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.98
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 537, Avg Reward: -3.894, Episode Reward: -2091.0
    æ£€æµ‹è¿›åº¦: 0/14 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(249,3139)'), ('usv_1', '(279,4120)'), ('usv_2', '(246,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7197477322256453), 'usv_1': np.float64(-1.6287118806847674)}
    Episode time: 53.7s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.18410675 0.11026706] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Step 100000, Episode Steps: 1537, Avg Reward: 8.123, Episode Reward: 12485.8
    æ£€æµ‹è¿›åº¦: 4/44 (9.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(338,3211)'), ('usv_1', '(366,4051)'), ('usv_2', '(254,5044)')]...
    Recent rewards sample: {'usv_0': np.float64(4.292904829622101), 'usv_1': np.float64(3.3815940805083704)}
    Episode time: 153.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Step 101000, Episode Steps: 2537, Avg Reward: 13.530, Episode Reward: 34324.8
    æ£€æµ‹è¿›åº¦: 8/73 (11.0%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(372,3297)'), ('usv_1', '(359,3959)'), ('usv_2', '(205,5033)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2891081330472876), 'usv_1': np.float64(3.382936753124076)}
    Episode time: 253.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 43991.6
  Targets Detected: 9/87 (9.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.66
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Step 102000, Episode Steps: 536, Avg Reward: 5.087, Episode Reward: 2726.5
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3132)'), ('usv_1', '(277,4115)'), ('usv_2', '(242,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(2.283212203451008), 'usv_1': np.float64(-0.628814047321624)}
    Episode time: 53.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Step 103000, Episode Steps: 1536, Avg Reward: 8.032, Episode Reward: 12336.6
    æ£€æµ‹è¿›åº¦: 4/37 (10.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(367,3164)'), ('usv_1', '(316,4032)'), ('usv_2', '(205,5090)')]...
    Recent rewards sample: {'usv_0': np.float64(4.298649074307075), 'usv_1': np.float64(-8.622908883339678)}
    Episode time: 153.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Step 104000, Episode Steps: 2536, Avg Reward: 5.424, Episode Reward: 13755.7
    æ£€æµ‹è¿›åº¦: 7/68 (10.3%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(474,3208)'), ('usv_1', '(258,3978)'), ('usv_2', '(200,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(2.318229608010702), 'usv_1': np.float64(-6.618552792961802)}
    Episode time: 253.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 15034.8
  Targets Detected: 10/80 (10.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.01

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 41789.3
Last 10 episodes average detections: 9.2
Best episode reward so far: 56250.7
Best detection count so far: 13
Learning trend: Improving (41789.3 vs 23074.9)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.19375096  0.00645163] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Step 105000, Episode Steps: 535, Avg Reward: 2.202, Episode Reward: 1177.9
    æ£€æµ‹è¿›åº¦: 1/12 (8.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3139)'), ('usv_1', '(268,4114)'), ('usv_2', '(237,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27062028033530894), 'usv_1': np.float64(-0.6248084118548982)}
    Episode time: 53.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Step 106000, Episode Steps: 1535, Avg Reward: 1.898, Episode Reward: 2913.7
    æ£€æµ‹è¿›åº¦: 1/40 (2.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(338,3155)'), ('usv_1', '(330,4032)'), ('usv_2', '(208,5056)')]...
    Recent rewards sample: {'usv_0': np.float64(0.29257682218271963), 'usv_1': np.float64(-0.6207097410680338)}
    Episode time: 153.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Step 107000, Episode Steps: 2535, Avg Reward: 4.977, Episode Reward: 12616.1
    æ£€æµ‹è¿›åº¦: 3/81 (3.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(418,3210)'), ('usv_1', '(288,3943)'), ('usv_2', '(227,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3105046059936347), 'usv_1': np.float64(3.380624800549806)}
    Episode time: 253.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 20189.0
  Targets Detected: 6/95 (5.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 6.73
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Step 108000, Episode Steps: 534, Avg Reward: 5.149, Episode Reward: 2749.5
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3140)'), ('usv_1', '(273,4128)'), ('usv_2', '(236,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(2.27322438420655), 'usv_1': np.float64(-0.6291262142700695)}
    Episode time: 53.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Step 109000, Episode Steps: 1534, Avg Reward: 13.612, Episode Reward: 20881.4
    æ£€æµ‹è¿›åº¦: 3/32 (9.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(342,3201)'), ('usv_1', '(340,4066)'), ('usv_2', '(218,5040)')]...
    Recent rewards sample: {'usv_0': np.float64(2.293354818569023), 'usv_1': np.float64(3.3922695125557327)}
    Episode time: 153.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 33906.0
  Targets Detected: 5/56 (7.1%)
  Steps: 2289
  Episode Time: 228.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.81
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.31755923 0.03707471] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Step 110000, Episode Steps: 245, Avg Reward: 5.889, Episode Reward: 1442.8
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3131)'), ('usv_1', '(226,4126)'), ('usv_2', '(233,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2739036058463261), 'usv_1': np.float64(-0.631737881674644)}
    Episode time: 24.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Step 111000, Episode Steps: 1245, Avg Reward: 9.173, Episode Reward: 11420.2
    æ£€æµ‹è¿›åº¦: 3/34 (8.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(335,3134)'), ('usv_1', '(232,4061)'), ('usv_2', '(241,5066)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3001044415491068), 'usv_1': np.float64(1.3738066349995597)}
    Episode time: 124.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Step 112000, Episode Steps: 2245, Avg Reward: 14.594, Episode Reward: 32764.5
    æ£€æµ‹è¿›åº¦: 5/61 (8.2%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(432,3112)'), ('usv_1', '(200,4042)'), ('usv_2', '(205,5044)')]...
    Recent rewards sample: {'usv_0': np.float64(4.324431464146237), 'usv_1': np.float64(1.373639902515055)}
    Episode time: 224.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 33102.5
  Targets Detected: 7/81 (3.7%)
  Steps: 2856
  Episode Time: 285.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 11.59
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Step 113000, Episode Steps: 389, Avg Reward: -3.905, Episode Reward: -1519.1
    æ£€æµ‹è¿›åº¦: 0/18 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(249,3130)'), ('usv_1', '(251,4125)'), ('usv_2', '(248,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.722756807364276), 'usv_1': np.float64(-1.6237135184679239)}
    Episode time: 38.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Step 114000, Episode Steps: 1389, Avg Reward: 3.145, Episode Reward: 4367.8
    æ£€æµ‹è¿›åº¦: 3/39 (7.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(359,3145)'), ('usv_1', '(341,4075)'), ('usv_2', '(243,5043)')]...
    Recent rewards sample: {'usv_0': np.float64(2.309978101363773), 'usv_1': np.float64(3.3855316517342633)}
    Episode time: 138.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.17976912 -0.01190481] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Step 115000, Episode Steps: 2389, Avg Reward: 4.315, Episode Reward: 10309.6
    æ£€æµ‹è¿›åº¦: 6/78 (7.7%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(436,3189)'), ('usv_1', '(389,3987)'), ('usv_2', '(202,5022)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3148618075888026), 'usv_1': np.float64(-6.61831332563186)}
    Episode time: 238.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 15244.7
  Targets Detected: 8/90 (6.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.08
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Step 116000, Episode Steps: 388, Avg Reward: -3.906, Episode Reward: -1515.6
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3135)'), ('usv_1', '(256,4126)'), ('usv_2', '(249,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7225045624755556), 'usv_1': np.float64(-1.6157923363952544)}
    Episode time: 38.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Step 117000, Episode Steps: 1388, Avg Reward: 0.727, Episode Reward: 1008.6
    æ£€æµ‹è¿›åº¦: 4/29 (13.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(331,3150)'), ('usv_1', '(327,4084)'), ('usv_2', '(249,5044)')]...
    Recent rewards sample: {'usv_0': np.float64(1.296982289867373), 'usv_1': np.float64(2.378242306496021)}
    Episode time: 138.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Step 118000, Episode Steps: 2388, Avg Reward: 8.530, Episode Reward: 20370.1
    æ£€æµ‹è¿›åº¦: 4/48 (8.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(372,3233)'), ('usv_1', '(274,4015)'), ('usv_2', '(205,5076)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2946753471583006), 'usv_1': np.float64(3.3765257185926156)}
    Episode time: 238.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 34731.1
  Targets Detected: 7/71 (8.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.57
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Step 119000, Episode Steps: 387, Avg Reward: 22.057, Episode Reward: 8536.2
    æ£€æµ‹è¿›åº¦: 5/19 (26.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3131)'), ('usv_1', '(248,4121)'), ('usv_2', '(234,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(4.271673058070047), 'usv_1': np.float64(3.3721890411273776)}
    Episode time: 38.7s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.38834391 0.09735982] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Step 120000, Episode Steps: 1387, Avg Reward: 22.868, Episode Reward: 31718.1
    æ£€æµ‹è¿›åº¦: 7/43 (16.3%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(339,3148)'), ('usv_1', '(335,4043)'), ('usv_2', '(205,5060)')]...
    Recent rewards sample: {'usv_0': np.float64(4.307255953660742), 'usv_1': np.float64(3.3854945979203492)}
    Episode time: 138.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Step 121000, Episode Steps: 2387, Avg Reward: 21.116, Episode Reward: 50404.3
    æ£€æµ‹è¿›åº¦: 12/68 (17.6%), Episode total: 14
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(440,3146)'), ('usv_1', '(324,3936)'), ('usv_2', '(202,5077)')]...
    Recent rewards sample: {'usv_0': np.float64(2.321978276179151), 'usv_1': np.float64(-6.621166873560732)}
    Episode time: 238.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 50565.0
  Targets Detected: 14/86 (14.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.85
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Step 122000, Episode Steps: 386, Avg Reward: 0.555, Episode Reward: 214.2
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3133)'), ('usv_1', '(250,4129)'), ('usv_2', '(241,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2799789259435086), 'usv_1': np.float64(-0.6182180284299847)}
    Episode time: 38.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Step 123000, Episode Steps: 1386, Avg Reward: 6.781, Episode Reward: 9398.0
    æ£€æµ‹è¿›åº¦: 3/32 (9.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(344,3151)'), ('usv_1', '(340,4053)'), ('usv_2', '(255,5068)')]...
    Recent rewards sample: {'usv_0': np.float64(2.303312570757218), 'usv_1': np.float64(3.3765892810567264)}
    Episode time: 138.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Step 124000, Episode Steps: 2386, Avg Reward: 7.536, Episode Reward: 17980.6
    æ£€æµ‹è¿›åº¦: 9/69 (13.0%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(463,3159)'), ('usv_1', '(300,3955)'), ('usv_2', '(205,5049)')]...
    Recent rewards sample: {'usv_0': np.float64(4.324487599547486), 'usv_1': np.float64(-8.618926983773326)}
    Episode time: 238.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 19807.6
  Targets Detected: 11/83 (10.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 6.60
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.03805631 0.21958607] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Step 125000, Episode Steps: 385, Avg Reward: -2.774, Episode Reward: -1068.0
    æ£€æµ‹è¿›åº¦: 1/16 (6.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3132)'), ('usv_1', '(253,4124)'), ('usv_2', '(248,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(2.274244152026707), 'usv_1': np.float64(-0.6297072302111473)}
    Episode time: 38.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Step 126000, Episode Steps: 1385, Avg Reward: 11.811, Episode Reward: 16358.4
    æ£€æµ‹è¿›åº¦: 5/42 (11.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(330,3162)'), ('usv_1', '(328,4057)'), ('usv_2', '(262,5078)')]...
    Recent rewards sample: {'usv_0': np.float64(4.291459855151556), 'usv_1': np.float64(1.388063217386053)}
    Episode time: 138.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Step 127000, Episode Steps: 2385, Avg Reward: 12.858, Episode Reward: 30665.4
    æ£€æµ‹è¿›åº¦: 5/68 (7.4%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(381,3243)'), ('usv_1', '(277,3990)'), ('usv_2', '(201,5068)')]...
    Recent rewards sample: {'usv_0': np.float64(4.293301749589151), 'usv_1': np.float64(-8.626270579193822)}
    Episode time: 238.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 31102.9
  Targets Detected: 7/85 (5.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.36
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Step 128000, Episode Steps: 384, Avg Reward: -3.340, Episode Reward: -1282.6
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3131)'), ('usv_1', '(241,4120)'), ('usv_2', '(237,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7198793641602168), 'usv_1': np.float64(-1.6271027799701403)}
    Episode time: 38.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Step 129000, Episode Steps: 1384, Avg Reward: 10.914, Episode Reward: 15105.3
    æ£€æµ‹è¿›åº¦: 3/37 (8.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(342,3152)'), ('usv_1', '(236,4036)'), ('usv_2', '(256,5053)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2999979456463886), 'usv_1': np.float64(3.3770401635562477)}
    Episode time: 138.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 25587.2
  Targets Detected: 5/48 (8.3%)
  Steps: 1881
  Episode Time: 188.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.60
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.0516561 -0.2706354] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Step 130000, Episode Steps: 503, Avg Reward: 5.587, Episode Reward: 2810.2
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3133)'), ('usv_1', '(277,4118)'), ('usv_2', '(238,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(1.276844323111645), 'usv_1': np.float64(2.373141976337827)}
    Episode time: 50.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Step 131000, Episode Steps: 1503, Avg Reward: 8.343, Episode Reward: 12540.1
    æ£€æµ‹è¿›åº¦: 2/44 (4.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(340,3124)'), ('usv_1', '(285,4023)'), ('usv_2', '(209,5060)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3061746506162126), 'usv_1': np.float64(2.384500344289633)}
    Episode time: 150.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 11881.3
  Targets Detected: 3/52 (3.8%)
  Steps: 2002
  Episode Time: 200.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 5.93

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 27611.7
Last 10 episodes average detections: 7.3
Best episode reward so far: 56250.7
Best detection count so far: 14
Learning trend: Declining (27611.7 vs 41789.3)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 56250.7
Final 10 episodes average: 27611.7
Best detection performance: 14 targets
Average detections (final 10): 7.3
============================================================
{"final_avg_reward": 27611.729781295457, "final_detection_rate": 7.3, "best_episode_reward": 56250.65628255833, "best_detection_count": 14, "total_episodes": 50}
Simulation finished.
