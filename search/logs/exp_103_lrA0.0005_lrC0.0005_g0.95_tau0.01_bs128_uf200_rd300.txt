D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: 2.900, Episode Reward: 2900.0
    æ£€æµ‹è¿›åº¦: 2/14 (14.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3134)'), ('usv_1', '(217,4143)'), ('usv_2', '(227,5095)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3800564979967307), 'usv_1': np.float64(0.46661611618075227)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 11.497, Episode Reward: 22994.0
    æ£€æµ‹è¿›åº¦: 3/36 (8.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(327,3159)'), ('usv_1', '(218,4128)'), ('usv_2', '(202,5106)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3947959534306116), 'usv_1': np.float64(3.4666472847893868)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 32179.7
  Targets Detected: 4/39 (7.7%)
  Steps: 2490
  Episode Time: 249.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.92
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 510, Avg Reward: -3.329, Episode Reward: -1697.6
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3139)'), ('usv_1', '(224,4137)'), ('usv_2', '(236,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.628209135969881), 'usv_1': np.float64(-1.5328937044849158)}
    Episode time: 51.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 1510, Avg Reward: 0.793, Episode Reward: 1196.8
    æ£€æµ‹è¿›åº¦: 3/25 (12.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(295,3135)'), ('usv_1', '(227,4155)'), ('usv_2', '(227,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3857844553497927), 'usv_1': np.float64(3.4674239402254177)}
    Episode time: 151.0s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.07255938 0.01789174] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 2510, Avg Reward: 7.228, Episode Reward: 18142.2
    æ£€æµ‹è¿›åº¦: 4/38 (10.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(345,3135)'), ('usv_1', '(209,4163)'), ('usv_2', '(212,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(2.4018446094004924), 'usv_1': np.float64(3.4661878017135965)}
    Episode time: 251.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 27213.7
  Targets Detected: 5/42 (9.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.07
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 509, Avg Reward: 20.243, Episode Reward: 10303.6
    æ£€æµ‹è¿›åº¦: 3/14 (21.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3123)'), ('usv_1', '(222,4130)'), ('usv_2', '(233,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3743294355674265), 'usv_1': np.float64(3.4669779582580746)}
    Episode time: 50.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 1509, Avg Reward: 19.895, Episode Reward: 30021.0
    æ£€æµ‹è¿›åº¦: 3/30 (10.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(309,3110)'), ('usv_1', '(236,4140)'), ('usv_2', '(252,5062)')]...
    Recent rewards sample: {'usv_0': np.float64(4.4004620614390575), 'usv_1': np.float64(3.468049321536503)}
    Episode time: 150.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 2509, Avg Reward: 22.089, Episode Reward: 55421.7
    æ£€æµ‹è¿›åº¦: 6/46 (13.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(366,3108)'), ('usv_1', '(226,4148)'), ('usv_2', '(211,5042)')]...
    Recent rewards sample: {'usv_0': np.float64(4.408388086736224), 'usv_1': np.float64(3.467278682976234)}
    Episode time: 250.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 66665.1
  Targets Detected: 7/50 (12.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 22.21
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 508, Avg Reward: 8.454, Episode Reward: 4294.6
    æ£€æµ‹è¿›åº¦: 2/11 (18.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3132)'), ('usv_1', '(221,4135)'), ('usv_2', '(228,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3737132877666807), 'usv_1': np.float64(0.4668807640154957)}
    Episode time: 50.8s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.13706221 -0.05864575] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 1508, Avg Reward: 13.509, Episode Reward: 20371.8
    æ£€æµ‹è¿›åº¦: 3/18 (16.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(300,3105)'), ('usv_1', '(221,4143)'), ('usv_2', '(246,5078)')]...
    Recent rewards sample: {'usv_0': np.float64(4.388971860491942), 'usv_1': np.float64(1.4669398548702328)}
    Episode time: 150.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 2508, Avg Reward: 16.197, Episode Reward: 40622.4
    æ£€æµ‹è¿›åº¦: 5/38 (13.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(355,3131)'), ('usv_1', '(242,4148)'), ('usv_2', '(214,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(4.399236699507132), 'usv_1': np.float64(1.471505037517478)}
    Episode time: 250.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 50870.5
  Targets Detected: 6/50 (12.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.95
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 507, Avg Reward: -3.274, Episode Reward: -1659.7
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3137)'), ('usv_1', '(222,4136)'), ('usv_2', '(237,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6321712638075896), 'usv_1': np.float64(-1.532825191637177)}
    Episode time: 50.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 1507, Avg Reward: 1.719, Episode Reward: 2591.2
    æ£€æµ‹è¿›åº¦: 2/27 (7.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(296,3168)'), ('usv_1', '(224,4158)'), ('usv_2', '(248,5073)')]...
    Recent rewards sample: {'usv_0': np.float64(4.382838596327129), 'usv_1': np.float64(1.4679000872387218)}
    Episode time: 150.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 2507, Avg Reward: 11.234, Episode Reward: 28162.8
    æ£€æµ‹è¿›åº¦: 5/41 (12.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(302,3235)'), ('usv_1', '(225,4145)'), ('usv_2', '(210,5053)')]...
    Recent rewards sample: {'usv_0': np.float64(4.378999805030413), 'usv_1': np.float64(3.4672466119221355)}
    Episode time: 250.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 39780.6
  Targets Detected: 7/48 (12.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.26
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.06254189 -0.325941  ] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 506, Avg Reward: 11.462, Episode Reward: 5799.6
    æ£€æµ‹è¿›åº¦: 2/5 (40.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3132)'), ('usv_1', '(220,4132)'), ('usv_2', '(233,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(1.371543293819655), 'usv_1': np.float64(2.4668682230366668)}
    Episode time: 50.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 1506, Avg Reward: 14.876, Episode Reward: 22402.7
    æ£€æµ‹è¿›åº¦: 3/21 (14.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3131)'), ('usv_1', '(232,4145)'), ('usv_2', '(236,5071)')]...
    Recent rewards sample: {'usv_0': np.float64(4.383256788141888), 'usv_1': np.float64(1.4677424905573102)}
    Episode time: 150.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 2506, Avg Reward: 17.330, Episode Reward: 43428.0
    æ£€æµ‹è¿›åº¦: 5/35 (14.3%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(325,3168)'), ('usv_1', '(227,4168)'), ('usv_2', '(205,5056)')]...
    Recent rewards sample: {'usv_0': np.float64(4.386500548085415), 'usv_1': np.float64(3.467567138876734)}
    Episode time: 250.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 55298.7
  Targets Detected: 8/37 (13.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.43
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 505, Avg Reward: 5.956, Episode Reward: 3007.5
    æ£€æµ‹è¿›åº¦: 2/10 (20.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(243,3137)'), ('usv_1', '(226,4133)'), ('usv_2', '(230,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3726206782399006), 'usv_1': np.float64(2.46726394737096)}
    Episode time: 50.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 1505, Avg Reward: 14.117, Episode Reward: 21245.9
    æ£€æµ‹è¿›åº¦: 4/26 (15.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3178)'), ('usv_1', '(225,4157)'), ('usv_2', '(216,5073)')]...
    Recent rewards sample: {'usv_0': np.float64(2.369883435457357), 'usv_1': np.float64(3.4672905535795664)}
    Episode time: 150.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 35153.6
  Targets Detected: 4/31 (12.9%)
  Steps: 2192
  Episode Time: 219.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.04
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.04939087 -0.16619532] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 313, Avg Reward: -3.252, Episode Reward: -1018.0
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3132)'), ('usv_1', '(217,4132)'), ('usv_2', '(224,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6311189502218821), 'usv_1': np.float64(-1.5334468054648647)}
    Episode time: 31.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 1313, Avg Reward: -3.255, Episode Reward: -4273.5
    æ£€æµ‹è¿›åº¦: 0/22 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3184)'), ('usv_1', '(231,4148)'), ('usv_2', '(210,5089)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6345166565966007), 'usv_1': np.float64(-1.532288320804267)}
    Episode time: 131.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 2313, Avg Reward: 3.185, Episode Reward: 7366.3
    æ£€æµ‹è¿›åº¦: 2/35 (5.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3226)'), ('usv_1', '(217,4148)'), ('usv_2', '(237,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3593890981567154), 'usv_1': np.float64(0.46661347581313706)}
    Episode time: 231.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 11609.6
  Targets Detected: 2/43 (4.7%)
  Steps: 2678
  Episode Time: 267.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 4.34
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 635, Avg Reward: -3.281, Episode Reward: -2083.6
    æ£€æµ‹è¿›åº¦: 0/9 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(243,3136)'), ('usv_1', '(221,4143)'), ('usv_2', '(231,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6297255754787698), 'usv_1': np.float64(-1.5327572229546342)}
    Episode time: 63.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 1635, Avg Reward: 7.093, Episode Reward: 11597.2
    æ£€æµ‹è¿›åº¦: 3/27 (11.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3186)'), ('usv_1', '(209,4166)'), ('usv_2', '(209,5085)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3714045091508678), 'usv_1': np.float64(3.4661775859427477)}
    Episode time: 163.5s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.12542206 -0.12075495] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 2635, Avg Reward: 12.664, Episode Reward: 33370.4
    æ£€æµ‹è¿›åº¦: 6/42 (14.3%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,3229)'), ('usv_1', '(204,4150)'), ('usv_2', '(221,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(4.360306842970851), 'usv_1': np.float64(3.466261641529644)}
    Episode time: 263.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 41427.0
  Targets Detected: 7/50 (12.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.80
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 634, Avg Reward: 0.412, Episode Reward: 261.4
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3146)'), ('usv_1', '(217,4137)'), ('usv_2', '(250,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3726103408234437), 'usv_1': np.float64(1.4700476586694635)}
    Episode time: 63.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 1634, Avg Reward: 5.975, Episode Reward: 9762.7
    æ£€æµ‹è¿›åº¦: 2/36 (5.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(318,3158)'), ('usv_1', '(209,4124)'), ('usv_2', '(241,5083)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3860979221839207), 'usv_1': np.float64(3.4679607021674856)}
    Episode time: 163.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 2634, Avg Reward: 12.881, Episode Reward: 33927.9
    æ£€æµ‹è¿›åº¦: 5/52 (9.6%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(361,3201)'), ('usv_1', '(218,4107)'), ('usv_2', '(234,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(4.394003811752653), 'usv_1': np.float64(3.4667039111494535)}
    Episode time: 263.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 41696.2
  Targets Detected: 6/56 (8.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.89

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 40189.5
Last 10 episodes average detections: 5.6
Best episode reward so far: 66665.1
Best detection count so far: 8
Buffer size: 28367
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 633, Avg Reward: 3.034, Episode Reward: 1920.8
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(243,3120)'), ('usv_1', '(230,4135)'), ('usv_2', '(235,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32290391869300483), 'usv_1': np.float64(-0.5816775520396825)}
    Episode time: 63.3s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-9.28618143e-02 -6.19725088e-05] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 1633, Avg Reward: 12.061, Episode Reward: 19695.6
    æ£€æµ‹è¿›åº¦: 4/47 (8.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(295,3117)'), ('usv_1', '(227,4161)'), ('usv_2', '(211,5090)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3360828638338615), 'usv_1': np.float64(3.417518671227265)}
    Episode time: 163.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 31714.5
  Targets Detected: 4/56 (7.1%)
  Steps: 2218
  Episode Time: 221.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.30
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 415, Avg Reward: -3.625, Episode Reward: -1504.5
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3140)'), ('usv_1', '(220,4130)'), ('usv_2', '(230,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6740713617293138), 'usv_1': np.float64(-1.583179966605251)}
    Episode time: 41.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 1415, Avg Reward: 0.623, Episode Reward: 882.0
    æ£€æµ‹è¿›åº¦: 0/20 (0.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,3182)'), ('usv_1', '(239,4143)'), ('usv_2', '(233,5066)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31365344929008876), 'usv_1': np.float64(-0.5807283568523649)}
    Episode time: 141.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 6322.7
  Targets Detected: 3/49 (2.0%)
  Steps: 2280
  Episode Time: 228.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 2.77
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 135, Avg Reward: -3.579, Episode Reward: -483.2
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3130)'), ('usv_1', '(215,4132)'), ('usv_2', '(220,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6849909624073761), 'usv_1': np.float64(-1.5835942565258954)}
    Episode time: 13.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 1135, Avg Reward: 4.270, Episode Reward: 4846.8
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3121)'), ('usv_1', '(203,4138)'), ('usv_2', '(223,5089)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33051674973791123), 'usv_1': np.float64(-0.5835013087669099)}
    Episode time: 113.5s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.15325143 0.34047642] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 2135, Avg Reward: 12.566, Episode Reward: 26828.5
    æ£€æµ‹è¿›åº¦: 4/48 (8.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(337,3142)'), ('usv_1', '(210,4119)'), ('usv_2', '(215,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(4.348015428529399), 'usv_1': np.float64(3.416057204844166)}
    Episode time: 213.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 47065.9
  Targets Detected: 5/60 (8.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.68
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 134, Avg Reward: -3.566, Episode Reward: -477.8
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3130)'), ('usv_1', '(213,4130)'), ('usv_2', '(218,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6832996914173651), 'usv_1': np.float64(-1.5837218019244754)}
    Episode time: 13.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 1134, Avg Reward: -0.227, Episode Reward: -257.7
    æ£€æµ‹è¿›åº¦: 3/22 (13.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(304,3139)'), ('usv_1', '(233,4135)'), ('usv_2', '(218,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3409830067423263), 'usv_1': np.float64(-0.5821869645458596)}
    Episode time: 113.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 2134, Avg Reward: 7.409, Episode Reward: 15810.6
    æ£€æµ‹è¿›åº¦: 4/43 (9.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(342,3181)'), ('usv_1', '(243,4154)'), ('usv_2', '(221,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(2.339110205658173), 'usv_1': np.float64(3.424492444446382)}
    Episode time: 213.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 23377.6
  Targets Detected: 4/47 (8.5%)
  Steps: 2592
  Episode Time: 259.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 9.02
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 542, Avg Reward: -1.736, Episode Reward: -941.0
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3134)'), ('usv_1', '(222,4138)'), ('usv_2', '(242,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.326112991797324), 'usv_1': np.float64(-0.5820180001365544)}
    Episode time: 54.2s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.07664973 0.21801304] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 1542, Avg Reward: 1.186, Episode Reward: 1828.9
    æ£€æµ‹è¿›åº¦: 1/36 (2.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(297,3140)'), ('usv_1', '(211,4145)'), ('usv_2', '(248,5091)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3403252162502266), 'usv_1': np.float64(0.4165417855980891)}
    Episode time: 154.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 2542, Avg Reward: 6.566, Episode Reward: 16690.1
    æ£€æµ‹è¿›åº¦: 3/60 (5.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(346,3168)'), ('usv_1', '(228,4132)'), ('usv_2', '(206,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(2.352140515476923), 'usv_1': np.float64(-6.582590695027752)}
    Episode time: 254.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 16192.7
  Targets Detected: 3/70 (4.3%)
  Steps: 2882
  Episode Time: 288.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 5.62
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 660, Avg Reward: 2.122, Episode Reward: 1400.8
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3139)'), ('usv_1', '(223,4140)'), ('usv_2', '(240,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3269424655462986), 'usv_1': np.float64(-0.5829788766024182)}
    Episode time: 66.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 1660, Avg Reward: 3.941, Episode Reward: 6542.8
    æ£€æµ‹è¿›åº¦: 3/39 (7.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3172)'), ('usv_1', '(213,4142)'), ('usv_2', '(204,5093)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3270095059059889), 'usv_1': np.float64(-0.5837466791072853)}
    Episode time: 166.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 9286.0
  Targets Detected: 3/44 (6.8%)
  Steps: 2010
  Episode Time: 201.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 4.62
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 650, Avg Reward: -3.606, Episode Reward: -2344.0
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3136)'), ('usv_1', '(217,4136)'), ('usv_2', '(238,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6770193340205406), 'usv_1': np.float64(-1.577462411693684)}
    Episode time: 65.0s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.1167743  -0.12812811] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 1650, Avg Reward: -0.397, Episode Reward: -655.3
    æ£€æµ‹è¿›åº¦: 2/37 (5.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3163)'), ('usv_1', '(205,4150)'), ('usv_2', '(233,5076)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33306901487366514), 'usv_1': np.float64(-0.5842905700098366)}
    Episode time: 165.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 2650, Avg Reward: 5.643, Episode Reward: 14955.1
    æ£€æµ‹è¿›åº¦: 3/62 (4.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(330,3197)'), ('usv_1', '(205,4145)'), ('usv_2', '(205,5077)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3371679279222537), 'usv_1': np.float64(1.4189465277444326)}
    Episode time: 265.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 20003.6
  Targets Detected: 4/65 (4.6%)
  Steps: 2957
  Episode Time: 295.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 6.76
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 693, Avg Reward: -3.922, Episode Reward: -2717.7
    æ£€æµ‹è¿›åº¦: 0/15 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3135)'), ('usv_1', '(219,4136)'), ('usv_2', '(243,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6724349181648577), 'usv_1': np.float64(-1.5832808507460046)}
    Episode time: 69.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 1693, Avg Reward: 5.301, Episode Reward: 8975.1
    æ£€æµ‹è¿›åº¦: 3/46 (6.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(305,3152)'), ('usv_1', '(230,4155)'), ('usv_2', '(230,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(2.341280983763601), 'usv_1': np.float64(3.417691245193793)}
    Episode time: 169.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 2693, Avg Reward: 5.126, Episode Reward: 13805.1
    æ£€æµ‹è¿›åº¦: 3/68 (4.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(344,3213)'), ('usv_1', '(221,4151)'), ('usv_2', '(261,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(2.341229096640772), 'usv_1': np.float64(3.4169531628124323)}
    Episode time: 269.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 13810.5
  Targets Detected: 3/70 (4.3%)
  Steps: 2720
  Episode Time: 272.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 5.08
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.20368453 -0.07120809] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 973, Avg Reward: -3.582, Episode Reward: -3485.7
    æ£€æµ‹è¿›åº¦: 0/28 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3167)'), ('usv_1', '(228,4144)'), ('usv_2', '(240,5090)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6778066670868117), 'usv_1': np.float64(-1.5815491273948972)}
    Episode time: 97.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 1973, Avg Reward: 2.163, Episode Reward: 4267.8
    æ£€æµ‹è¿›åº¦: 3/54 (5.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3211)'), ('usv_1', '(214,4141)'), ('usv_2', '(210,5091)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3181301875546083), 'usv_1': np.float64(3.416941725625234)}
    Episode time: 197.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 2973, Avg Reward: 8.727, Episode Reward: 25944.8
    æ£€æµ‹è¿›åº¦: 6/78 (7.7%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3265)'), ('usv_1', '(226,4127)'), ('usv_2', '(247,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(2.307434484553064), 'usv_1': np.float64(3.41729742132481)}
    Episode time: 297.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 26860.3
  Targets Detected: 7/80 (8.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.95
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 972, Avg Reward: -3.200, Episode Reward: -3110.9
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3136)'), ('usv_1', '(218,4143)'), ('usv_2', '(234,5092)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6656463719820895), 'usv_1': np.float64(-1.583331930238317)}
    Episode time: 97.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 1972, Avg Reward: 4.991, Episode Reward: 9842.0
    æ£€æµ‹è¿›åº¦: 3/35 (8.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(314,3165)'), ('usv_1', '(201,4135)'), ('usv_2', '(209,5069)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3360272998174154), 'usv_1': np.float64(0.41537799068819115)}
    Episode time: 197.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 14294.4
  Targets Detected: 3/42 (7.1%)
  Steps: 2350
  Episode Time: 235.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 6.08

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 20892.8
Last 10 episodes average detections: 3.9
Best episode reward so far: 66665.1
Best detection count so far: 8
Learning trend: Declining (20892.8 vs 40189.5)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.08052743 -0.06826999] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 622, Avg Reward: -3.600, Episode Reward: -2239.3
    æ£€æµ‹è¿›åº¦: 0/22 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3128)'), ('usv_1', '(216,4139)'), ('usv_2', '(248,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6736680156517323), 'usv_1': np.float64(-1.583487165907524)}
    Episode time: 62.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 1622, Avg Reward: -1.269, Episode Reward: -2057.6
    æ£€æµ‹è¿›åº¦: 0/38 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(294,3144)'), ('usv_1', '(207,4155)'), ('usv_2', '(206,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3329377849316232), 'usv_1': np.float64(-0.5841109326708129)}
    Episode time: 162.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: -1624.1
  Targets Detected: 0/39 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -0.90
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 821, Avg Reward: 10.716, Episode Reward: 8797.7
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3136)'), ('usv_1', '(230,4147)'), ('usv_2', '(232,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3326618015134724), 'usv_1': np.float64(0.42364240434805733)}
    Episode time: 82.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 1821, Avg Reward: 13.554, Episode Reward: 24681.0
    æ£€æµ‹è¿›åº¦: 4/28 (14.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3189)'), ('usv_1', '(223,4163)'), ('usv_2', '(205,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(2.332009000565021), 'usv_1': np.float64(1.4172149862430814)}
    Episode time: 182.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 2821, Avg Reward: 15.769, Episode Reward: 44483.2
    æ£€æµ‹è¿›åº¦: 3/47 (6.4%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(317,3247)'), ('usv_1', '(208,4144)'), ('usv_2', '(229,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(4.329209460881199), 'usv_1': np.float64(1.4158859109930377)}
    Episode time: 282.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 47515.6
  Targets Detected: 5/49 (6.1%)
  Steps: 2970
  Episode Time: 297.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.00
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.16499353  0.26346596] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 851, Avg Reward: -2.868, Episode Reward: -2440.6
    æ£€æµ‹è¿›åº¦: 0/22 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3151)'), ('usv_1', '(216,4134)'), ('usv_2', '(230,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3207089707064681), 'usv_1': np.float64(1.417413021647961)}
    Episode time: 85.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 1851, Avg Reward: 3.462, Episode Reward: 6408.1
    æ£€æµ‹è¿›åº¦: 3/45 (6.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3217)'), ('usv_1', '(205,4144)'), ('usv_2', '(202,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3194735485176712), 'usv_1': np.float64(2.4214835858884953)}
    Episode time: 185.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 2851, Avg Reward: 7.789, Episode Reward: 22206.3
    æ£€æµ‹è¿›åº¦: 4/67 (6.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3257)'), ('usv_1', '(210,4131)'), ('usv_2', '(209,5162)')]...
    Recent rewards sample: {'usv_0': np.float64(4.307393721661011), 'usv_1': np.float64(1.4238939101735322)}
    Episode time: 285.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 24678.5
  Targets Detected: 4/68 (4.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.22
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 850, Avg Reward: -3.174, Episode Reward: -2697.9
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3148)'), ('usv_1', '(231,4129)'), ('usv_2', '(228,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6720177159780277), 'usv_1': np.float64(-1.5823711901311674)}
    Episode time: 85.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 1850, Avg Reward: -2.587, Episode Reward: -4785.6
    æ£€æµ‹è¿›åº¦: 2/43 (4.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3207)'), ('usv_1', '(237,4160)'), ('usv_2', '(206,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3179362798054806), 'usv_1': np.float64(0.4186672250007446)}
    Episode time: 185.0s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.18380704  0.23508709] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 2850, Avg Reward: 5.299, Episode Reward: 15102.0
    æ£€æµ‹è¿›åº¦: 6/81 (7.4%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3243)'), ('usv_1', '(235,4175)'), ('usv_2', '(222,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(4.297747553641744), 'usv_1': np.float64(3.418265810470322)}
    Episode time: 285.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 17900.5
  Targets Detected: 6/81 (7.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.96
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 849, Avg Reward: -3.586, Episode Reward: -3044.1
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3146)'), ('usv_1', '(235,4143)'), ('usv_2', '(251,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6672216967680351), 'usv_1': np.float64(-1.5810512943516928)}
    Episode time: 84.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 1849, Avg Reward: 2.255, Episode Reward: 4168.8
    æ£€æµ‹è¿›åº¦: 2/46 (4.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(307,3183)'), ('usv_1', '(240,4156)'), ('usv_2', '(256,5074)')]...
    Recent rewards sample: {'usv_0': np.float64(2.335420596055256), 'usv_1': np.float64(1.418413994974606)}
    Episode time: 184.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 2849, Avg Reward: 9.173, Episode Reward: 26133.6
    æ£€æµ‹è¿›åº¦: 6/63 (9.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3232)'), ('usv_1', '(244,4176)'), ('usv_2', '(245,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(4.321635898008149), 'usv_1': np.float64(3.4189475975087147)}
    Episode time: 284.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 29229.2
  Targets Detected: 6/73 (8.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.74
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 848, Avg Reward: 8.526, Episode Reward: 7230.2
    æ£€æµ‹è¿›åº¦: 4/21 (19.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3139)'), ('usv_1', '(226,4135)'), ('usv_2', '(245,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3252713370268432), 'usv_1': np.float64(2.417274629851681)}
    Episode time: 84.8s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.05664372 -0.17864108] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 1848, Avg Reward: 12.453, Episode Reward: 23013.0
    æ£€æµ‹è¿›åº¦: 5/45 (11.1%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(319,3140)'), ('usv_1', '(220,4125)'), ('usv_2', '(240,5076)')]...
    Recent rewards sample: {'usv_0': np.float64(2.338676397245692), 'usv_1': np.float64(3.4167931223233055)}
    Episode time: 184.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 2848, Avg Reward: 15.818, Episode Reward: 45049.3
    æ£€æµ‹è¿›åº¦: 7/71 (9.9%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(352,3182)'), ('usv_1', '(218,4133)'), ('usv_2', '(200,5082)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3413302022963123), 'usv_1': np.float64(3.4166158384582026)}
    Episode time: 284.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 48191.4
  Targets Detected: 8/74 (6.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.06
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 847, Avg Reward: -1.104, Episode Reward: -935.2
    æ£€æµ‹è¿›åº¦: 2/22 (9.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3145)'), ('usv_1', '(216,4146)'), ('usv_2', '(240,5103)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32495068740662125), 'usv_1': np.float64(-0.5834770197742722)}
    Episode time: 84.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 1847, Avg Reward: 3.141, Episode Reward: 5800.7
    æ£€æµ‹è¿›åº¦: 3/40 (7.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(283,3200)'), ('usv_1', '(209,4133)'), ('usv_2', '(206,5106)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3281614246028988), 'usv_1': np.float64(0.41594722581844024)}
    Episode time: 184.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 2847, Avg Reward: 7.244, Episode Reward: 20624.0
    æ£€æµ‹è¿›åº¦: 1/68 (1.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3269)'), ('usv_1', '(240,4120)'), ('usv_2', '(219,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3155773471326055), 'usv_1': np.float64(1.4183360844176365)}
    Episode time: 284.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 22864.5
  Targets Detected: 5/76 (1.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.62
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.05201914 -0.30077986] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 846, Avg Reward: -0.609, Episode Reward: -514.8
    æ£€æµ‹è¿›åº¦: 1/16 (6.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3144)'), ('usv_1', '(218,4138)'), ('usv_2', '(209,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32178589645221434), 'usv_1': np.float64(-0.5823226073193838)}
    Episode time: 84.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 1846, Avg Reward: 6.577, Episode Reward: 12142.1
    æ£€æµ‹è¿›åº¦: 1/35 (2.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(294,3194)'), ('usv_1', '(212,4123)'), ('usv_2', '(204,5097)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3284188758266064), 'usv_1': np.float64(2.4192081033508086)}
    Episode time: 184.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 13893.4
  Targets Detected: 2/37 (2.7%)
  Steps: 1964
  Episode Time: 196.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.07
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 882, Avg Reward: 10.573, Episode Reward: 9325.0
    æ£€æµ‹è¿›åº¦: 4/17 (23.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3123)'), ('usv_1', '(228,4139)'), ('usv_2', '(222,5109)')]...
    Recent rewards sample: {'usv_0': np.float64(4.328775742816285), 'usv_1': np.float64(3.420389396941154)}
    Episode time: 88.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 1882, Avg Reward: 18.713, Episode Reward: 35218.6
    æ£€æµ‹è¿›åº¦: 10/41 (24.4%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(330,3128)'), ('usv_1', '(212,4151)'), ('usv_2', '(203,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(4.347682632478527), 'usv_1': np.float64(3.4163044338231154)}
    Episode time: 188.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 2882, Avg Reward: 21.109, Episode Reward: 60836.2
    æ£€æµ‹è¿›åº¦: 14/59 (23.7%), Episode total: 14
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(367,3185)'), ('usv_1', '(207,4134)'), ('usv_2', '(237,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(4.344765531760648), 'usv_1': np.float64(3.4157923678887006)}
    Episode time: 288.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 63506.4
  Targets Detected: 14/60 (23.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.16
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.10642426 0.19786259] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 881, Avg Reward: -3.585, Episode Reward: -3158.3
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3157)'), ('usv_1', '(229,4143)'), ('usv_2', '(238,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6768804851747683), 'usv_1': np.float64(-1.5774686343955282)}
    Episode time: 88.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 1881, Avg Reward: 7.637, Episode Reward: 14364.4
    æ£€æµ‹è¿›åº¦: 4/36 (11.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3214)'), ('usv_1', '(223,4161)'), ('usv_2', '(205,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(4.316744660200592), 'usv_1': np.float64(3.4171627817575745)}
    Episode time: 188.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 2881, Avg Reward: 12.895, Episode Reward: 37150.5
    æ£€æµ‹è¿›åº¦: 8/54 (14.8%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3268)'), ('usv_1', '(209,4158)'), ('usv_2', '(235,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(4.306004981171957), 'usv_1': np.float64(3.4189194525746904)}
    Episode time: 288.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: 39843.5
  Targets Detected: 9/60 (13.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.28

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 30599.9
Last 10 episodes average detections: 5.9
Best episode reward so far: 66665.1
Best detection count so far: 14
Learning trend: Improving (30599.9 vs 20892.8)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 880, Avg Reward: 8.309, Episode Reward: 7311.8
    æ£€æµ‹è¿›åº¦: 2/30 (6.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3127)'), ('usv_1', '(228,4131)'), ('usv_2', '(222,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(3.276237621821883), 'usv_1': np.float64(0.36743773612066866)}
    Episode time: 88.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 18330.4
  Targets Detected: 2/51 (3.9%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_136s
  Average Reward/Step: 10.18
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 79, Avg Reward: -3.909, Episode Reward: -308.8
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(212,4130)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7365535132152232), 'usv_1': np.float64(-1.6337732662748583)}
    Episode time: 7.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.24795642  0.04425012] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 1079, Avg Reward: -1.441, Episode Reward: -1554.6
    æ£€æµ‹è¿›åº¦: 1/23 (4.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3142)'), ('usv_1', '(230,4143)'), ('usv_2', '(242,5070)')]...
    Recent rewards sample: {'usv_0': np.float64(2.274365633882095), 'usv_1': np.float64(-0.6324272936829765)}
    Episode time: 107.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 2079, Avg Reward: 5.351, Episode Reward: 11125.1
    æ£€æµ‹è¿›åº¦: 3/58 (5.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3183)'), ('usv_1', '(225,4176)'), ('usv_2', '(200,5086)')]...
    Recent rewards sample: {'usv_0': np.float64(4.271807257103172), 'usv_1': np.float64(1.371704231761151)}
    Episode time: 207.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 29653.9
  Targets Detected: 6/86 (4.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.88
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 78, Avg Reward: -3.911, Episode Reward: -305.0
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3130)'), ('usv_1', '(213,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7277685947462429), 'usv_1': np.float64(-1.6337504765112527)}
    Episode time: 7.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 1078, Avg Reward: 14.842, Episode Reward: 15999.7
    æ£€æµ‹è¿›åº¦: 5/56 (8.9%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3138)'), ('usv_1', '(211,4147)'), ('usv_2', '(237,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(2.282133198381828), 'usv_1': np.float64(1.366160697676433)}
    Episode time: 107.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 2078, Avg Reward: 17.782, Episode Reward: 36950.7
    æ£€æµ‹è¿›åº¦: 7/76 (9.2%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(329,3157)'), ('usv_1', '(216,4136)'), ('usv_2', '(208,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2921775243756115), 'usv_1': np.float64(3.366463462977322)}
    Episode time: 207.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 46164.6
  Targets Detected: 9/81 (8.6%)
  Steps: 2536
  Episode Time: 253.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.20
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.22203193 -0.16783578] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 542, Avg Reward: 1.314, Episode Reward: 712.4
    æ£€æµ‹è¿›åº¦: 1/20 (5.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(249,3152)'), ('usv_1', '(226,4129)'), ('usv_2', '(241,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26920775185696266), 'usv_1': np.float64(1.3736510789520864)}
    Episode time: 54.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 1542, Avg Reward: 13.217, Episode Reward: 20379.9
    æ£€æµ‹è¿›åº¦: 4/57 (7.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3184)'), ('usv_1', '(217,4140)'), ('usv_2', '(220,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(4.276278687526038), 'usv_1': np.float64(3.366624173358016)}
    Episode time: 154.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 2542, Avg Reward: 16.445, Episode Reward: 41803.2
    æ£€æµ‹è¿›åº¦: 4/71 (5.6%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(324,3232)'), ('usv_1', '(221,4125)'), ('usv_2', '(231,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2779837205181885), 'usv_1': np.float64(3.366888351872621)}
    Episode time: 254.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 49042.1
  Targets Detected: 7/87 (5.7%)
  Steps: 2826
  Episode Time: 282.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 17.35
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 716, Avg Reward: -3.057, Episode Reward: -2188.8
    æ£€æµ‹è¿›åº¦: 1/26 (3.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3143)'), ('usv_1', '(214,4145)'), ('usv_2', '(238,5107)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27774222760841805), 'usv_1': np.float64(-0.6336196301267002)}
    Episode time: 71.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 1716, Avg Reward: 12.115, Episode Reward: 20789.8
    æ£€æµ‹è¿›åº¦: 6/51 (11.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(311,3177)'), ('usv_1', '(206,4144)'), ('usv_2', '(201,5079)')]...
    Recent rewards sample: {'usv_0': np.float64(4.292028748789672), 'usv_1': np.float64(3.3657324492266785)}
    Episode time: 171.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 14595.2
  Targets Detected: 7/63 (7.9%)
  Steps: 2391
  Episode Time: 239.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 6.10
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.04253711 0.21049168] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 325, Avg Reward: -3.764, Episode Reward: -1223.4
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3132)'), ('usv_1', '(217,4130)'), ('usv_2', '(230,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26706405501344777), 'usv_1': np.float64(-0.6334237453180769)}
    Episode time: 32.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 1325, Avg Reward: 13.407, Episode Reward: 17764.3
    æ£€æµ‹è¿›åº¦: 4/32 (12.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3138)'), ('usv_1', '(226,4149)'), ('usv_2', '(236,5073)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2900119578524234), 'usv_1': np.float64(3.367328912717193)}
    Episode time: 132.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 2325, Avg Reward: 18.574, Episode Reward: 43184.9
    æ£€æµ‹è¿›åº¦: 8/70 (11.4%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(351,3152)'), ('usv_1', '(209,4145)'), ('usv_2', '(206,5080)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3021546725358744), 'usv_1': np.float64(3.367632038636062)}
    Episode time: 232.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 57520.5
  Targets Detected: 13/88 (10.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.17
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 324, Avg Reward: 7.451, Episode Reward: 2414.1
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3129)'), ('usv_1', '(214,4131)'), ('usv_2', '(230,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(3.26777446274642), 'usv_1': np.float64(1.366350441257778)}
    Episode time: 32.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 1324, Avg Reward: 18.491, Episode Reward: 24482.2
    æ£€æµ‹è¿›åº¦: 7/40 (17.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3142)'), ('usv_1', '(203,4143)'), ('usv_2', '(225,5079)')]...
    Recent rewards sample: {'usv_0': np.float64(4.284349514898093), 'usv_1': np.float64(1.3658091878548273)}
    Episode time: 132.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.25737247  0.24634294] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Step 100000, Episode Steps: 2324, Avg Reward: 17.876, Episode Reward: 41543.1
    æ£€æµ‹è¿›åº¦: 9/65 (13.8%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(317,3188)'), ('usv_1', '(202,4122)'), ('usv_2', '(207,5105)')]...
    Recent rewards sample: {'usv_0': np.float64(4.281807608353839), 'usv_1': np.float64(1.36640863975695)}
    Episode time: 232.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 45582.9
  Targets Detected: 11/84 (13.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.19
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Step 101000, Episode Steps: 323, Avg Reward: -3.933, Episode Reward: -1270.5
    æ£€æµ‹è¿›åº¦: 0/14 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3130)'), ('usv_1', '(222,4132)'), ('usv_2', '(226,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7304776339598822), 'usv_1': np.float64(-1.6329284159037414)}
    Episode time: 32.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Step 102000, Episode Steps: 1323, Avg Reward: 3.290, Episode Reward: 4352.6
    æ£€æµ‹è¿›åº¦: 1/43 (2.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3124)'), ('usv_1', '(232,4149)'), ('usv_2', '(210,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2860080619581775), 'usv_1': np.float64(0.36778249697810184)}
    Episode time: 132.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Step 103000, Episode Steps: 2323, Avg Reward: 12.130, Episode Reward: 28177.4
    æ£€æµ‹è¿›åº¦: 8/83 (9.6%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(340,3154)'), ('usv_1', '(221,4147)'), ('usv_2', '(224,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2953420891953895), 'usv_1': np.float64(3.3680394357942713)}
    Episode time: 232.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 42544.1
  Targets Detected: 10/100 (10.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.18
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Step 104000, Episode Steps: 322, Avg Reward: -3.917, Episode Reward: -1261.3
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3131)'), ('usv_1', '(216,4131)'), ('usv_2', '(224,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.732220679550772), 'usv_1': np.float64(-1.6335386769178624)}
    Episode time: 32.2s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.24393938  0.07291724] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Step 105000, Episode Steps: 1322, Avg Reward: 13.714, Episode Reward: 18130.4
    æ£€æµ‹è¿›åº¦: 4/38 (10.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(301,3144)'), ('usv_1', '(210,4146)'), ('usv_2', '(205,5103)')]...
    Recent rewards sample: {'usv_0': np.float64(4.283829908903341), 'usv_1': np.float64(3.3660687468881605)}
    Episode time: 132.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Step 106000, Episode Steps: 2322, Avg Reward: 18.116, Episode Reward: 42064.3
    æ£€æµ‹è¿›åº¦: 7/83 (8.4%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(335,3166)'), ('usv_1', '(207,4136)'), ('usv_2', '(225,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(2.293356244877944), 'usv_1': np.float64(3.365826242673924)}
    Episode time: 232.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 53974.4
  Targets Detected: 10/94 (7.4%)
  Steps: 2927
  Episode Time: 292.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.44
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Step 107000, Episode Steps: 395, Avg Reward: -2.373, Episode Reward: -937.3
    æ£€æµ‹è¿›åº¦: 0/15 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3125)'), ('usv_1', '(222,4132)'), ('usv_2', '(232,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2719547559437735), 'usv_1': np.float64(1.3669185876097014)}
    Episode time: 39.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Step 108000, Episode Steps: 1395, Avg Reward: 12.070, Episode Reward: 16838.1
    æ£€æµ‹è¿›åº¦: 4/40 (10.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3130)'), ('usv_1', '(220,4142)'), ('usv_2', '(214,5096)')]...
    Recent rewards sample: {'usv_0': np.float64(2.283698979060163), 'usv_1': np.float64(3.3668364887108266)}
    Episode time: 139.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Step 109000, Episode Steps: 2395, Avg Reward: 14.597, Episode Reward: 34960.7
    æ£€æµ‹è¿›åº¦: 6/60 (10.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(298,3174)'), ('usv_1', '(208,4127)'), ('usv_2', '(222,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(2.278898162053604), 'usv_1': np.float64(3.3660993041730105)}
    Episode time: 239.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 46611.5
  Targets Detected: 9/75 (8.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.53

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 40402.0
Last 10 episodes average detections: 8.4
Best episode reward so far: 66665.1
Best detection count so far: 14
Learning trend: Improving (40402.0 vs 30599.9)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.00067893 0.36122318] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Step 110000, Episode Steps: 394, Avg Reward: -3.924, Episode Reward: -1545.9
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3132)'), ('usv_1', '(217,4131)'), ('usv_2', '(223,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.732122648032025), 'usv_1': np.float64(-1.633396645319946)}
    Episode time: 39.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Step 111000, Episode Steps: 1394, Avg Reward: 7.548, Episode Reward: 10522.0
    æ£€æµ‹è¿›åº¦: 3/58 (5.2%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(290,3144)'), ('usv_1', '(226,4160)'), ('usv_2', '(214,5080)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2809919680530775), 'usv_1': np.float64(2.3674418881260553)}
    Episode time: 139.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Step 112000, Episode Steps: 2394, Avg Reward: 12.559, Episode Reward: 30065.7
    æ£€æµ‹è¿›åº¦: 7/88 (8.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(343,3167)'), ('usv_1', '(220,4146)'), ('usv_2', '(203,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(4.294927336378432), 'usv_1': np.float64(3.368263358888627)}
    Episode time: 239.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 41968.0
  Targets Detected: 8/113 (7.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.98
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Step 113000, Episode Steps: 393, Avg Reward: 2.691, Episode Reward: 1057.6
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3137)'), ('usv_1', '(217,4135)'), ('usv_2', '(225,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(4.274507953415472), 'usv_1': np.float64(3.369169681994764)}
    Episode time: 39.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Step 114000, Episode Steps: 1393, Avg Reward: 18.232, Episode Reward: 25397.4
    æ£€æµ‹è¿›åº¦: 6/67 (9.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3165)'), ('usv_1', '(211,4162)'), ('usv_2', '(205,5100)')]...
    Recent rewards sample: {'usv_0': np.float64(4.281536683488626), 'usv_1': np.float64(3.3662977176209274)}
    Episode time: 139.3s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.33053055 -0.10612745] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Step 115000, Episode Steps: 2393, Avg Reward: 18.984, Episode Reward: 45428.2
    æ£€æµ‹è¿›åº¦: 7/85 (8.2%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(312,3227)'), ('usv_1', '(204,4152)'), ('usv_2', '(231,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(4.275505669158299), 'usv_1': np.float64(3.3656938996533174)}
    Episode time: 239.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 60271.1
  Targets Detected: 11/96 (9.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.08
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Step 116000, Episode Steps: 392, Avg Reward: -3.919, Episode Reward: -1536.1
    æ£€æµ‹è¿›åº¦: 0/9 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3133)'), ('usv_1', '(222,4133)'), ('usv_2', '(230,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7323998948243686), 'usv_1': np.float64(-1.6330785302016486)}
    Episode time: 39.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Step 117000, Episode Steps: 1392, Avg Reward: 2.523, Episode Reward: 3512.0
    æ£€æµ‹è¿›åº¦: 3/39 (7.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(285,3166)'), ('usv_1', '(206,4149)'), ('usv_2', '(229,5100)')]...
    Recent rewards sample: {'usv_0': np.float64(1.282043077576144), 'usv_1': np.float64(0.3671552089694645)}
    Episode time: 139.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Step 118000, Episode Steps: 2392, Avg Reward: 8.020, Episode Reward: 19183.9
    æ£€æµ‹è¿›åº¦: 4/62 (6.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(291,3213)'), ('usv_1', '(209,4136)'), ('usv_2', '(214,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2719885147699364), 'usv_1': np.float64(1.3659965950343675)}
    Episode time: 239.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 29399.7
  Targets Detected: 6/73 (8.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.80
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Step 119000, Episode Steps: 391, Avg Reward: 10.104, Episode Reward: 3950.7
    æ£€æµ‹è¿›åº¦: 2/8 (25.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3138)'), ('usv_1', '(227,4133)'), ('usv_2', '(231,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2646730948140923), 'usv_1': np.float64(0.372316883654618)}
    Episode time: 39.1s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.0310004   0.02006011] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Step 120000, Episode Steps: 1391, Avg Reward: 16.643, Episode Reward: 23151.0
    æ£€æµ‹è¿›åº¦: 4/34 (11.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3196)'), ('usv_1', '(221,4150)'), ('usv_2', '(239,5083)')]...
    Recent rewards sample: {'usv_0': np.float64(4.269945075112278), 'usv_1': np.float64(1.374974781622607)}
    Episode time: 139.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 35276.0
  Targets Detected: 5/49 (2.0%)
  Steps: 2064
  Episode Time: 206.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 17.09
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Step 121000, Episode Steps: 327, Avg Reward: 6.427, Episode Reward: 2101.6
    æ£€æµ‹è¿›åº¦: 2/7 (28.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3133)'), ('usv_1', '(218,4131)'), ('usv_2', '(231,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2785357382185145), 'usv_1': np.float64(2.3666241974945867)}
    Episode time: 32.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Step 122000, Episode Steps: 1327, Avg Reward: 16.062, Episode Reward: 21314.3
    æ£€æµ‹è¿›åº¦: 6/36 (16.7%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3180)'), ('usv_1', '(205,4137)'), ('usv_2', '(228,5077)')]...
    Recent rewards sample: {'usv_0': np.float64(4.280462869214339), 'usv_1': np.float64(3.365697805996473)}
    Episode time: 132.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Step 123000, Episode Steps: 2327, Avg Reward: 18.320, Episode Reward: 42630.7
    æ£€æµ‹è¿›åº¦: 8/64 (12.5%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(329,3209)'), ('usv_1', '(210,4117)'), ('usv_2', '(207,5065)')]...
    Recent rewards sample: {'usv_0': np.float64(2.282001249170156), 'usv_1': np.float64(3.36704140196344)}
    Episode time: 232.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 56961.3
  Targets Detected: 11/79 (12.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.98
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Step 124000, Episode Steps: 326, Avg Reward: 13.513, Episode Reward: 4405.2
    æ£€æµ‹è¿›åº¦: 2/10 (20.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3137)'), ('usv_1', '(216,4131)'), ('usv_2', '(227,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2649205769091243), 'usv_1': np.float64(0.36652819863989183)}
    Episode time: 32.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.00288971  0.00942773] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Step 125000, Episode Steps: 1326, Avg Reward: 16.736, Episode Reward: 22192.5
    æ£€æµ‹è¿›åº¦: 4/39 (10.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(272,3184)'), ('usv_1', '(211,4138)'), ('usv_2', '(221,5092)')]...
    Recent rewards sample: {'usv_0': np.float64(4.270844520246207), 'usv_1': np.float64(3.3671417940600117)}
    Episode time: 132.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Step 126000, Episode Steps: 2326, Avg Reward: 18.273, Episode Reward: 42503.3
    æ£€æµ‹è¿›åº¦: 5/64 (7.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3216)'), ('usv_1', '(220,4130)'), ('usv_2', '(210,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(4.274550505766207), 'usv_1': np.float64(1.367764849231536)}
    Episode time: 232.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 58745.9
  Targets Detected: 10/80 (11.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.58
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Step 127000, Episode Steps: 325, Avg Reward: 3.960, Episode Reward: 1287.0
    æ£€æµ‹è¿›åº¦: 1/17 (5.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3134)'), ('usv_1', '(218,4132)'), ('usv_2', '(233,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27165208428778453), 'usv_1': np.float64(-0.6333706909087652)}
    Episode time: 32.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Step 128000, Episode Steps: 1325, Avg Reward: 7.737, Episode Reward: 10251.7
    æ£€æµ‹è¿›åº¦: 2/39 (5.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(287,3168)'), ('usv_1', '(219,4150)'), ('usv_2', '(223,5078)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2848722928113636), 'usv_1': np.float64(1.3672111531981113)}
    Episode time: 132.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Step 129000, Episode Steps: 2325, Avg Reward: 14.898, Episode Reward: 34637.2
    æ£€æµ‹è¿›åº¦: 9/76 (11.8%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3227)'), ('usv_1', '(210,4140)'), ('usv_2', '(204,5082)')]...
    Recent rewards sample: {'usv_0': np.float64(4.272925027708366), 'usv_1': np.float64(1.3688670073850089)}
    Episode time: 232.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 49431.1
  Targets Detected: 13/94 (11.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.47
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.22344424 -0.15603014] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Step 130000, Episode Steps: 324, Avg Reward: -3.924, Episode Reward: -1271.5
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3133)'), ('usv_1', '(226,4132)'), ('usv_2', '(235,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7259102333047889), 'usv_1': np.float64(-1.630588929182943)}
    Episode time: 32.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Step 131000, Episode Steps: 1324, Avg Reward: 3.459, Episode Reward: 4580.4
    æ£€æµ‹è¿›åº¦: 3/49 (6.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3159)'), ('usv_1', '(231,4149)'), ('usv_2', '(253,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(4.281638341140618), 'usv_1': np.float64(1.3681393162023383)}
    Episode time: 132.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 132000...
    MADDPG UPDATE finished.
    Step 132000, Episode Steps: 2324, Avg Reward: 10.391, Episode Reward: 24148.2
    æ£€æµ‹è¿›åº¦: 6/68 (8.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(326,3201)'), ('usv_1', '(241,4141)'), ('usv_2', '(224,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(4.291445663583498), 'usv_1': np.float64(1.372571262531796)}
    Episode time: 232.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 28268.2
  Targets Detected: 10/87 (11.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.42
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 133000...
    MADDPG UPDATE finished.
    Step 133000, Episode Steps: 323, Avg Reward: -3.921, Episode Reward: -1266.4
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3130)'), ('usv_1', '(220,4134)'), ('usv_2', '(226,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7320710809943463), 'usv_1': np.float64(-1.631187244229216)}
    Episode time: 32.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 134000...
    MADDPG UPDATE finished.
    Step 134000, Episode Steps: 1323, Avg Reward: -2.235, Episode Reward: -2956.6
    æ£€æµ‹è¿›åº¦: 1/34 (2.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3093)'), ('usv_1', '(207,4148)'), ('usv_2', '(254,5097)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2845632425274004), 'usv_1': np.float64(-0.6341599393019559)}
    Episode time: 132.3s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.27465655 -0.06446739] (agent usv_0)
    MADDPG UPDATING at time_step 135000...
    MADDPG UPDATE finished.
    Step 135000, Episode Steps: 2323, Avg Reward: 2.066, Episode Reward: 4799.3
    æ£€æµ‹è¿›åº¦: 2/59 (3.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(316,3057)'), ('usv_1', '(206,4160)'), ('usv_2', '(231,5053)')]...
    Recent rewards sample: {'usv_0': np.float64(3.8747932015126043), 'usv_1': np.float64(-0.6341324001730673)}
    Episode time: 232.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 9638.5
  Targets Detected: 3/72 (4.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 3.21
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 136000...
    MADDPG UPDATE finished.
    Step 136000, Episode Steps: 322, Avg Reward: -3.918, Episode Reward: -1261.6
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3129)'), ('usv_1', '(217,4132)'), ('usv_2', '(230,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7289128441123829), 'usv_1': np.float64(-1.6334116019092533)}
    Episode time: 32.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 137000...
    MADDPG UPDATE finished.
    Step 137000, Episode Steps: 1322, Avg Reward: 2.878, Episode Reward: 3804.6
    æ£€æµ‹è¿›åº¦: 2/31 (6.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3153)'), ('usv_1', '(209,4144)'), ('usv_2', '(229,5080)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2738231851974775), 'usv_1': np.float64(0.3659731046875099)}
    Episode time: 132.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 138000...
    MADDPG UPDATE finished.
    Step 138000, Episode Steps: 2322, Avg Reward: 8.742, Episode Reward: 20298.6
    æ£€æµ‹è¿›åº¦: 3/54 (5.6%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3193)'), ('usv_1', '(209,4127)'), ('usv_2', '(208,5095)')]...
    Recent rewards sample: {'usv_0': np.float64(4.273583980769274), 'usv_1': np.float64(1.3659442529149883)}
    Episode time: 232.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 26488.6
  Targets Detected: 4/69 (4.3%)
  Steps: 2681
  Episode Time: 268.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 9.88

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 39644.8
Last 10 episodes average detections: 8.1
Best episode reward so far: 66665.1
Best detection count so far: 14
Learning trend: Declining (39644.8 vs 40402.0)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 66665.1
Final 10 episodes average: 39644.8
Best detection performance: 14 targets
Average detections (final 10): 8.1
============================================================
{"final_avg_reward": 39644.84483905627, "final_detection_rate": 8.1, "best_episode_reward": 66665.09079045976, "best_detection_count": 14, "total_episodes": 50}
Simulation finished.
