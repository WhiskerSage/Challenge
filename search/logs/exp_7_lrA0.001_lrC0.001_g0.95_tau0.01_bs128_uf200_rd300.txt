D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: -1.206, Episode Reward: -1205.5
    æ£€æµ‹è¿›åº¦: 2/10 (20.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3118)'), ('usv_1', '(264,4160)'), ('usv_2', '(209,5154)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3811849443108064), 'usv_1': np.float64(-0.5225873612241628)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 3.943, Episode Reward: 7886.6
    æ£€æµ‹è¿›åº¦: 4/35 (11.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(287,3043)'), ('usv_1', '(257,4203)'), ('usv_2', '(202,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(7.972918325031805), 'usv_1': np.float64(1.4707611430086014)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 3000, Avg Reward: 9.970, Episode Reward: 29908.7
    æ£€æµ‹è¿›åº¦: 2/49 (4.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(287,2987)'), ('usv_1', '(206,4187)'), ('usv_2', '(223,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(7.9755046128444), 'usv_1': np.float64(1.4703521454685524)}
    Episode time: 300.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 29929.2
  Targets Detected: 4/49 (4.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.97
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 999, Avg Reward: 2.292, Episode Reward: 2290.2
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3084)'), ('usv_1', '(250,4165)'), ('usv_2', '(219,5167)')]...
    Recent rewards sample: {'usv_0': np.float64(4.973940756339975), 'usv_1': np.float64(0.47025496071200545)}
    Episode time: 99.9s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.02545448 -0.04367305] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 1999, Avg Reward: 11.870, Episode Reward: 23728.4
    æ£€æµ‹è¿›åº¦: 4/37 (10.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3015)'), ('usv_1', '(230,4162)'), ('usv_2', '(207,5173)')]...
    Recent rewards sample: {'usv_0': np.float64(5.978289823104824), 'usv_1': np.float64(3.4719947850496364)}
    Episode time: 199.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 45808.3
  Targets Detected: 6/47 (6.4%)
  Steps: 2952
  Episode Time: 295.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.52
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 47, Avg Reward: -2.816, Episode Reward: -132.4
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3130)'), ('usv_1', '(217,4130)'), ('usv_2', '(214,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.636094300762659), 'usv_1': np.float64(-1.5310025050229774)}
    Episode time: 4.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 1047, Avg Reward: 1.357, Episode Reward: 1420.9
    æ£€æµ‹è¿›åº¦: 2/19 (10.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3091)'), ('usv_1', '(238,4158)'), ('usv_2', '(220,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3861880411376224), 'usv_1': np.float64(-0.5296687223031161)}
    Episode time: 104.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 7217.4
  Targets Detected: 2/26 (7.7%)
  Steps: 1921
  Episode Time: 192.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 3.76
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 126, Avg Reward: -3.144, Episode Reward: -396.2
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3129)'), ('usv_1', '(225,4131)'), ('usv_2', '(214,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6353479049547692), 'usv_1': np.float64(-1.5292639948758548)}
    Episode time: 12.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 1126, Avg Reward: 1.562, Episode Reward: 1759.2
    æ£€æµ‹è¿›åº¦: 2/19 (10.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(285,3111)'), ('usv_1', '(227,4168)'), ('usv_2', '(207,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(3.386084489361508), 'usv_1': np.float64(0.47530500384873764)}
    Episode time: 112.6s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.00428272 -0.13053536] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 2126, Avg Reward: 7.141, Episode Reward: 15181.3
    æ£€æµ‹è¿›åº¦: 1/26 (3.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(297,3051)'), ('usv_1', '(205,4153)'), ('usv_2', '(212,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(4.976023824947893), 'usv_1': np.float64(0.4690433103092)}
    Episode time: 212.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 17252.4
  Targets Detected: 3/28 (3.6%)
  Steps: 2294
  Episode Time: 229.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.52
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 832, Avg Reward: 14.789, Episode Reward: 12304.3
    æ£€æµ‹è¿›åº¦: 3/11 (27.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3121)'), ('usv_1', '(244,4160)'), ('usv_2', '(217,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(2.378903945439061), 'usv_1': np.float64(1.4734136773776623)}
    Episode time: 83.2s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 1832, Avg Reward: 16.605, Episode Reward: 30420.2
    æ£€æµ‹è¿›åº¦: 5/25 (20.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(331,3107)'), ('usv_1', '(218,4183)'), ('usv_2', '(208,5154)')]...
    Recent rewards sample: {'usv_0': np.float64(2.398653663672241), 'usv_1': np.float64(1.467122430755328)}
    Episode time: 183.2s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 47725.1
  Targets Detected: 5/29 (13.8%)
  Steps: 2705
  Episode Time: 270.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 17.64
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 127, Avg Reward: -3.147, Episode Reward: -399.7
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3129)'), ('usv_1', '(218,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6340580111768785), 'usv_1': np.float64(-1.533335551123736)}
    Episode time: 12.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 1127, Avg Reward: 14.762, Episode Reward: 16636.3
    æ£€æµ‹è¿›åº¦: 5/27 (18.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(298,3119)'), ('usv_1', '(236,4173)'), ('usv_2', '(216,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3968682196979767), 'usv_1': np.float64(3.474346788906389)}
    Episode time: 112.7s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.09403402 0.08403236] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 2127, Avg Reward: 18.638, Episode Reward: 39644.0
    æ£€æµ‹è¿›åº¦: 5/39 (12.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(336,3072)'), ('usv_1', '(216,4207)'), ('usv_2', '(204,5150)')]...
    Recent rewards sample: {'usv_0': np.float64(7.985089492661212), 'usv_1': np.float64(3.4768617883050927)}
    Episode time: 212.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 64343.5
  Targets Detected: 8/51 (13.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.44
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 126, Avg Reward: -3.158, Episode Reward: -397.9
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3130)'), ('usv_1', '(223,4130)'), ('usv_2', '(219,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6243248951134021), 'usv_1': np.float64(-1.5290323534112031)}
    Episode time: 12.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 1126, Avg Reward: 2.913, Episode Reward: 3280.3
    æ£€æµ‹è¿›åº¦: 1/21 (4.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3113)'), ('usv_1', '(260,4178)'), ('usv_2', '(218,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3890131068010674), 'usv_1': np.float64(0.4701727441023926)}
    Episode time: 112.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 2126, Avg Reward: 6.746, Episode Reward: 14341.0
    æ£€æµ‹è¿›åº¦: 2/31 (6.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(350,3076)'), ('usv_1', '(211,4182)'), ('usv_2', '(210,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(4.979301096081646), 'usv_1': np.float64(2.4735673640225078)}
    Episode time: 212.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 16019.7
  Targets Detected: 2/31 (6.5%)
  Steps: 2328
  Episode Time: 232.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 6.88
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 798, Avg Reward: -3.263, Episode Reward: -2604.2
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3145)'), ('usv_1', '(252,4151)'), ('usv_2', '(224,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6173554853799169), 'usv_1': np.float64(-1.5271992125677398)}
    Episode time: 79.8s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.06512348 -0.20443273] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 1798, Avg Reward: -0.280, Episode Reward: -502.8
    æ£€æµ‹è¿›åº¦: 3/26 (11.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(338,3167)'), ('usv_1', '(237,4179)'), ('usv_2', '(202,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(4.395812773171255), 'usv_1': np.float64(1.4692340678452736)}
    Episode time: 179.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 2798, Avg Reward: 7.109, Episode Reward: 19891.5
    æ£€æµ‹è¿›åº¦: 5/35 (14.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(395,3145)'), ('usv_1', '(252,4144)'), ('usv_2', '(210,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(4.411383812949927), 'usv_1': np.float64(3.4772373875572633)}
    Episode time: 279.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 24035.6
  Targets Detected: 5/43 (11.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.01
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 797, Avg Reward: 14.617, Episode Reward: 11649.5
    æ£€æµ‹è¿›åº¦: 3/13 (23.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3121)'), ('usv_1', '(238,4167)'), ('usv_2', '(209,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3872523798862675), 'usv_1': np.float64(1.4697447346844976)}
    Episode time: 79.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 1797, Avg Reward: 17.495, Episode Reward: 31439.2
    æ£€æµ‹è¿›åº¦: 4/32 (12.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(341,3080)'), ('usv_1', '(204,4185)'), ('usv_2', '(209,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(7.981284838679791), 'usv_1': np.float64(1.466125721099134)}
    Episode time: 179.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 2797, Avg Reward: 20.412, Episode Reward: 57091.9
    æ£€æµ‹è¿›åº¦: 4/43 (9.3%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(328,3003)'), ('usv_1', '(236,4151)'), ('usv_2', '(217,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(7.978876196907228), 'usv_1': np.float64(1.4694080769737488)}
    Episode time: 279.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 61952.8
  Targets Detected: 7/45 (6.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.64
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.11229593 0.15431451] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 796, Avg Reward: 1.943, Episode Reward: 1546.9
    æ£€æµ‹è¿›åº¦: 1/18 (5.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3110)'), ('usv_1', '(244,4160)'), ('usv_2', '(211,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(0.37680568075631937), 'usv_1': np.float64(-0.5227543110877221)}
    Episode time: 79.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 1796, Avg Reward: 8.940, Episode Reward: 16056.3
    æ£€æµ‹è¿›åº¦: 3/35 (8.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3058)'), ('usv_1', '(218,4206)'), ('usv_2', '(209,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(5.97081468997944), 'usv_1': np.float64(1.4676402691473553)}
    Episode time: 179.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 2796, Avg Reward: 14.211, Episode Reward: 39732.6
    æ£€æµ‹è¿›åº¦: 5/55 (9.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3052)'), ('usv_1', '(201,4172)'), ('usv_2', '(222,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(7.972432762282859), 'usv_1': np.float64(3.465675738356877)}
    Episode time: 279.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 44722.1
  Targets Detected: 5/57 (8.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.90

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 35900.6
Last 10 episodes average detections: 4.7
Best episode reward so far: 64343.5
Best detection count so far: 8
Buffer size: 27205
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 795, Avg Reward: 2.980, Episode Reward: 2369.3
    æ£€æµ‹è¿›åº¦: 1/21 (4.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3113)'), ('usv_1', '(232,4151)'), ('usv_2', '(215,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(1.330502537251847), 'usv_1': np.float64(0.4250945984764247)}
    Episode time: 79.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 1795, Avg Reward: 10.083, Episode Reward: 18098.5
    æ£€æµ‹è¿›åº¦: 2/30 (6.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3064)'), ('usv_1', '(203,4184)'), ('usv_2', '(210,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(5.924519869924568), 'usv_1': np.float64(1.4160331299604745)}
    Episode time: 179.5s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.14154231 -0.10813026] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 2795, Avg Reward: 11.992, Episode Reward: 33517.0
    æ£€æµ‹è¿›åº¦: 3/53 (5.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3013)'), ('usv_1', '(216,4159)'), ('usv_2', '(222,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(7.924529632361706), 'usv_1': np.float64(1.4215649855227608)}
    Episode time: 279.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 38123.6
  Targets Detected: 4/55 (3.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.70
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 794, Avg Reward: 10.488, Episode Reward: 8327.2
    æ£€æµ‹è¿›åº¦: 2/39 (5.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3119)'), ('usv_1', '(223,4163)'), ('usv_2', '(227,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(2.325160565626666), 'usv_1': np.float64(3.4222093499117854)}
    Episode time: 79.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 1794, Avg Reward: 15.333, Episode Reward: 27507.8
    æ£€æµ‹è¿›åº¦: 2/71 (2.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3068)'), ('usv_1', '(202,4170)'), ('usv_2', '(215,5160)')]...
    Recent rewards sample: {'usv_0': np.float64(5.918286227313118), 'usv_1': np.float64(3.4156928706845004)}
    Episode time: 179.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 33427.1
  Targets Detected: 4/81 (3.7%)
  Steps: 2049
  Episode Time: 204.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.31
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 745, Avg Reward: -0.900, Episode Reward: -670.4
    æ£€æµ‹è¿›åº¦: 1/18 (5.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3111)'), ('usv_1', '(216,4163)'), ('usv_2', '(229,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33797814174876717), 'usv_1': np.float64(-0.5832864643160962)}
    Episode time: 74.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 1745, Avg Reward: 6.664, Episode Reward: 11628.8
    æ£€æµ‹è¿›åº¦: 2/47 (4.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(303,3038)'), ('usv_1', '(205,4148)'), ('usv_2', '(205,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(4.9285724380168325), 'usv_1': np.float64(0.4229797800665247)}
    Episode time: 174.5s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.04647747 -0.04753577] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 2745, Avg Reward: 11.650, Episode Reward: 31980.0
    æ£€æµ‹è¿›åº¦: 6/61 (9.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(323,2972)'), ('usv_1', '(217,4112)'), ('usv_2', '(215,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(5.930203219529215), 'usv_1': np.float64(1.4203124705126458)}
    Episode time: 274.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 37623.2
  Targets Detected: 6/70 (7.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.54
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 744, Avg Reward: 5.486, Episode Reward: 4081.5
    æ£€æµ‹è¿›åº¦: 1/21 (4.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3099)'), ('usv_1', '(243,4154)'), ('usv_2', '(219,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3349093493774833), 'usv_1': np.float64(2.4186659195583835)}
    Episode time: 74.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 1744, Avg Reward: 10.619, Episode Reward: 18519.3
    æ£€æµ‹è¿›åº¦: 1/42 (2.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3038)'), ('usv_1', '(220,4162)'), ('usv_2', '(205,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(4.922223977669524), 'usv_1': np.float64(2.4233168088273085)}
    Episode time: 174.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 22092.3
  Targets Detected: 2/44 (2.3%)
  Steps: 1999
  Episode Time: 199.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 11.05
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 745, Avg Reward: 12.963, Episode Reward: 9657.6
    æ£€æµ‹è¿›åº¦: 3/13 (23.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3096)'), ('usv_1', '(241,4155)'), ('usv_2', '(237,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(2.325146208372547), 'usv_1': np.float64(1.4184865945116973)}
    Episode time: 74.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 1745, Avg Reward: 17.351, Episode Reward: 30278.1
    æ£€æµ‹è¿›åº¦: 4/36 (11.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3020)'), ('usv_1', '(202,4186)'), ('usv_2', '(212,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(5.925038830375578), 'usv_1': np.float64(1.422028812299962)}
    Episode time: 174.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 43716.2
  Targets Detected: 4/47 (8.5%)
  Steps: 2416
  Episode Time: 241.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.09
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.02739901 -0.04264032] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 329, Avg Reward: 15.066, Episode Reward: 4956.6
    æ£€æµ‹è¿›åº¦: 2/9 (22.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3127)'), ('usv_1', '(231,4134)'), ('usv_2', '(219,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3198591396750263), 'usv_1': np.float64(0.42737629444951386)}
    Episode time: 32.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 1329, Avg Reward: 14.841, Episode Reward: 19724.1
    æ£€æµ‹è¿›åº¦: 5/30 (16.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3064)'), ('usv_1', '(241,4176)'), ('usv_2', '(212,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(7.936416845868738), 'usv_1': np.float64(1.4187503910000836)}
    Episode time: 132.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 2329, Avg Reward: 17.945, Episode Reward: 41794.4
    æ£€æµ‹è¿›åº¦: 4/44 (9.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3008)'), ('usv_1', '(203,4166)'), ('usv_2', '(228,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(7.930424045597665), 'usv_1': np.float64(3.4157086158911287)}
    Episode time: 232.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 46978.1
  Targets Detected: 6/47 (10.6%)
  Steps: 2496
  Episode Time: 249.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.82
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 833, Avg Reward: -3.590, Episode Reward: -2990.2
    æ£€æµ‹è¿›åº¦: 0/16 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3121)'), ('usv_1', '(219,4161)'), ('usv_2', '(208,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.671397195809041), 'usv_1': np.float64(-1.5764282364948405)}
    Episode time: 83.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 1833, Avg Reward: -0.639, Episode Reward: -1171.3
    æ£€æµ‹è¿›åº¦: 1/33 (3.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3077)'), ('usv_1', '(204,4162)'), ('usv_2', '(203,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9198761725518754), 'usv_1': np.float64(1.4204867498275182)}
    Episode time: 183.3s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.023441   -0.00794301] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 2833, Avg Reward: 0.775, Episode Reward: 2196.1
    æ£€æµ‹è¿›åº¦: 2/56 (3.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,3083)'), ('usv_1', '(209,4122)'), ('usv_2', '(221,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(4.91588142596107), 'usv_1': np.float64(0.4159830842651351)}
    Episode time: 283.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 4406.4
  Targets Detected: 2/63 (3.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 1.47
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 832, Avg Reward: 5.325, Episode Reward: 4430.3
    æ£€æµ‹è¿›åº¦: 2/23 (8.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(287,3114)'), ('usv_1', '(252,4150)'), ('usv_2', '(227,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3343783171689285), 'usv_1': np.float64(0.42237760842156824)}
    Episode time: 83.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 1832, Avg Reward: 9.146, Episode Reward: 16755.1
    æ£€æµ‹è¿›åº¦: 1/55 (1.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(287,3059)'), ('usv_1', '(241,4175)'), ('usv_2', '(210,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(6.922604517955878), 'usv_1': np.float64(0.41872062839774626)}
    Episode time: 183.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 17859.3
  Targets Detected: 2/57 (1.8%)
  Steps: 1889
  Episode Time: 188.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 9.45
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 943, Avg Reward: 6.912, Episode Reward: 6517.7
    æ£€æµ‹è¿›åº¦: 2/14 (14.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3093)'), ('usv_1', '(248,4175)'), ('usv_2', '(213,5157)')]...
    Recent rewards sample: {'usv_0': np.float64(1.333034621129059), 'usv_1': np.float64(2.4196401070954607)}
    Episode time: 94.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 17920.5
  Targets Detected: 2/36 (5.6%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_145s
  Average Reward/Step: 9.95
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 142, Avg Reward: -3.573, Episode Reward: -507.4
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3131)'), ('usv_1', '(222,4130)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6843585261909351), 'usv_1': np.float64(-1.582057086743144)}
    Episode time: 14.2s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.10678788 -0.21403319] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 1142, Avg Reward: 5.751, Episode Reward: 6567.9
    æ£€æµ‹è¿›åº¦: 2/33 (6.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3122)'), ('usv_1', '(241,4174)'), ('usv_2', '(222,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(4.332455284199664), 'usv_1': np.float64(1.4186891742004826)}
    Episode time: 114.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 2142, Avg Reward: 13.040, Episode Reward: 27932.1
    æ£€æµ‹è¿›åº¦: 4/64 (6.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3081)'), ('usv_1', '(209,4190)'), ('usv_2', '(225,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(5.921382650953307), 'usv_1': np.float64(1.4184535955505613)}
    Episode time: 214.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 33277.4
  Targets Detected: 6/82 (6.1%)
  Steps: 2390
  Episode Time: 239.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.92

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 29542.4
Last 10 episodes average detections: 3.8
Best episode reward so far: 64343.5
Best detection count so far: 8
Learning trend: Declining (29542.4 vs 35900.6)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 752, Avg Reward: -3.591, Episode Reward: -2700.3
    æ£€æµ‹è¿›åº¦: 0/15 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3138)'), ('usv_1', '(228,4153)'), ('usv_2', '(210,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6708160275644492), 'usv_1': np.float64(-1.5725717692445746)}
    Episode time: 75.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 1752, Avg Reward: -3.599, Episode Reward: -6306.1
    æ£€æµ‹è¿›åº¦: 0/39 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(351,3135)'), ('usv_1', '(205,4190)'), ('usv_2', '(204,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6442636604459815), 'usv_1': np.float64(-1.5809766905650502)}
    Episode time: 175.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: -6480.5
  Targets Detected: 0/42 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.60
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 951, Avg Reward: 14.554, Episode Reward: 13840.7
    æ£€æµ‹è¿›åº¦: 5/22 (22.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3121)'), ('usv_1', '(257,4153)'), ('usv_2', '(225,5152)')]...
    Recent rewards sample: {'usv_0': np.float64(4.343207587057876), 'usv_1': np.float64(1.4246602126587438)}
    Episode time: 95.1s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.22513462 -0.09326531] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 1951, Avg Reward: 18.319, Episode Reward: 35739.4
    æ£€æµ‹è¿›åº¦: 8/45 (17.8%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(364,3090)'), ('usv_1', '(286,4195)'), ('usv_2', '(206,5152)')]...
    Recent rewards sample: {'usv_0': np.float64(4.360718028357646), 'usv_1': np.float64(3.426483247284887)}
    Episode time: 195.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 2951, Avg Reward: 21.288, Episode Reward: 62821.7
    æ£€æµ‹è¿›åº¦: 10/69 (14.5%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(377,3017)'), ('usv_1', '(258,4200)'), ('usv_2', '(208,5162)')]...
    Recent rewards sample: {'usv_0': np.float64(7.934006859911935), 'usv_1': np.float64(1.422290287566752)}
    Episode time: 295.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 64023.8
  Targets Detected: 10/69 (14.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.33
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 950, Avg Reward: 3.740, Episode Reward: 3553.1
    æ£€æµ‹è¿›åº¦: 1/18 (5.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3109)'), ('usv_1', '(217,4175)'), ('usv_2', '(227,5158)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3260500321861324), 'usv_1': np.float64(0.4169006815696179)}
    Episode time: 95.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 1950, Avg Reward: 15.657, Episode Reward: 30532.1
    æ£€æµ‹è¿›åº¦: 7/51 (13.7%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(290,3023)'), ('usv_1', '(204,4181)'), ('usv_2', '(212,5158)')]...
    Recent rewards sample: {'usv_0': np.float64(5.925608042158247), 'usv_1': np.float64(3.4161743580326913)}
    Episode time: 195.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 2950, Avg Reward: 19.201, Episode Reward: 56644.1
    æ£€æµ‹è¿›åº¦: 7/65 (10.8%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,2973)'), ('usv_1', '(252,4172)'), ('usv_2', '(214,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(7.924284865595162), 'usv_1': np.float64(3.420542112451616)}
    Episode time: 295.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 57875.4
  Targets Detected: 10/66 (10.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.29
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.11931003 0.00931958] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 949, Avg Reward: 12.398, Episode Reward: 11765.7
    æ£€æµ‹è¿›åº¦: 3/27 (11.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3120)'), ('usv_1', '(243,4160)'), ('usv_2', '(211,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(4.335120266332975), 'usv_1': np.float64(1.420738842261425)}
    Episode time: 94.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 1949, Avg Reward: 17.410, Episode Reward: 33932.5
    æ£€æµ‹è¿›åº¦: 6/60 (10.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(314,3072)'), ('usv_1', '(209,4163)'), ('usv_2', '(208,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(7.926098279609836), 'usv_1': np.float64(1.417134547495114)}
    Episode time: 194.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 2949, Avg Reward: 19.829, Episode Reward: 58474.9
    æ£€æµ‹è¿›åº¦: 8/90 (8.9%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(297,3002)'), ('usv_1', '(232,4152)'), ('usv_2', '(238,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(7.924701040384407), 'usv_1': np.float64(1.4225580069844623)}
    Episode time: 294.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 59731.9
  Targets Detected: 9/92 (8.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.90
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 948, Avg Reward: 14.280, Episode Reward: 13537.0
    æ£€æµ‹è¿›åº¦: 3/32 (9.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3094)'), ('usv_1', '(241,4168)'), ('usv_2', '(215,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(4.331122474852234), 'usv_1': np.float64(3.41934303102446)}
    Episode time: 94.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 1948, Avg Reward: 19.571, Episode Reward: 38124.1
    æ£€æµ‹è¿›åº¦: 5/63 (7.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3020)'), ('usv_1', '(217,4137)'), ('usv_2', '(201,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(5.92162129003071), 'usv_1': np.float64(3.4283436171253117)}
    Episode time: 194.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 50132.6
  Targets Detected: 5/68 (7.4%)
  Steps: 2487
  Episode Time: 248.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 20.16
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.06069591 -0.12337477] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 461, Avg Reward: 19.126, Episode Reward: 8817.2
    æ£€æµ‹è¿›åº¦: 4/24 (16.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3128)'), ('usv_1', '(229,4143)'), ('usv_2', '(219,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(2.323579752966176), 'usv_1': np.float64(1.4174944315251228)}
    Episode time: 46.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 1461, Avg Reward: 18.561, Episode Reward: 27117.8
    æ£€æµ‹è¿›åº¦: 3/53 (5.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3083)'), ('usv_1', '(212,4197)'), ('usv_2', '(219,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(5.921205336340277), 'usv_1': np.float64(1.4169588027483653)}
    Episode time: 146.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 35306.3
  Targets Detected: 6/59 (6.8%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_140s
  Average Reward/Step: 19.60
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 660, Avg Reward: 4.972, Episode Reward: 3281.6
    æ£€æµ‹è¿›åº¦: 1/13 (7.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3100)'), ('usv_1', '(243,4147)'), ('usv_2', '(233,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3323494205237205), 'usv_1': np.float64(0.4226679249860299)}
    Episode time: 66.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 1660, Avg Reward: 16.164, Episode Reward: 26832.3
    æ£€æµ‹è¿›åº¦: 6/42 (14.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3044)'), ('usv_1', '(222,4199)'), ('usv_2', '(223,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(7.9243207997691325), 'usv_1': np.float64(1.4177925271884866)}
    Episode time: 166.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 2660, Avg Reward: 19.240, Episode Reward: 51179.6
    æ£€æµ‹è¿›åº¦: 6/54 (11.1%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,2977)'), ('usv_1', '(200,4190)'), ('usv_2', '(232,5151)')]...
    Recent rewards sample: {'usv_0': np.float64(5.923495614241398), 'usv_1': np.float64(3.4159543642893375)}
    Episode time: 266.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 60480.1
  Targets Detected: 10/63 (12.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.15
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.00591827  0.01287379] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 659, Avg Reward: -1.021, Episode Reward: -672.8
    æ£€æµ‹è¿›åº¦: 1/12 (8.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3123)'), ('usv_1', '(247,4148)'), ('usv_2', '(223,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3223364672973873), 'usv_1': np.float64(-0.5802504382852888)}
    Episode time: 65.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 1659, Avg Reward: 3.172, Episode Reward: 5261.7
    æ£€æµ‹è¿›åº¦: 1/26 (3.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3061)'), ('usv_1', '(234,4176)'), ('usv_2', '(203,5161)')]...
    Recent rewards sample: {'usv_0': np.float64(4.920884778214253), 'usv_1': np.float64(0.4191977954426691)}
    Episode time: 165.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 7252.3
  Targets Detected: 2/28 (3.6%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_140s
  Average Reward/Step: 4.03
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 858, Avg Reward: 2.679, Episode Reward: 2299.0
    æ£€æµ‹è¿›åº¦: 1/17 (5.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3101)'), ('usv_1', '(241,4146)'), ('usv_2', '(230,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32430090615402707), 'usv_1': np.float64(-0.5815530785427486)}
    Episode time: 85.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 8044.4
  Targets Detected: 1/33 (3.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_168s
  Average Reward/Step: 4.47
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 57, Avg Reward: -3.479, Episode Reward: -198.3
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(216,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6827670249992761), 'usv_1': np.float64(-1.5810593859265243)}
    Episode time: 5.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 1057, Avg Reward: 13.701, Episode Reward: 14481.9
    æ£€æµ‹è¿›åº¦: 8/37 (21.6%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(262,3105)'), ('usv_1', '(221,4152)'), ('usv_2', '(218,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(4.329248309698839), 'usv_1': np.float64(1.4169892016161825)}
    Episode time: 105.7s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.04812482 0.11223683] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 2057, Avg Reward: 17.894, Episode Reward: 36808.6
    æ£€æµ‹è¿›åº¦: 11/51 (21.6%), Episode total: 12
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3051)'), ('usv_1', '(200,4131)'), ('usv_2', '(201,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(5.924162767309212), 'usv_1': np.float64(3.415293588460365)}
    Episode time: 205.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: 56288.8
  Targets Detected: 12/79 (12.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.76

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 39265.5
Last 10 episodes average detections: 6.5
Best episode reward so far: 64343.5
Best detection count so far: 12
Learning trend: Improving (39265.5 vs 29542.4)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 56, Avg Reward: -3.899, Episode Reward: -218.4
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(212,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7367083084356251), 'usv_1': np.float64(-1.6231352630220666)}
    Episode time: 5.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 1056, Avg Reward: 6.816, Episode Reward: 7197.6
    æ£€æµ‹è¿›åº¦: 2/35 (5.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(286,3106)'), ('usv_1', '(239,4162)'), ('usv_2', '(219,5153)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2861403470494537), 'usv_1': np.float64(3.369922821348533)}
    Episode time: 105.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 27443.5
  Targets Detected: 4/56 (1.8%)
  Steps: 2032
  Episode Time: 203.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.51
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 24, Avg Reward: -3.829, Episode Reward: -91.9
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(215,4130)'), ('usv_2', '(214,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7308255088355933), 'usv_1': np.float64(-1.6272798106523745)}
    Episode time: 2.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 1024, Avg Reward: -3.909, Episode Reward: -4002.8
    æ£€æµ‹è¿›åº¦: 0/24 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(286,3092)'), ('usv_1', '(237,4163)'), ('usv_2', '(225,5164)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7081986747161054), 'usv_1': np.float64(-1.6207052304477132)}
    Episode time: 102.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.00791091 -0.10078806] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 2024, Avg Reward: 0.245, Episode Reward: 495.3
    æ£€æµ‹è¿›åº¦: 2/51 (3.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(304,3052)'), ('usv_1', '(209,4182)'), ('usv_2', '(203,5190)')]...
    Recent rewards sample: {'usv_0': np.float64(4.8808291934952335), 'usv_1': np.float64(0.3686774428829003)}
    Episode time: 202.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 12703.8
  Targets Detected: 4/69 (5.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 4.23
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 23, Avg Reward: -4.363, Episode Reward: -100.3
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(212,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7294809057424885), 'usv_1': np.float64(-1.622033315666937)}
    Episode time: 2.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 1023, Avg Reward: 4.772, Episode Reward: 4881.6
    æ£€æµ‹è¿›åº¦: 3/39 (7.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3099)'), ('usv_1', '(227,4160)'), ('usv_2', '(211,5150)')]...
    Recent rewards sample: {'usv_0': np.float64(4.277785689218237), 'usv_1': np.float64(1.3710449584896827)}
    Episode time: 102.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 2023, Avg Reward: 13.442, Episode Reward: 27193.4
    æ£€æµ‹è¿›åº¦: 4/61 (6.6%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3049)'), ('usv_1', '(207,4179)'), ('usv_2', '(212,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(7.87080190159962), 'usv_1': np.float64(1.3736022583458634)}
    Episode time: 202.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 33504.7
  Targets Detected: 8/66 (7.6%)
  Steps: 2244
  Episode Time: 224.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.93
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 779, Avg Reward: 13.549, Episode Reward: 10554.3
    æ£€æµ‹è¿›åº¦: 3/24 (12.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3114)'), ('usv_1', '(221,4159)'), ('usv_2', '(222,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(4.284109352879988), 'usv_1': np.float64(1.367001227788125)}
    Episode time: 77.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.14491418  0.30913616] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 1779, Avg Reward: 16.259, Episode Reward: 28925.4
    æ£€æµ‹è¿›åº¦: 3/44 (6.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(296,3065)'), ('usv_1', '(208,4144)'), ('usv_2', '(207,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(5.873505393457766), 'usv_1': np.float64(1.3712227349611674)}
    Episode time: 177.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 29358.8
  Targets Detected: 5/45 (6.7%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_124s
  Average Reward/Step: 16.30
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 978, Avg Reward: -1.028, Episode Reward: -1005.3
    æ£€æµ‹è¿›åº¦: 1/26 (3.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(284,3109)'), ('usv_1', '(248,4152)'), ('usv_2', '(232,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(0.28707655170110924), 'usv_1': np.float64(-0.6279722295131642)}
    Episode time: 97.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 1978, Avg Reward: 4.532, Episode Reward: 8965.0
    æ£€æµ‹è¿›åº¦: 3/49 (6.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(283,3033)'), ('usv_1', '(249,4201)'), ('usv_2', '(207,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(5.872830197681886), 'usv_1': np.float64(1.3766041092212329)}
    Episode time: 197.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 2978, Avg Reward: 11.084, Episode Reward: 33009.2
    æ£€æµ‹è¿›åº¦: 5/74 (6.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,2982)'), ('usv_1', '(204,4234)'), ('usv_2', '(217,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(7.879061208988086), 'usv_1': np.float64(3.367463304686982)}
    Episode time: 297.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 33554.4
  Targets Detected: 6/74 (6.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.18
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 977, Avg Reward: -1.635, Episode Reward: -1597.4
    æ£€æµ‹è¿›åº¦: 2/20 (10.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3111)'), ('usv_1', '(253,4165)'), ('usv_2', '(226,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2838199427066961), 'usv_1': np.float64(-0.6243631903382896)}
    Episode time: 97.7s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.0148543   0.03556767] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 1977, Avg Reward: 5.845, Episode Reward: 11554.9
    æ£€æµ‹è¿›åº¦: 5/46 (10.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,3071)'), ('usv_1', '(225,4200)'), ('usv_2', '(205,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8661390316685464), 'usv_1': np.float64(3.368034505270992)}
    Episode time: 197.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 2977, Avg Reward: 12.806, Episode Reward: 38124.4
    æ£€æµ‹è¿›åº¦: 9/78 (11.5%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3128)'), ('usv_1', '(230,4167)'), ('usv_2', '(204,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(4.264355804699455), 'usv_1': np.float64(3.37574445475674)}
    Episode time: 297.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 38663.3
  Targets Detected: 9/80 (11.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.88
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 976, Avg Reward: 5.280, Episode Reward: 5153.6
    æ£€æµ‹è¿›åº¦: 2/26 (7.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3083)'), ('usv_1', '(245,4159)'), ('usv_2', '(210,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(4.87683706675484), 'usv_1': np.float64(0.370809118561783)}
    Episode time: 97.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 1976, Avg Reward: 12.827, Episode Reward: 25345.6
    æ£€æµ‹è¿›åº¦: 4/59 (6.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3020)'), ('usv_1', '(203,4195)'), ('usv_2', '(221,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(5.87947613547154), 'usv_1': np.float64(1.370583579213724)}
    Episode time: 197.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 2976, Avg Reward: 17.012, Episode Reward: 50628.2
    æ£€æµ‹è¿›åº¦: 6/88 (6.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,2967)'), ('usv_1', '(214,4142)'), ('usv_2', '(249,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(5.869865364148763), 'usv_1': np.float64(3.3772821600005694)}
    Episode time: 297.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 51224.0
  Targets Detected: 7/88 (6.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.07
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.25471754 -0.61415187] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 975, Avg Reward: 6.002, Episode Reward: 5852.2
    æ£€æµ‹è¿›åº¦: 3/37 (8.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3098)'), ('usv_1', '(226,4164)'), ('usv_2', '(218,5151)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2853582561737804), 'usv_1': np.float64(2.3674331367637675)}
    Episode time: 97.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 1975, Avg Reward: 14.810, Episode Reward: 29250.7
    æ£€æµ‹è¿›åº¦: 5/60 (8.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3012)'), ('usv_1', '(206,4160)'), ('usv_2', '(210,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(7.875507048239232), 'usv_1': np.float64(3.369327399478556)}
    Episode time: 197.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 39962.6
  Targets Detected: 6/67 (7.5%)
  Steps: 2426
  Episode Time: 242.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.47
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 549, Avg Reward: -1.229, Episode Reward: -674.9
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3114)'), ('usv_1', '(235,4139)'), ('usv_2', '(218,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27277828458340825), 'usv_1': np.float64(-0.6320166249273924)}
    Episode time: 54.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 1549, Avg Reward: 12.350, Episode Reward: 19129.5
    æ£€æµ‹è¿›åº¦: 6/41 (14.6%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(268,3055)'), ('usv_1', '(212,4176)'), ('usv_2', '(219,5157)')]...
    Recent rewards sample: {'usv_0': np.float64(7.871277864562202), 'usv_1': np.float64(1.3695476994051616)}
    Episode time: 154.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 2549, Avg Reward: 17.553, Episode Reward: 44743.5
    æ£€æµ‹è¿›åº¦: 10/77 (13.0%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,2987)'), ('usv_1', '(210,4144)'), ('usv_2', '(205,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(7.872579913853446), 'usv_1': np.float64(1.3670851391748182)}
    Episode time: 254.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 56588.9
  Targets Detected: 11/91 (11.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.86
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.06717606 0.08680463] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Step 100000, Episode Steps: 548, Avg Reward: 6.396, Episode Reward: 3505.2
    æ£€æµ‹è¿›åº¦: 3/15 (20.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3106)'), ('usv_1', '(239,4158)'), ('usv_2', '(227,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(2.280236435353407), 'usv_1': np.float64(1.373373258057431)}
    Episode time: 54.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Step 101000, Episode Steps: 1548, Avg Reward: 15.696, Episode Reward: 24298.1
    æ£€æµ‹è¿›åº¦: 4/44 (9.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3045)'), ('usv_1', '(227,4206)'), ('usv_2', '(223,5168)')]...
    Recent rewards sample: {'usv_0': np.float64(7.871471946277713), 'usv_1': np.float64(1.3732642541371538)}
    Episode time: 154.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Step 102000, Episode Steps: 2548, Avg Reward: 19.210, Episode Reward: 48946.0
    æ£€æµ‹è¿›åº¦: 4/63 (6.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3000)'), ('usv_1', '(206,4213)'), ('usv_2', '(218,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(7.875031602072378), 'usv_1': np.float64(3.3769500153120156)}
    Episode time: 254.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 52648.5
  Targets Detected: 6/66 (6.1%)
  Steps: 2692
  Episode Time: 269.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 19.56

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 37565.3
Last 10 episodes average detections: 6.6
Best episode reward so far: 64343.5
Best detection count so far: 12
Learning trend: Declining (37565.3 vs 39265.5)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Step 103000, Episode Steps: 856, Avg Reward: 1.282, Episode Reward: 1097.8
    æ£€æµ‹è¿›åº¦: 2/29 (6.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3111)'), ('usv_1', '(223,4150)'), ('usv_2', '(215,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2812081774541104), 'usv_1': np.float64(2.371080251700224)}
    Episode time: 85.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Step 104000, Episode Steps: 1856, Avg Reward: 12.760, Episode Reward: 23682.6
    æ£€æµ‹è¿›åº¦: 7/61 (11.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3042)'), ('usv_1', '(202,4191)'), ('usv_2', '(212,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(7.876419396585481), 'usv_1': np.float64(1.3689390025399315)}
    Episode time: 185.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.13604524 0.08262145] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Step 105000, Episode Steps: 2856, Avg Reward: 17.511, Episode Reward: 50012.3
    æ£€æµ‹è¿›åº¦: 11/98 (11.2%), Episode total: 12
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3010)'), ('usv_1', '(207,4165)'), ('usv_2', '(229,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(7.875097906388226), 'usv_1': np.float64(3.366024083173305)}
    Episode time: 285.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 55262.5
  Targets Detected: 13/101 (10.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.41
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Step 106000, Episode Steps: 855, Avg Reward: 12.294, Episode Reward: 10511.3
    æ£€æµ‹è¿›åº¦: 3/26 (11.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3104)'), ('usv_1', '(251,4151)'), ('usv_2', '(221,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(4.283389067983959), 'usv_1': np.float64(1.3692226603250601)}
    Episode time: 85.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Step 107000, Episode Steps: 1855, Avg Reward: 17.202, Episode Reward: 31909.4
    æ£€æµ‹è¿›åº¦: 4/61 (6.6%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(330,3024)'), ('usv_1', '(215,4166)'), ('usv_2', '(205,5161)')]...
    Recent rewards sample: {'usv_0': np.float64(7.876463983452132), 'usv_1': np.float64(1.367619314233539)}
    Episode time: 185.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Step 108000, Episode Steps: 2855, Avg Reward: 19.769, Episode Reward: 56439.3
    æ£€æµ‹è¿›åº¦: 6/91 (6.6%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(327,2944)'), ('usv_1', '(233,4105)'), ('usv_2', '(216,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(5.880538968011844), 'usv_1': np.float64(3.3678926208078117)}
    Episode time: 285.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 59615.8
  Targets Detected: 7/93 (6.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.87
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Step 109000, Episode Steps: 854, Avg Reward: 13.780, Episode Reward: 11768.1
    æ£€æµ‹è¿›åº¦: 2/19 (10.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(287,3132)'), ('usv_1', '(243,4159)'), ('usv_2', '(233,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2818486229179458), 'usv_1': np.float64(0.36874833543244545)}
    Episode time: 85.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 26199.0
  Targets Detected: 3/46 (2.2%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_170s
  Average Reward/Step: 14.55
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.03023199 -0.34047976] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Step 110000, Episode Steps: 53, Avg Reward: -3.897, Episode Reward: -206.5
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(215,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.736643648250937), 'usv_1': np.float64(-1.6304849513255733)}
    Episode time: 5.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Step 111000, Episode Steps: 1053, Avg Reward: 14.191, Episode Reward: 14943.0
    æ£€æµ‹è¿›åº¦: 5/26 (19.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3082)'), ('usv_1', '(227,4167)'), ('usv_2', '(217,5156)')]...
    Recent rewards sample: {'usv_0': np.float64(5.871183344204185), 'usv_1': np.float64(1.3695033901150104)}
    Episode time: 105.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Step 112000, Episode Steps: 2053, Avg Reward: 19.206, Episode Reward: 39430.9
    æ£€æµ‹è¿›åº¦: 8/54 (14.8%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,3021)'), ('usv_1', '(207,4162)'), ('usv_2', '(202,5177)')]...
    Recent rewards sample: {'usv_0': np.float64(5.870285947557964), 'usv_1': np.float64(3.366019500875389)}
    Episode time: 205.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 63457.5
  Targets Detected: 13/78 (14.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.15
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Step 113000, Episode Steps: 52, Avg Reward: 2.064, Episode Reward: 107.3
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(215,4130)'), ('usv_2', '(216,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2640404736076857), 'usv_1': np.float64(-0.6290521680143715)}
    Episode time: 5.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Step 114000, Episode Steps: 1052, Avg Reward: 17.806, Episode Reward: 18731.6
    æ£€æµ‹è¿›åº¦: 4/37 (10.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3071)'), ('usv_1', '(273,4152)'), ('usv_2', '(237,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(7.871528621231049), 'usv_1': np.float64(1.3719045779698642)}
    Episode time: 105.2s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.19919663 -0.1382812 ] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Step 115000, Episode Steps: 2052, Avg Reward: 21.732, Episode Reward: 44593.9
    æ£€æµ‹è¿›åº¦: 6/64 (9.4%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3012)'), ('usv_1', '(256,4183)'), ('usv_2', '(219,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(7.878104739205204), 'usv_1': np.float64(1.369942385504543)}
    Episode time: 205.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 68203.8
  Targets Detected: 10/78 (9.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 22.73
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Step 116000, Episode Steps: 51, Avg Reward: -3.896, Episode Reward: -198.7
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7358766839231194), 'usv_1': np.float64(-1.632736854787598)}
    Episode time: 5.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Step 117000, Episode Steps: 1051, Avg Reward: 0.110, Episode Reward: 115.4
    æ£€æµ‹è¿›åº¦: 1/43 (2.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3101)'), ('usv_1', '(266,4158)'), ('usv_2', '(234,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(2.28693974718623), 'usv_1': np.float64(-0.618780616047861)}
    Episode time: 105.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Step 118000, Episode Steps: 2051, Avg Reward: 5.800, Episode Reward: 11896.2
    æ£€æµ‹è¿›åº¦: 3/60 (5.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(345,3066)'), ('usv_1', '(240,4170)'), ('usv_2', '(210,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(6.879759851359682), 'usv_1': np.float64(0.37752688402292267)}
    Episode time: 205.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 36312.9
  Targets Detected: 7/77 (7.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.10
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Step 119000, Episode Steps: 50, Avg Reward: -3.892, Episode Reward: -194.6
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(215,4130)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7346052438038353), 'usv_1': np.float64(-1.6317656802173923)}
    Episode time: 5.0s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.0242625  -0.03917385] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Step 120000, Episode Steps: 1050, Avg Reward: 8.615, Episode Reward: 9046.2
    æ£€æµ‹è¿›åº¦: 2/40 (5.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3120)'), ('usv_1', '(243,4158)'), ('usv_2', '(203,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2824402363208507), 'usv_1': np.float64(0.3686911086836895)}
    Episode time: 105.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Step 121000, Episode Steps: 2050, Avg Reward: 12.023, Episode Reward: 24646.9
    æ£€æµ‹è¿›åº¦: 3/71 (4.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(312,3073)'), ('usv_1', '(205,4136)'), ('usv_2', '(216,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(7.876492201390183), 'usv_1': np.float64(3.368572743090189)}
    Episode time: 205.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 48131.2
  Targets Detected: 8/87 (3.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.04
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Step 122000, Episode Steps: 49, Avg Reward: -3.893, Episode Reward: -190.7
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(215,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7366772265430255), 'usv_1': np.float64(-1.6315627677474833)}
    Episode time: 4.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Step 123000, Episode Steps: 1049, Avg Reward: 9.859, Episode Reward: 10342.2
    æ£€æµ‹è¿›åº¦: 4/40 (10.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(296,3113)'), ('usv_1', '(248,4170)'), ('usv_2', '(221,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(2.295463491465026), 'usv_1': np.float64(3.373706564963764)}
    Episode time: 104.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Step 124000, Episode Steps: 2049, Avg Reward: 20.025, Episode Reward: 41031.8
    æ£€æµ‹è¿›åº¦: 12/75 (16.0%), Episode total: 13
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(308,3044)'), ('usv_1', '(205,4211)'), ('usv_2', '(225,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8800735309727115), 'usv_1': np.float64(3.374525537830933)}
    Episode time: 204.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 66579.2
  Targets Detected: 15/96 (13.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 22.19
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.24825046 0.0821285 ] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Step 125000, Episode Steps: 48, Avg Reward: 4.084, Episode Reward: 196.1
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3130)'), ('usv_1', '(215,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2747418601436088), 'usv_1': np.float64(-0.6326137061737103)}
    Episode time: 4.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Step 126000, Episode Steps: 1048, Avg Reward: 17.474, Episode Reward: 18312.8
    æ£€æµ‹è¿›åº¦: 5/29 (17.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3100)'), ('usv_1', '(253,4154)'), ('usv_2', '(230,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(2.280891147282021), 'usv_1': np.float64(1.3694246328258144)}
    Episode time: 104.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Step 127000, Episode Steps: 2048, Avg Reward: 24.553, Episode Reward: 50285.1
    æ£€æµ‹è¿›åº¦: 9/70 (12.9%), Episode total: 12
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3037)'), ('usv_1', '(210,4175)'), ('usv_2', '(223,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(7.870596903084064), 'usv_1': np.float64(3.3683588012155834)}
    Episode time: 204.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 77406.6
  Targets Detected: 15/88 (13.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 25.79
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Step 128000, Episode Steps: 47, Avg Reward: 3.963, Episode Reward: 186.3
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3130)'), ('usv_1', '(213,4130)'), ('usv_2', '(214,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26740042746944315), 'usv_1': np.float64(1.3699380410426305)}
    Episode time: 4.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Step 129000, Episode Steps: 1047, Avg Reward: 19.428, Episode Reward: 20341.6
    æ£€æµ‹è¿›åº¦: 6/43 (14.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3107)'), ('usv_1', '(209,4157)'), ('usv_2', '(212,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(4.285356449525597), 'usv_1': np.float64(3.3661252609902075)}
    Episode time: 104.7s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.26025317  0.14488695] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Step 130000, Episode Steps: 2047, Avg Reward: 21.834, Episode Reward: 44694.9
    æ£€æµ‹è¿›åº¦: 10/85 (11.8%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(344,3066)'), ('usv_1', '(206,4127)'), ('usv_2', '(209,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(7.876743906160116), 'usv_1': np.float64(3.365740545136977)}
    Episode time: 204.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 65828.9
  Targets Detected: 11/105 (9.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.94

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 56699.7
Last 10 episodes average detections: 10.2
Best episode reward so far: 77406.6
Best detection count so far: 15
Learning trend: Improving (56699.7 vs 37565.3)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 77406.6
Final 10 episodes average: 56699.7
Best detection performance: 15 targets
Average detections (final 10): 10.2
============================================================
{"final_avg_reward": 56699.73930750706, "final_detection_rate": 10.2, "best_episode_reward": 77406.56829756695, "best_detection_count": 15, "total_episodes": 50}
Simulation finished.
