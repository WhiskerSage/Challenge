D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: 4.679, Episode Reward: 4679.1
    æ£€æµ‹è¿›åº¦: 1/23 (4.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3131)'), ('usv_1', '(275,4153)'), ('usv_2', '(291,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3781933812084532), 'usv_1': np.float64(0.473107133638516)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 12.250, Episode Reward: 24500.0
    æ£€æµ‹è¿›åº¦: 5/46 (10.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(315,3119)'), ('usv_1', '(322,4173)'), ('usv_2', '(317,5052)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3908634419994175), 'usv_1': np.float64(1.4747934669909224)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 3000, Avg Reward: 14.935, Episode Reward: 44805.7
    æ£€æµ‹è¿›åº¦: 7/59 (11.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(338,3079)'), ('usv_1', '(364,4230)'), ('usv_2', '(300,4997)')]...
    Recent rewards sample: {'usv_0': np.float64(5.9760866222038675), 'usv_1': np.float64(1.4788021970653484)}
    Episode time: 300.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 44826.0
  Targets Detected: 7/59 (11.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.94
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 999, Avg Reward: 9.824, Episode Reward: 9814.6
    æ£€æµ‹è¿›åº¦: 2/22 (9.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3124)'), ('usv_1', '(269,4148)'), ('usv_2', '(265,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(2.385396526169388), 'usv_1': np.float64(1.4766841058832094)}
    Episode time: 99.9s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.1557897  -0.13077119] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 1999, Avg Reward: 14.446, Episode Reward: 28877.6
    æ£€æµ‹è¿›åº¦: 3/37 (8.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(327,3132)'), ('usv_1', '(319,4154)'), ('usv_2', '(288,5067)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3919981967817754), 'usv_1': np.float64(1.4744550465226456)}
    Episode time: 199.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 30617.4
  Targets Detected: 4/37 (8.1%)
  Steps: 2092
  Episode Time: 209.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.64
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 907, Avg Reward: 9.204, Episode Reward: 8347.8
    æ£€æµ‹è¿›åº¦: 1/19 (5.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3108)'), ('usv_1', '(254,4168)'), ('usv_2', '(276,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3747871528298194), 'usv_1': np.float64(1.4764989714158787)}
    Episode time: 90.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 1907, Avg Reward: 15.459, Episode Reward: 29479.4
    æ£€æµ‹è¿›åº¦: 4/37 (10.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3068)'), ('usv_1', '(263,4214)'), ('usv_2', '(338,5075)')]...
    Recent rewards sample: {'usv_0': np.float64(7.978534352806334), 'usv_1': np.float64(3.4710893711405904)}
    Episode time: 190.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 2907, Avg Reward: 17.928, Episode Reward: 52117.7
    æ£€æµ‹è¿›åº¦: 5/63 (7.9%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3024)'), ('usv_1', '(294,4250)'), ('usv_2', '(397,5034)')]...
    Recent rewards sample: {'usv_0': np.float64(7.971578889406946), 'usv_1': np.float64(3.4798540532849813)}
    Episode time: 290.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 54218.9
  Targets Detected: 6/63 (6.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.07
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 906, Avg Reward: 3.601, Episode Reward: 3262.9
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3119)'), ('usv_1', '(254,4149)'), ('usv_2', '(278,5109)')]...
    Recent rewards sample: {'usv_0': np.float64(0.37586389279268184), 'usv_1': np.float64(1.4694633938768407)}
    Episode time: 90.6s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.15020622 -0.1495738 ] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 1906, Avg Reward: 8.133, Episode Reward: 15501.3
    æ£€æµ‹è¿›åº¦: 3/25 (12.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(297,3114)'), ('usv_1', '(266,4193)'), ('usv_2', '(289,5058)')]...
    Recent rewards sample: {'usv_0': np.float64(4.386891351664362), 'usv_1': np.float64(3.4721787566016555)}
    Episode time: 190.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 32076.1
  Targets Detected: 4/33 (9.1%)
  Steps: 2773
  Episode Time: 277.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 11.57
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 133, Avg Reward: 0.012, Episode Reward: 1.6
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(219,4130)'), ('usv_2', '(219,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3630459843596837), 'usv_1': np.float64(-0.5314083051961954)}
    Episode time: 13.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 1133, Avg Reward: 14.551, Episode Reward: 16486.4
    æ£€æµ‹è¿›åº¦: 4/25 (16.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3107)'), ('usv_1', '(272,4136)'), ('usv_2', '(285,5094)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3775568007210937), 'usv_1': np.float64(1.4707974232335217)}
    Episode time: 113.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 33730.6
  Targets Detected: 6/44 (11.4%)
  Steps: 2025
  Episode Time: 202.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.66
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 108, Avg Reward: 11.138, Episode Reward: 1202.9
    æ£€æµ‹è¿›åº¦: 1/1 (100.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3131)'), ('usv_1', '(215,4130)'), ('usv_2', '(215,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.36711828849235695), 'usv_1': np.float64(-0.5335899050423908)}
    Episode time: 10.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 1108, Avg Reward: 4.464, Episode Reward: 4946.4
    æ£€æµ‹è¿›åº¦: 1/5 (20.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3141)'), ('usv_1', '(259,4123)'), ('usv_2', '(278,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(0.379868591788039), 'usv_1': np.float64(-0.5302190994760596)}
    Episode time: 110.8s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.15443547 -0.08224211] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 2108, Avg Reward: 11.716, Episode Reward: 24697.3
    æ£€æµ‹è¿›åº¦: 5/23 (21.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(300,3153)'), ('usv_1', '(303,4083)'), ('usv_2', '(337,5076)')]...
    Recent rewards sample: {'usv_0': np.float64(4.384211912617072), 'usv_1': np.float64(1.48475785909435)}
    Episode time: 210.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 42863.2
  Targets Detected: 6/35 (17.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.28
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 107, Avg Reward: 14.848, Episode Reward: 1588.7
    æ£€æµ‹è¿›åº¦: 1/2 (50.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3130)'), ('usv_1', '(216,4130)'), ('usv_2', '(220,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3675845143428417), 'usv_1': np.float64(1.4665096174002272)}
    Episode time: 10.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 1107, Avg Reward: 10.913, Episode Reward: 12080.2
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3126)'), ('usv_1', '(265,4146)'), ('usv_2', '(282,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3758246570588795), 'usv_1': np.float64(2.470302409189255)}
    Episode time: 110.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 21019.4
  Targets Detected: 2/24 (8.3%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_126s
  Average Reward/Step: 11.67
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 306, Avg Reward: -3.255, Episode Reward: -996.0
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3132)'), ('usv_1', '(232,4136)'), ('usv_2', '(249,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6320272842792298), 'usv_1': np.float64(-1.528811105088062)}
    Episode time: 30.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 1306, Avg Reward: 5.626, Episode Reward: 7347.4
    æ£€æµ‹è¿›åº¦: 3/28 (10.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3137)'), ('usv_1', '(296,4170)'), ('usv_2', '(314,5090)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3818525059345164), 'usv_1': np.float64(2.4808471119617126)}
    Episode time: 130.6s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.21919355 0.31417114] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 2306, Avg Reward: 10.324, Episode Reward: 23807.8
    æ£€æµ‹è¿›åº¦: 3/43 (7.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(315,3108)'), ('usv_1', '(330,4234)'), ('usv_2', '(245,5047)')]...
    Recent rewards sample: {'usv_0': np.float64(4.399317970157659), 'usv_1': np.float64(3.47638879497584)}
    Episode time: 230.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 40157.5
  Targets Detected: 6/54 (7.4%)
  Steps: 2978
  Episode Time: 297.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.48
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 328, Avg Reward: -2.732, Episode Reward: -896.0
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3125)'), ('usv_1', '(234,4132)'), ('usv_2', '(240,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3666271701743443), 'usv_1': np.float64(-0.5321527271238974)}
    Episode time: 32.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 1328, Avg Reward: 7.955, Episode Reward: 10564.4
    æ£€æµ‹è¿›åº¦: 2/20 (10.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3131)'), ('usv_1', '(293,4150)'), ('usv_2', '(280,5062)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3793187039342247), 'usv_1': np.float64(0.4735931204602113)}
    Episode time: 132.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 15630.0
  Targets Detected: 2/26 (3.8%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_133s
  Average Reward/Step: 8.68
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 527, Avg Reward: 1.315, Episode Reward: 692.9
    æ£€æµ‹è¿›åº¦: 1/4 (25.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3138)'), ('usv_1', '(238,4137)'), ('usv_2', '(244,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(0.36714389617634746), 'usv_1': np.float64(-0.5318460151737504)}
    Episode time: 52.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 1527, Avg Reward: 13.094, Episode Reward: 19995.3
    æ£€æµ‹è¿›åº¦: 5/19 (26.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3149)'), ('usv_1', '(298,4200)'), ('usv_2', '(317,5106)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3792416211829766), 'usv_1': np.float64(3.4862099911944835)}
    Episode time: 152.7s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.14209413  0.15854162] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 2527, Avg Reward: 16.641, Episode Reward: 42050.9
    æ£€æµ‹è¿›åº¦: 7/41 (17.1%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(283,3120)'), ('usv_1', '(336,4251)'), ('usv_2', '(352,5040)')]...
    Recent rewards sample: {'usv_0': np.float64(4.382324252752545), 'usv_1': np.float64(3.4772486310870416)}
    Episode time: 252.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 51853.7
  Targets Detected: 8/43 (14.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.28

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 36699.3
Last 10 episodes average detections: 5.1
Best episode reward so far: 54218.9
Best detection count so far: 8
Buffer size: 25474
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 526, Avg Reward: -3.610, Episode Reward: -1899.0
    æ£€æµ‹è¿›åº¦: 0/14 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3136)'), ('usv_1', '(246,4138)'), ('usv_2', '(241,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6834812751291038), 'usv_1': np.float64(-1.5794023193415787)}
    Episode time: 52.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 1526, Avg Reward: -3.605, Episode Reward: -5501.0
    æ£€æµ‹è¿›åº¦: 0/41 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3172)'), ('usv_1', '(298,4174)'), ('usv_2', '(273,5057)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6828086118231825), 'usv_1': np.float64(-1.5769719245653375)}
    Episode time: 152.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 2526, Avg Reward: 4.338, Episode Reward: 10956.8
    æ£€æµ‹è¿›åº¦: 6/63 (9.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(269,3214)'), ('usv_1', '(342,4221)'), ('usv_2', '(232,5011)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3185030424873023), 'usv_1': np.float64(1.4297604369635075)}
    Episode time: 252.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 18842.7
  Targets Detected: 6/67 (9.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 6.28
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 525, Avg Reward: -3.704, Episode Reward: -1944.6
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3129)'), ('usv_1', '(246,4136)'), ('usv_2', '(247,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6818222848541088), 'usv_1': np.float64(-1.5781000234370943)}
    Episode time: 52.5s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.13179947 -0.31296546] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 1525, Avg Reward: 7.780, Episode Reward: 11863.9
    æ£€æµ‹è¿›åº¦: 3/32 (9.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3127)'), ('usv_1', '(309,4145)'), ('usv_2', '(312,5103)')]...
    Recent rewards sample: {'usv_0': np.float64(2.327357206679219), 'usv_1': np.float64(1.424624390507781)}
    Episode time: 152.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 2525, Avg Reward: 12.644, Episode Reward: 31926.6
    æ£€æµ‹è¿›åº¦: 4/49 (8.2%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3078)'), ('usv_1', '(350,4163)'), ('usv_2', '(371,5092)')]...
    Recent rewards sample: {'usv_0': np.float64(5.929032224914998), 'usv_1': np.float64(1.4280462879508686)}
    Episode time: 252.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 41578.7
  Targets Detected: 7/58 (5.2%)
  Steps: 2963
  Episode Time: 296.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.03
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 562, Avg Reward: -3.603, Episode Reward: -2024.6
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3128)'), ('usv_1', '(265,4128)'), ('usv_2', '(236,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6702848886993319), 'usv_1': np.float64(-1.579768105273857)}
    Episode time: 56.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 1562, Avg Reward: 6.035, Episode Reward: 9427.4
    æ£€æµ‹è¿›åº¦: 4/35 (11.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(309,3121)'), ('usv_1', '(305,4116)'), ('usv_2', '(264,5040)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3455347839414755), 'usv_1': np.float64(1.4265656887087315)}
    Episode time: 156.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 2562, Avg Reward: 9.671, Episode Reward: 24777.8
    æ£€æµ‹è¿›åº¦: 6/56 (10.7%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(341,3118)'), ('usv_1', '(362,4123)'), ('usv_2', '(267,4958)')]...
    Recent rewards sample: {'usv_0': np.float64(2.349776114072797), 'usv_1': np.float64(1.4308631101499985)}
    Episode time: 256.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 33388.0
  Targets Detected: 7/69 (10.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.13
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.13931578 -0.24277629] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 561, Avg Reward: 6.529, Episode Reward: 3662.8
    æ£€æµ‹è¿›åº¦: 4/12 (33.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(249,3135)'), ('usv_1', '(245,4127)'), ('usv_2', '(245,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3216385000333943), 'usv_1': np.float64(0.43805602593794957)}
    Episode time: 56.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 1561, Avg Reward: 11.787, Episode Reward: 18399.8
    æ£€æµ‹è¿›åº¦: 6/39 (15.4%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3166)'), ('usv_1', '(320,4118)'), ('usv_2', '(272,5068)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3307911482694568), 'usv_1': np.float64(1.4244422597485134)}
    Episode time: 156.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 2561, Avg Reward: 12.928, Episode Reward: 33109.0
    æ£€æµ‹è¿›åº¦: 4/53 (7.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(303,3218)'), ('usv_1', '(370,4140)'), ('usv_2', '(251,5019)')]...
    Recent rewards sample: {'usv_0': np.float64(2.324494904177378), 'usv_1': np.float64(1.428280547296925)}
    Episode time: 256.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 35638.4
  Targets Detected: 7/54 (9.3%)
  Steps: 2672
  Episode Time: 267.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.34
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 889, Avg Reward: -4.847, Episode Reward: -4308.7
    æ£€æµ‹è¿›åº¦: 0/23 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3125)'), ('usv_1', '(256,4090)'), ('usv_2', '(273,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.666888403787327), 'usv_1': np.float64(-1.5792187883331523)}
    Episode time: 88.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: -9437.7
  Targets Detected: 0/38 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -5.24
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 88, Avg Reward: -4.642, Episode Reward: -408.5
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3130)'), ('usv_1', '(218,4130)'), ('usv_2', '(218,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6773582803394078), 'usv_1': np.float64(-1.574374512281615)}
    Episode time: 8.8s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.07275583 -0.13524919] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 1088, Avg Reward: -3.856, Episode Reward: -4195.7
    æ£€æµ‹è¿›åº¦: 0/19 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3161)'), ('usv_1', '(280,4088)'), ('usv_2', '(292,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32270221212043215), 'usv_1': np.float64(-0.5754136422979441)}
    Episode time: 108.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 2088, Avg Reward: -0.897, Episode Reward: -1872.8
    æ£€æµ‹è¿›åº¦: 1/37 (2.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(295,3176)'), ('usv_1', '(311,4057)'), ('usv_2', '(350,5049)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33010284127913714), 'usv_1': np.float64(-0.5738555447958563)}
    Episode time: 208.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: -1778.2
  Targets Detected: 1/42 (2.4%)
  Steps: 2333
  Episode Time: 233.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: -0.76
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 755, Avg Reward: 5.044, Episode Reward: 3808.3
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3127)'), ('usv_1', '(249,4125)'), ('usv_2', '(264,5105)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3233937620653483), 'usv_1': np.float64(-0.5805690113890029)}
    Episode time: 75.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 1755, Avg Reward: 6.192, Episode Reward: 10867.8
    æ£€æµ‹è¿›åº¦: 2/33 (6.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(291,3114)'), ('usv_1', '(308,4081)'), ('usv_2', '(325,5060)')]...
    Recent rewards sample: {'usv_0': np.float64(1.337455733943926), 'usv_1': np.float64(0.4238134956179769)}
    Episode time: 175.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 2755, Avg Reward: 10.437, Episode Reward: 28754.2
    æ£€æµ‹è¿›åº¦: 5/56 (8.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(316,3066)'), ('usv_1', '(369,4069)'), ('usv_2', '(387,5000)')]...
    Recent rewards sample: {'usv_0': np.float64(7.924613726242274), 'usv_1': np.float64(1.4325861647869318)}
    Episode time: 275.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 34168.9
  Targets Detected: 5/59 (8.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.39
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.25228287  0.06992511] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 754, Avg Reward: -3.787, Episode Reward: -2855.4
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3140)'), ('usv_1', '(267,4143)'), ('usv_2', '(268,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6799338250697549), 'usv_1': np.float64(-1.5732517260139505)}
    Episode time: 75.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 1754, Avg Reward: 1.033, Episode Reward: 1811.5
    æ£€æµ‹è¿›åº¦: 2/36 (5.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3153)'), ('usv_1', '(318,4149)'), ('usv_2', '(315,5080)')]...
    Recent rewards sample: {'usv_0': np.float64(3.327797460092981), 'usv_1': np.float64(0.4266352600050889)}
    Episode time: 175.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 2754, Avg Reward: 6.997, Episode Reward: 19269.6
    æ£€æµ‹è¿›åº¦: 3/60 (5.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(318,3166)'), ('usv_1', '(380,4168)'), ('usv_2', '(360,5031)')]...
    Recent rewards sample: {'usv_0': np.float64(4.335956669075925), 'usv_1': np.float64(1.4354800243105923)}
    Episode time: 275.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 23797.9
  Targets Detected: 4/66 (4.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.93
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 753, Avg Reward: -3.157, Episode Reward: -2377.3
    æ£€æµ‹è¿›åº¦: 1/23 (4.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3128)'), ('usv_1', '(274,4129)'), ('usv_2', '(249,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6807206123754653), 'usv_1': np.float64(-1.5703466350719604)}
    Episode time: 75.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 1753, Avg Reward: 5.128, Episode Reward: 8990.1
    æ£€æµ‹è¿›åº¦: 5/55 (9.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3115)'), ('usv_1', '(344,4145)'), ('usv_2', '(288,5049)')]...
    Recent rewards sample: {'usv_0': np.float64(4.329730081001184), 'usv_1': np.float64(1.4273261409662736)}
    Episode time: 175.3s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.17770617 0.18306983] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 2753, Avg Reward: 10.163, Episode Reward: 27979.4
    æ£€æµ‹è¿›åº¦: 4/81 (4.9%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(302,3085)'), ('usv_1', '(384,4172)'), ('usv_2', '(269,4975)')]...
    Recent rewards sample: {'usv_0': np.float64(7.92634066612826), 'usv_1': np.float64(1.432489387651711)}
    Episode time: 275.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 29430.2
  Targets Detected: 6/82 (4.9%)
  Steps: 2819
  Episode Time: 281.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.44
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 934, Avg Reward: 2.076, Episode Reward: 1938.7
    æ£€æµ‹è¿›åº¦: 3/30 (10.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3125)'), ('usv_1', '(265,4128)'), ('usv_2', '(275,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3218523521570216), 'usv_1': np.float64(0.42960415338510916)}
    Episode time: 93.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 1934, Avg Reward: 9.953, Episode Reward: 19249.2
    æ£€æµ‹è¿›åº¦: 4/42 (9.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3073)'), ('usv_1', '(325,4160)'), ('usv_2', '(344,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(7.919115023403254), 'usv_1': np.float64(1.4365017094608703)}
    Episode time: 193.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 41192.4
  Targets Detected: 5/60 (5.0%)
  Steps: 2931
  Episode Time: 293.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.05

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 24682.1
Last 10 episodes average detections: 4.8
Best episode reward so far: 54218.9
Best detection count so far: 8
Learning trend: Declining (24682.1 vs 36699.3)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 3, Avg Reward: -0.604, Episode Reward: -1.8
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3130)'), ('usv_1', '(211,4130)'), ('usv_2', '(211,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6746870097416665), 'usv_1': np.float64(-1.5707927489099789)}
    Episode time: 0.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 1003, Avg Reward: -3.618, Episode Reward: -3628.7
    æ£€æµ‹è¿›åº¦: 0/25 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3137)'), ('usv_1', '(274,4110)'), ('usv_2', '(289,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6749352268360366), 'usv_1': np.float64(-1.5758362056910136)}
    Episode time: 100.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: -6694.1
  Targets Detected: 0/36 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.72
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.1323874  -0.19325628] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 202, Avg Reward: -3.588, Episode Reward: -724.8
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3131)'), ('usv_1', '(228,4130)'), ('usv_2', '(221,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6810454783978849), 'usv_1': np.float64(-1.5825894331267205)}
    Episode time: 20.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 1202, Avg Reward: -2.995, Episode Reward: -3599.9
    æ£€æµ‹è¿›åº¦: 1/21 (4.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(283,3145)'), ('usv_1', '(284,4147)'), ('usv_2', '(271,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6710866512991157), 'usv_1': np.float64(-1.5782853454096184)}
    Episode time: 120.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 2202, Avg Reward: 4.568, Episode Reward: 10058.5
    æ£€æµ‹è¿›åº¦: 5/41 (12.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(322,3138)'), ('usv_1', '(347,4161)'), ('usv_2', '(257,5035)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3408375295391144), 'usv_1': np.float64(1.4319387693797125)}
    Episode time: 220.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 27539.5
  Targets Detected: 8/57 (12.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.18
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 201, Avg Reward: 6.033, Episode Reward: 1212.5
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3131)'), ('usv_1', '(226,4129)'), ('usv_2', '(226,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3178151684077284), 'usv_1': np.float64(1.4233702532490184)}
    Episode time: 20.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 1201, Avg Reward: 18.898, Episode Reward: 22696.0
    æ£€æµ‹è¿›åº¦: 4/35 (11.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3147)'), ('usv_1', '(293,4146)'), ('usv_2', '(266,5082)')]...
    Recent rewards sample: {'usv_0': np.float64(4.334826530181546), 'usv_1': np.float64(3.4288999188978)}
    Episode time: 120.1s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.38941069  0.04350887] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 2201, Avg Reward: 20.214, Episode Reward: 44490.8
    æ£€æµ‹è¿›åº¦: 5/53 (9.4%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(326,3137)'), ('usv_1', '(330,4191)'), ('usv_2', '(302,5016)')]...
    Recent rewards sample: {'usv_0': np.float64(4.342056502296715), 'usv_1': np.float64(3.430533520392003)}
    Episode time: 220.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 51405.5
  Targets Detected: 5/59 (5.1%)
  Steps: 2539
  Episode Time: 253.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 20.25
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 662, Avg Reward: -3.621, Episode Reward: -2396.9
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3130)'), ('usv_1', '(244,4132)'), ('usv_2', '(253,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6716276977795339), 'usv_1': np.float64(-1.5770771436053204)}
    Episode time: 66.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 1662, Avg Reward: 1.869, Episode Reward: 3105.9
    æ£€æµ‹è¿›åº¦: 2/36 (5.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(286,3119)'), ('usv_1', '(309,4142)'), ('usv_2', '(226,5063)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3344239729878105), 'usv_1': np.float64(0.42453687628569736)}
    Episode time: 166.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 2662, Avg Reward: 8.582, Episode Reward: 22844.9
    æ£€æµ‹è¿›åº¦: 4/57 (7.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(305,3078)'), ('usv_1', '(362,4187)'), ('usv_2', '(201,5020)')]...
    Recent rewards sample: {'usv_0': np.float64(7.926627777081336), 'usv_1': np.float64(1.4299974475201402)}
    Episode time: 266.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 30478.6
  Targets Detected: 5/67 (6.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.16
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 661, Avg Reward: -4.397, Episode Reward: -2906.1
    æ£€æµ‹è¿›åº¦: 0/25 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3132)'), ('usv_1', '(250,4119)'), ('usv_2', '(242,5097)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6764811351855945), 'usv_1': np.float64(-1.5757015795664713)}
    Episode time: 66.1s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.1559289   0.02419928] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 1661, Avg Reward: -3.929, Episode Reward: -6525.4
    æ£€æµ‹è¿›åº¦: 0/41 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3130)'), ('usv_1', '(294,4078)'), ('usv_2', '(237,5022)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33179116310301704), 'usv_1': np.float64(-0.570929454885253)}
    Episode time: 166.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: -6189.4
  Targets Detected: 0/42 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.44
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 860, Avg Reward: -3.222, Episode Reward: -2770.6
    æ£€æµ‹è¿›åº¦: 0/21 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3122)'), ('usv_1', '(253,4164)'), ('usv_2', '(238,5097)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32626923414043274), 'usv_1': np.float64(-0.5805319820808015)}
    Episode time: 86.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 1860, Avg Reward: 6.187, Episode Reward: 11507.4
    æ£€æµ‹è¿›åº¦: 3/43 (7.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(302,3110)'), ('usv_1', '(293,4217)'), ('usv_2', '(236,5033)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3469160801319133), 'usv_1': np.float64(1.4248314512722144)}
    Episode time: 186.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 2860, Avg Reward: 10.934, Episode Reward: 31272.6
    æ£€æµ‹è¿›åº¦: 2/59 (3.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(341,3079)'), ('usv_1', '(349,4236)'), ('usv_2', '(209,4987)')]...
    Recent rewards sample: {'usv_0': np.float64(5.926321334507284), 'usv_1': np.float64(1.4338258834218465)}
    Episode time: 286.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 32332.5
  Targets Detected: 3/59 (3.4%)
  Steps: 2913
  Episode Time: 291.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 11.10
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 947, Avg Reward: 3.899, Episode Reward: 3692.5
    æ£€æµ‹è¿›åº¦: 1/14 (7.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3124)'), ('usv_1', '(264,4147)'), ('usv_2', '(277,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(2.326851704755219), 'usv_1': np.float64(-0.5778183132053093)}
    Episode time: 94.7s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.03029293 0.13207304] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 1947, Avg Reward: 10.843, Episode Reward: 21111.3
    æ£€æµ‹è¿›åº¦: 4/37 (10.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3080)'), ('usv_1', '(316,4189)'), ('usv_2', '(344,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(7.9233834984986045), 'usv_1': np.float64(3.4271066129991814)}
    Episode time: 194.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 2947, Avg Reward: 15.715, Episode Reward: 46312.2
    æ£€æµ‹è¿›åº¦: 7/61 (11.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3027)'), ('usv_1', '(376,4208)'), ('usv_2', '(405,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(7.922514275407545), 'usv_1': np.float64(3.4305652517132765)}
    Episode time: 294.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 47609.5
  Targets Detected: 7/62 (11.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.86
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 946, Avg Reward: -3.688, Episode Reward: -3489.2
    æ£€æµ‹è¿›åº¦: 0/26 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3131)'), ('usv_1', '(263,4131)'), ('usv_2', '(269,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6670586390081247), 'usv_1': np.float64(-1.5789457072810194)}
    Episode time: 94.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 1946, Avg Reward: -1.745, Episode Reward: -3395.8
    æ£€æµ‹è¿›åº¦: 2/42 (4.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(302,3111)'), ('usv_1', '(325,4143)'), ('usv_2', '(316,5041)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3385337300241744), 'usv_1': np.float64(0.4318558731474762)}
    Episode time: 194.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 2946, Avg Reward: 5.490, Episode Reward: 16174.7
    æ£€æµ‹è¿›åº¦: 4/67 (6.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(336,3071)'), ('usv_1', '(369,4176)'), ('usv_2', '(318,4979)')]...
    Recent rewards sample: {'usv_0': np.float64(5.927042926477474), 'usv_1': np.float64(3.4283905038941507)}
    Episode time: 294.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 17380.7
  Targets Detected: 6/69 (5.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.79
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.23610143 0.33030763] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 945, Avg Reward: 1.625, Episode Reward: 1535.6
    æ£€æµ‹è¿›åº¦: 1/28 (3.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3149)'), ('usv_1', '(234,4167)'), ('usv_2', '(248,5107)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3349004513598429), 'usv_1': np.float64(-0.5698790296311845)}
    Episode time: 94.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 1945, Avg Reward: 4.397, Episode Reward: 8551.9
    æ£€æµ‹è¿›åº¦: 2/50 (4.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(294,3181)'), ('usv_1', '(256,4215)'), ('usv_2', '(263,5039)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3269341643602646), 'usv_1': np.float64(0.42061635682764864)}
    Episode time: 194.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 2945, Avg Reward: 9.268, Episode Reward: 27293.5
    æ£€æµ‹è¿›åº¦: 5/64 (7.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3215)'), ('usv_1', '(314,4233)'), ('usv_2', '(225,5023)')]...
    Recent rewards sample: {'usv_0': np.float64(4.317798793310905), 'usv_1': np.float64(1.4252261682719003)}
    Episode time: 294.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 29062.9
  Targets Detected: 7/67 (10.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.68
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 944, Avg Reward: 9.591, Episode Reward: 9053.6
    æ£€æµ‹è¿›åº¦: 3/29 (10.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3119)'), ('usv_1', '(276,4131)'), ('usv_2', '(301,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3247632215355063), 'usv_1': np.float64(1.431174016810917)}
    Episode time: 94.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: 22108.7
  Targets Detected: 3/46 (6.5%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_127s
  Average Reward/Step: 12.28

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 24503.5
Last 10 episodes average detections: 4.4
Best episode reward so far: 54218.9
Best detection count so far: 8
Learning trend: Declining (24503.5 vs 24682.1)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 143, Avg Reward: -3.926, Episode Reward: -561.4
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3129)'), ('usv_1', '(218,4130)'), ('usv_2', '(220,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7361280251399756), 'usv_1': np.float64(-1.6320917551078817)}
    Episode time: 14.3s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.03639526  0.16983451] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 1143, Avg Reward: -0.802, Episode Reward: -916.3
    æ£€æµ‹è¿›åº¦: 2/42 (4.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3133)'), ('usv_1', '(253,4161)'), ('usv_2', '(270,5080)')]...
    Recent rewards sample: {'usv_0': np.float64(3.286880836942663), 'usv_1': np.float64(0.3694365605879466)}
    Episode time: 114.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 2143, Avg Reward: 10.782, Episode Reward: 23106.6
    æ£€æµ‹è¿›åº¦: 6/67 (9.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3177)'), ('usv_1', '(267,4217)'), ('usv_2', '(250,5015)')]...
    Recent rewards sample: {'usv_0': np.float64(4.275852111302522), 'usv_1': np.float64(3.373351757453845)}
    Episode time: 214.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 34425.1
  Targets Detected: 7/78 (7.7%)
  Steps: 2689
  Episode Time: 268.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.80
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 454, Avg Reward: 3.070, Episode Reward: 1393.6
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(240,3132)'), ('usv_1', '(238,4138)'), ('usv_2', '(247,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2704079111928993), 'usv_1': np.float64(-0.63184568295689)}
    Episode time: 45.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 1454, Avg Reward: 13.150, Episode Reward: 19120.2
    æ£€æµ‹è¿›åº¦: 3/43 (7.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3114)'), ('usv_1', '(293,4130)'), ('usv_2', '(322,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(4.28132403661349), 'usv_1': np.float64(1.372529981952194)}
    Episode time: 145.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 2454, Avg Reward: 18.132, Episode Reward: 44496.1
    æ£€æµ‹è¿›åº¦: 7/69 (10.1%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(317,3066)'), ('usv_1', '(330,4093)'), ('usv_2', '(382,5109)')]...
    Recent rewards sample: {'usv_0': np.float64(7.882493423328178), 'usv_1': np.float64(3.375386241411105)}
    Episode time: 245.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 58799.7
  Targets Detected: 10/80 (11.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.59
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.12163099  0.02549585] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 453, Avg Reward: -3.929, Episode Reward: -1779.7
    æ£€æµ‹è¿›åº¦: 0/19 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3130)'), ('usv_1', '(252,4130)'), ('usv_2', '(241,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7318236675017381), 'usv_1': np.float64(-1.6248807424441345)}
    Episode time: 45.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 1453, Avg Reward: 8.051, Episode Reward: 11697.8
    æ£€æµ‹è¿›åº¦: 3/47 (6.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3135)'), ('usv_1', '(314,4143)'), ('usv_2', '(311,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(1.28478695587052), 'usv_1': np.float64(2.375826416431478)}
    Episode time: 145.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 16150.1
  Targets Detected: 3/53 (3.8%)
  Steps: 1821
  Episode Time: 182.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 8.87
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 632, Avg Reward: 5.399, Episode Reward: 3412.1
    æ£€æµ‹è¿›åº¦: 2/20 (10.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3134)'), ('usv_1', '(250,4131)'), ('usv_2', '(261,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2683848767574646), 'usv_1': np.float64(0.3728059537399273)}
    Episode time: 63.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 1632, Avg Reward: 16.871, Episode Reward: 27533.7
    æ£€æµ‹è¿›åº¦: 7/59 (11.9%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3145)'), ('usv_1', '(296,4171)'), ('usv_2', '(344,5106)')]...
    Recent rewards sample: {'usv_0': np.float64(4.280011348834998), 'usv_1': np.float64(3.375850127936306)}
    Episode time: 163.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 49641.0
  Targets Detected: 9/89 (7.9%)
  Steps: 2618
  Episode Time: 261.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.96
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 14, Avg Reward: -3.778, Episode Reward: -52.9
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(213,4130)'), ('usv_2', '(212,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7321578877662861), 'usv_1': np.float64(-1.6217064460692596)}
    Episode time: 1.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.08137293 0.24444272] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 1014, Avg Reward: 15.337, Episode Reward: 15552.2
    æ£€æµ‹è¿›åº¦: 6/35 (17.1%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(243,3097)'), ('usv_1', '(273,4126)'), ('usv_2', '(266,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2785189280645435), 'usv_1': np.float64(3.374636367067991)}
    Episode time: 101.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 2014, Avg Reward: 18.590, Episode Reward: 37440.5
    æ£€æµ‹è¿›åº¦: 7/66 (10.6%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3055)'), ('usv_1', '(333,4089)'), ('usv_2', '(285,5055)')]...
    Recent rewards sample: {'usv_0': np.float64(5.879019083319683), 'usv_1': np.float64(3.378594979572452)}
    Episode time: 201.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 53290.7
  Targets Detected: 8/85 (8.2%)
  Steps: 2746
  Episode Time: 274.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 19.41
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 268, Avg Reward: -1.333, Episode Reward: -357.3
    æ£€æµ‹è¿›åº¦: 1/7 (14.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3130)'), ('usv_1', '(234,4129)'), ('usv_2', '(232,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2713473491891917), 'usv_1': np.float64(-0.6320936284739661)}
    Episode time: 26.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 1268, Avg Reward: 2.614, Episode Reward: 3314.7
    æ£€æµ‹è¿›åº¦: 2/38 (5.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3126)'), ('usv_1', '(280,4169)'), ('usv_2', '(290,5083)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2825973710045941), 'usv_1': np.float64(2.371596612735133)}
    Episode time: 126.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 2268, Avg Reward: 9.499, Episode Reward: 21544.3
    æ£€æµ‹è¿›åº¦: 3/63 (4.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(336,3135)'), ('usv_1', '(293,4233)'), ('usv_2', '(317,5012)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2938792054661232), 'usv_1': np.float64(3.3737137113189775)}
    Episode time: 226.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 26817.1
  Targets Detected: 5/72 (2.8%)
  Steps: 2595
  Episode Time: 259.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.33
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.01644778 0.03346419] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 673, Avg Reward: 6.372, Episode Reward: 4288.3
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3122)'), ('usv_1', '(243,4137)'), ('usv_2', '(248,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2713611148027621), 'usv_1': np.float64(0.3695710172668858)}
    Episode time: 67.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 1673, Avg Reward: 9.397, Episode Reward: 15721.4
    æ£€æµ‹è¿›åº¦: 3/40 (7.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(272,3087)'), ('usv_1', '(325,4162)'), ('usv_2', '(264,5066)')]...
    Recent rewards sample: {'usv_0': np.float64(2.289038071758236), 'usv_1': np.float64(1.3759952583499349)}
    Episode time: 167.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 2673, Avg Reward: 14.448, Episode Reward: 38618.7
    æ£€æµ‹è¿›åº¦: 5/70 (7.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(314,3046)'), ('usv_1', '(357,4211)'), ('usv_2', '(257,5001)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8830116244261434), 'usv_1': np.float64(3.380926588027899)}
    Episode time: 267.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 48222.5
  Targets Detected: 8/79 (8.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.07
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 672, Avg Reward: 14.726, Episode Reward: 9895.6
    æ£€æµ‹è¿›åº¦: 2/11 (18.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3128)'), ('usv_1', '(244,4147)'), ('usv_2', '(271,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(3.270001788809193), 'usv_1': np.float64(0.36870385092476154)}
    Episode time: 67.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 1672, Avg Reward: 15.984, Episode Reward: 26724.5
    æ£€æµ‹è¿›åº¦: 3/44 (6.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3105)'), ('usv_1', '(271,4207)'), ('usv_2', '(293,5049)')]...
    Recent rewards sample: {'usv_0': np.float64(4.283841237070632), 'usv_1': np.float64(3.3757259298257623)}
    Episode time: 167.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 46009.5
  Targets Detected: 5/74 (4.1%)
  Steps: 2525
  Episode Time: 252.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.22
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.1192158  -0.10191712] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 100000, Episode Steps: 147, Avg Reward: -4.081, Episode Reward: -599.9
    æ£€æµ‹è¿›åº¦: 0/9 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3130)'), ('usv_1', '(225,4128)'), ('usv_2', '(222,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7336417908206367), 'usv_1': np.float64(-1.627391889582328)}
    Episode time: 14.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 101000, Episode Steps: 1147, Avg Reward: 7.858, Episode Reward: 9013.2
    æ£€æµ‹è¿›åº¦: 3/29 (10.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3125)'), ('usv_1', '(292,4152)'), ('usv_2', '(298,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(2.280176608680214), 'usv_1': np.float64(3.372328356265001)}
    Episode time: 114.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 102000, Episode Steps: 2147, Avg Reward: 12.605, Episode Reward: 27064.0
    æ£€æµ‹è¿›åº¦: 3/57 (5.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(315,3106)'), ('usv_1', '(336,4195)'), ('usv_2', '(334,5037)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2944822214159815), 'usv_1': np.float64(3.3765056070859343)}
    Episode time: 214.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 44941.9
  Targets Detected: 5/79 (3.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.98
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 103000, Episode Steps: 146, Avg Reward: -3.923, Episode Reward: -572.8
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(224,4130)'), ('usv_2', '(226,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7368394876673081), 'usv_1': np.float64(-1.6288781758915238)}
    Episode time: 14.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 104000, Episode Steps: 1146, Avg Reward: 14.416, Episode Reward: 16520.2
    æ£€æµ‹è¿›åº¦: 1/43 (2.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3103)'), ('usv_1', '(288,4136)'), ('usv_2', '(277,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(4.272485112465635), 'usv_1': np.float64(3.373994398282349)}
    Episode time: 114.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.06674003 -0.1170305 ] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 105000, Episode Steps: 2146, Avg Reward: 19.786, Episode Reward: 42460.1
    æ£€æµ‹è¿›åº¦: 9/78 (11.5%), Episode total: 12
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3057)'), ('usv_1', '(339,4172)'), ('usv_2', '(346,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(7.867057867662253), 'usv_1': np.float64(3.377062940842702)}
    Episode time: 214.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 62740.4
  Targets Detected: 15/97 (12.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.91

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 44103.8
Last 10 episodes average detections: 7.5
Best episode reward so far: 62740.4
Best detection count so far: 15
Learning trend: Improving (44103.8 vs 24503.5)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 106000, Episode Steps: 145, Avg Reward: 11.492, Episode Reward: 1666.4
    æ£€æµ‹è¿›åº¦: 1/12 (8.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3130)'), ('usv_1', '(225,4129)'), ('usv_2', '(218,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2667754363088005), 'usv_1': np.float64(-0.6327978083343374)}
    Episode time: 14.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 107000, Episode Steps: 1145, Avg Reward: 13.358, Episode Reward: 15295.3
    æ£€æµ‹è¿›åº¦: 3/45 (6.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3108)'), ('usv_1', '(274,4096)'), ('usv_2', '(259,5071)')]...
    Recent rewards sample: {'usv_0': np.float64(2.282067831506464), 'usv_1': np.float64(1.3760868366666053)}
    Episode time: 114.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 108000, Episode Steps: 2145, Avg Reward: 18.113, Episode Reward: 38853.3
    æ£€æµ‹è¿›åº¦: 5/73 (6.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(289,3078)'), ('usv_1', '(331,4096)'), ('usv_2', '(246,5013)')]...
    Recent rewards sample: {'usv_0': np.float64(5.880416643426063), 'usv_1': np.float64(3.390281030673961)}
    Episode time: 214.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 61804.2
  Targets Detected: 8/85 (8.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.59
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 109000, Episode Steps: 144, Avg Reward: -3.921, Episode Reward: -564.6
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3130)'), ('usv_1', '(219,4130)'), ('usv_2', '(218,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7341926645100465), 'usv_1': np.float64(-1.6304281504223026)}
    Episode time: 14.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.32679838 -0.04539097] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 110000, Episode Steps: 1144, Avg Reward: -1.470, Episode Reward: -1682.1
    æ£€æµ‹è¿›åº¦: 1/33 (3.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3118)'), ('usv_1', '(251,4166)'), ('usv_2', '(255,5086)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2753435168433116), 'usv_1': np.float64(1.374491238084512)}
    Episode time: 114.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 111000, Episode Steps: 2144, Avg Reward: 10.157, Episode Reward: 21776.8
    æ£€æµ‹è¿›åº¦: 6/57 (10.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(272,3087)'), ('usv_1', '(287,4201)'), ('usv_2', '(238,5022)')]...
    Recent rewards sample: {'usv_0': np.float64(4.287416397030229), 'usv_1': np.float64(3.3765447042087935)}
    Episode time: 214.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 43839.2
  Targets Detected: 9/75 (6.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.61
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 112000, Episode Steps: 143, Avg Reward: -3.925, Episode Reward: -561.3
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3130)'), ('usv_1', '(217,4130)'), ('usv_2', '(216,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7347004704219049), 'usv_1': np.float64(-1.6306850543976068)}
    Episode time: 14.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 113000, Episode Steps: 1143, Avg Reward: 5.756, Episode Reward: 6578.6
    æ£€æµ‹è¿›åº¦: 3/22 (13.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(269,3132)'), ('usv_1', '(296,4158)'), ('usv_2', '(276,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2771763442823927), 'usv_1': np.float64(0.38410963153709266)}
    Episode time: 114.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 114000, Episode Steps: 2143, Avg Reward: 11.447, Episode Reward: 24530.8
    æ£€æµ‹è¿›åº¦: 5/45 (11.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(309,3156)'), ('usv_1', '(325,4202)'), ('usv_2', '(340,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(4.290300228842515), 'usv_1': np.float64(3.375418874662328)}
    Episode time: 214.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 40871.0
  Targets Detected: 7/69 (8.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.62
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.20251237 -0.04832406] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 115000, Episode Steps: 142, Avg Reward: -3.923, Episode Reward: -557.1
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3129)'), ('usv_1', '(218,4130)'), ('usv_2', '(225,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7312275202082037), 'usv_1': np.float64(-1.6295066260076527)}
    Episode time: 14.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 116000, Episode Steps: 1142, Avg Reward: 0.434, Episode Reward: 495.7
    æ£€æµ‹è¿›åº¦: 1/31 (3.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3108)'), ('usv_1', '(258,4182)'), ('usv_2', '(257,5070)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2813534414628234), 'usv_1': np.float64(-0.6278240804371131)}
    Episode time: 114.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 117000, Episode Steps: 2142, Avg Reward: 9.058, Episode Reward: 19403.0
    æ£€æµ‹è¿›åº¦: 4/70 (5.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(297,3074)'), ('usv_1', '(225,4239)'), ('usv_2', '(208,5048)')]...
    Recent rewards sample: {'usv_0': np.float64(7.873071142286102), 'usv_1': np.float64(3.375103445735201)}
    Episode time: 214.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 33039.4
  Targets Detected: 5/78 (3.8%)
  Steps: 2716
  Episode Time: 271.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.16
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 118000, Episode Steps: 426, Avg Reward: 5.741, Episode Reward: 2445.5
    æ£€æµ‹è¿›åº¦: 1/17 (5.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3128)'), ('usv_1', '(230,4140)'), ('usv_2', '(253,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2686413006807329), 'usv_1': np.float64(-0.6263869615497373)}
    Episode time: 42.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 119000, Episode Steps: 1426, Avg Reward: 10.854, Episode Reward: 15477.8
    æ£€æµ‹è¿›åº¦: 3/57 (5.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(284,3106)'), ('usv_1', '(242,4191)'), ('usv_2', '(311,5092)')]...
    Recent rewards sample: {'usv_0': np.float64(2.284774522324005), 'usv_1': np.float64(3.369012275525683)}
    Episode time: 142.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.10308876 -0.05712902] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 120000, Episode Steps: 2426, Avg Reward: 14.602, Episode Reward: 35425.4
    æ£€æµ‹è¿›åº¦: 6/81 (7.4%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(308,3118)'), ('usv_1', '(219,4241)'), ('usv_2', '(297,5017)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2902440375185416), 'usv_1': np.float64(3.370771043769288)}
    Episode time: 242.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 47463.9
  Targets Detected: 8/96 (7.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.82
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 121000, Episode Steps: 425, Avg Reward: 2.182, Episode Reward: 927.4
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3127)'), ('usv_1', '(234,4130)'), ('usv_2', '(242,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2758888247545332), 'usv_1': np.float64(3.370285501894969)}
    Episode time: 42.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 122000, Episode Steps: 1425, Avg Reward: 18.525, Episode Reward: 26398.2
    æ£€æµ‹è¿›åº¦: 8/52 (15.4%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3092)'), ('usv_1', '(293,4141)'), ('usv_2', '(309,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2798681688622695), 'usv_1': np.float64(3.3731668691552006)}
    Episode time: 142.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 123000, Episode Steps: 2425, Avg Reward: 21.249, Episode Reward: 51529.9
    æ£€æµ‹è¿›åº¦: 8/68 (11.8%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(266,3055)'), ('usv_1', '(334,4196)'), ('usv_2', '(341,5079)')]...
    Recent rewards sample: {'usv_0': np.float64(7.87109301729397), 'usv_1': np.float64(1.3809943826864677)}
    Episode time: 242.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 67397.3
  Targets Detected: 12/84 (13.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 22.46
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 124000, Episode Steps: 424, Avg Reward: -4.705, Episode Reward: -1995.0
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3129)'), ('usv_1', '(243,4124)'), ('usv_2', '(246,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7310386142672614), 'usv_1': np.float64(-1.6307578953060258)}
    Episode time: 42.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.28344217  0.27338277] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 125000, Episode Steps: 1424, Avg Reward: 6.389, Episode Reward: 9097.7
    æ£€æµ‹è¿›åº¦: 3/29 (10.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(262,3104)'), ('usv_1', '(298,4137)'), ('usv_2', '(275,5051)')]...
    Recent rewards sample: {'usv_0': np.float64(4.279296947388447), 'usv_1': np.float64(3.373957274038328)}
    Episode time: 142.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 126000, Episode Steps: 2424, Avg Reward: 13.264, Episode Reward: 32153.1
    æ£€æµ‹è¿›åº¦: 6/56 (10.7%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3059)'), ('usv_1', '(337,4173)'), ('usv_2', '(245,4988)')]...
    Recent rewards sample: {'usv_0': np.float64(7.873464421133802), 'usv_1': np.float64(3.3765550199009358)}
    Episode time: 242.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 46588.7
  Targets Detected: 7/72 (8.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.52
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 127000, Episode Steps: 423, Avg Reward: -3.937, Episode Reward: -1665.3
    æ£€æµ‹è¿›åº¦: 0/16 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3125)'), ('usv_1', '(227,4124)'), ('usv_2', '(249,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7308536550956233), 'usv_1': np.float64(-1.6296372852736805)}
    Episode time: 42.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 128000, Episode Steps: 1423, Avg Reward: 5.334, Episode Reward: 7590.3
    æ£€æµ‹è¿›åº¦: 3/37 (8.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3113)'), ('usv_1', '(284,4109)'), ('usv_2', '(307,5077)')]...
    Recent rewards sample: {'usv_0': np.float64(4.277044270008385), 'usv_1': np.float64(1.3737221663755164)}
    Episode time: 142.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 129000, Episode Steps: 2423, Avg Reward: 10.557, Episode Reward: 25578.6
    æ£€æµ‹è¿›åº¦: 5/61 (8.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(292,3085)'), ('usv_1', '(319,4057)'), ('usv_2', '(311,5009)')]...
    Recent rewards sample: {'usv_0': np.float64(5.872553327812117), 'usv_1': np.float64(3.377782953505722)}
    Episode time: 242.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 41886.3
  Targets Detected: 10/81 (11.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.96
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.04286557 0.0058321 ] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 130000, Episode Steps: 422, Avg Reward: 3.114, Episode Reward: 1313.9
    æ£€æµ‹è¿›åº¦: 2/11 (18.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3128)'), ('usv_1', '(230,4130)'), ('usv_2', '(244,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2694909460074547), 'usv_1': np.float64(1.3727453176071043)}
    Episode time: 42.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 131000, Episode Steps: 1422, Avg Reward: 11.573, Episode Reward: 16456.9
    æ£€æµ‹è¿›åº¦: 4/34 (11.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3082)'), ('usv_1', '(278,4094)'), ('usv_2', '(282,5092)')]...
    Recent rewards sample: {'usv_0': np.float64(5.871579441245361), 'usv_1': np.float64(1.3789710375615956)}
    Episode time: 142.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 132000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 132000, Episode Steps: 2422, Avg Reward: 18.227, Episode Reward: 44145.2
    æ£€æµ‹è¿›åº¦: 8/74 (10.8%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3052)'), ('usv_1', '(347,4046)'), ('usv_2', '(253,5020)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8736000711123175), 'usv_1': np.float64(3.3792570011969447)}
    Episode time: 242.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 60125.9
  Targets Detected: 10/101 (9.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.04
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 133000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 133000, Episode Steps: 421, Avg Reward: 2.425, Episode Reward: 1020.9
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3127)'), ('usv_1', '(233,4129)'), ('usv_2', '(243,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26855143920798585), 'usv_1': np.float64(-0.6322313394268531)}
    Episode time: 42.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 134000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 134000, Episode Steps: 1421, Avg Reward: 6.527, Episode Reward: 9275.0
    æ£€æµ‹è¿›åº¦: 4/45 (8.9%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3091)'), ('usv_1', '(287,4135)'), ('usv_2', '(300,5109)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2812390309671928), 'usv_1': np.float64(0.37294670006091635)}
    Episode time: 142.1s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.21237863 -0.13855775] (agent usv_0)
    MADDPG UPDATING at time_step 135000...
    MADDPG UPDATE finished.
    Avg Actor Loss: 0.0131, Avg Critic Loss: 201.9270
    Step 135000, Episode Steps: 2421, Avg Reward: 12.196, Episode Reward: 29525.5
    æ£€æµ‹è¿›åº¦: 5/73 (6.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(305,3053)'), ('usv_1', '(335,4169)'), ('usv_2', '(340,5049)')]...
    Recent rewards sample: {'usv_0': np.float64(5.874009842904224), 'usv_1': np.float64(1.375774240994807)}
    Episode time: 242.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 47483.2
  Targets Detected: 11/96 (11.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.82

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 49049.9
Last 10 episodes average detections: 8.7
Best episode reward so far: 67397.3
Best detection count so far: 15
Learning trend: Improving (49049.9 vs 44103.8)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 67397.3
Final 10 episodes average: 49049.9
Best detection performance: 15 targets
Average detections (final 10): 8.7
============================================================
{"final_avg_reward": 49049.923005312354, "final_detection_rate": 8.7, "best_episode_reward": 67397.28600946777, "best_detection_count": 15, "total_episodes": 50}
Simulation finished.
