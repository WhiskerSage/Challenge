D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: 8.199, Episode Reward: 8198.7
    æ£€æµ‹è¿›åº¦: 2/11 (18.2%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3110)'), ('usv_1', '(230,4101)'), ('usv_2', '(246,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(2.368041663018074), 'usv_1': np.float64(1.4714248695286098)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 13.319, Episode Reward: 26637.7
    æ£€æµ‹è¿›åº¦: 3/21 (14.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3086)'), ('usv_1', '(201,4096)'), ('usv_2', '(274,5094)')]...
    Recent rewards sample: {'usv_0': np.float64(5.96614361692098), 'usv_1': np.float64(-3.5344324563183296)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 28778.7
  Targets Detected: 4/22 (13.6%)
  Steps: 2190
  Episode Time: 219.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.14
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 810, Avg Reward: -0.045, Episode Reward: -36.1
    æ£€æµ‹è¿›åº¦: 1/16 (6.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3115)'), ('usv_1', '(235,4114)'), ('usv_2', '(242,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3732274140764864), 'usv_1': np.float64(-0.5290125590486818)}
    Episode time: 81.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 1810, Avg Reward: 3.194, Episode Reward: 5782.0
    æ£€æµ‹è¿›åº¦: 3/34 (8.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3096)'), ('usv_1', '(208,4108)'), ('usv_2', '(280,5105)')]...
    Recent rewards sample: {'usv_0': np.float64(1.366629851163002), 'usv_1': np.float64(0.46594112865272175)}
    Episode time: 181.0s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.18827298  0.10134472] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 2810, Avg Reward: 5.222, Episode Reward: 14673.0
    æ£€æµ‹è¿›åº¦: 3/44 (6.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3109)'), ('usv_1', '(205,4152)'), ('usv_2', '(309,5077)')]...
    Recent rewards sample: {'usv_0': np.float64(1.4489109372877702), 'usv_1': np.float64(0.47623594791796586)}
    Episode time: 281.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 15421.3
  Targets Detected: 3/47 (6.4%)
  Steps: 2894
  Episode Time: 289.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 5.33
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 916, Avg Reward: -3.260, Episode Reward: -2985.9
    æ£€æµ‹è¿›åº¦: 0/16 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3115)'), ('usv_1', '(235,4091)'), ('usv_2', '(243,5107)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6319339982241028), 'usv_1': np.float64(-1.531766549703165)}
    Episode time: 91.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 1916, Avg Reward: -3.400, Episode Reward: -6513.6
    æ£€æµ‹è¿›åº¦: 1/28 (3.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3103)'), ('usv_1', '(201,4051)'), ('usv_2', '(262,5084)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3668842589911685), 'usv_1': np.float64(-4.533490384001924)}
    Episode time: 191.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 2916, Avg Reward: 3.729, Episode Reward: 10873.9
    æ£€æµ‹è¿›åº¦: 5/44 (11.4%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3111)'), ('usv_1', '(207,4060)'), ('usv_2', '(285,5063)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3634686753166214), 'usv_1': np.float64(3.4757855101394277)}
    Episode time: 291.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 12632.4
  Targets Detected: 6/44 (11.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 4.21
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 915, Avg Reward: -3.256, Episode Reward: -2979.1
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3127)'), ('usv_1', '(263,4111)'), ('usv_2', '(247,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6305780469184683), 'usv_1': np.float64(-1.5259614788958198)}
    Episode time: 91.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: -9824.9
  Targets Detected: 0/23 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -5.46
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.00618627 -0.05141253] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 114, Avg Reward: -4.597, Episode Reward: -524.0
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3129)'), ('usv_1', '(216,4129)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6341940819814683), 'usv_1': np.float64(-1.533481041603042)}
    Episode time: 11.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 1114, Avg Reward: 2.103, Episode Reward: 2343.1
    æ£€æµ‹è¿›åº¦: 2/19 (10.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3109)'), ('usv_1', '(270,4117)'), ('usv_2', '(256,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3688876472518166), 'usv_1': np.float64(3.4746671846162496)}
    Episode time: 111.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 2114, Avg Reward: 11.705, Episode Reward: 24744.5
    æ£€æµ‹è¿›åº¦: 5/30 (16.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3109)'), ('usv_1', '(317,4094)'), ('usv_2', '(276,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3665050318531122), 'usv_1': np.float64(3.4743580248218047)}
    Episode time: 211.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 35332.2
  Targets Detected: 5/40 (12.5%)
  Steps: 2849
  Episode Time: 284.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.40
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 265, Avg Reward: -3.408, Episode Reward: -903.1
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3129)'), ('usv_1', '(223,4128)'), ('usv_2', '(218,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6342200543470602), 'usv_1': np.float64(-1.532995540230376)}
    Episode time: 26.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 1265, Avg Reward: 1.383, Episode Reward: 1749.2
    æ£€æµ‹è¿›åº¦: 2/12 (16.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3120)'), ('usv_1', '(224,4084)'), ('usv_2', '(252,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3750160400737936), 'usv_1': np.float64(2.4674622570929357)}
    Episode time: 126.5s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.26439695 -0.09053315] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 2265, Avg Reward: 7.117, Episode Reward: 16120.5
    æ£€æµ‹è¿›åº¦: 3/27 (11.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3092)'), ('usv_1', '(200,4083)'), ('usv_2', '(260,5087)')]...
    Recent rewards sample: {'usv_0': np.float64(2.387237208615199), 'usv_1': np.float64(-1.5276655989107306)}
    Episode time: 226.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 20672.2
  Targets Detected: 4/32 (9.4%)
  Steps: 2777
  Episode Time: 277.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.44
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 488, Avg Reward: 2.174, Episode Reward: 1060.8
    æ£€æµ‹è¿›åº¦: 1/6 (16.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3128)'), ('usv_1', '(235,4124)'), ('usv_2', '(237,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3657189577161872), 'usv_1': np.float64(0.4757382106594714)}
    Episode time: 48.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 1488, Avg Reward: 9.975, Episode Reward: 14842.7
    æ£€æµ‹è¿›åº¦: 2/30 (6.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3110)'), ('usv_1', '(233,4085)'), ('usv_2', '(254,5094)')]...
    Recent rewards sample: {'usv_0': np.float64(2.369834624393086), 'usv_1': np.float64(1.468084661283537)}
    Episode time: 148.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 2488, Avg Reward: 14.841, Episode Reward: 36924.4
    æ£€æµ‹è¿›åº¦: 4/43 (9.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,3102)'), ('usv_1', '(209,4111)'), ('usv_2', '(229,5063)')]...
    Recent rewards sample: {'usv_0': np.float64(2.364222830691965), 'usv_1': np.float64(1.46873773961604)}
    Episode time: 248.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 45518.0
  Targets Detected: 6/53 (5.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.17
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 487, Avg Reward: 21.849, Episode Reward: 10640.4
    æ£€æµ‹è¿›åº¦: 4/9 (44.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3123)'), ('usv_1', '(231,4118)'), ('usv_2', '(226,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(4.378747060975982), 'usv_1': np.float64(3.4677002116391122)}
    Episode time: 48.7s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.07833883 -0.00340958] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 1487, Avg Reward: 21.595, Episode Reward: 32112.0
    æ£€æµ‹è¿›åº¦: 3/19 (15.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3119)'), ('usv_1', '(261,4070)'), ('usv_2', '(220,5081)')]...
    Recent rewards sample: {'usv_0': np.float64(4.365340667421641), 'usv_1': np.float64(3.4704356497197546)}
    Episode time: 148.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 38641.5
  Targets Detected: 5/22 (13.6%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_146s
  Average Reward/Step: 21.46
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 686, Avg Reward: -3.267, Episode Reward: -2241.3
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3120)'), ('usv_1', '(240,4104)'), ('usv_2', '(241,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6342954369584919), 'usv_1': np.float64(-1.5229804886756706)}
    Episode time: 68.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 1686, Avg Reward: 2.498, Episode Reward: 4212.3
    æ£€æµ‹è¿›åº¦: 3/27 (11.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3107)'), ('usv_1', '(215,4080)'), ('usv_2', '(261,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(4.366527931182585), 'usv_1': np.float64(1.4736045864148823)}
    Episode time: 168.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 2686, Avg Reward: 8.167, Episode Reward: 21936.1
    æ£€æµ‹è¿›åº¦: 5/39 (12.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3124)'), ('usv_1', '(209,4116)'), ('usv_2', '(277,5089)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3627958081085465), 'usv_1': np.float64(1.466002120443545)}
    Episode time: 268.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 27245.6
  Targets Detected: 5/44 (11.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.08
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 685, Avg Reward: 18.866, Episode Reward: 12923.5
    æ£€æµ‹è¿›åº¦: 4/13 (30.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3126)'), ('usv_1', '(244,4133)'), ('usv_2', '(231,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(2.367969563409571), 'usv_1': np.float64(3.4765979625221677)}
    Episode time: 68.5s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.03430807 -0.18112314] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 1685, Avg Reward: 20.860, Episode Reward: 35149.6
    æ£€æµ‹è¿›åº¦: 8/28 (28.6%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3102)'), ('usv_1', '(279,4087)'), ('usv_2', '(267,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(4.37254555700978), 'usv_1': np.float64(-1.5248769974138154)}
    Episode time: 168.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 2685, Avg Reward: 18.640, Episode Reward: 50047.5
    æ£€æµ‹è¿›åº¦: 9/42 (21.4%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3094)'), ('usv_1', '(243,4084)'), ('usv_2', '(300,5109)')]...
    Recent rewards sample: {'usv_0': np.float64(4.368731725672411), 'usv_1': np.float64(-1.5301034464837224)}
    Episode time: 268.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 53715.5
  Targets Detected: 11/44 (20.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.90

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 26813.2
Last 10 episodes average detections: 4.9
Best episode reward so far: 53715.5
Best detection count so far: 11
Buffer size: 26316
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 684, Avg Reward: -3.583, Episode Reward: -2450.6
    æ£€æµ‹è¿›åº¦: 0/21 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3114)'), ('usv_1', '(241,4106)'), ('usv_2', '(239,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6826036757525584), 'usv_1': np.float64(-1.574762343056265)}
    Episode time: 68.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 1684, Avg Reward: 1.830, Episode Reward: 3081.1
    æ£€æµ‹è¿›åº¦: 4/50 (8.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(200,3101)'), ('usv_1', '(252,4061)'), ('usv_2', '(267,5089)')]...
    Recent rewards sample: {'usv_0': np.float64(4.318292020281148), 'usv_1': np.float64(-4.573755629272949)}
    Episode time: 168.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 2684, Avg Reward: 8.444, Episode Reward: 22664.4
    æ£€æµ‹è¿›åº¦: 9/76 (11.8%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3109)'), ('usv_1', '(214,4059)'), ('usv_2', '(285,5076)')]...
    Recent rewards sample: {'usv_0': np.float64(4.314237870090769), 'usv_1': np.float64(3.4195737126806343)}
    Episode time: 268.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 28533.9
  Targets Detected: 13/86 (11.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.51
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.18048383  0.15555   ] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 683, Avg Reward: -3.063, Episode Reward: -2091.8
    æ£€æµ‹è¿›åº¦: 0/18 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3126)'), ('usv_1', '(224,4114)'), ('usv_2', '(236,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3168521899422974), 'usv_1': np.float64(-0.5806070539775707)}
    Episode time: 68.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 1683, Avg Reward: 2.259, Episode Reward: 3802.1
    æ£€æµ‹è¿›åº¦: 3/35 (8.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3101)'), ('usv_1', '(209,4090)'), ('usv_2', '(260,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3173104574826016), 'usv_1': np.float64(-0.5830429017779379)}
    Episode time: 168.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 2683, Avg Reward: 8.948, Episode Reward: 24007.1
    æ£€æµ‹è¿›åº¦: 7/64 (10.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3097)'), ('usv_1', '(218,4126)'), ('usv_2', '(260,5073)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3184876798004246), 'usv_1': np.float64(3.418433575199291)}
    Episode time: 268.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 30507.8
  Targets Detected: 7/69 (10.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.17
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 682, Avg Reward: -3.602, Episode Reward: -2456.3
    æ£€æµ‹è¿›åº¦: 0/17 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3123)'), ('usv_1', '(244,4112)'), ('usv_2', '(226,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6835661128038413), 'usv_1': np.float64(-1.579326425879357)}
    Episode time: 68.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 1682, Avg Reward: 2.257, Episode Reward: 3796.4
    æ£€æµ‹è¿›åº¦: 1/39 (2.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3094)'), ('usv_1', '(261,4053)'), ('usv_2', '(231,5086)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3169740694952843), 'usv_1': np.float64(0.42074042540447887)}
    Episode time: 168.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 9661.8
  Targets Detected: 1/50 (0.0%)
  Steps: 2315
  Episode Time: 231.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 4.17
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.03894814  0.01398644] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 367, Avg Reward: -3.604, Episode Reward: -1322.8
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3128)'), ('usv_1', '(229,4119)'), ('usv_2', '(225,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6845031914260187), 'usv_1': np.float64(-1.571500929057097)}
    Episode time: 36.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 1367, Avg Reward: 0.766, Episode Reward: 1047.0
    æ£€æµ‹è¿›åº¦: 1/26 (3.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3112)'), ('usv_1', '(220,4081)'), ('usv_2', '(257,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3158785606590113), 'usv_1': np.float64(-0.5827562126120209)}
    Episode time: 136.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 2367, Avg Reward: 2.190, Episode Reward: 5184.9
    æ£€æµ‹è¿›åº¦: 3/48 (6.2%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3125)'), ('usv_1', '(203,4104)'), ('usv_2', '(298,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(3.317622730516653), 'usv_1': np.float64(0.418145851141033)}
    Episode time: 236.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 12120.4
  Targets Detected: 3/63 (4.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 4.04
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 366, Avg Reward: -3.609, Episode Reward: -1320.8
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3126)'), ('usv_1', '(231,4128)'), ('usv_2', '(223,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.684543016397512), 'usv_1': np.float64(-1.582333087103958)}
    Episode time: 36.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 1366, Avg Reward: -5.108, Episode Reward: -6976.9
    æ£€æµ‹è¿›åº¦: 0/38 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3109)'), ('usv_1', '(258,4096)'), ('usv_2', '(250,5084)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32123952123739274), 'usv_1': np.float64(-8.574072434596454)}
    Episode time: 136.6s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.25335909  0.14485325] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 2366, Avg Reward: -3.734, Episode Reward: -8833.5
    æ£€æµ‹è¿›åº¦: 2/54 (3.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3095)'), ('usv_1', '(212,4068)'), ('usv_2', '(270,5069)')]...
    Recent rewards sample: {'usv_0': np.float64(4.320411445388608), 'usv_1': np.float64(-6.58314222094684)}
    Episode time: 236.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: -62.3
  Targets Detected: 2/62 (1.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: -0.02
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 365, Avg Reward: -2.116, Episode Reward: -772.2
    æ£€æµ‹è¿›åº¦: 0/14 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3122)'), ('usv_1', '(228,4130)'), ('usv_2', '(227,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31717980653436906), 'usv_1': np.float64(-0.5781099259868062)}
    Episode time: 36.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 1365, Avg Reward: 14.104, Episode Reward: 19251.9
    æ£€æµ‹è¿›åº¦: 4/32 (12.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3103)'), ('usv_1', '(266,4110)'), ('usv_2', '(265,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(4.323260320879774), 'usv_1': np.float64(3.425981248209413)}
    Episode time: 136.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 26326.9
  Targets Detected: 6/39 (10.3%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_125s
  Average Reward/Step: 14.62
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 564, Avg Reward: -3.602, Episode Reward: -2031.6
    æ£€æµ‹è¿›åº¦: 0/20 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3134)'), ('usv_1', '(246,4128)'), ('usv_2', '(230,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6852658008657972), 'usv_1': np.float64(-1.5782019570451862)}
    Episode time: 56.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 1564, Avg Reward: -3.342, Episode Reward: -5226.5
    æ£€æµ‹è¿›åº¦: 1/31 (3.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3129)'), ('usv_1', '(253,4084)'), ('usv_2', '(273,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32237628145991826), 'usv_1': np.float64(-8.571714141808304)}
    Episode time: 156.4s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.17167326 -0.11120144] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 2564, Avg Reward: -5.024, Episode Reward: -12882.7
    æ£€æµ‹è¿›åº¦: 2/53 (3.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3128)'), ('usv_1', '(217,4051)'), ('usv_2', '(286,5097)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3189860607735993), 'usv_1': np.float64(-7.580347783575959)}
    Episode time: 256.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: -6785.0
  Targets Detected: 5/62 (8.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: -2.26
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 563, Avg Reward: 4.281, Episode Reward: 2410.3
    æ£€æµ‹è¿›åº¦: 1/9 (11.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3122)'), ('usv_1', '(228,4116)'), ('usv_2', '(235,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3170952090334912), 'usv_1': np.float64(-0.5805425815344764)}
    Episode time: 56.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 1563, Avg Reward: 12.516, Episode Reward: 19563.0
    æ£€æµ‹è¿›åº¦: 2/32 (6.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3097)'), ('usv_1', '(204,4084)'), ('usv_2', '(268,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(2.320962762200487), 'usv_1': np.float64(3.416995936676731)}
    Episode time: 156.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 2563, Avg Reward: 16.796, Episode Reward: 43049.3
    æ£€æµ‹è¿›åº¦: 4/56 (7.1%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3059)'), ('usv_1', '(207,4087)'), ('usv_2', '(302,5090)')]...
    Recent rewards sample: {'usv_0': np.float64(5.977707837703972), 'usv_1': np.float64(3.4161583406034515)}
    Episode time: 256.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 52621.0
  Targets Detected: 6/64 (6.2%)
  Steps: 2993
  Episode Time: 299.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 17.58
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 570, Avg Reward: -3.700, Episode Reward: -2109.3
    æ£€æµ‹è¿›åº¦: 0/15 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3110)'), ('usv_1', '(235,4118)'), ('usv_2', '(224,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6809419331320978), 'usv_1': np.float64(-1.582056613920766)}
    Episode time: 57.0s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.14920338 -0.07213258] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 1570, Avg Reward: -2.038, Episode Reward: -3199.2
    æ£€æµ‹è¿›åº¦: 1/43 (2.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3092)'), ('usv_1', '(229,4077)'), ('usv_2', '(250,5096)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3226774280389804), 'usv_1': np.float64(-0.5799459769127838)}
    Episode time: 157.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 2570, Avg Reward: 1.989, Episode Reward: 5113.0
    æ£€æµ‹è¿›åº¦: 5/71 (7.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3113)'), ('usv_1', '(207,4064)'), ('usv_2', '(281,5077)')]...
    Recent rewards sample: {'usv_0': np.float64(4.319099990070442), 'usv_1': np.float64(-4.582423424392701)}
    Episode time: 257.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 8392.7
  Targets Detected: 8/75 (9.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 2.80
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 569, Avg Reward: -3.589, Episode Reward: -2041.9
    æ£€æµ‹è¿›åº¦: 0/14 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3121)'), ('usv_1', '(236,4120)'), ('usv_2', '(238,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6783024331319012), 'usv_1': np.float64(-1.5809617352356393)}
    Episode time: 56.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 1569, Avg Reward: -0.129, Episode Reward: -201.8
    æ£€æµ‹è¿›åº¦: 2/35 (5.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3097)'), ('usv_1', '(238,4066)'), ('usv_2', '(263,5091)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3205967024051968), 'usv_1': np.float64(0.41980994246097336)}
    Episode time: 156.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 2569, Avg Reward: 2.819, Episode Reward: 7242.9
    æ£€æµ‹è¿›åº¦: 3/53 (5.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(201,3087)'), ('usv_1', '(200,4073)'), ('usv_2', '(276,5050)')]...
    Recent rewards sample: {'usv_0': np.float64(7.916736518113609), 'usv_1': np.float64(-6.583170062176565)}
    Episode time: 256.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 8039.7
  Targets Detected: 6/60 (8.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 2.68

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 16935.7
Last 10 episodes average detections: 5.7
Best episode reward so far: 53715.5
Best detection count so far: 13
Learning trend: Declining (16935.7 vs 26813.2)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.14188734  0.14392067] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 568, Avg Reward: -3.169, Episode Reward: -1799.8
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3126)'), ('usv_1', '(246,4118)'), ('usv_2', '(226,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31747108619823217), 'usv_1': np.float64(-0.5701552350054302)}
    Episode time: 56.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 1568, Avg Reward: 10.784, Episode Reward: 16909.3
    æ£€æµ‹è¿›åº¦: 6/41 (14.6%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3104)'), ('usv_1', '(262,4079)'), ('usv_2', '(250,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3281504508729265), 'usv_1': np.float64(1.4203513173593705)}
    Episode time: 156.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 2568, Avg Reward: 14.531, Episode Reward: 37316.4
    æ£€æµ‹è¿›åº¦: 3/58 (5.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3101)'), ('usv_1', '(236,4108)'), ('usv_2', '(252,5085)')]...
    Recent rewards sample: {'usv_0': np.float64(4.321637983291663), 'usv_1': np.float64(1.421108546034517)}
    Episode time: 256.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 39375.3
  Targets Detected: 6/58 (5.2%)
  Steps: 2669
  Episode Time: 266.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.75
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 899, Avg Reward: 5.177, Episode Reward: 4653.9
    æ£€æµ‹è¿›åº¦: 3/21 (14.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3121)'), ('usv_1', '(227,4082)'), ('usv_2', '(235,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3197951153642702), 'usv_1': np.float64(0.41986249432157297)}
    Episode time: 89.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 1899, Avg Reward: 8.232, Episode Reward: 15631.8
    æ£€æµ‹è¿›åº¦: 3/37 (8.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3096)'), ('usv_1', '(204,4059)'), ('usv_2', '(226,5075)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3290410442292044), 'usv_1': np.float64(-6.58014828023253)}
    Episode time: 189.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 16364.0
  Targets Detected: 5/41 (7.3%)
  Steps: 2194
  Episode Time: 219.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.46
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.30858884 -0.18246085] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 705, Avg Reward: -3.668, Episode Reward: -2585.9
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3123)'), ('usv_1', '(248,4117)'), ('usv_2', '(238,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6858850443692129), 'usv_1': np.float64(-1.577009506913775)}
    Episode time: 70.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 1705, Avg Reward: -3.187, Episode Reward: -5433.0
    æ£€æµ‹è¿›åº¦: 2/33 (6.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3137)'), ('usv_1', '(280,4087)'), ('usv_2', '(266,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(3.310948324764182), 'usv_1': np.float64(-7.578338887152739)}
    Episode time: 170.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 2705, Avg Reward: -2.586, Episode Reward: -6993.8
    æ£€æµ‹è¿›åº¦: 4/52 (7.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3138)'), ('usv_1', '(292,4049)'), ('usv_2', '(265,5086)')]...
    Recent rewards sample: {'usv_0': np.float64(4.314831747316913), 'usv_1': np.float64(-6.576868397180519)}
    Episode time: 270.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: -6673.1
  Targets Detected: 4/65 (6.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: -2.22
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 704, Avg Reward: -2.798, Episode Reward: -1969.9
    æ£€æµ‹è¿›åº¦: 1/7 (14.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3126)'), ('usv_1', '(248,4126)'), ('usv_2', '(227,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3195137478972536), 'usv_1': np.float64(-0.5810770226378773)}
    Episode time: 70.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 1704, Avg Reward: 12.923, Episode Reward: 22021.5
    æ£€æµ‹è¿›åº¦: 4/31 (12.9%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3099)'), ('usv_1', '(261,4078)'), ('usv_2', '(269,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(4.319434217744759), 'usv_1': np.float64(3.422362564852273)}
    Episode time: 170.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 38505.3
  Targets Detected: 7/53 (7.5%)
  Steps: 2438
  Episode Time: 243.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.79
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.07398527 -0.09995228] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 266, Avg Reward: -3.606, Episode Reward: -959.2
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3128)'), ('usv_1', '(226,4131)'), ('usv_2', '(224,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6828848217639945), 'usv_1': np.float64(-1.5764259608790712)}
    Episode time: 26.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 1266, Avg Reward: 5.937, Episode Reward: 7516.1
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3115)'), ('usv_1', '(268,4098)'), ('usv_2', '(251,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3175593288058978), 'usv_1': np.float64(2.4206210016901517)}
    Episode time: 126.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 16396.2
  Targets Detected: 2/46 (4.3%)
  Steps: 2101
  Episode Time: 210.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.80
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 165, Avg Reward: -1.487, Episode Reward: -245.4
    æ£€æµ‹è¿›åº¦: 1/4 (25.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3129)'), ('usv_1', '(220,4130)'), ('usv_2', '(221,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6860077682864699), 'usv_1': np.float64(-1.5831874915846185)}
    Episode time: 16.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 1165, Avg Reward: 14.137, Episode Reward: 16469.7
    æ£€æµ‹è¿›åº¦: 4/33 (12.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3119)'), ('usv_1', '(242,4103)'), ('usv_2', '(248,5097)')]...
    Recent rewards sample: {'usv_0': np.float64(4.317066747888605), 'usv_1': np.float64(1.4185571919985018)}
    Episode time: 116.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 2165, Avg Reward: 17.379, Episode Reward: 37625.5
    æ£€æµ‹è¿›åº¦: 5/49 (10.2%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3120)'), ('usv_1', '(212,4064)'), ('usv_2', '(255,5074)')]...
    Recent rewards sample: {'usv_0': np.float64(4.317498194270885), 'usv_1': np.float64(1.4169736167588858)}
    Episode time: 216.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 48933.0
  Targets Detected: 7/59 (8.5%)
  Steps: 2749
  Episode Time: 274.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 17.80
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.19474271 -0.1236096 ] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 416, Avg Reward: -3.599, Episode Reward: -1497.2
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3122)'), ('usv_1', '(238,4121)'), ('usv_2', '(233,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6778037430402609), 'usv_1': np.float64(-1.5818257511368903)}
    Episode time: 41.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 1416, Avg Reward: 8.441, Episode Reward: 11952.0
    æ£€æµ‹è¿›åº¦: 1/39 (2.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3101)'), ('usv_1', '(219,4072)'), ('usv_2', '(251,5091)')]...
    Recent rewards sample: {'usv_0': np.float64(4.323118975109871), 'usv_1': np.float64(1.4229565534231727)}
    Episode time: 141.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 2416, Avg Reward: 13.472, Episode Reward: 32547.2
    æ£€æµ‹è¿›åº¦: 5/59 (8.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3098)'), ('usv_1', '(203,4070)'), ('usv_2', '(244,5063)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3237631864516075), 'usv_1': np.float64(1.4282979843324028)}
    Episode time: 241.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 37497.1
  Targets Detected: 7/75 (5.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.49
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 415, Avg Reward: -1.744, Episode Reward: -723.9
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3128)'), ('usv_1', '(231,4121)'), ('usv_2', '(236,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3155686871798459), 'usv_1': np.float64(1.4190857854927952)}
    Episode time: 41.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 1415, Avg Reward: 7.878, Episode Reward: 11147.5
    æ£€æµ‹è¿›åº¦: 2/25 (8.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3117)'), ('usv_1', '(219,4069)'), ('usv_2', '(274,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(1.316760356592997), 'usv_1': np.float64(2.4173333960763213)}
    Episode time: 141.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 15606.6
  Targets Detected: 2/29 (6.9%)
  Steps: 1847
  Episode Time: 184.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 8.45
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.24443986 -0.37328222] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 568, Avg Reward: 11.948, Episode Reward: 6786.3
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3113)'), ('usv_1', '(243,4123)'), ('usv_2', '(230,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3163607194671136), 'usv_1': np.float64(2.4249708072395126)}
    Episode time: 56.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 1568, Avg Reward: 15.531, Episode Reward: 24352.0
    æ£€æµ‹è¿›åº¦: 2/54 (3.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3115)'), ('usv_1', '(279,4066)'), ('usv_2', '(240,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3228775884923394), 'usv_1': np.float64(3.4231495642139613)}
    Episode time: 156.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 2568, Avg Reward: 13.058, Episode Reward: 33533.3
    æ£€æµ‹è¿›åº¦: 4/75 (5.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3130)'), ('usv_1', '(245,4029)'), ('usv_2', '(249,5073)')]...
    Recent rewards sample: {'usv_0': np.float64(2.319180495993789), 'usv_1': np.float64(-4.578320858303439)}
    Episode time: 256.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 42696.7
  Targets Detected: 7/83 (6.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.23
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 567, Avg Reward: -1.684, Episode Reward: -955.0
    æ£€æµ‹è¿›åº¦: 1/13 (7.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3125)'), ('usv_1', '(240,4117)'), ('usv_2', '(229,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3171584172285524), 'usv_1': np.float64(-0.576747097676725)}
    Episode time: 56.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 1567, Avg Reward: 3.878, Episode Reward: 6077.4
    æ£€æµ‹è¿›åº¦: 2/33 (6.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3115)'), ('usv_1', '(232,4098)'), ('usv_2', '(268,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3142512804821433), 'usv_1': np.float64(0.41790610724538)}
    Episode time: 156.7s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.13941435 0.08360826] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 2567, Avg Reward: 8.640, Episode Reward: 22179.5
    æ£€æµ‹è¿›åº¦: 4/63 (6.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3143)'), ('usv_1', '(210,4139)'), ('usv_2', '(299,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3184788185524345), 'usv_1': np.float64(-2.5819490186107865)}
    Episode time: 256.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: 29903.3
  Targets Detected: 5/81 (4.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.96

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 27860.4
Last 10 episodes average detections: 5.2
Best episode reward so far: 53715.5
Best detection count so far: 13
Learning trend: Improving (27860.4 vs 16935.7)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 566, Avg Reward: 2.248, Episode Reward: 1272.5
    æ£€æµ‹è¿›åº¦: 1/24 (4.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3121)'), ('usv_1', '(238,4130)'), ('usv_2', '(228,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(2.271748680404799), 'usv_1': np.float64(-0.6224334038287627)}
    Episode time: 56.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 1566, Avg Reward: 6.819, Episode Reward: 10677.9
    æ£€æµ‹è¿›åº¦: 4/52 (7.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3109)'), ('usv_1', '(217,4108)'), ('usv_2', '(232,5086)')]...
    Recent rewards sample: {'usv_0': np.float64(4.265881012503404), 'usv_1': np.float64(1.3686926145000884)}
    Episode time: 156.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 2566, Avg Reward: 5.720, Episode Reward: 14677.0
    æ£€æµ‹è¿›åº¦: 3/70 (4.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3128)'), ('usv_1', '(208,4148)'), ('usv_2', '(248,5064)')]...
    Recent rewards sample: {'usv_0': np.float64(4.305677608085254), 'usv_1': np.float64(-6.6331932931421225)}
    Episode time: 256.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 14686.0
  Targets Detected: 4/73 (4.1%)
  Steps: 2665
  Episode Time: 266.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 5.51
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 901, Avg Reward: 7.720, Episode Reward: 6955.7
    æ£€æµ‹è¿›åº¦: 2/30 (6.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,3132)'), ('usv_1', '(243,4095)'), ('usv_2', '(235,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2710507994533211), 'usv_1': np.float64(2.371890427637587)}
    Episode time: 90.1s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.08817064 -0.28040363] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 1901, Avg Reward: 14.567, Episode Reward: 27692.0
    æ£€æµ‹è¿›åº¦: 5/65 (7.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3112)'), ('usv_1', '(238,4030)'), ('usv_2', '(212,5084)')]...
    Recent rewards sample: {'usv_0': np.float64(2.274700260101969), 'usv_1': np.float64(3.3714544939183284)}
    Episode time: 190.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 2901, Avg Reward: 16.515, Episode Reward: 47911.1
    æ£€æµ‹è¿›åº¦: 6/84 (7.1%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3113)'), ('usv_1', '(209,4045)'), ('usv_2', '(209,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(4.268478497122475), 'usv_1': np.float64(-6.631834675581674)}
    Episode time: 290.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 47853.9
  Targets Detected: 6/88 (6.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.95
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 900, Avg Reward: 4.824, Episode Reward: 4342.0
    æ£€æµ‹è¿›åº¦: 1/36 (2.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3113)'), ('usv_1', '(253,4096)'), ('usv_2', '(256,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2671853897724561), 'usv_1': np.float64(1.3695972587982803)}
    Episode time: 90.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 8130.5
  Targets Detected: 1/56 (1.8%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_169s
  Average Reward/Step: 4.51
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 99, Avg Reward: 1.968, Episode Reward: 194.9
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(219,4130)'), ('usv_2', '(218,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2636223263953038), 'usv_1': np.float64(-0.6331457827230801)}
    Episode time: 9.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 1099, Avg Reward: 10.047, Episode Reward: 11041.8
    æ£€æµ‹è¿›åº¦: 3/26 (11.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3123)'), ('usv_1', '(253,4103)'), ('usv_2', '(247,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(4.263166890826565), 'usv_1': np.float64(3.373669851153746)}
    Episode time: 109.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.13858317 0.08244298] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 2099, Avg Reward: 12.650, Episode Reward: 26552.0
    æ£€æµ‹è¿›åº¦: 6/63 (9.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3143)'), ('usv_1', '(268,4051)'), ('usv_2', '(287,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(4.263337972528664), 'usv_1': np.float64(-6.626721961789327)}
    Episode time: 209.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 29165.1
  Targets Detected: 7/90 (7.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.72
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 98, Avg Reward: -3.911, Episode Reward: -383.3
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3130)'), ('usv_1', '(217,4130)'), ('usv_2', '(215,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7372570059464665), 'usv_1': np.float64(-1.6334525698259699)}
    Episode time: 9.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 1098, Avg Reward: 3.451, Episode Reward: 3789.4
    æ£€æµ‹è¿›åº¦: 3/40 (7.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3108)'), ('usv_1', '(239,4080)'), ('usv_2', '(247,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2675391629230925), 'usv_1': np.float64(2.371172391954602)}
    Episode time: 109.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 2098, Avg Reward: 10.692, Episode Reward: 22431.1
    æ£€æµ‹è¿›åº¦: 4/67 (6.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,3118)'), ('usv_1', '(203,4055)'), ('usv_2', '(251,5082)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2640787286954906), 'usv_1': np.float64(3.3695523403648906)}
    Episode time: 209.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 31814.7
  Targets Detected: 6/83 (3.6%)
  Steps: 2619
  Episode Time: 261.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.15
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 479, Avg Reward: 14.138, Episode Reward: 6772.0
    æ£€æµ‹è¿›åº¦: 2/22 (9.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3125)'), ('usv_1', '(232,4113)'), ('usv_2', '(228,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2648178048299246), 'usv_1': np.float64(0.36775670731876753)}
    Episode time: 47.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.33654978 -0.26522611] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 1479, Avg Reward: 12.289, Episode Reward: 18175.5
    æ£€æµ‹è¿›åº¦: 1/43 (2.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3104)'), ('usv_1', '(224,4066)'), ('usv_2', '(264,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2649550104292848), 'usv_1': np.float64(0.3678138581990973)}
    Episode time: 147.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 21816.4
  Targets Detected: 4/56 (3.6%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_161s
  Average Reward/Step: 12.11
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 678, Avg Reward: 8.684, Episode Reward: 5887.6
    æ£€æµ‹è¿›åº¦: 3/23 (13.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3117)'), ('usv_1', '(242,4118)'), ('usv_2', '(243,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(4.266845073186265), 'usv_1': np.float64(3.368972503398645)}
    Episode time: 67.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 1678, Avg Reward: 16.156, Episode Reward: 27109.1
    æ£€æµ‹è¿›åº¦: 4/52 (7.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3135)'), ('usv_1', '(271,4076)'), ('usv_2', '(246,5086)')]...
    Recent rewards sample: {'usv_0': np.float64(4.259459816571676), 'usv_1': np.float64(3.3711308590188382)}
    Episode time: 167.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 2678, Avg Reward: 17.979, Episode Reward: 48148.6
    æ£€æµ‹è¿›åº¦: 6/88 (6.8%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3166)'), ('usv_1', '(257,4034)'), ('usv_2', '(217,5062)')]...
    Recent rewards sample: {'usv_0': np.float64(2.256480594388671), 'usv_1': np.float64(3.3765276342471875)}
    Episode time: 267.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 54390.4
  Targets Detected: 9/94 (6.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.12
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 677, Avg Reward: 3.708, Episode Reward: 2510.4
    æ£€æµ‹è¿›åº¦: 1/27 (3.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3121)'), ('usv_1', '(241,4117)'), ('usv_2', '(238,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26688928946179924), 'usv_1': np.float64(-0.6305415018811709)}
    Episode time: 67.7s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.04407807 0.01061459] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Step 100000, Episode Steps: 1677, Avg Reward: 8.450, Episode Reward: 14170.7
    æ£€æµ‹è¿›åº¦: 7/61 (11.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3099)'), ('usv_1', '(225,4082)'), ('usv_2', '(264,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(4.268979325076762), 'usv_1': np.float64(-6.6304449673015196)}
    Episode time: 167.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Step 101000, Episode Steps: 2677, Avg Reward: 5.893, Episode Reward: 15775.6
    æ£€æµ‹è¿›åº¦: 9/77 (11.7%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3114)'), ('usv_1', '(201,4076)'), ('usv_2', '(300,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(2.268190224177172), 'usv_1': np.float64(3.3659088984624015)}
    Episode time: 267.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 21619.7
  Targets Detected: 10/79 (8.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.20
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Step 102000, Episode Steps: 676, Avg Reward: 1.076, Episode Reward: 727.2
    æ£€æµ‹è¿›åº¦: 1/24 (4.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3130)'), ('usv_1', '(235,4128)'), ('usv_2', '(230,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27088271539751296), 'usv_1': np.float64(1.3739228798296992)}
    Episode time: 67.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Step 103000, Episode Steps: 1676, Avg Reward: 6.512, Episode Reward: 10914.6
    æ£€æµ‹è¿›åº¦: 2/54 (3.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3106)'), ('usv_1', '(262,4076)'), ('usv_2', '(206,5086)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2862417747029524), 'usv_1': np.float64(-7.624600260007966)}
    Episode time: 167.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Step 104000, Episode Steps: 2676, Avg Reward: 6.239, Episode Reward: 16694.9
    æ£€æµ‹è¿›åº¦: 7/80 (8.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3120)'), ('usv_1', '(214,4057)'), ('usv_2', '(202,5095)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2687705403350513), 'usv_1': np.float64(3.3672786699454242)}
    Episode time: 267.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 24277.4
  Targets Detected: 8/91 (7.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.09
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.10292154 -0.08588474] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Step 105000, Episode Steps: 675, Avg Reward: 11.743, Episode Reward: 7926.5
    æ£€æµ‹è¿›åº¦: 3/18 (16.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3132)'), ('usv_1', '(242,4124)'), ('usv_2', '(237,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(4.273902878046128), 'usv_1': np.float64(1.3685085633137337)}
    Episode time: 67.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Step 106000, Episode Steps: 1675, Avg Reward: 14.094, Episode Reward: 23606.9
    æ£€æµ‹è¿›åº¦: 8/52 (15.4%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3130)'), ('usv_1', '(237,4091)'), ('usv_2', '(244,5097)')]...
    Recent rewards sample: {'usv_0': np.float64(4.275807681568715), 'usv_1': np.float64(-8.629963632896558)}
    Episode time: 167.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Step 107000, Episode Steps: 2675, Avg Reward: 8.880, Episode Reward: 23755.2
    æ£€æµ‹è¿›åº¦: 8/79 (10.1%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,3139)'), ('usv_1', '(204,4100)'), ('usv_2', '(228,5068)')]...
    Recent rewards sample: {'usv_0': np.float64(4.271343612379124), 'usv_1': np.float64(-8.63424511263224)}
    Episode time: 267.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 25742.3
  Targets Detected: 9/83 (9.6%)
  Steps: 2814
  Episode Time: 281.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 9.15

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 27949.6
Last 10 episodes average detections: 6.4
Best episode reward so far: 54390.4
Best detection count so far: 13
Learning trend: Improving (27949.6 vs 27860.4)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Step 108000, Episode Steps: 861, Avg Reward: 10.202, Episode Reward: 8783.8
    æ£€æµ‹è¿›åº¦: 4/28 (14.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3107)'), ('usv_1', '(254,4109)'), ('usv_2', '(226,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(2.273818795930441), 'usv_1': np.float64(1.369484312151342)}
    Episode time: 86.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Step 109000, Episode Steps: 1861, Avg Reward: 10.750, Episode Reward: 20006.5
    æ£€æµ‹è¿›åº¦: 9/61 (14.8%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3110)'), ('usv_1', '(247,4073)'), ('usv_2', '(233,5087)')]...
    Recent rewards sample: {'usv_0': np.float64(4.265923082834125), 'usv_1': np.float64(-6.627607551333817)}
    Episode time: 186.1s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.15816865 0.00415454] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Step 110000, Episode Steps: 2861, Avg Reward: 7.540, Episode Reward: 21572.3
    æ£€æµ‹è¿›åº¦: 12/89 (13.5%), Episode total: 14
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3135)'), ('usv_1', '(213,4080)'), ('usv_2', '(213,5049)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2641721300965125), 'usv_1': np.float64(-6.628274209454791)}
    Episode time: 286.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 22231.8
  Targets Detected: 15/94 (13.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.41
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Step 111000, Episode Steps: 860, Avg Reward: -0.197, Episode Reward: -169.4
    æ£€æµ‹è¿›åº¦: 2/37 (5.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3120)'), ('usv_1', '(253,4119)'), ('usv_2', '(246,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2671020258130695), 'usv_1': np.float64(-0.630019704688351)}
    Episode time: 86.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Step 112000, Episode Steps: 1860, Avg Reward: 11.033, Episode Reward: 20520.6
    æ£€æµ‹è¿›åº¦: 5/68 (7.4%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3111)'), ('usv_1', '(275,4061)'), ('usv_2', '(279,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(4.263570971552358), 'usv_1': np.float64(1.3795828740136882)}
    Episode time: 186.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 35442.4
  Targets Detected: 5/89 (5.6%)
  Steps: 2685
  Episode Time: 268.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.20
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Step 113000, Episode Steps: 175, Avg Reward: -3.919, Episode Reward: -685.7
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3129)'), ('usv_1', '(223,4130)'), ('usv_2', '(218,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7348744854217159), 'usv_1': np.float64(-1.6330017503628267)}
    Episode time: 17.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Step 114000, Episode Steps: 1175, Avg Reward: 4.340, Episode Reward: 5099.4
    æ£€æµ‹è¿›åº¦: 2/42 (4.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3112)'), ('usv_1', '(227,4087)'), ('usv_2', '(231,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(4.270750821829066), 'usv_1': np.float64(1.3736576865515042)}
    Episode time: 117.5s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.13995561 -0.32786232] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Step 115000, Episode Steps: 2175, Avg Reward: 10.213, Episode Reward: 22213.5
    æ£€æµ‹è¿›åº¦: 4/75 (5.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3088)'), ('usv_1', '(209,4095)'), ('usv_2', '(242,5085)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2720856755338654), 'usv_1': np.float64(1.3661485208000825)}
    Episode time: 217.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 36714.1
  Targets Detected: 5/86 (5.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.23
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Step 116000, Episode Steps: 174, Avg Reward: -0.056, Episode Reward: -9.7
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3129)'), ('usv_1', '(219,4127)'), ('usv_2', '(219,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2653269527156747), 'usv_1': np.float64(0.36723342952170523)}
    Episode time: 17.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Step 117000, Episode Steps: 1174, Avg Reward: 14.135, Episode Reward: 16595.0
    æ£€æµ‹è¿›åº¦: 3/45 (6.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3124)'), ('usv_1', '(213,4082)'), ('usv_2', '(244,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(4.263951211180765), 'usv_1': np.float64(1.3698601062968394)}
    Episode time: 117.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 33641.9
  Targets Detected: 5/71 (4.2%)
  Steps: 2052
  Episode Time: 205.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.39
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Step 118000, Episode Steps: 122, Avg Reward: -3.917, Episode Reward: -477.9
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3130)'), ('usv_1', '(224,4129)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7342779434663896), 'usv_1': np.float64(-1.632931813377289)}
    Episode time: 12.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Step 119000, Episode Steps: 1122, Avg Reward: 4.009, Episode Reward: 4497.8
    æ£€æµ‹è¿›åº¦: 3/28 (10.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3119)'), ('usv_1', '(273,4114)'), ('usv_2', '(246,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2719776804339615), 'usv_1': np.float64(2.376151109244271)}
    Episode time: 112.2s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.23604603  0.19432585] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Step 120000, Episode Steps: 2122, Avg Reward: 8.293, Episode Reward: 17597.7
    æ£€æµ‹è¿›åº¦: 5/59 (8.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3119)'), ('usv_1', '(260,4065)'), ('usv_2', '(253,5070)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2616076192377728), 'usv_1': np.float64(-6.627549006870229)}
    Episode time: 212.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 20802.7
  Targets Detected: 10/80 (8.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 6.93
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Step 121000, Episode Steps: 121, Avg Reward: -3.916, Episode Reward: -473.8
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7359632538886911), 'usv_1': np.float64(-1.6336447169296247)}
    Episode time: 12.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Step 122000, Episode Steps: 1121, Avg Reward: -1.029, Episode Reward: -1153.9
    æ£€æµ‹è¿›åº¦: 1/36 (2.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3112)'), ('usv_1', '(213,4082)'), ('usv_2', '(246,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2788983638605337), 'usv_1': np.float64(-0.6266714120531607)}
    Episode time: 112.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Step 123000, Episode Steps: 2121, Avg Reward: 0.882, Episode Reward: 1871.6
    æ£€æµ‹è¿›åº¦: 3/59 (5.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3092)'), ('usv_1', '(207,4037)'), ('usv_2', '(278,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2747824681935302), 'usv_1': np.float64(-8.628650450528863)}
    Episode time: 212.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 17035.2
  Targets Detected: 5/75 (5.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.68
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Step 124000, Episode Steps: 120, Avg Reward: 13.574, Episode Reward: 1628.8
    æ£€æµ‹è¿›åº¦: 1/8 (12.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(218,4129)'), ('usv_2', '(214,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2645923312872669), 'usv_1': np.float64(1.371658717412088)}
    Episode time: 12.0s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.21997339 -0.01257947] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Step 125000, Episode Steps: 1120, Avg Reward: 5.145, Episode Reward: 5762.8
    æ£€æµ‹è¿›åº¦: 1/37 (2.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3118)'), ('usv_1', '(241,4099)'), ('usv_2', '(257,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2678385900947653), 'usv_1': np.float64(1.3709567844863133)}
    Episode time: 112.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Step 126000, Episode Steps: 2120, Avg Reward: 6.011, Episode Reward: 12744.1
    æ£€æµ‹è¿›åº¦: 3/63 (4.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3112)'), ('usv_1', '(208,4078)'), ('usv_2', '(288,5156)')]...
    Recent rewards sample: {'usv_0': np.float64(4.264259782565602), 'usv_1': np.float64(-6.625636337789633)}
    Episode time: 212.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 22660.8
  Targets Detected: 6/81 (6.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.55
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Step 127000, Episode Steps: 119, Avg Reward: 10.049, Episode Reward: 1195.9
    æ£€æµ‹è¿›åº¦: 1/1 (100.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(216,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(2.264066453985383), 'usv_1': np.float64(-0.6272403251708921)}
    Episode time: 11.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Step 128000, Episode Steps: 1119, Avg Reward: 13.060, Episode Reward: 14614.0
    æ£€æµ‹è¿›åº¦: 3/27 (11.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3104)'), ('usv_1', '(240,4105)'), ('usv_2', '(229,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(4.276248514527651), 'usv_1': np.float64(1.3743620090670472)}
    Episode time: 111.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 29314.1
  Targets Detected: 5/51 (3.9%)
  Steps: 1930
  Episode Time: 193.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.19
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Step 129000, Episode Steps: 189, Avg Reward: 3.890, Episode Reward: 735.1
    æ£€æµ‹è¿›åº¦: 1/3 (33.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3131)'), ('usv_1', '(231,4130)'), ('usv_2', '(225,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2702447959983091), 'usv_1': np.float64(-0.6207811795526743)}
    Episode time: 18.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.27049591  0.13029849] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Step 130000, Episode Steps: 1189, Avg Reward: 15.834, Episode Reward: 18826.6
    æ£€æµ‹è¿›åº¦: 4/28 (14.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3119)'), ('usv_1', '(248,4106)'), ('usv_2', '(252,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2711934229749313), 'usv_1': np.float64(1.3720081868437526)}
    Episode time: 118.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Step 131000, Episode Steps: 2189, Avg Reward: 16.331, Episode Reward: 35748.7
    æ£€æµ‹è¿›åº¦: 6/54 (11.1%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3116)'), ('usv_1', '(209,4093)'), ('usv_2', '(261,5090)')]...
    Recent rewards sample: {'usv_0': np.float64(2.268058089320295), 'usv_1': np.float64(1.3718807048123298)}
    Episode time: 218.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 48969.3
  Targets Detected: 8/80 (10.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.32
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 132000...
    MADDPG UPDATE finished.
    Step 132000, Episode Steps: 188, Avg Reward: -3.919, Episode Reward: -736.9
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3128)'), ('usv_1', '(223,4131)'), ('usv_2', '(219,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7342268821663931), 'usv_1': np.float64(-1.6329851126518946)}
    Episode time: 18.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 133000...
    MADDPG UPDATE finished.
    Step 133000, Episode Steps: 1188, Avg Reward: 1.374, Episode Reward: 1632.3
    æ£€æµ‹è¿›åº¦: 0/32 (0.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3115)'), ('usv_1', '(255,4101)'), ('usv_2', '(241,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2621482018125637), 'usv_1': np.float64(-0.6238418406980928)}
    Episode time: 118.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 4317.4
  Targets Detected: 1/47 (0.0%)
  Steps: 1827
  Episode Time: 182.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 2.36

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 27113.0
Last 10 episodes average detections: 6.5
Best episode reward so far: 54390.4
Best detection count so far: 15
Learning trend: Declining (27113.0 vs 27949.6)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 54390.4
Final 10 episodes average: 27113.0
Best detection performance: 15 targets
Average detections (final 10): 6.5
============================================================
{"final_avg_reward": 27112.965549367655, "final_detection_rate": 6.5, "best_episode_reward": 54390.36854838566, "best_detection_count": 15, "total_episodes": 50}
Simulation finished.
