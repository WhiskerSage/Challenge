D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: 9.254, Episode Reward: 9254.2
    æ£€æµ‹è¿›åº¦: 4/25 (16.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3132)'), ('usv_1', '(313,4101)'), ('usv_2', '(243,5150)')]...
    Recent rewards sample: {'usv_0': np.float64(4.374330198128794), 'usv_1': np.float64(1.4822991548789313)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 13.933, Episode Reward: 27865.3
    æ£€æµ‹è¿›åº¦: 6/52 (11.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(298,3128)'), ('usv_1', '(367,4032)'), ('usv_2', '(220,5178)')]...
    Recent rewards sample: {'usv_0': np.float64(4.385182005373992), 'usv_1': np.float64(-3.517170103507538)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 3000, Avg Reward: 13.029, Episode Reward: 39086.3
    æ£€æµ‹è¿›åº¦: 6/66 (9.1%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(337,3115)'), ('usv_1', '(345,3951)'), ('usv_2', '(216,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3969540561013405), 'usv_1': np.float64(-3.518287822828399)}
    Episode time: 300.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 39097.2
  Targets Detected: 8/66 (9.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.03
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 999, Avg Reward: 10.117, Episode Reward: 10106.7
    æ£€æµ‹è¿›åº¦: 5/23 (21.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3121)'), ('usv_1', '(297,4107)'), ('usv_2', '(266,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(4.377890589233023), 'usv_1': np.float64(1.4776615428331805)}
    Episode time: 99.9s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.14572874 -0.10623412] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 1999, Avg Reward: 16.907, Episode Reward: 33798.0
    æ£€æµ‹è¿›åº¦: 6/47 (12.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(300,3089)'), ('usv_1', '(354,4040)'), ('usv_2', '(307,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(4.391422372974161), 'usv_1': np.float64(3.481262525336721)}
    Episode time: 199.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 2999, Avg Reward: 20.737, Episode Reward: 62189.5
    æ£€æµ‹è¿›åº¦: 8/57 (14.0%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(342,3071)'), ('usv_1', '(275,4038)'), ('usv_2', '(339,5184)')]...
    Recent rewards sample: {'usv_0': np.float64(7.98148880246095), 'usv_1': np.float64(3.4721706101327374)}
    Episode time: 299.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 62242.1
  Targets Detected: 10/57 (14.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.74
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 998, Avg Reward: -3.630, Episode Reward: -3622.5
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3130)'), ('usv_1', '(305,4080)'), ('usv_2', '(243,5162)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6238738597174096), 'usv_1': np.float64(-1.517118592677665)}
    Episode time: 99.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: -9166.7
  Targets Detected: 0/22 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -5.09
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 197, Avg Reward: -3.540, Episode Reward: -697.4
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3130)'), ('usv_1', '(221,4124)'), ('usv_2', '(223,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6301937658455447), 'usv_1': np.float64(-1.5291241638251212)}
    Episode time: 19.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 1197, Avg Reward: -0.498, Episode Reward: -595.9
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3128)'), ('usv_1', '(248,4046)'), ('usv_2', '(231,5165)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3735698487846548), 'usv_1': np.float64(-0.519164235947587)}
    Episode time: 119.7s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.14742264 -0.5093791 ] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 2197, Avg Reward: 3.670, Episode Reward: 8063.8
    æ£€æµ‹è¿›åº¦: 3/31 (9.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3100)'), ('usv_1', '(211,3962)'), ('usv_2', '(209,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3795747070711126), 'usv_1': np.float64(1.4706358709922047)}
    Episode time: 219.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 17367.0
  Targets Detected: 4/41 (4.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.79
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 196, Avg Reward: -3.213, Episode Reward: -629.8
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3130)'), ('usv_1', '(222,4129)'), ('usv_2', '(215,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6357667191270934), 'usv_1': np.float64(-1.5330819580844879)}
    Episode time: 19.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 1196, Avg Reward: -3.228, Episode Reward: -3860.4
    æ£€æµ‹è¿›åº¦: 1/17 (5.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3099)'), ('usv_1', '(296,4059)'), ('usv_2', '(204,5165)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6244185439496622), 'usv_1': np.float64(-1.525792836997055)}
    Episode time: 119.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 2196, Avg Reward: -0.697, Episode Reward: -1531.6
    æ£€æµ‹è¿›åº¦: 2/38 (5.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3064)'), ('usv_1', '(273,3965)'), ('usv_2', '(211,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(4.975339959624324), 'usv_1': np.float64(-4.521643277409895)}
    Episode time: 219.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 8055.0
  Targets Detected: 5/49 (6.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 2.68
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 195, Avg Reward: -3.207, Episode Reward: -625.4
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3130)'), ('usv_1', '(226,4131)'), ('usv_2', '(230,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6356614651839011), 'usv_1': np.float64(-1.5221971917541173)}
    Episode time: 19.5s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.02947463  0.11253969] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 1195, Avg Reward: -3.262, Episode Reward: -3898.7
    æ£€æµ‹è¿›åº¦: 0/17 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3109)'), ('usv_1', '(313,4125)'), ('usv_2', '(281,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6246530807433982), 'usv_1': np.float64(-1.5179846200102463)}
    Episode time: 119.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: -5844.9
  Targets Detected: 0/21 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.25
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 394, Avg Reward: 3.614, Episode Reward: 1423.8
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3127)'), ('usv_1', '(245,4116)'), ('usv_2', '(230,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(0.36695055538473065), 'usv_1': np.float64(-0.5218271143640598)}
    Episode time: 39.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 1394, Avg Reward: 13.351, Episode Reward: 18611.3
    æ£€æµ‹è¿›åº¦: 2/26 (7.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3088)'), ('usv_1', '(293,4027)'), ('usv_2', '(246,5173)')]...
    Recent rewards sample: {'usv_0': np.float64(2.37749387526529), 'usv_1': np.float64(1.473749417971593)}
    Episode time: 139.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 25096.9
  Targets Detected: 4/32 (3.1%)
  Steps: 1941
  Episode Time: 194.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.93
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 453, Avg Reward: -2.721, Episode Reward: -1232.5
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3125)'), ('usv_1', '(269,4126)'), ('usv_2', '(228,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3789667698174929), 'usv_1': np.float64(-0.521454143649133)}
    Episode time: 45.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 1453, Avg Reward: 10.535, Episode Reward: 15307.7
    æ£€æµ‹è¿›åº¦: 4/28 (14.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3089)'), ('usv_1', '(347,4081)'), ('usv_2', '(217,5183)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3854788998884575), 'usv_1': np.float64(3.480013567144507)}
    Episode time: 145.3s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.32193357 -0.40573349] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 2453, Avg Reward: 15.940, Episode Reward: 39102.0
    æ£€æµ‹è¿›åº¦: 5/54 (9.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3059)'), ('usv_1', '(398,3995)'), ('usv_2', '(203,5179)')]...
    Recent rewards sample: {'usv_0': np.float64(7.971369443989293), 'usv_1': np.float64(3.4890449307820655)}
    Episode time: 245.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 44363.6
  Targets Detected: 6/59 (6.8%)
  Steps: 2669
  Episode Time: 266.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.62
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 784, Avg Reward: 8.049, Episode Reward: 6310.2
    æ£€æµ‹è¿›åº¦: 3/8 (37.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3125)'), ('usv_1', '(289,4111)'), ('usv_2', '(238,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(2.370917769956395), 'usv_1': np.float64(1.480872697015279)}
    Episode time: 78.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 1784, Avg Reward: 14.738, Episode Reward: 26293.4
    æ£€æµ‹è¿›åº¦: 6/21 (28.6%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(296,3140)'), ('usv_1', '(344,4022)'), ('usv_2', '(204,5171)')]...
    Recent rewards sample: {'usv_0': np.float64(4.383059468025184), 'usv_1': np.float64(1.4850514349367896)}
    Episode time: 178.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 42980.3
  Targets Detected: 7/30 (20.0%)
  Steps: 2638
  Episode Time: 263.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.29
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 146, Avg Reward: 9.061, Episode Reward: 1322.9
    æ£€æµ‹è¿›åº¦: 1/5 (20.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3129)'), ('usv_1', '(221,4129)'), ('usv_2', '(216,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3693084529794053), 'usv_1': np.float64(-0.5330426825729696)}
    Episode time: 14.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 1146, Avg Reward: 15.664, Episode Reward: 17951.4
    æ£€æµ‹è¿›åº¦: 2/22 (9.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3104)'), ('usv_1', '(336,4137)'), ('usv_2', '(236,5180)')]...
    Recent rewards sample: {'usv_0': np.float64(2.377595850628972), 'usv_1': np.float64(1.4861374910802807)}
    Episode time: 114.6s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.15433554  0.24683593] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 2146, Avg Reward: 17.642, Episode Reward: 37860.7
    æ£€æµ‹è¿›åº¦: 3/42 (7.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3069)'), ('usv_1', '(403,4090)'), ('usv_2', '(211,5192)')]...
    Recent rewards sample: {'usv_0': np.float64(5.9690031473038605), 'usv_1': np.float64(1.4818638700506885)}
    Episode time: 214.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 54908.0
  Targets Detected: 5/55 (7.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.30

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 27909.8
Last 10 episodes average detections: 4.9
Best episode reward so far: 62242.1
Best detection count so far: 10
Buffer size: 25855
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 145, Avg Reward: -4.065, Episode Reward: -589.4
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(222,4129)'), ('usv_2', '(217,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6814477928121238), 'usv_1': np.float64(-1.5830854092705386)}
    Episode time: 14.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 1145, Avg Reward: 11.767, Episode Reward: 13473.4
    æ£€æµ‹è¿›åº¦: 4/24 (16.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3134)'), ('usv_1', '(291,4086)'), ('usv_2', '(240,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(4.32182860367249), 'usv_1': np.float64(3.4277362243682736)}
    Episode time: 114.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 2145, Avg Reward: 13.842, Episode Reward: 29692.1
    æ£€æµ‹è¿›åº¦: 5/38 (13.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3133)'), ('usv_1', '(302,4001)'), ('usv_2', '(216,5183)')]...
    Recent rewards sample: {'usv_0': np.float64(4.330278554430505), 'usv_1': np.float64(-6.569370683260619)}
    Episode time: 214.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 34173.8
  Targets Detected: 8/64 (9.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.39
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 144, Avg Reward: -3.619, Episode Reward: -521.2
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3129)'), ('usv_1', '(219,4130)'), ('usv_2', '(223,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6788801951803561), 'usv_1': np.float64(-1.5772427223781247)}
    Episode time: 14.4s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.23006102 -0.0555403 ] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 1144, Avg Reward: -0.126, Episode Reward: -144.0
    æ£€æµ‹è¿›åº¦: 1/37 (2.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3121)'), ('usv_1', '(315,4087)'), ('usv_2', '(213,5162)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3265760310456516), 'usv_1': np.float64(1.4258545007364205)}
    Episode time: 114.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: -2781.2
  Targets Detected: 1/55 (0.0%)
  Steps: 2047
  Episode Time: 204.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: -1.36
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 97, Avg Reward: -4.077, Episode Reward: -395.5
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(224,4130)'), ('usv_2', '(216,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.686960508586854), 'usv_1': np.float64(-1.5829238822167113)}
    Episode time: 9.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 1097, Avg Reward: 3.449, Episode Reward: 3783.9
    æ£€æµ‹è¿›åº¦: 1/28 (3.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3126)'), ('usv_1', '(334,4117)'), ('usv_2', '(262,5166)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3264679331098597), 'usv_1': np.float64(-0.5713387853523033)}
    Episode time: 109.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 6817.1
  Targets Detected: 1/38 (2.6%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_158s
  Average Reward/Step: 3.79
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 296, Avg Reward: 4.164, Episode Reward: 1232.5
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3132)'), ('usv_1', '(237,4130)'), ('usv_2', '(221,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3182100887717496), 'usv_1': np.float64(-0.5819255206572135)}
    Episode time: 29.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 1296, Avg Reward: 10.466, Episode Reward: 13564.0
    æ£€æµ‹è¿›åº¦: 3/32 (9.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3135)'), ('usv_1', '(301,4059)'), ('usv_2', '(202,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(2.32628657359858), 'usv_1': np.float64(3.424589931291049)}
    Episode time: 129.6s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.18176404 -0.19981221] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 2296, Avg Reward: 13.493, Episode Reward: 30979.7
    æ£€æµ‹è¿›åº¦: 4/45 (8.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(290,3160)'), ('usv_1', '(246,3986)'), ('usv_2', '(207,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3388239158704556), 'usv_1': np.float64(3.4217820640644225)}
    Episode time: 229.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 35831.0
  Targets Detected: 5/47 (8.5%)
  Steps: 2558
  Episode Time: 255.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.01
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 738, Avg Reward: 10.159, Episode Reward: 7497.6
    æ£€æµ‹è¿›åº¦: 2/30 (6.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3124)'), ('usv_1', '(265,4110)'), ('usv_2', '(233,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3251352921259536), 'usv_1': np.float64(0.42371403944546815)}
    Episode time: 73.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 1738, Avg Reward: 11.750, Episode Reward: 20422.2
    æ£€æµ‹è¿›åº¦: 4/54 (7.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3101)'), ('usv_1', '(250,4010)'), ('usv_2', '(207,5150)')]...
    Recent rewards sample: {'usv_0': np.float64(4.336322507707598), 'usv_1': np.float64(1.4289515111368916)}
    Episode time: 173.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 2738, Avg Reward: 16.901, Episode Reward: 46273.8
    æ£€æµ‹è¿›åº¦: 8/85 (9.4%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3083)'), ('usv_1', '(203,3944)'), ('usv_2', '(243,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(7.91781096226584), 'usv_1': np.float64(3.4210063540457183)}
    Episode time: 273.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 52511.1
  Targets Detected: 12/94 (9.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.50
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 737, Avg Reward: 1.860, Episode Reward: 1370.7
    æ£€æµ‹è¿›åº¦: 2/19 (10.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3117)'), ('usv_1', '(303,4106)'), ('usv_2', '(242,5151)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32558037202612755), 'usv_1': np.float64(-0.5606489093652547)}
    Episode time: 73.7s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.11828787  0.07722895] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 1737, Avg Reward: 6.007, Episode Reward: 10434.4
    æ£€æµ‹è¿›åº¦: 3/45 (6.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(309,3103)'), ('usv_1', '(386,4053)'), ('usv_2', '(221,5161)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3445365480310236), 'usv_1': np.float64(2.4439139656653737)}
    Episode time: 173.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 2737, Avg Reward: 10.400, Episode Reward: 28464.0
    æ£€æµ‹è¿›åº¦: 5/75 (6.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(339,3071)'), ('usv_1', '(375,3974)'), ('usv_2', '(217,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(5.930262044978444), 'usv_1': np.float64(3.43151416851214)}
    Episode time: 273.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 35522.4
  Targets Detected: 6/83 (7.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.84
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 736, Avg Reward: 14.167, Episode Reward: 10427.3
    æ£€æµ‹è¿›åº¦: 3/22 (13.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3128)'), ('usv_1', '(282,4123)'), ('usv_2', '(247,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3230600478045997), 'usv_1': np.float64(1.429516169708394)}
    Episode time: 73.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 1736, Avg Reward: 15.940, Episode Reward: 27671.3
    æ£€æµ‹è¿›åº¦: 2/41 (4.9%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3099)'), ('usv_1', '(368,4057)'), ('usv_2', '(269,5175)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3345062499443365), 'usv_1': np.float64(1.4340013379136227)}
    Episode time: 173.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 33174.0
  Targets Detected: 4/59 (3.4%)
  Steps: 2185
  Episode Time: 218.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.18
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 551, Avg Reward: 1.314, Episode Reward: 724.0
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3126)'), ('usv_1', '(255,4104)'), ('usv_2', '(228,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(0.316724325589647), 'usv_1': np.float64(-0.5764641663396797)}
    Episode time: 55.1s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.27477204  0.00276817] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 1551, Avg Reward: 6.230, Episode Reward: 9663.4
    æ£€æµ‹è¿›åº¦: 2/36 (5.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3092)'), ('usv_1', '(320,4018)'), ('usv_2', '(212,5182)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3307091331105658), 'usv_1': np.float64(2.4288512278059544)}
    Episode time: 155.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 18011.7
  Targets Detected: 3/50 (4.0%)
  Steps: 2352
  Episode Time: 235.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.66
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 199, Avg Reward: -3.585, Episode Reward: -713.5
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3130)'), ('usv_1', '(238,4129)'), ('usv_2', '(218,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6848912458245527), 'usv_1': np.float64(-1.5818200492382704)}
    Episode time: 19.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 1199, Avg Reward: -1.438, Episode Reward: -1724.0
    æ£€æµ‹è¿›åº¦: 1/18 (5.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3097)'), ('usv_1', '(313,4118)'), ('usv_2', '(207,5178)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3283905576850732), 'usv_1': np.float64(-0.5682889494637723)}
    Episode time: 119.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 2199, Avg Reward: 7.968, Episode Reward: 17521.8
    æ£€æµ‹è¿›åº¦: 4/39 (10.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3054)'), ('usv_1', '(387,4048)'), ('usv_2', '(203,5176)')]...
    Recent rewards sample: {'usv_0': np.float64(5.917284052493723), 'usv_1': np.float64(1.4347134884176267)}
    Episode time: 219.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 24549.3
  Targets Detected: 4/63 (6.3%)
  Steps: 2963
  Episode Time: 296.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 8.29
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 236, Avg Reward: 6.537, Episode Reward: 1542.7
    æ£€æµ‹è¿›åº¦: 1/6 (16.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3130)'), ('usv_1', '(240,4128)'), ('usv_2', '(226,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3146233800452687), 'usv_1': np.float64(-0.5758802146566622)}
    Episode time: 23.6s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.33697094 0.40499043] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 1236, Avg Reward: 10.094, Episode Reward: 12475.8
    æ£€æµ‹è¿›åº¦: 3/23 (13.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3126)'), ('usv_1', '(336,4127)'), ('usv_2', '(250,5178)')]...
    Recent rewards sample: {'usv_0': np.float64(4.331430489276405), 'usv_1': np.float64(1.43291973253694)}
    Episode time: 123.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 2236, Avg Reward: 14.013, Episode Reward: 31332.0
    æ£€æµ‹è¿›åº¦: 4/47 (8.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3135)'), ('usv_1', '(431,4082)'), ('usv_2', '(207,5168)')]...
    Recent rewards sample: {'usv_0': np.float64(4.331778614025347), 'usv_1': np.float64(1.4376422855103677)}
    Episode time: 223.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 46919.3
  Targets Detected: 5/68 (7.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.63

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 28472.8
Last 10 episodes average detections: 4.9
Best episode reward so far: 62242.1
Best detection count so far: 12
Learning trend: Improving (28472.8 vs 27909.8)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 235, Avg Reward: -3.594, Episode Reward: -844.6
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3126)'), ('usv_1', '(232,4129)'), ('usv_2', '(223,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6820325064787689), 'usv_1': np.float64(-1.5707948291476381)}
    Episode time: 23.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 1235, Avg Reward: -1.070, Episode Reward: -1320.9
    æ£€æµ‹è¿›åº¦: 1/19 (5.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(281,3123)'), ('usv_1', '(246,4044)'), ('usv_2', '(235,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3316054936635541), 'usv_1': np.float64(-0.5801367496683558)}
    Episode time: 123.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 2235, Avg Reward: 3.376, Episode Reward: 7546.2
    æ£€æµ‹è¿›åº¦: 2/45 (4.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3095)'), ('usv_1', '(201,4009)'), ('usv_2', '(210,5160)')]...
    Recent rewards sample: {'usv_0': np.float64(2.340683550379173), 'usv_1': np.float64(3.4179483767648184)}
    Episode time: 223.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 20465.9
  Targets Detected: 3/61 (1.6%)
  Steps: 2813
  Episode Time: 281.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.28
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.13081846  0.26736487] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 422, Avg Reward: -3.616, Episode Reward: -1526.1
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3129)'), ('usv_1', '(256,4122)'), ('usv_2', '(227,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6813545665122612), 'usv_1': np.float64(-1.5804580160143182)}
    Episode time: 42.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 1422, Avg Reward: 3.031, Episode Reward: 4310.7
    æ£€æµ‹è¿›åº¦: 2/25 (8.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3117)'), ('usv_1', '(331,4072)'), ('usv_2', '(230,5198)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3258968707449594), 'usv_1': np.float64(0.4256774589518366)}
    Episode time: 142.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 2422, Avg Reward: 6.738, Episode Reward: 16319.7
    æ£€æµ‹è¿›åº¦: 3/48 (6.2%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(287,3092)'), ('usv_1', '(376,3970)'), ('usv_2', '(201,5194)')]...
    Recent rewards sample: {'usv_0': np.float64(4.340651366422692), 'usv_1': np.float64(-4.564674558819416)}
    Episode time: 242.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 24010.2
  Targets Detected: 5/57 (8.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.00
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 421, Avg Reward: -4.290, Episode Reward: -1805.9
    æ£€æµ‹è¿›åº¦: 0/9 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3132)'), ('usv_1', '(253,4120)'), ('usv_2', '(226,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6804753223599932), 'usv_1': np.float64(-1.5696344837369292)}
    Episode time: 42.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 1421, Avg Reward: -3.350, Episode Reward: -4760.2
    æ£€æµ‹è¿›åº¦: 1/31 (3.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3132)'), ('usv_1', '(328,4060)'), ('usv_2', '(231,5187)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3251423033141174), 'usv_1': np.float64(2.4296169676355923)}
    Episode time: 142.1s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.00951776 0.06260078] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 2421, Avg Reward: 7.940, Episode Reward: 19221.9
    æ£€æµ‹è¿›åº¦: 4/52 (7.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(300,3139)'), ('usv_1', '(270,4024)'), ('usv_2', '(204,5188)')]...
    Recent rewards sample: {'usv_0': np.float64(4.334540459439781), 'usv_1': np.float64(3.4292523306124876)}
    Episode time: 242.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 35599.4
  Targets Detected: 9/73 (11.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.86
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 420, Avg Reward: 4.449, Episode Reward: 1868.7
    æ£€æµ‹è¿›åº¦: 2/10 (20.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3131)'), ('usv_1', '(253,4133)'), ('usv_2', '(227,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3219801851273707), 'usv_1': np.float64(-0.5806907218907704)}
    Episode time: 42.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 1420, Avg Reward: 3.275, Episode Reward: 4650.4
    æ£€æµ‹è¿›åº¦: 2/35 (5.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3117)'), ('usv_1', '(324,4104)'), ('usv_2', '(205,5189)')]...
    Recent rewards sample: {'usv_0': np.float64(2.33231558493206), 'usv_1': np.float64(-0.574870801368045)}
    Episode time: 142.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 6350.1
  Targets Detected: 2/37 (5.4%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_165s
  Average Reward/Step: 3.53
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 619, Avg Reward: 2.222, Episode Reward: 1375.1
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3127)'), ('usv_1', '(275,4119)'), ('usv_2', '(238,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(0.326536075999065), 'usv_1': np.float64(-0.573301913438985)}
    Episode time: 61.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 1619, Avg Reward: 5.298, Episode Reward: 8577.7
    æ£€æµ‹è¿›åº¦: 2/30 (6.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3096)'), ('usv_1', '(354,4088)'), ('usv_2', '(232,5187)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3329638703987365), 'usv_1': np.float64(3.427785704201309)}
    Episode time: 161.9s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.0564448  0.03028405] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 2619, Avg Reward: 12.942, Episode Reward: 33895.8
    æ£€æµ‹è¿›åº¦: 5/50 (10.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3060)'), ('usv_1', '(401,3998)'), ('usv_2', '(205,5183)')]...
    Recent rewards sample: {'usv_0': np.float64(5.919055540093234), 'usv_1': np.float64(3.4375961658313434)}
    Episode time: 261.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 43070.9
  Targets Detected: 5/52 (7.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.35
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 618, Avg Reward: 10.427, Episode Reward: 6443.8
    æ£€æµ‹è¿›åº¦: 3/11 (27.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3121)'), ('usv_1', '(265,4131)'), ('usv_2', '(250,5150)')]...
    Recent rewards sample: {'usv_0': np.float64(4.323618862210493), 'usv_1': np.float64(1.4227230469683514)}
    Episode time: 61.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 1618, Avg Reward: 16.048, Episode Reward: 25965.5
    æ£€æµ‹è¿›åº¦: 4/38 (10.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3087)'), ('usv_1', '(354,4081)'), ('usv_2', '(235,5193)')]...
    Recent rewards sample: {'usv_0': np.float64(4.328921954040991), 'usv_1': np.float64(3.442896140392307)}
    Episode time: 161.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 40083.8
  Targets Detected: 4/59 (6.8%)
  Steps: 2575
  Episode Time: 257.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.57
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 43, Avg Reward: -3.408, Episode Reward: -146.5
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(215,4130)'), ('usv_2', '(220,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6826243799423855), 'usv_1': np.float64(-1.5801224924907067)}
    Episode time: 4.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 1043, Avg Reward: -3.714, Episode Reward: -3873.3
    æ£€æµ‹è¿›åº¦: 1/20 (5.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3115)'), ('usv_1', '(298,4124)'), ('usv_2', '(245,5168)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6744112214252581), 'usv_1': np.float64(-1.566936434775082)}
    Episode time: 104.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: -5146.7
  Targets Detected: 1/41 (2.4%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_164s
  Average Reward/Step: -2.86
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.11030665 -0.01928002] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 242, Avg Reward: 7.308, Episode Reward: 1768.5
    æ£€æµ‹è¿›åº¦: 1/5 (20.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3131)'), ('usv_1', '(235,4128)'), ('usv_2', '(230,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3154379916270027), 'usv_1': np.float64(1.4242961374720897)}
    Episode time: 24.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 1242, Avg Reward: 4.937, Episode Reward: 6132.0
    æ£€æµ‹è¿›åº¦: 1/23 (4.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(266,3127)'), ('usv_1', '(301,4106)'), ('usv_2', '(295,5154)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3269388545797949), 'usv_1': np.float64(-0.566156152864723)}
    Episode time: 124.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 2242, Avg Reward: 6.126, Episode Reward: 13735.4
    æ£€æµ‹è¿›åº¦: 2/57 (3.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(313,3126)'), ('usv_1', '(358,4025)'), ('usv_2', '(283,5181)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3392377128376258), 'usv_1': np.float64(0.43974179312501116)}
    Episode time: 224.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 24016.2
  Targets Detected: 4/79 (5.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.00
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 241, Avg Reward: 5.436, Episode Reward: 1310.2
    æ£€æµ‹è¿›åº¦: 1/8 (12.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3131)'), ('usv_1', '(240,4129)'), ('usv_2', '(225,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3165540930952577), 'usv_1': np.float64(0.4268096295677086)}
    Episode time: 24.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 1241, Avg Reward: 11.891, Episode Reward: 14756.8
    æ£€æµ‹è¿›åº¦: 3/32 (9.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(266,3125)'), ('usv_1', '(304,4090)'), ('usv_2', '(251,5168)')]...
    Recent rewards sample: {'usv_0': np.float64(2.327329250865942), 'usv_1': np.float64(1.4234238459815272)}
    Episode time: 124.1s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.20782741 -0.04106234] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 2241, Avg Reward: 14.946, Episode Reward: 33494.5
    æ£€æµ‹è¿›åº¦: 4/58 (6.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(315,3105)'), ('usv_1', '(264,4030)'), ('usv_2', '(224,5196)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3449243962265798), 'usv_1': np.float64(3.432683254603938)}
    Episode time: 224.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 48314.8
  Targets Detected: 6/63 (6.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.10
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 240, Avg Reward: -4.117, Episode Reward: -988.0
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3128)'), ('usv_1', '(240,4121)'), ('usv_2', '(230,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.684301039425621), 'usv_1': np.float64(-1.5687557766061142)}
    Episode time: 24.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 1240, Avg Reward: 2.331, Episode Reward: 2890.5
    æ£€æµ‹è¿›åº¦: 1/13 (7.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(262,3105)'), ('usv_1', '(308,4077)'), ('usv_2', '(248,5171)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3327749962347544), 'usv_1': np.float64(-0.5731098862595808)}
    Episode time: 124.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 2240, Avg Reward: 7.231, Episode Reward: 16197.8
    æ£€æµ‹è¿›åº¦: 3/44 (6.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(283,3061)'), ('usv_1', '(303,3990)'), ('usv_2', '(210,5160)')]...
    Recent rewards sample: {'usv_0': np.float64(7.925271830080462), 'usv_1': np.float64(-6.574335504968669)}
    Episode time: 224.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: 19701.9
  Targets Detected: 4/56 (7.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 6.57

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 25646.7
Last 10 episodes average detections: 4.3
Best episode reward so far: 62242.1
Best detection count so far: 12
Learning trend: Declining (25646.7 vs 28472.8)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 239, Avg Reward: 2.782, Episode Reward: 664.8
    æ£€æµ‹è¿›åº¦: 1/12 (8.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3130)'), ('usv_1', '(225,4129)'), ('usv_2', '(225,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2647961291176792), 'usv_1': np.float64(0.36879710555194034)}
    Episode time: 23.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.1312646  -0.05892441] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 1239, Avg Reward: 15.983, Episode Reward: 19802.9
    æ£€æµ‹è¿›åº¦: 4/44 (9.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3141)'), ('usv_1', '(333,4122)'), ('usv_2', '(228,5180)')]...
    Recent rewards sample: {'usv_0': np.float64(2.277006102240737), 'usv_1': np.float64(3.3865741756944034)}
    Episode time: 123.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 2239, Avg Reward: 18.010, Episode Reward: 40324.3
    æ£€æµ‹è¿›åº¦: 8/69 (11.6%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3172)'), ('usv_1', '(370,4046)'), ('usv_2', '(202,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(4.274595680654769), 'usv_1': np.float64(3.383613395249238)}
    Episode time: 223.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 54874.2
  Targets Detected: 8/83 (8.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.29
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 238, Avg Reward: -4.797, Episode Reward: -1141.6
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3130)'), ('usv_1', '(240,4130)'), ('usv_2', '(224,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.734380750462486), 'usv_1': np.float64(-1.6316785354924117)}
    Episode time: 23.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 1238, Avg Reward: -3.353, Episode Reward: -4151.0
    æ£€æµ‹è¿›åº¦: 2/43 (4.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3136)'), ('usv_1', '(339,4095)'), ('usv_2', '(206,5165)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2836833056433886), 'usv_1': np.float64(-0.6212772718537857)}
    Episode time: 123.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 2238, Avg Reward: 3.538, Episode Reward: 7918.3
    æ£€æµ‹è¿›åº¦: 6/81 (7.4%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(305,3116)'), ('usv_1', '(352,4000)'), ('usv_2', '(210,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(4.288685467978716), 'usv_1': np.float64(3.3796742682086878)}
    Episode time: 223.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 22379.3
  Targets Detected: 9/100 (7.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.46
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.09393292 -0.07902737] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 237, Avg Reward: -3.968, Episode Reward: -940.4
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3128)'), ('usv_1', '(230,4130)'), ('usv_2', '(220,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7319818645635034), 'usv_1': np.float64(-1.6284121622663406)}
    Episode time: 23.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 1237, Avg Reward: 17.437, Episode Reward: 21569.0
    æ£€æµ‹è¿›åº¦: 4/43 (9.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3115)'), ('usv_1', '(328,4108)'), ('usv_2', '(205,5166)')]...
    Recent rewards sample: {'usv_0': np.float64(4.279622682702318), 'usv_1': np.float64(3.379511286112159)}
    Episode time: 123.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 36965.8
  Targets Detected: 5/53 (5.7%)
  Steps: 2026
  Episode Time: 202.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.25
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 211, Avg Reward: -3.726, Episode Reward: -786.1
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3128)'), ('usv_1', '(230,4128)'), ('usv_2', '(217,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26677565516946533), 'usv_1': np.float64(-0.6255329447501015)}
    Episode time: 21.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 1211, Avg Reward: 8.946, Episode Reward: 10833.4
    æ£€æµ‹è¿›åº¦: 1/24 (4.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3113)'), ('usv_1', '(338,4106)'), ('usv_2', '(241,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2812733753251828), 'usv_1': np.float64(0.3828991023492656)}
    Episode time: 121.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 2211, Avg Reward: 14.689, Episode Reward: 32478.0
    æ£€æµ‹è¿›åº¦: 6/48 (12.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(301,3098)'), ('usv_1', '(386,4049)'), ('usv_2', '(213,5207)')]...
    Recent rewards sample: {'usv_0': np.float64(2.290192195231824), 'usv_1': np.float64(3.3821511098100405)}
    Episode time: 221.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 46358.1
  Targets Detected: 10/67 (11.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.45
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.01565234 -0.15244611] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 210, Avg Reward: -5.391, Episode Reward: -1132.0
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3131)'), ('usv_1', '(229,4129)'), ('usv_2', '(219,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7344412718050808), 'usv_1': np.float64(-1.6325045859827494)}
    Episode time: 21.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 1210, Avg Reward: -3.034, Episode Reward: -3670.7
    æ£€æµ‹è¿›åº¦: 1/37 (2.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3117)'), ('usv_1', '(275,4069)'), ('usv_2', '(207,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2757108195627398), 'usv_1': np.float64(-0.616704242007187)}
    Episode time: 121.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 2210, Avg Reward: 0.709, Episode Reward: 1567.6
    æ£€æµ‹è¿›åº¦: 3/58 (5.2%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3067)'), ('usv_1', '(265,3987)'), ('usv_2', '(203,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(7.873408418283907), 'usv_1': np.float64(-8.620630837696453)}
    Episode time: 221.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 3377.5
  Targets Detected: 4/72 (4.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 1.13
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 209, Avg Reward: 7.233, Episode Reward: 1511.7
    æ£€æµ‹è¿›åº¦: 1/6 (16.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3133)'), ('usv_1', '(241,4129)'), ('usv_2', '(226,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2698539446940424), 'usv_1': np.float64(-0.6234775739818582)}
    Episode time: 20.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 1209, Avg Reward: 18.310, Episode Reward: 22137.4
    æ£€æµ‹è¿›åº¦: 8/40 (20.0%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3153)'), ('usv_1', '(310,4087)'), ('usv_2', '(216,5156)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2738907697414144), 'usv_1': np.float64(3.383843674737582)}
    Episode time: 120.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.17696093 0.12121714] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 2209, Avg Reward: 18.763, Episode Reward: 41448.2
    æ£€æµ‹è¿›åº¦: 8/62 (12.9%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(307,3159)'), ('usv_1', '(386,3979)'), ('usv_2', '(208,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(2.288016882128643), 'usv_1': np.float64(3.38663554664945)}
    Episode time: 220.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 46119.0
  Targets Detected: 9/71 (11.3%)
  Steps: 2454
  Episode Time: 245.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.79
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 755, Avg Reward: 20.093, Episode Reward: 15170.2
    æ£€æµ‹è¿›åº¦: 4/30 (13.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3124)'), ('usv_1', '(287,4118)'), ('usv_2', '(241,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(4.276787185953493), 'usv_1': np.float64(3.375900299251117)}
    Episode time: 75.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 1755, Avg Reward: 22.377, Episode Reward: 39271.8
    æ£€æµ‹è¿›åº¦: 9/56 (16.1%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3085)'), ('usv_1', '(335,4030)'), ('usv_2', '(251,5177)')]...
    Recent rewards sample: {'usv_0': np.float64(7.869806229352877), 'usv_1': np.float64(1.3846681931812066)}
    Episode time: 175.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 2755, Avg Reward: 24.516, Episode Reward: 67541.9
    æ£€æµ‹è¿›åº¦: 13/85 (15.3%), Episode total: 14
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3073)'), ('usv_1', '(288,3958)'), ('usv_2', '(211,5187)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8685631395393685), 'usv_1': np.float64(3.382024873974757)}
    Episode time: 275.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 74210.0
  Targets Detected: 15/89 (14.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 24.73
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 754, Avg Reward: -3.983, Episode Reward: -3003.0
    æ£€æµ‹è¿›åº¦: 0/14 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3133)'), ('usv_1', '(261,4097)'), ('usv_2', '(249,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7271034431014682), 'usv_1': np.float64(-1.6279352544804513)}
    Episode time: 75.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.04395526 -0.09458377] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Step 100000, Episode Steps: 1754, Avg Reward: 1.165, Episode Reward: 2043.0
    æ£€æµ‹è¿›åº¦: 2/52 (3.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3102)'), ('usv_1', '(320,4013)'), ('usv_2', '(221,5202)')]...
    Recent rewards sample: {'usv_0': np.float64(3.283790723132496), 'usv_1': np.float64(0.375999459606688)}
    Episode time: 175.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Step 101000, Episode Steps: 2754, Avg Reward: 1.189, Episode Reward: 3275.1
    æ£€æµ‹è¿›åº¦: 4/64 (6.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(292,3061)'), ('usv_1', '(307,3903)'), ('usv_2', '(222,5170)')]...
    Recent rewards sample: {'usv_0': np.float64(7.872914850983642), 'usv_1': np.float64(-8.620691369575926)}
    Episode time: 275.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 3710.0
  Targets Detected: 4/68 (4.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 1.24
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Step 102000, Episode Steps: 753, Avg Reward: 10.800, Episode Reward: 8132.4
    æ£€æµ‹è¿›åº¦: 3/21 (14.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3117)'), ('usv_1', '(280,4099)'), ('usv_2', '(248,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2732756554417213), 'usv_1': np.float64(3.3725471686424804)}
    Episode time: 75.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Step 103000, Episode Steps: 1753, Avg Reward: 16.224, Episode Reward: 28440.1
    æ£€æµ‹è¿›åº¦: 2/44 (4.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3079)'), ('usv_1', '(271,4019)'), ('usv_2', '(277,5161)')]...
    Recent rewards sample: {'usv_0': np.float64(5.868579222539053), 'usv_1': np.float64(3.379348827774912)}
    Episode time: 175.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 31983.8
  Targets Detected: 5/50 (4.0%)
  Steps: 1917
  Episode Time: 191.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.68
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Step 104000, Episode Steps: 836, Avg Reward: 2.934, Episode Reward: 2452.9
    æ£€æµ‹è¿›åº¦: 2/24 (8.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3114)'), ('usv_1', '(257,4074)'), ('usv_2', '(247,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2735392360181004), 'usv_1': np.float64(-0.6279495246981421)}
    Episode time: 83.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.06275539 -0.00534359] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Step 105000, Episode Steps: 1836, Avg Reward: 5.290, Episode Reward: 9712.0
    æ£€æµ‹è¿›åº¦: 4/51 (7.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3075)'), ('usv_1', '(242,3993)'), ('usv_2', '(248,5206)')]...
    Recent rewards sample: {'usv_0': np.float64(4.8684722090378925), 'usv_1': np.float64(-9.620544556585877)}
    Episode time: 183.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 6404.0
  Targets Detected: 5/70 (5.7%)
  Steps: 2399
  Episode Time: 239.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 2.67

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 32638.2
Last 10 episodes average detections: 7.4
Best episode reward so far: 74210.0
Best detection count so far: 15
Learning trend: Improving (32638.2 vs 25646.7)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Step 106000, Episode Steps: 437, Avg Reward: -3.919, Episode Reward: -1712.7
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3125)'), ('usv_1', '(253,4120)'), ('usv_2', '(239,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7329199099295032), 'usv_1': np.float64(-1.629542141794027)}
    Episode time: 43.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Step 107000, Episode Steps: 1437, Avg Reward: 5.943, Episode Reward: 8540.8
    æ£€æµ‹è¿›åº¦: 4/36 (11.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3086)'), ('usv_1', '(329,4071)'), ('usv_2', '(248,5186)')]...
    Recent rewards sample: {'usv_0': np.float64(7.872200291226728), 'usv_1': np.float64(1.380504724429735)}
    Episode time: 143.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Step 108000, Episode Steps: 2437, Avg Reward: 11.361, Episode Reward: 27686.0
    æ£€æµ‹è¿›åº¦: 6/64 (9.4%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3060)'), ('usv_1', '(380,3995)'), ('usv_2', '(204,5177)')]...
    Recent rewards sample: {'usv_0': np.float64(7.868516372190229), 'usv_1': np.float64(-8.605744567415794)}
    Episode time: 243.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 31350.8
  Targets Detected: 9/80 (8.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.45
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Step 109000, Episode Steps: 436, Avg Reward: 1.871, Episode Reward: 815.7
    æ£€æµ‹è¿›åº¦: 1/9 (11.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3133)'), ('usv_1', '(245,4119)'), ('usv_2', '(230,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2698605733106074), 'usv_1': np.float64(-0.6312558384402374)}
    Episode time: 43.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.32548664 -0.33396628] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Step 110000, Episode Steps: 1436, Avg Reward: 10.539, Episode Reward: 15133.3
    æ£€æµ‹è¿›åº¦: 4/44 (9.1%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3130)'), ('usv_1', '(311,4045)'), ('usv_2', '(209,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(2.279600246050415), 'usv_1': np.float64(1.3798867285515164)}
    Episode time: 143.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 23906.0
  Targets Detected: 7/63 (7.9%)
  Steps: 2156
  Episode Time: 215.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 11.09
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Step 111000, Episode Steps: 280, Avg Reward: -3.986, Episode Reward: -1116.0
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3131)'), ('usv_1', '(227,4128)'), ('usv_2', '(227,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26656075997013184), 'usv_1': np.float64(-0.6323798252877926)}
    Episode time: 28.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Step 112000, Episode Steps: 1280, Avg Reward: 12.134, Episode Reward: 15532.1
    æ£€æµ‹è¿›åº¦: 3/40 (7.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3144)'), ('usv_1', '(303,4080)'), ('usv_2', '(240,5181)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2769873527311653), 'usv_1': np.float64(3.3734563777634134)}
    Episode time: 128.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Step 113000, Episode Steps: 2280, Avg Reward: 16.120, Episode Reward: 36752.8
    æ£€æµ‹è¿›åº¦: 5/64 (7.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(330,3170)'), ('usv_1', '(254,3974)'), ('usv_2', '(204,5192)')]...
    Recent rewards sample: {'usv_0': np.float64(2.288444849352574), 'usv_1': np.float64(3.3727705465580966)}
    Episode time: 228.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 53425.8
  Targets Detected: 7/88 (8.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.80
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Step 114000, Episode Steps: 279, Avg Reward: 18.844, Episode Reward: 5257.5
    æ£€æµ‹è¿›åº¦: 2/14 (14.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3131)'), ('usv_1', '(231,4124)'), ('usv_2', '(224,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(2.265638646116499), 'usv_1': np.float64(3.367621480514119)}
    Episode time: 27.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.1518866  -0.18144391] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Step 115000, Episode Steps: 1279, Avg Reward: 23.246, Episode Reward: 29731.8
    æ£€æµ‹è¿›åº¦: 5/49 (10.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3125)'), ('usv_1', '(288,4044)'), ('usv_2', '(217,5176)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2731876424364925), 'usv_1': np.float64(3.374410587928521)}
    Episode time: 127.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Step 116000, Episode Steps: 2279, Avg Reward: 24.408, Episode Reward: 55626.3
    æ£€æµ‹è¿›åº¦: 8/83 (9.6%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3087)'), ('usv_1', '(286,3980)'), ('usv_2', '(205,5165)')]...
    Recent rewards sample: {'usv_0': np.float64(4.284226947749947), 'usv_1': np.float64(3.3746558644320173)}
    Episode time: 227.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 78370.1
  Targets Detected: 16/106 (12.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 26.11
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Step 117000, Episode Steps: 278, Avg Reward: 13.272, Episode Reward: 3689.5
    æ£€æµ‹è¿›åº¦: 2/11 (18.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3130)'), ('usv_1', '(239,4126)'), ('usv_2', '(222,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2687993915822724), 'usv_1': np.float64(0.37568110440296687)}
    Episode time: 27.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Step 118000, Episode Steps: 1278, Avg Reward: 17.099, Episode Reward: 21852.3
    æ£€æµ‹è¿›åº¦: 6/39 (15.4%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(268,3137)'), ('usv_1', '(339,4091)'), ('usv_2', '(230,5165)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2760199701340635), 'usv_1': np.float64(1.3810848700763567)}
    Episode time: 127.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Step 119000, Episode Steps: 2278, Avg Reward: 18.840, Episode Reward: 42918.3
    æ£€æµ‹è¿›åº¦: 9/64 (14.1%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(307,3158)'), ('usv_1', '(406,4015)'), ('usv_2', '(213,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(4.293822933097035), 'usv_1': np.float64(3.3822120974178276)}
    Episode time: 227.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 61408.6
  Targets Detected: 14/88 (12.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.46
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.1477392  -0.06797872] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Step 120000, Episode Steps: 277, Avg Reward: 9.268, Episode Reward: 2567.2
    æ£€æµ‹è¿›åº¦: 2/11 (18.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3133)'), ('usv_1', '(225,4127)'), ('usv_2', '(221,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2676118730551119), 'usv_1': np.float64(-0.6298311842270634)}
    Episode time: 27.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Step 121000, Episode Steps: 1277, Avg Reward: 12.761, Episode Reward: 16296.1
    æ£€æµ‹è¿›åº¦: 4/43 (9.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3140)'), ('usv_1', '(301,4066)'), ('usv_2', '(272,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(4.278605051376969), 'usv_1': np.float64(3.377382354440156)}
    Episode time: 127.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Step 122000, Episode Steps: 2277, Avg Reward: 17.118, Episode Reward: 38978.2
    æ£€æµ‹è¿›åº¦: 6/64 (9.4%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3148)'), ('usv_1', '(325,3956)'), ('usv_2', '(296,5173)')]...
    Recent rewards sample: {'usv_0': np.float64(4.282651400331191), 'usv_1': np.float64(3.3857625210915634)}
    Episode time: 227.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 56147.7
  Targets Detected: 11/79 (10.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.71
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Step 123000, Episode Steps: 276, Avg Reward: -3.826, Episode Reward: -1056.0
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3126)'), ('usv_1', '(243,4125)'), ('usv_2', '(221,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27492931415707567), 'usv_1': np.float64(-0.6304382490450782)}
    Episode time: 27.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Step 124000, Episode Steps: 1276, Avg Reward: 20.832, Episode Reward: 26582.0
    æ£€æµ‹è¿›åº¦: 8/49 (16.3%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3109)'), ('usv_1', '(325,4061)'), ('usv_2', '(210,5168)')]...
    Recent rewards sample: {'usv_0': np.float64(4.279393089140232), 'usv_1': np.float64(3.3833629362222677)}
    Episode time: 127.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.23362797 -0.0499353 ] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Step 125000, Episode Steps: 2276, Avg Reward: 22.896, Episode Reward: 52111.2
    æ£€æµ‹è¿›åº¦: 11/80 (13.8%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3081)'), ('usv_1', '(351,3981)'), ('usv_2', '(209,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8697332842111845), 'usv_1': np.float64(3.3832317955241376)}
    Episode time: 227.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 61288.4
  Targets Detected: 14/97 (13.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.42
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Step 126000, Episode Steps: 275, Avg Reward: 6.832, Episode Reward: 1878.7
    æ£€æµ‹è¿›åº¦: 1/6 (16.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3130)'), ('usv_1', '(234,4125)'), ('usv_2', '(228,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27022474793622653), 'usv_1': np.float64(-0.6321270421015956)}
    Episode time: 27.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Step 127000, Episode Steps: 1275, Avg Reward: 10.563, Episode Reward: 13467.5
    æ£€æµ‹è¿›åº¦: 5/34 (14.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3114)'), ('usv_1', '(280,4044)'), ('usv_2', '(240,5177)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2777478986438777), 'usv_1': np.float64(1.3797615115087725)}
    Episode time: 127.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Step 128000, Episode Steps: 2275, Avg Reward: 16.776, Episode Reward: 38166.5
    æ£€æµ‹è¿›åº¦: 11/68 (16.2%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3081)'), ('usv_1', '(272,3955)'), ('usv_2', '(203,5204)')]...
    Recent rewards sample: {'usv_0': np.float64(7.872228476899256), 'usv_1': np.float64(1.383013567962509)}
    Episode time: 227.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 56555.7
  Targets Detected: 13/79 (13.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.85
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Step 129000, Episode Steps: 274, Avg Reward: -4.423, Episode Reward: -1211.8
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3128)'), ('usv_1', '(231,4129)'), ('usv_2', '(229,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.730181801925637), 'usv_1': np.float64(-1.630397772539882)}
    Episode time: 27.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.07047839  0.36409054] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Step 130000, Episode Steps: 1274, Avg Reward: 8.053, Episode Reward: 10259.8
    æ£€æµ‹è¿›åº¦: 5/40 (12.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3091)'), ('usv_1', '(304,4079)'), ('usv_2', '(276,5177)')]...
    Recent rewards sample: {'usv_0': np.float64(2.278643965352199), 'usv_1': np.float64(1.3888237268315748)}
    Episode time: 127.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Step 131000, Episode Steps: 2274, Avg Reward: 10.521, Episode Reward: 23925.8
    æ£€æµ‹è¿›åº¦: 6/68 (8.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3048)'), ('usv_1', '(282,3986)'), ('usv_2', '(253,5205)')]...
    Recent rewards sample: {'usv_0': np.float64(5.874705489485741), 'usv_1': np.float64(-8.620840108969908)}
    Episode time: 227.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 26313.4
  Targets Detected: 8/83 (7.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.77
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 132000...
    MADDPG UPDATE finished.
    Step 132000, Episode Steps: 273, Avg Reward: -4.365, Episode Reward: -1191.7
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3130)'), ('usv_1', '(242,4131)'), ('usv_2', '(220,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7308822782475018), 'usv_1': np.float64(-1.624286886803677)}
    Episode time: 27.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 133000...
    MADDPG UPDATE finished.
    Step 133000, Episode Steps: 1273, Avg Reward: 5.389, Episode Reward: 6860.2
    æ£€æµ‹è¿›åº¦: 4/46 (8.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3119)'), ('usv_1', '(308,4089)'), ('usv_2', '(234,5152)')]...
    Recent rewards sample: {'usv_0': np.float64(4.277670513134983), 'usv_1': np.float64(3.386427941052723)}
    Episode time: 127.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 134000...
    MADDPG UPDATE finished.
    Step 134000, Episode Steps: 2273, Avg Reward: 9.091, Episode Reward: 20663.9
    æ£€æµ‹è¿›åº¦: 4/70 (5.7%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3078)'), ('usv_1', '(327,3982)'), ('usv_2', '(201,5169)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8697879919890585), 'usv_1': np.float64(-6.61261821699555)}
    Episode time: 227.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 23361.4
  Targets Detected: 7/78 (6.4%)
  Steps: 2819
  Episode Time: 281.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 8.29

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 47212.8
Last 10 episodes average detections: 10.6
Best episode reward so far: 78370.1
Best detection count so far: 16
Learning trend: Improving (47212.8 vs 32638.2)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 78370.1
Final 10 episodes average: 47212.8
Best detection performance: 16 targets
Average detections (final 10): 10.6
============================================================
{"final_avg_reward": 47212.77600991963, "final_detection_rate": 10.6, "best_episode_reward": 78370.0651530903, "best_detection_count": 16, "total_episodes": 50}
Simulation finished.
