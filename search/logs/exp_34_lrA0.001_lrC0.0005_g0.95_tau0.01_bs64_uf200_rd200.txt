D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: -3.260, Episode Reward: -3260.0
    æ£€æµ‹è¿›åº¦: 0/27 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3146)'), ('usv_1', '(296,4121)'), ('usv_2', '(282,5183)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6330445228487921), 'usv_1': np.float64(-1.5186797574148212)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 0.976, Episode Reward: 1952.8
    æ£€æµ‹è¿›åº¦: 2/42 (4.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,3186)'), ('usv_1', '(402,4093)'), ('usv_2', '(245,5211)')]...
    Recent rewards sample: {'usv_0': np.float64(1.363018287223432), 'usv_1': np.float64(0.48387027410755423)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 11675.6
  Targets Detected: 2/59 (3.4%)
  Steps: 2932
  Episode Time: 293.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 3.98
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 68, Avg Reward: -3.004, Episode Reward: -204.3
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(218,4130)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6366782931217034), 'usv_1': np.float64(-1.5333270729782973)}
    Episode time: 6.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 1068, Avg Reward: 4.623, Episode Reward: 4937.5
    æ£€æµ‹è¿›åº¦: 2/15 (13.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(249,3136)'), ('usv_1', '(294,4067)'), ('usv_2', '(298,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(4.371455878667746), 'usv_1': np.float64(1.4759296319956512)}
    Episode time: 106.8s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.04635671 0.16303863] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 2068, Avg Reward: 11.603, Episode Reward: 23995.5
    æ£€æµ‹è¿›åº¦: 4/27 (14.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3182)'), ('usv_1', '(348,4003)'), ('usv_2', '(337,5198)')]...
    Recent rewards sample: {'usv_0': np.float64(4.371854793656988), 'usv_1': np.float64(1.4858163961362618)}
    Episode time: 206.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 30679.3
  Targets Detected: 4/29 (13.8%)
  Steps: 2467
  Episode Time: 246.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.44
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 601, Avg Reward: -3.275, Episode Reward: -1968.3
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3134)'), ('usv_1', '(265,4134)'), ('usv_2', '(243,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6314923623915972), 'usv_1': np.float64(-1.5223103109513954)}
    Episode time: 60.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 1601, Avg Reward: -2.265, Episode Reward: -3626.4
    æ£€æµ‹è¿›åº¦: 2/25 (8.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3168)'), ('usv_1', '(338,4203)'), ('usv_2', '(208,5189)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3708559508747218), 'usv_1': np.float64(-0.5138909478613225)}
    Episode time: 160.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 2601, Avg Reward: 5.038, Episode Reward: 13104.3
    æ£€æµ‹è¿›åº¦: 3/37 (8.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3205)'), ('usv_1', '(387,4305)'), ('usv_2', '(210,5154)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3617176727551783), 'usv_1': np.float64(3.489300776837724)}
    Episode time: 260.1s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 20606.7
  Targets Detected: 4/41 (7.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 6.87
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 600, Avg Reward: 9.801, Episode Reward: 5880.8
    æ£€æµ‹è¿›åº¦: 2/14 (14.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3134)'), ('usv_1', '(255,4134)'), ('usv_2', '(239,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3674103388040264), 'usv_1': np.float64(2.4704400432677978)}
    Episode time: 60.0s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.02316936 -0.21527305] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 1600, Avg Reward: 9.761, Episode Reward: 15617.2
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3163)'), ('usv_1', '(359,4135)'), ('usv_2', '(208,5190)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3741773402235145), 'usv_1': np.float64(2.4861108768651636)}
    Episode time: 160.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 15767.4
  Targets Detected: 2/23 (8.7%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_139s
  Average Reward/Step: 8.75
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 799, Avg Reward: -3.263, Episode Reward: -2607.0
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3138)'), ('usv_1', '(290,4088)'), ('usv_2', '(250,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6301302094504193), 'usv_1': np.float64(-1.5243713224874786)}
    Episode time: 79.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 1799, Avg Reward: -0.458, Episode Reward: -824.5
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3163)'), ('usv_1', '(356,4039)'), ('usv_2', '(230,5193)')]...
    Recent rewards sample: {'usv_0': np.float64(0.36848720459923057), 'usv_1': np.float64(-0.5177805210512257)}
    Episode time: 179.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 2799, Avg Reward: 6.967, Episode Reward: 19499.3
    æ£€æµ‹è¿›åº¦: 3/38 (7.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3182)'), ('usv_1', '(444,3989)'), ('usv_2', '(202,5193)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3665776114600527), 'usv_1': np.float64(3.496578707165418)}
    Episode time: 279.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 23413.9
  Targets Detected: 5/39 (7.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.80
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 798, Avg Reward: 2.239, Episode Reward: 1786.7
    æ£€æµ‹è¿›åº¦: 1/14 (7.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3145)'), ('usv_1', '(283,4142)'), ('usv_2', '(275,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(0.37282208922911286), 'usv_1': np.float64(-0.5273421648325698)}
    Episode time: 79.8s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.47068334  0.24738942] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 1798, Avg Reward: 5.118, Episode Reward: 9201.7
    æ£€æµ‹è¿›åº¦: 3/24 (12.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3179)'), ('usv_1', '(395,4165)'), ('usv_2', '(281,5218)')]...
    Recent rewards sample: {'usv_0': np.float64(2.367846549951886), 'usv_1': np.float64(1.4912586675562474)}
    Episode time: 179.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 2798, Avg Reward: 8.031, Episode Reward: 22471.8
    æ£€æµ‹è¿›åº¦: 7/51 (13.7%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3201)'), ('usv_1', '(486,4196)'), ('usv_2', '(231,5205)')]...
    Recent rewards sample: {'usv_0': np.float64(2.361920770151921), 'usv_1': np.float64(3.489526490351154)}
    Episode time: 279.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 24261.6
  Targets Detected: 7/57 (12.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.08
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 797, Avg Reward: -3.263, Episode Reward: -2600.6
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3143)'), ('usv_1', '(274,4124)'), ('usv_2', '(253,5168)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6379380312514042), 'usv_1': np.float64(-1.5290804204221098)}
    Episode time: 79.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 1797, Avg Reward: 4.659, Episode Reward: 8372.2
    æ£€æµ‹è¿›åº¦: 4/22 (18.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3164)'), ('usv_1', '(375,4157)'), ('usv_2', '(227,5218)')]...
    Recent rewards sample: {'usv_0': np.float64(4.362661445952332), 'usv_1': np.float64(1.4911253018334518)}
    Episode time: 179.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 2797, Avg Reward: 9.797, Episode Reward: 27402.3
    æ£€æµ‹è¿›åº¦: 5/37 (13.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3144)'), ('usv_1', '(459,4205)'), ('usv_2', '(208,5225)')]...
    Recent rewards sample: {'usv_0': np.float64(2.359150986461145), 'usv_1': np.float64(1.4890656783423664)}
    Episode time: 279.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 31732.0
  Targets Detected: 6/40 (15.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.57
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.04147003 -0.06654147] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 796, Avg Reward: -3.320, Episode Reward: -2642.9
    æ£€æµ‹è¿›åº¦: 0/14 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3135)'), ('usv_1', '(269,4108)'), ('usv_2', '(250,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6304615337620023), 'usv_1': np.float64(-1.5225659761976185)}
    Episode time: 79.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 1796, Avg Reward: 4.372, Episode Reward: 7851.4
    æ£€æµ‹è¿›åº¦: 4/35 (11.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3151)'), ('usv_1', '(374,4073)'), ('usv_2', '(202,5170)')]...
    Recent rewards sample: {'usv_0': np.float64(4.376390207638277), 'usv_1': np.float64(1.4809214994819535)}
    Episode time: 179.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 2796, Avg Reward: 8.951, Episode Reward: 25026.3
    æ£€æµ‹è¿›åº¦: 5/54 (9.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(292,3188)'), ('usv_1', '(449,4083)'), ('usv_2', '(212,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3797104321919145), 'usv_1': np.float64(1.4854453139280421)}
    Episode time: 279.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 29025.9
  Targets Detected: 6/59 (8.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.67
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 795, Avg Reward: -3.299, Episode Reward: -2622.8
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(240,3136)'), ('usv_1', '(291,4149)'), ('usv_2', '(264,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6269153132874633), 'usv_1': np.float64(-1.521414089569281)}
    Episode time: 79.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 1795, Avg Reward: -1.990, Episode Reward: -3572.8
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,3168)'), ('usv_1', '(372,4213)'), ('usv_2', '(226,5204)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3654502348576172), 'usv_1': np.float64(-0.514105425889498)}
    Episode time: 179.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: -8139.7
  Targets Detected: 1/30 (3.3%)
  Steps: 2754
  Episode Time: 275.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: -2.96
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.04989334  0.14580909] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 41, Avg Reward: -2.989, Episode Reward: -122.5
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(213,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6369548995535255), 'usv_1': np.float64(-1.5337084258869382)}
    Episode time: 4.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 1041, Avg Reward: 15.945, Episode Reward: 16599.2
    æ£€æµ‹è¿›åº¦: 4/17 (23.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3140)'), ('usv_1', '(320,4125)'), ('usv_2', '(225,5171)')]...
    Recent rewards sample: {'usv_0': np.float64(4.373386076403395), 'usv_1': np.float64(1.4793072192590913)}
    Episode time: 104.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 2041, Avg Reward: 18.537, Episode Reward: 37833.8
    æ£€æµ‹è¿›åº¦: 5/37 (13.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3167)'), ('usv_1', '(423,4142)'), ('usv_2', '(203,5181)')]...
    Recent rewards sample: {'usv_0': np.float64(4.369193463891212), 'usv_1': np.float64(3.4872065957730154)}
    Episode time: 204.1s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 58585.6
  Targets Detected: 6/57 (10.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.52

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 23760.8
Last 10 episodes average detections: 4.3
Best episode reward so far: 58585.6
Best detection count so far: 7
Buffer size: 27960
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 40, Avg Reward: -3.391, Episode Reward: -135.6
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(222,4130)'), ('usv_2', '(214,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.687081237821846), 'usv_1': np.float64(-1.5667020669641383)}
    Episode time: 4.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 1040, Avg Reward: 2.804, Episode Reward: 2915.7
    æ£€æµ‹è¿›åº¦: 1/20 (5.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3160)'), ('usv_1', '(293,4169)'), ('usv_2', '(247,5181)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33099204371793667), 'usv_1': np.float64(1.427165193264313)}
    Episode time: 104.0s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.18818967 -0.11326159] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 2040, Avg Reward: 9.848, Episode Reward: 20089.1
    æ£€æµ‹è¿›åº¦: 2/49 (4.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3164)'), ('usv_1', '(322,4255)'), ('usv_2', '(245,5247)')]...
    Recent rewards sample: {'usv_0': np.float64(2.31766387272027), 'usv_1': np.float64(3.43598915812636)}
    Episode time: 204.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 26744.3
  Targets Detected: 4/59 (5.1%)
  Steps: 2375
  Episode Time: 237.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 11.26
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 665, Avg Reward: -3.228, Episode Reward: -2146.8
    æ£€æµ‹è¿›åº¦: 1/19 (5.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3130)'), ('usv_1', '(272,4135)'), ('usv_2', '(254,5150)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6765209066691493), 'usv_1': np.float64(-1.577564788862212)}
    Episode time: 66.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 1665, Avg Reward: -1.625, Episode Reward: -2705.6
    æ£€æµ‹è¿›åº¦: 2/38 (5.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3141)'), ('usv_1', '(356,4170)'), ('usv_2', '(248,5211)')]...
    Recent rewards sample: {'usv_0': np.float64(0.328666480396793), 'usv_1': np.float64(-0.5716221774393919)}
    Episode time: 166.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 3054.9
  Targets Detected: 3/70 (2.9%)
  Steps: 2656
  Episode Time: 265.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 1.15
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 9, Avg Reward: -2.601, Episode Reward: -23.4
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3130)'), ('usv_1', '(212,4130)'), ('usv_2', '(212,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6802631253197804), 'usv_1': np.float64(-1.5693186883077919)}
    Episode time: 0.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 1009, Avg Reward: -0.819, Episode Reward: -826.0
    æ£€æµ‹è¿›åº¦: 1/20 (5.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3135)'), ('usv_1', '(326,4114)'), ('usv_2', '(260,5182)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32112283781881656), 'usv_1': np.float64(-0.573402111151023)}
    Episode time: 100.9s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.28668241 0.15304099] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 2009, Avg Reward: 5.841, Episode Reward: 11735.3
    æ£€æµ‹è¿›åº¦: 4/47 (8.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3169)'), ('usv_1', '(399,4132)'), ('usv_2', '(221,5242)')]...
    Recent rewards sample: {'usv_0': np.float64(4.328604807220946), 'usv_1': np.float64(3.4382120612529983)}
    Episode time: 200.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 19329.4
  Targets Detected: 8/60 (8.3%)
  Steps: 2573
  Episode Time: 257.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.51
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 436, Avg Reward: -3.597, Episode Reward: -1568.2
    æ£€æµ‹è¿›åº¦: 0/9 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3128)'), ('usv_1', '(250,4135)'), ('usv_2', '(234,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6794200594350088), 'usv_1': np.float64(-1.5788752645657658)}
    Episode time: 43.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 1436, Avg Reward: -0.940, Episode Reward: -1350.4
    æ£€æµ‹è¿›åº¦: 3/36 (8.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3130)'), ('usv_1', '(340,4189)'), ('usv_2', '(204,5211)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3272457529431585), 'usv_1': np.float64(3.438166801353523)}
    Episode time: 143.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 2436, Avg Reward: 6.624, Episode Reward: 16135.1
    æ£€æµ‹è¿›åº¦: 2/53 (3.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(269,3157)'), ('usv_1', '(403,4283)'), ('usv_2', '(208,5197)')]...
    Recent rewards sample: {'usv_0': np.float64(4.323908998444831), 'usv_1': np.float64(3.439095368142654)}
    Episode time: 243.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 19715.6
  Targets Detected: 4/57 (3.5%)
  Steps: 2629
  Episode Time: 262.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.50
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 807, Avg Reward: -3.595, Episode Reward: -2901.0
    æ£€æµ‹è¿›åº¦: 0/18 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3146)'), ('usv_1', '(280,4143)'), ('usv_2', '(277,5160)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6839570026081978), 'usv_1': np.float64(-1.5736260113489164)}
    Episode time: 80.7s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.06031539 -0.35277752] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 1807, Avg Reward: -1.616, Episode Reward: -2919.6
    æ£€æµ‹è¿›åº¦: 1/33 (3.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3179)'), ('usv_1', '(351,4193)'), ('usv_2', '(281,5214)')]...
    Recent rewards sample: {'usv_0': np.float64(3.311914895055964), 'usv_1': np.float64(0.4344368138955317)}
    Episode time: 180.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 2807, Avg Reward: 3.445, Episode Reward: 9670.1
    æ£€æµ‹è¿›åº¦: 5/65 (7.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3204)'), ('usv_1', '(428,4271)'), ('usv_2', '(212,5239)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3035847911971317), 'usv_1': np.float64(1.4394358317246132)}
    Episode time: 280.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 12848.0
  Targets Detected: 5/67 (7.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 4.28
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 806, Avg Reward: 1.155, Episode Reward: 931.3
    æ£€æµ‹è¿›åº¦: 1/16 (6.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3141)'), ('usv_1', '(280,4131)'), ('usv_2', '(264,5164)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3189977477300365), 'usv_1': np.float64(-0.5696684729455621)}
    Episode time: 80.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 1806, Avg Reward: 6.233, Episode Reward: 11257.5
    æ£€æµ‹è¿›åº¦: 2/43 (4.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3170)'), ('usv_1', '(375,4156)'), ('usv_2', '(266,5230)')]...
    Recent rewards sample: {'usv_0': np.float64(4.319499318724301), 'usv_1': np.float64(1.4358790221901279)}
    Episode time: 180.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 2806, Avg Reward: 10.953, Episode Reward: 30733.8
    æ£€æµ‹è¿›åº¦: 2/49 (4.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3166)'), ('usv_1', '(440,4234)'), ('usv_2', '(215,5228)')]...
    Recent rewards sample: {'usv_0': np.float64(4.308387572463865), 'usv_1': np.float64(3.4379868278087944)}
    Episode time: 280.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 32041.4
  Targets Detected: 4/52 (3.8%)
  Steps: 2870
  Episode Time: 287.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 11.16
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.27917639 -0.15586686] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 936, Avg Reward: 0.420, Episode Reward: 393.0
    æ£€æµ‹è¿›åº¦: 2/18 (11.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(240,3142)'), ('usv_1', '(299,4169)'), ('usv_2', '(265,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3292409873324421), 'usv_1': np.float64(-0.5675553990108935)}
    Episode time: 93.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 2999.9
  Targets Detected: 2/27 (3.7%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_130s
  Average Reward/Step: 1.67
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 135, Avg Reward: -3.565, Episode Reward: -481.3
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3131)'), ('usv_1', '(225,4131)'), ('usv_2', '(221,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6861578729972757), 'usv_1': np.float64(-1.57659940491671)}
    Episode time: 13.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 1135, Avg Reward: 9.040, Episode Reward: 10260.8
    æ£€æµ‹è¿›åº¦: 2/29 (6.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3156)'), ('usv_1', '(320,4164)'), ('usv_2', '(292,5178)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3160632366995015), 'usv_1': np.float64(3.4245887689792927)}
    Episode time: 113.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 2135, Avg Reward: 13.677, Episode Reward: 29200.6
    æ£€æµ‹è¿›åº¦: 4/50 (8.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3160)'), ('usv_1', '(368,4238)'), ('usv_2', '(299,5237)')]...
    Recent rewards sample: {'usv_0': np.float64(2.310621246270051), 'usv_1': np.float64(3.437237443216027)}
    Episode time: 213.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 45185.3
  Targets Detected: 6/67 (7.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.06
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 134, Avg Reward: -3.572, Episode Reward: -478.6
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3131)'), ('usv_1', '(222,4131)'), ('usv_2', '(225,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6859966832996899), 'usv_1': np.float64(-1.5830125579262018)}
    Episode time: 13.4s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.12083201  0.18608491] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 1134, Avg Reward: -3.571, Episode Reward: -4049.8
    æ£€æµ‹è¿›åº¦: 0/22 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3158)'), ('usv_1', '(324,4173)'), ('usv_2', '(263,5191)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6863326787373607), 'usv_1': np.float64(-1.5657275400526636)}
    Episode time: 113.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: -6390.0
  Targets Detected: 0/28 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.55
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 333, Avg Reward: 6.732, Episode Reward: 2241.8
    æ£€æµ‹è¿›åº¦: 2/14 (14.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3133)'), ('usv_1', '(245,4133)'), ('usv_2', '(232,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3180861469539877), 'usv_1': np.float64(0.4276868223995187)}
    Episode time: 33.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 1333, Avg Reward: 14.914, Episode Reward: 19880.3
    æ£€æµ‹è¿›åº¦: 4/31 (12.9%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3142)'), ('usv_1', '(352,4198)'), ('usv_2', '(270,5186)')]...
    Recent rewards sample: {'usv_0': np.float64(4.324682389411834), 'usv_1': np.float64(1.4355444609396577)}
    Episode time: 133.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 30462.5
  Targets Detected: 5/46 (8.7%)
  Steps: 1850
  Episode Time: 185.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.47

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 18599.1
Last 10 episodes average detections: 4.1
Best episode reward so far: 58585.6
Best detection count so far: 8
Learning trend: Declining (18599.1 vs 23760.8)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 483, Avg Reward: 6.051, Episode Reward: 2922.8
    æ£€æµ‹è¿›åº¦: 1/19 (5.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3132)'), ('usv_1', '(257,4140)'), ('usv_2', '(248,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(2.326902889103584), 'usv_1': np.float64(1.4313471767641395)}
    Episode time: 48.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 1483, Avg Reward: 17.141, Episode Reward: 25419.5
    æ£€æµ‹è¿›åº¦: 5/38 (13.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3170)'), ('usv_1', '(333,4182)'), ('usv_2', '(280,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3151233843718826), 'usv_1': np.float64(3.4327235445833075)}
    Episode time: 148.3s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.01179377 0.07081568] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 2483, Avg Reward: 18.819, Episode Reward: 46728.3
    æ£€æµ‹è¿›åº¦: 6/65 (9.2%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3194)'), ('usv_1', '(350,4275)'), ('usv_2', '(233,5203)')]...
    Recent rewards sample: {'usv_0': np.float64(2.304771100149784), 'usv_1': np.float64(3.4317822223914582)}
    Episode time: 248.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 57992.2
  Targets Detected: 7/72 (6.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.32
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 482, Avg Reward: 3.925, Episode Reward: 1891.9
    æ£€æµ‹è¿›åº¦: 1/14 (7.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3139)'), ('usv_1', '(265,4127)'), ('usv_2', '(243,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(0.316381300323453), 'usv_1': np.float64(-0.5722999222698681)}
    Episode time: 48.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 1482, Avg Reward: 4.437, Episode Reward: 6575.9
    æ£€æµ‹è¿›åº¦: 2/45 (4.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3180)'), ('usv_1', '(368,4151)'), ('usv_2', '(231,5192)')]...
    Recent rewards sample: {'usv_0': np.float64(0.313636445892264), 'usv_1': np.float64(-0.5666096797705623)}
    Episode time: 148.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 2482, Avg Reward: 8.522, Episode Reward: 21150.5
    æ£€æµ‹è¿›åº¦: 3/72 (4.2%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3214)'), ('usv_1', '(452,4161)'), ('usv_2', '(207,5185)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3160334071510764), 'usv_1': np.float64(3.4376058698044156)}
    Episode time: 248.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 31001.9
  Targets Detected: 4/79 (5.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.33
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 481, Avg Reward: -4.592, Episode Reward: -2208.5
    æ£€æµ‹è¿›åº¦: 0/16 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3147)'), ('usv_1', '(272,4136)'), ('usv_2', '(253,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6821680208700165), 'usv_1': np.float64(-1.5702602774875896)}
    Episode time: 48.1s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.22476621 -0.11620397] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 1481, Avg Reward: 9.798, Episode Reward: 14510.6
    æ£€æµ‹è¿›åº¦: 5/49 (10.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3187)'), ('usv_1', '(398,4151)'), ('usv_2', '(221,5207)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3092190535601995), 'usv_1': np.float64(1.4419593621029074)}
    Episode time: 148.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 2481, Avg Reward: 13.341, Episode Reward: 33099.5
    æ£€æµ‹è¿›åº¦: 5/74 (6.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3209)'), ('usv_1', '(474,4220)'), ('usv_2', '(200,5193)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3058072675050125), 'usv_1': np.float64(1.4449720073336856)}
    Episode time: 248.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 41701.3
  Targets Detected: 7/83 (7.2%)
  Steps: 2908
  Episode Time: 290.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.34
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 573, Avg Reward: 14.270, Episode Reward: 8176.6
    æ£€æµ‹è¿›åº¦: 3/19 (15.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3136)'), ('usv_1', '(270,4135)'), ('usv_2', '(255,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3175567911692356), 'usv_1': np.float64(3.4217562435993694)}
    Episode time: 57.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 1573, Avg Reward: 16.795, Episode Reward: 26418.9
    æ£€æµ‹è¿›åº¦: 4/44 (9.1%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3168)'), ('usv_1', '(312,4195)'), ('usv_2', '(259,5221)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3173892860894743), 'usv_1': np.float64(3.4243494853286087)}
    Episode time: 157.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 33272.2
  Targets Detected: 6/49 (8.2%)
  Steps: 1907
  Episode Time: 190.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 17.45
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 666, Avg Reward: 4.983, Episode Reward: 3318.5
    æ£€æµ‹è¿›åº¦: 1/28 (3.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3137)'), ('usv_1', '(275,4134)'), ('usv_2', '(247,5158)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3169632945590948), 'usv_1': np.float64(-0.5693880129125493)}
    Episode time: 66.6s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.01415994  0.10168958] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 1666, Avg Reward: 9.022, Episode Reward: 15031.2
    æ£€æµ‹è¿›åº¦: 4/51 (7.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3166)'), ('usv_1', '(364,4166)'), ('usv_2', '(255,5235)')]...
    Recent rewards sample: {'usv_0': np.float64(4.328392292320021), 'usv_1': np.float64(1.438890934658426)}
    Episode time: 166.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 2666, Avg Reward: 12.575, Episode Reward: 33525.8
    æ£€æµ‹è¿›åº¦: 5/73 (6.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3192)'), ('usv_1', '(469,4214)'), ('usv_2', '(211,5284)')]...
    Recent rewards sample: {'usv_0': np.float64(2.318963040284053), 'usv_1': np.float64(1.4363548108324284)}
    Episode time: 266.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 41066.7
  Targets Detected: 8/81 (9.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.68
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 665, Avg Reward: 5.165, Episode Reward: 3434.7
    æ£€æµ‹è¿›åº¦: 1/21 (4.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3125)'), ('usv_1', '(277,4143)'), ('usv_2', '(267,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31821572486102223), 'usv_1': np.float64(-0.573026556127312)}
    Episode time: 66.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 1665, Avg Reward: 6.863, Episode Reward: 11426.7
    æ£€æµ‹è¿›åº¦: 2/48 (4.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3125)'), ('usv_1', '(364,4190)'), ('usv_2', '(314,5178)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3304376252172458), 'usv_1': np.float64(0.4281873532570406)}
    Episode time: 166.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 2665, Avg Reward: 6.209, Episode Reward: 16547.8
    æ£€æµ‹è¿›åº¦: 4/75 (5.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(289,3163)'), ('usv_1', '(411,4299)'), ('usv_2', '(257,5209)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3301204697348794), 'usv_1': np.float64(1.4402123142760987)}
    Episode time: 266.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 17162.7
  Targets Detected: 6/83 (4.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.72
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.08288351 0.03290376] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 664, Avg Reward: 10.138, Episode Reward: 6732.0
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3147)'), ('usv_1', '(269,4140)'), ('usv_2', '(241,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3186809712036123), 'usv_1': np.float64(2.4265559414650957)}
    Episode time: 66.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 1664, Avg Reward: 12.309, Episode Reward: 20481.5
    æ£€æµ‹è¿›åº¦: 3/33 (9.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3173)'), ('usv_1', '(377,4137)'), ('usv_2', '(220,5223)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3075905203451947), 'usv_1': np.float64(3.4383651819786447)}
    Episode time: 166.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 2664, Avg Reward: 12.303, Episode Reward: 32776.2
    æ£€æµ‹è¿›åº¦: 7/59 (11.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(201,3167)'), ('usv_1', '(447,4149)'), ('usv_2', '(206,5212)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3074533132044173), 'usv_1': np.float64(3.4345780952187637)}
    Episode time: 266.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 41086.8
  Targets Detected: 9/63 (14.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.69
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 663, Avg Reward: 13.267, Episode Reward: 8795.9
    æ£€æµ‹è¿›åº¦: 2/23 (8.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3133)'), ('usv_1', '(264,4145)'), ('usv_2', '(276,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3198986624551674), 'usv_1': np.float64(2.4241172176798234)}
    Episode time: 66.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 1663, Avg Reward: 15.423, Episode Reward: 25648.4
    æ£€æµ‹è¿›åº¦: 7/45 (15.6%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(272,3152)'), ('usv_1', '(329,4185)'), ('usv_2', '(304,5182)')]...
    Recent rewards sample: {'usv_0': np.float64(4.327095280919592), 'usv_1': np.float64(256.4342959491521)}
    Episode time: 166.3s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.14771355 -0.06191604] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 2663, Avg Reward: 15.852, Episode Reward: 42213.1
    æ£€æµ‹è¿›åº¦: 5/64 (7.8%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3184)'), ('usv_1', '(352,4285)'), ('usv_2', '(281,5253)')]...
    Recent rewards sample: {'usv_0': np.float64(4.324567163007955), 'usv_1': np.float64(1.4344056346825638)}
    Episode time: 266.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 43712.0
  Targets Detected: 8/64 (7.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.57
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 662, Avg Reward: 4.110, Episode Reward: 2720.6
    æ£€æµ‹è¿›åº¦: 2/22 (9.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3131)'), ('usv_1', '(267,4157)'), ('usv_2', '(258,5157)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3190276028853583), 'usv_1': np.float64(2.4301129452182506)}
    Episode time: 66.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 1662, Avg Reward: 11.738, Episode Reward: 19508.5
    æ£€æµ‹è¿›åº¦: 5/50 (10.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(262,3154)'), ('usv_1', '(354,4212)'), ('usv_2', '(255,5213)')]...
    Recent rewards sample: {'usv_0': np.float64(2.322330698343298), 'usv_1': np.float64(3.43378286073502)}
    Episode time: 166.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 2662, Avg Reward: 10.143, Episode Reward: 27001.0
    æ£€æµ‹è¿›åº¦: 6/66 (9.1%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3148)'), ('usv_1', '(440,4273)'), ('usv_2', '(206,5227)')]...
    Recent rewards sample: {'usv_0': np.float64(4.316695452846566), 'usv_1': np.float64(3.435338897462655)}
    Episode time: 266.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 28626.1
  Targets Detected: 8/74 (9.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.54
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 661, Avg Reward: 5.034, Episode Reward: 3327.6
    æ£€æµ‹è¿›åº¦: 2/23 (8.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3146)'), ('usv_1', '(265,4131)'), ('usv_2', '(251,5154)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3146764964781568), 'usv_1': np.float64(0.4292489583830874)}
    Episode time: 66.1s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.01086203 -0.20993076] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 1661, Avg Reward: 11.900, Episode Reward: 19765.7
    æ£€æµ‹è¿›åº¦: 3/51 (5.9%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3172)'), ('usv_1', '(363,4179)'), ('usv_2', '(240,5206)')]...
    Recent rewards sample: {'usv_0': np.float64(4.311374106636658), 'usv_1': np.float64(1.436585760541751)}
    Episode time: 166.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: 30698.6
  Targets Detected: 7/54 (7.4%)
  Steps: 2186
  Episode Time: 218.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.04

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 36632.1
Last 10 episodes average detections: 7.0
Best episode reward so far: 58585.6
Best detection count so far: 9
Learning trend: Improving (36632.1 vs 18599.1)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 475, Avg Reward: -3.915, Episode Reward: -1859.6
    æ£€æµ‹è¿›åº¦: 0/18 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3135)'), ('usv_1', '(258,4148)'), ('usv_2', '(258,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7342753670120463), 'usv_1': np.float64(-1.6266109747505253)}
    Episode time: 47.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 1475, Avg Reward: -0.576, Episode Reward: -850.2
    æ£€æµ‹è¿›åº¦: 1/48 (2.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3142)'), ('usv_1', '(319,4211)'), ('usv_2', '(284,5208)')]...
    Recent rewards sample: {'usv_0': np.float64(4.278417632532332), 'usv_1': np.float64(1.375618376300031)}
    Episode time: 147.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 2475, Avg Reward: 7.661, Episode Reward: 18961.2
    æ£€æµ‹è¿›åº¦: 5/79 (6.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(304,3152)'), ('usv_1', '(377,4314)'), ('usv_2', '(244,5245)')]...
    Recent rewards sample: {'usv_0': np.float64(4.286458320069649), 'usv_1': np.float64(1.3820730716875933)}
    Episode time: 247.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 29306.2
  Targets Detected: 7/90 (7.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.77
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 474, Avg Reward: 6.402, Episode Reward: 3034.4
    æ£€æµ‹è¿›åº¦: 2/13 (15.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3130)'), ('usv_1', '(261,4141)'), ('usv_2', '(241,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2657929906074337), 'usv_1': np.float64(0.37708676647137795)}
    Episode time: 47.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.07968706 -0.15238217] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 1474, Avg Reward: 14.738, Episode Reward: 21724.0
    æ£€æµ‹è¿›åº¦: 5/43 (11.6%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3145)'), ('usv_1', '(355,4193)'), ('usv_2', '(286,5209)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2723757302196494), 'usv_1': np.float64(1.3875854919270254)}
    Episode time: 147.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 2474, Avg Reward: 16.905, Episode Reward: 41823.1
    æ£€æµ‹è¿›åº¦: 6/80 (7.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3168)'), ('usv_1', '(397,4270)'), ('usv_2', '(266,5277)')]...
    Recent rewards sample: {'usv_0': np.float64(4.269492662913807), 'usv_1': np.float64(3.391815054700479)}
    Episode time: 247.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 54595.7
  Targets Detected: 8/88 (9.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.19
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 473, Avg Reward: 7.208, Episode Reward: 3409.6
    æ£€æµ‹è¿›åº¦: 2/13 (15.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3133)'), ('usv_1', '(261,4138)'), ('usv_2', '(240,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(3.268669047341668), 'usv_1': np.float64(2.3789625492872224)}
    Episode time: 47.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 1473, Avg Reward: 14.421, Episode Reward: 21242.4
    æ£€æµ‹è¿›åº¦: 5/44 (11.4%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3160)'), ('usv_1', '(340,4163)'), ('usv_2', '(228,5193)')]...
    Recent rewards sample: {'usv_0': np.float64(4.26332740375722), 'usv_1': np.float64(3.3921684312642704)}
    Episode time: 147.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 2473, Avg Reward: 13.516, Episode Reward: 33424.5
    æ£€æµ‹è¿›åº¦: 10/72 (13.9%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3141)'), ('usv_1', '(422,4219)'), ('usv_2', '(208,5185)')]...
    Recent rewards sample: {'usv_0': np.float64(4.259885365878927), 'usv_1': np.float64(3.393090141480763)}
    Episode time: 247.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 34012.7
  Targets Detected: 12/84 (13.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.33
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.11680793  0.02613283] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 472, Avg Reward: -3.911, Episode Reward: -1845.9
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3130)'), ('usv_1', '(270,4137)'), ('usv_2', '(244,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7321398822543436), 'usv_1': np.float64(-1.6239373344631964)}
    Episode time: 47.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 1472, Avg Reward: 0.028, Episode Reward: 41.4
    æ£€æµ‹è¿›åº¦: 1/38 (2.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3149)'), ('usv_1', '(354,4171)'), ('usv_2', '(276,5201)')]...
    Recent rewards sample: {'usv_0': np.float64(0.272953280155243), 'usv_1': np.float64(-0.622788904465791)}
    Episode time: 147.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 2472, Avg Reward: 6.481, Episode Reward: 16021.2
    æ£€æµ‹è¿›åº¦: 2/63 (3.2%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3181)'), ('usv_1', '(432,4261)'), ('usv_2', '(240,5241)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2638679004939046), 'usv_1': np.float64(1.3960654167347837)}
    Episode time: 247.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 25174.0
  Targets Detected: 5/73 (5.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.39
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 471, Avg Reward: -3.915, Episode Reward: -1843.9
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3132)'), ('usv_1', '(259,4145)'), ('usv_2', '(252,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7305923232102542), 'usv_1': np.float64(-1.6301857414981902)}
    Episode time: 47.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 1471, Avg Reward: 3.183, Episode Reward: 4682.4
    æ£€æµ‹è¿›åº¦: 3/39 (7.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3165)'), ('usv_1', '(327,4206)'), ('usv_2', '(295,5179)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2630209104096273), 'usv_1': np.float64(0.37855669150251203)}
    Episode time: 147.1s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.19887111  0.18778685] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 2471, Avg Reward: 11.027, Episode Reward: 27248.6
    æ£€æµ‹è¿›åº¦: 7/63 (11.1%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3207)'), ('usv_1', '(353,4290)'), ('usv_2', '(241,5190)')]...
    Recent rewards sample: {'usv_0': np.float64(4.254040123958908), 'usv_1': np.float64(3.3822773289115906)}
    Episode time: 247.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 39282.2
  Targets Detected: 9/76 (11.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.09
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 470, Avg Reward: 9.535, Episode Reward: 4481.3
    æ£€æµ‹è¿›åº¦: 4/21 (19.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3129)'), ('usv_1', '(253,4139)'), ('usv_2', '(244,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2665008501985087), 'usv_1': np.float64(1.3693084547090617)}
    Episode time: 47.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 1470, Avg Reward: 16.448, Episode Reward: 24178.7
    æ£€æµ‹è¿›åº¦: 6/47 (12.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3173)'), ('usv_1', '(348,4176)'), ('usv_2', '(265,5173)')]...
    Recent rewards sample: {'usv_0': np.float64(4.268760793691196), 'usv_1': np.float64(1.3788092154527232)}
    Episode time: 147.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 2470, Avg Reward: 17.631, Episode Reward: 43547.4
    æ£€æµ‹è¿›åº¦: 8/70 (11.4%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3203)'), ('usv_1', '(391,4252)'), ('usv_2', '(201,5188)')]...
    Recent rewards sample: {'usv_0': np.float64(4.256817067839845), 'usv_1': np.float64(1.3848656760555427)}
    Episode time: 247.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 55069.2
  Targets Detected: 11/80 (12.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.35
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 469, Avg Reward: 16.991, Episode Reward: 7968.8
    æ£€æµ‹è¿›åº¦: 3/24 (12.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3137)'), ('usv_1', '(265,4131)'), ('usv_2', '(231,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(2.266403781305247), 'usv_1': np.float64(3.375209487296882)}
    Episode time: 46.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.2276421   0.02418059] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Step 100000, Episode Steps: 1469, Avg Reward: 18.513, Episode Reward: 27195.9
    æ£€æµ‹è¿›åº¦: 6/34 (17.6%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3180)'), ('usv_1', '(357,4149)'), ('usv_2', '(205,5207)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2594376805732006), 'usv_1': np.float64(3.3843732516817537)}
    Episode time: 146.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Step 101000, Episode Steps: 2469, Avg Reward: 18.487, Episode Reward: 45644.3
    æ£€æµ‹è¿›åº¦: 6/62 (9.7%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(204,3184)'), ('usv_1', '(469,4161)'), ('usv_2', '(202,5165)')]...
    Recent rewards sample: {'usv_0': np.float64(2.253546730889946), 'usv_1': np.float64(3.3955621996813115)}
    Episode time: 246.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 45862.4
  Targets Detected: 7/62 (9.7%)
  Steps: 2481
  Episode Time: 248.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.49
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Step 102000, Episode Steps: 988, Avg Reward: 1.327, Episode Reward: 1310.7
    æ£€æµ‹è¿›åº¦: 1/24 (4.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3150)'), ('usv_1', '(312,4125)'), ('usv_2', '(281,5162)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2668689314450927), 'usv_1': np.float64(-0.6132078555149356)}
    Episode time: 98.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Step 103000, Episode Steps: 1988, Avg Reward: 4.002, Episode Reward: 7956.9
    æ£€æµ‹è¿›åº¦: 2/52 (3.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3184)'), ('usv_1', '(402,4062)'), ('usv_2', '(274,5225)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2678059418110155), 'usv_1': np.float64(0.38610251967138365)}
    Episode time: 198.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Step 104000, Episode Steps: 2988, Avg Reward: 5.620, Episode Reward: 16791.3
    æ£€æµ‹è¿›åº¦: 6/89 (6.7%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3221)'), ('usv_1', '(481,3995)'), ('usv_2', '(234,5202)')]...
    Recent rewards sample: {'usv_0': np.float64(4.260903699588761), 'usv_1': np.float64(1.398311175810127)}
    Episode time: 298.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 17054.1
  Targets Detected: 6/90 (6.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.68
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.25191709  0.01634012] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Step 105000, Episode Steps: 987, Avg Reward: 8.584, Episode Reward: 8472.2
    æ£€æµ‹è¿›åº¦: 6/44 (13.6%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3128)'), ('usv_1', '(301,4123)'), ('usv_2', '(287,5157)')]...
    Recent rewards sample: {'usv_0': np.float64(2.271486938757654), 'usv_1': np.float64(3.3732541834916434)}
    Episode time: 98.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Step 106000, Episode Steps: 1987, Avg Reward: 13.390, Episode Reward: 26606.3
    æ£€æµ‹è¿›åº¦: 9/78 (11.5%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3157)'), ('usv_1', '(418,4143)'), ('usv_2', '(333,5217)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2740662110715295), 'usv_1': np.float64(3.390155889779461)}
    Episode time: 198.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Step 107000, Episode Steps: 2987, Avg Reward: 15.725, Episode Reward: 46971.3
    æ£€æµ‹è¿›åº¦: 14/102 (13.7%), Episode total: 15
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(262,3187)'), ('usv_1', '(480,4211)'), ('usv_2', '(292,5263)')]...
    Recent rewards sample: {'usv_0': np.float64(2.267971222419456), 'usv_1': np.float64(3.3871580936637953)}
    Episode time: 298.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 47226.6
  Targets Detected: 15/102 (12.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.74
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Step 108000, Episode Steps: 986, Avg Reward: 2.630, Episode Reward: 2592.7
    æ£€æµ‹è¿›åº¦: 1/41 (2.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3154)'), ('usv_1', '(302,4143)'), ('usv_2', '(264,5168)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2670085057688014), 'usv_1': np.float64(2.3750627072800903)}
    Episode time: 98.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Step 109000, Episode Steps: 1986, Avg Reward: 11.883, Episode Reward: 23600.0
    æ£€æµ‹è¿›åº¦: 3/70 (4.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3178)'), ('usv_1', '(383,4194)'), ('usv_2', '(221,5239)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2598485273756914), 'usv_1': np.float64(3.3813370973769565)}
    Episode time: 198.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.3661237   0.49306932] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Step 110000, Episode Steps: 2986, Avg Reward: 16.032, Episode Reward: 47872.3
    æ£€æµ‹è¿›åº¦: 7/102 (6.9%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3167)'), ('usv_1', '(455,4259)'), ('usv_2', '(202,5205)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2577993251795805), 'usv_1': np.float64(3.3871270473787245)}
    Episode time: 298.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 48204.9
  Targets Detected: 9/102 (6.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.06

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 39578.8
Last 10 episodes average detections: 8.9
Best episode reward so far: 58585.6
Best detection count so far: 15
Learning trend: Improving (39578.8 vs 36632.1)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Step 111000, Episode Steps: 985, Avg Reward: 7.911, Episode Reward: 7792.4
    æ£€æµ‹è¿›åº¦: 2/33 (6.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3156)'), ('usv_1', '(314,4133)'), ('usv_2', '(280,5166)')]...
    Recent rewards sample: {'usv_0': np.float64(1.26256350626628), 'usv_1': np.float64(0.3748754410914994)}
    Episode time: 98.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Step 112000, Episode Steps: 1985, Avg Reward: 8.503, Episode Reward: 16879.0
    æ£€æµ‹è¿›åº¦: 5/64 (7.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,3165)'), ('usv_1', '(393,4172)'), ('usv_2', '(253,5213)')]...
    Recent rewards sample: {'usv_0': np.float64(4.257871016243359), 'usv_1': np.float64(1.3821538950571277)}
    Episode time: 198.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Step 113000, Episode Steps: 2985, Avg Reward: 6.118, Episode Reward: 18261.3
    æ£€æµ‹è¿›åº¦: 6/106 (5.7%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3152)'), ('usv_1', '(441,4235)'), ('usv_2', '(205,5199)')]...
    Recent rewards sample: {'usv_0': np.float64(4.257233238665613), 'usv_1': np.float64(3.389286887529999)}
    Episode time: 298.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 18258.6
  Targets Detected: 7/106 (5.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 6.08
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Step 114000, Episode Steps: 984, Avg Reward: 8.022, Episode Reward: 7893.6
    æ£€æµ‹è¿›åº¦: 3/18 (16.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3123)'), ('usv_1', '(321,4161)'), ('usv_2', '(278,5153)')]...
    Recent rewards sample: {'usv_0': np.float64(4.272924806100245), 'usv_1': np.float64(3.374910222479829)}
    Episode time: 98.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.15535627  0.11713666] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Step 115000, Episode Steps: 1984, Avg Reward: 15.232, Episode Reward: 30219.3
    æ£€æµ‹è¿›åº¦: 6/46 (13.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(287,3119)'), ('usv_1', '(433,4175)'), ('usv_2', '(319,5198)')]...
    Recent rewards sample: {'usv_0': np.float64(4.283675730628437), 'usv_1': np.float64(3.391638391265241)}
    Episode time: 198.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 36924.4
  Targets Detected: 7/79 (7.6%)
  Steps: 2829
  Episode Time: 282.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.05
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Step 116000, Episode Steps: 155, Avg Reward: 9.152, Episode Reward: 1418.5
    æ£€æµ‹è¿›åº¦: 1/7 (14.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3132)'), ('usv_1', '(227,4133)'), ('usv_2', '(225,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2644426729705742), 'usv_1': np.float64(2.376686880174587)}
    Episode time: 15.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Step 117000, Episode Steps: 1155, Avg Reward: 19.702, Episode Reward: 22755.9
    æ£€æµ‹è¿›åº¦: 7/37 (18.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3164)'), ('usv_1', '(329,4168)'), ('usv_2', '(262,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(4.266836947838032), 'usv_1': np.float64(3.3752747877389853)}
    Episode time: 115.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Step 118000, Episode Steps: 2155, Avg Reward: 20.076, Episode Reward: 43264.6
    æ£€æµ‹è¿›åº¦: 7/58 (12.1%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3200)'), ('usv_1', '(418,4201)'), ('usv_2', '(203,5187)')]...
    Recent rewards sample: {'usv_0': np.float64(2.267994453341482), 'usv_1': np.float64(3.3857943064780924)}
    Episode time: 215.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 62380.1
  Targets Detected: 11/83 (12.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.79
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Step 119000, Episode Steps: 154, Avg Reward: 0.230, Episode Reward: 35.5
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3131)'), ('usv_1', '(224,4131)'), ('usv_2', '(225,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26389878155474533), 'usv_1': np.float64(-0.6318848720107335)}
    Episode time: 15.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.16300864  0.04177581] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Step 120000, Episode Steps: 1154, Avg Reward: 9.050, Episode Reward: 10444.2
    æ£€æµ‹è¿›åº¦: 2/33 (6.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3169)'), ('usv_1', '(300,4204)'), ('usv_2', '(258,5188)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2637212714446262), 'usv_1': np.float64(0.3820245120941894)}
    Episode time: 115.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 18895.9
  Targets Detected: 2/52 (3.8%)
  Steps: 1830
  Episode Time: 183.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.33
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Step 121000, Episode Steps: 324, Avg Reward: -2.746, Episode Reward: -889.9
    æ£€æµ‹è¿›åº¦: 0/15 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3131)'), ('usv_1', '(249,4133)'), ('usv_2', '(230,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2665949741135978), 'usv_1': np.float64(-0.61895374237555)}
    Episode time: 32.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Step 122000, Episode Steps: 1324, Avg Reward: 2.520, Episode Reward: 3335.8
    æ£€æµ‹è¿›åº¦: 2/37 (5.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3155)'), ('usv_1', '(327,4206)'), ('usv_2', '(302,5188)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2686570803410463), 'usv_1': np.float64(-0.6171070445207828)}
    Episode time: 132.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Step 123000, Episode Steps: 2324, Avg Reward: 5.891, Episode Reward: 13691.4
    æ£€æµ‹è¿›åº¦: 5/60 (8.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3185)'), ('usv_1', '(349,4283)'), ('usv_2', '(242,5202)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2557769859431906), 'usv_1': np.float64(3.379108403825363)}
    Episode time: 232.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 26197.8
  Targets Detected: 6/85 (4.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.73
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Step 124000, Episode Steps: 323, Avg Reward: -3.921, Episode Reward: -1266.4
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3133)'), ('usv_1', '(237,4132)'), ('usv_2', '(236,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7355105396532544), 'usv_1': np.float64(-1.62238242929926)}
    Episode time: 32.3s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.07206812 0.22999797] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Step 125000, Episode Steps: 1323, Avg Reward: 7.537, Episode Reward: 9971.1
    æ£€æµ‹è¿›åº¦: 3/45 (6.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3160)'), ('usv_1', '(354,4172)'), ('usv_2', '(261,5195)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2658147424322745), 'usv_1': np.float64(1.3822549074296964)}
    Episode time: 132.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Step 126000, Episode Steps: 2323, Avg Reward: 12.141, Episode Reward: 28202.5
    æ£€æµ‹è¿›åº¦: 4/50 (8.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3183)'), ('usv_1', '(442,4229)'), ('usv_2', '(213,5236)')]...
    Recent rewards sample: {'usv_0': np.float64(4.256625081102273), 'usv_1': np.float64(1.3907733249367413)}
    Episode time: 232.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 42578.2
  Targets Detected: 7/65 (10.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.19
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Step 127000, Episode Steps: 322, Avg Reward: -4.547, Episode Reward: -1464.1
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3136)'), ('usv_1', '(236,4128)'), ('usv_2', '(244,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7331566734057178), 'usv_1': np.float64(-1.6227773805546626)}
    Episode time: 32.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Step 128000, Episode Steps: 1322, Avg Reward: 7.315, Episode Reward: 9670.0
    æ£€æµ‹è¿›åº¦: 3/43 (7.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3168)'), ('usv_1', '(302,4181)'), ('usv_2', '(282,5182)')]...
    Recent rewards sample: {'usv_0': np.float64(4.269449698350642), 'usv_1': np.float64(1.3783944203447622)}
    Episode time: 132.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Step 129000, Episode Steps: 2322, Avg Reward: 12.960, Episode Reward: 30092.2
    æ£€æµ‹è¿›åº¦: 8/76 (10.5%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3190)'), ('usv_1', '(369,4238)'), ('usv_2', '(235,5227)')]...
    Recent rewards sample: {'usv_0': np.float64(4.260088107493147), 'usv_1': np.float64(3.380373842620542)}
    Episode time: 232.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 44391.1
  Targets Detected: 11/87 (8.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.79
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.10709281 -0.06626884] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Step 130000, Episode Steps: 321, Avg Reward: 14.621, Episode Reward: 4693.4
    æ£€æµ‹è¿›åº¦: 3/13 (23.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3131)'), ('usv_1', '(245,4132)'), ('usv_2', '(225,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2642857118723385), 'usv_1': np.float64(2.380294131948389)}
    Episode time: 32.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Step 131000, Episode Steps: 1321, Avg Reward: 21.149, Episode Reward: 27938.3
    æ£€æµ‹è¿›åº¦: 4/36 (11.1%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3150)'), ('usv_1', '(338,4158)'), ('usv_2', '(226,5194)')]...
    Recent rewards sample: {'usv_0': np.float64(4.266082537441524), 'usv_1': np.float64(3.3831995597470064)}
    Episode time: 132.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 43074.1
  Targets Detected: 9/58 (10.3%)
  Steps: 1928
  Episode Time: 192.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 22.34
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 132000...
    MADDPG UPDATE finished.
    Step 132000, Episode Steps: 393, Avg Reward: 0.615, Episode Reward: 241.6
    æ£€æµ‹è¿›åº¦: 2/10 (20.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3126)'), ('usv_1', '(251,4129)'), ('usv_2', '(239,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2714619544126227), 'usv_1': np.float64(-0.6240547364957671)}
    Episode time: 39.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 133000...
    MADDPG UPDATE finished.
    Step 133000, Episode Steps: 1393, Avg Reward: 10.904, Episode Reward: 15189.7
    æ£€æµ‹è¿›åº¦: 4/37 (10.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3148)'), ('usv_1', '(343,4111)'), ('usv_2', '(226,5194)')]...
    Recent rewards sample: {'usv_0': np.float64(4.276041849743275), 'usv_1': np.float64(1.3772288571703921)}
    Episode time: 139.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 27528.2
  Targets Detected: 4/63 (4.8%)
  Steps: 2073
  Episode Time: 207.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.28
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 134000...
    MADDPG UPDATE finished.
    Step 134000, Episode Steps: 320, Avg Reward: 2.348, Episode Reward: 751.2
    æ£€æµ‹è¿›åº¦: 1/8 (12.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3130)'), ('usv_1', '(248,4133)'), ('usv_2', '(231,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26517427445125175), 'usv_1': np.float64(-0.6275473160530892)}
    Episode time: 32.0s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.2325768  -0.06773407] (agent usv_0)
    MADDPG UPDATING at time_step 135000...
    MADDPG UPDATE finished.
    Step 135000, Episode Steps: 1320, Avg Reward: 4.245, Episode Reward: 5604.0
    æ£€æµ‹è¿›åº¦: 4/34 (11.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(266,3135)'), ('usv_1', '(337,4158)'), ('usv_2', '(232,5221)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2794094552706545), 'usv_1': np.float64(-0.6232073638473484)}
    Episode time: 132.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 136000...
    MADDPG UPDATE finished.
    Step 136000, Episode Steps: 2320, Avg Reward: 4.164, Episode Reward: 9660.2
    æ£€æµ‹è¿›åº¦: 4/51 (7.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(268,3168)'), ('usv_1', '(392,4224)'), ('usv_2', '(206,5217)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2744604581862212), 'usv_1': np.float64(-0.619258396031225)}
    Episode time: 232.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 11156.2
  Targets Detected: 4/56 (7.1%)
  Steps: 2519
  Episode Time: 251.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 4.43

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 33138.5
Last 10 episodes average detections: 6.8
Best episode reward so far: 62380.1
Best detection count so far: 15
Learning trend: Declining (33138.5 vs 39578.8)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 62380.1
Final 10 episodes average: 33138.5
Best detection performance: 15 targets
Average detections (final 10): 6.8
============================================================
{"final_avg_reward": 33138.46432385384, "final_detection_rate": 6.8, "best_episode_reward": 62380.10171473666, "best_detection_count": 15, "total_episodes": 50}
Simulation finished.
