D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: 6.773, Episode Reward: 6772.7
    æ£€æµ‹è¿›åº¦: 2/18 (11.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3157)'), ('usv_1', '(242,4120)'), ('usv_2', '(253,5152)')]...
    Recent rewards sample: {'usv_0': np.float64(1.36560291210839), 'usv_1': np.float64(0.469082581422837)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 13.143, Episode Reward: 26286.7
    æ£€æµ‹è¿›åº¦: 4/29 (13.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3154)'), ('usv_1', '(263,4076)'), ('usv_2', '(238,5186)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3660546308766355), 'usv_1': np.float64(3.4744805568458075)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 3000, Avg Reward: 16.333, Episode Reward: 48998.1
    æ£€æµ‹è¿›åº¦: 7/43 (16.3%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3167)'), ('usv_1', '(278,4036)'), ('usv_2', '(204,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(4.372628711100182), 'usv_1': np.float64(3.4751437177114397)}
    Episode time: 300.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 49020.8
  Targets Detected: 9/43 (16.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.33
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 999, Avg Reward: -3.304, Episode Reward: -3300.9
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3153)'), ('usv_1', '(259,4114)'), ('usv_2', '(242,5170)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6405650568886486), 'usv_1': np.float64(-1.519969309044217)}
    Episode time: 99.9s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.10771701  0.31261009] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 1999, Avg Reward: 5.367, Episode Reward: 10728.2
    æ£€æµ‹è¿›åº¦: 3/26 (11.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3140)'), ('usv_1', '(235,4097)'), ('usv_2', '(219,5212)')]...
    Recent rewards sample: {'usv_0': np.float64(4.362557502147309), 'usv_1': np.float64(3.4718637876317526)}
    Episode time: 199.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 2999, Avg Reward: 9.575, Episode Reward: 28715.7
    æ£€æµ‹è¿›åº¦: 3/42 (7.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3133)'), ('usv_1', '(204,4145)'), ('usv_2', '(203,5191)')]...
    Recent rewards sample: {'usv_0': np.float64(4.365644247328196), 'usv_1': np.float64(1.4656498828184654)}
    Episode time: 299.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 28749.1
  Targets Detected: 4/42 (7.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.58
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 998, Avg Reward: 11.955, Episode Reward: 11931.4
    æ£€æµ‹è¿›åº¦: 4/16 (25.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3149)'), ('usv_1', '(267,4101)'), ('usv_2', '(242,5164)')]...
    Recent rewards sample: {'usv_0': np.float64(4.362707463977605), 'usv_1': np.float64(1.4765312581004162)}
    Episode time: 99.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 1998, Avg Reward: 15.824, Episode Reward: 31616.9
    æ£€æµ‹è¿›åº¦: 4/30 (13.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3138)'), ('usv_1', '(257,4063)'), ('usv_2', '(211,5193)')]...
    Recent rewards sample: {'usv_0': np.float64(4.363463116144119), 'usv_1': np.float64(1.4725556579751942)}
    Episode time: 199.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 34033.8
  Targets Detected: 5/33 (9.1%)
  Steps: 2127
  Episode Time: 212.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.00
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 871, Avg Reward: 4.542, Episode Reward: 3955.9
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3162)'), ('usv_1', '(236,4115)'), ('usv_2', '(249,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3621739011379), 'usv_1': np.float64(-0.5319638989640515)}
    Episode time: 87.1s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.35813553  0.33464589] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 1871, Avg Reward: 10.960, Episode Reward: 20506.8
    æ£€æµ‹è¿›åº¦: 3/28 (10.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3153)'), ('usv_1', '(235,4085)'), ('usv_2', '(245,5184)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3590144076780524), 'usv_1': np.float64(3.468274404750275)}
    Episode time: 187.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 2871, Avg Reward: 13.429, Episode Reward: 38554.2
    æ£€æµ‹è¿›åº¦: 4/38 (10.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3157)'), ('usv_1', '(213,4051)'), ('usv_2', '(208,5180)')]...
    Recent rewards sample: {'usv_0': np.float64(2.361537425661849), 'usv_1': np.float64(3.472291642400256)}
    Episode time: 287.1s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 40723.1
  Targets Detected: 4/39 (10.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.57
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 870, Avg Reward: 2.664, Episode Reward: 2317.3
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(240,3141)'), ('usv_1', '(244,4120)'), ('usv_2', '(261,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(0.37243488241694755), 'usv_1': np.float64(-0.5313899523557085)}
    Episode time: 87.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 1870, Avg Reward: 5.167, Episode Reward: 9663.2
    æ£€æµ‹è¿›åº¦: 2/38 (5.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3158)'), ('usv_1', '(246,4075)'), ('usv_2', '(252,5188)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3609712527574744), 'usv_1': np.float64(0.4692283620932136)}
    Episode time: 187.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 17942.4
  Targets Detected: 2/48 (4.2%)
  Steps: 2678
  Episode Time: 267.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 6.70
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 192, Avg Reward: -3.213, Episode Reward: -617.0
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(218,4129)'), ('usv_2', '(217,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6367253575147555), 'usv_1': np.float64(-1.5238367591582418)}
    Episode time: 19.2s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.16023668 -0.06186618] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 1192, Avg Reward: 5.414, Episode Reward: 6453.1
    æ£€æµ‹è¿›åº¦: 4/17 (23.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3138)'), ('usv_1', '(246,4091)'), ('usv_2', '(256,5181)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3632846534203342), 'usv_1': np.float64(2.469020349196377)}
    Episode time: 119.2s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 22291.3
  Targets Detected: 5/30 (10.0%)
  Steps: 2190
  Episode Time: 219.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.18
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 2, Avg Reward: 8.683, Episode Reward: 17.4
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3130)'), ('usv_1', '(210,4130)'), ('usv_2', '(210,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6237572559099822), 'usv_1': np.float64(-1.519442348918203)}
    Episode time: 0.2s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 1002, Avg Reward: 5.139, Episode Reward: 5149.3
    æ£€æµ‹è¿›åº¦: 2/14 (14.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3160)'), ('usv_1', '(211,4101)'), ('usv_2', '(256,5151)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3609111999661652), 'usv_1': np.float64(2.468339768016479)}
    Episode time: 100.2s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 15043.9
  Targets Detected: 2/27 (7.4%)
  Steps: 1927
  Episode Time: 192.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.81
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 75, Avg Reward: -3.650, Episode Reward: -273.7
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(219,4130)'), ('usv_2', '(219,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6369932673603751), 'usv_1': np.float64(-1.5262398235203554)}
    Episode time: 7.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 1075, Avg Reward: -3.522, Episode Reward: -3785.9
    æ£€æµ‹è¿›åº¦: 0/14 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3146)'), ('usv_1', '(236,4098)'), ('usv_2', '(249,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6352886535516546), 'usv_1': np.float64(-1.5265910159969653)}
    Episode time: 107.5s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.01047865 -0.11173915] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 2075, Avg Reward: 1.824, Episode Reward: 3785.4
    æ£€æµ‹è¿›åº¦: 3/26 (11.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3155)'), ('usv_1', '(203,4093)'), ('usv_2', '(226,5214)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3651114507187674), 'usv_1': np.float64(0.46572377165009216)}
    Episode time: 207.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 21959.3
  Targets Detected: 5/37 (10.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.32
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 74, Avg Reward: 3.289, Episode Reward: 243.4
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(218,4130)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3651863365265201), 'usv_1': np.float64(1.4780472089447478)}
    Episode time: 7.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 1074, Avg Reward: 12.967, Episode Reward: 13927.0
    æ£€æµ‹è¿›åº¦: 3/26 (11.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3150)'), ('usv_1', '(264,4102)'), ('usv_2', '(255,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(4.363179513610925), 'usv_1': np.float64(3.4708033326587637)}
    Episode time: 107.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 2074, Avg Reward: 18.752, Episode Reward: 38890.7
    æ£€æµ‹è¿›åº¦: 8/45 (17.8%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3129)'), ('usv_1', '(221,4068)'), ('usv_2', '(252,5215)')]...
    Recent rewards sample: {'usv_0': np.float64(4.37099383149729), 'usv_1': np.float64(3.4683669953447627)}
    Episode time: 207.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 58650.0
  Targets Detected: 9/55 (14.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.54
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 73, Avg Reward: -3.011, Episode Reward: -219.8
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(214,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.636778647915252), 'usv_1': np.float64(-1.5336856455315475)}
    Episode time: 7.3s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.43542346  0.07113194] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 1073, Avg Reward: 8.301, Episode Reward: 8907.2
    æ£€æµ‹è¿›åº¦: 3/14 (21.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3162)'), ('usv_1', '(231,4081)'), ('usv_2', '(235,5163)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3596403438337776), 'usv_1': np.float64(3.472064134134124)}
    Episode time: 107.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 2073, Avg Reward: 14.485, Episode Reward: 30027.1
    æ£€æµ‹è¿›åº¦: 6/28 (21.4%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3139)'), ('usv_1', '(217,4038)'), ('usv_2', '(232,5202)')]...
    Recent rewards sample: {'usv_0': np.float64(2.359561104880419), 'usv_1': np.float64(1.4730013091452765)}
    Episode time: 207.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 47684.7
  Targets Detected: 10/49 (18.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.89

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 33609.8
Last 10 episodes average detections: 5.5
Best episode reward so far: 58650.0
Best detection count so far: 10
Buffer size: 26928
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 72, Avg Reward: -3.511, Episode Reward: -252.8
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(215,4130)'), ('usv_2', '(215,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.685877647753067), 'usv_1': np.float64(-1.579879336660605)}
    Episode time: 7.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 1072, Avg Reward: -3.605, Episode Reward: -3864.8
    æ£€æµ‹è¿›åº¦: 0/18 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3146)'), ('usv_1', '(254,4108)'), ('usv_2', '(255,5173)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.688459603005695), 'usv_1': np.float64(-1.5773633129348419)}
    Episode time: 107.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 2072, Avg Reward: 0.332, Episode Reward: 688.6
    æ£€æµ‹è¿›åº¦: 1/38 (2.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3124)'), ('usv_1', '(223,4070)'), ('usv_2', '(241,5210)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3192011740276577), 'usv_1': np.float64(0.42488847507102245)}
    Episode time: 207.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 11307.2
  Targets Detected: 3/61 (4.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 3.77
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.2478036  0.19504707] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 71, Avg Reward: -3.655, Episode Reward: -259.5
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(214,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6834549570205772), 'usv_1': np.float64(-1.5766828673104014)}
    Episode time: 7.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 1071, Avg Reward: -3.629, Episode Reward: -3887.1
    æ£€æµ‹è¿›åº¦: 0/21 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3148)'), ('usv_1', '(257,4143)'), ('usv_2', '(272,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6881827630223556), 'usv_1': np.float64(-1.58035730799935)}
    Episode time: 107.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 2071, Avg Reward: 0.636, Episode Reward: 1316.5
    æ£€æµ‹è¿›åº¦: 3/46 (6.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3124)'), ('usv_1', '(311,4122)'), ('usv_2', '(301,5164)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3200421129693956), 'usv_1': np.float64(356.43276349187124)}
    Episode time: 207.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 19768.4
  Targets Detected: 4/64 (3.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 6.59
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 70, Avg Reward: -4.731, Episode Reward: -331.2
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(220,4130)'), ('usv_2', '(216,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.684772147254378), 'usv_1': np.float64(-1.578092067136703)}
    Episode time: 7.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 1070, Avg Reward: -2.232, Episode Reward: -2388.0
    æ£€æµ‹è¿›åº¦: 0/27 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3152)'), ('usv_1', '(246,4104)'), ('usv_2', '(257,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31395677962065227), 'usv_1': np.float64(-0.5728531141170522)}
    Episode time: 107.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 1542.2
  Targets Detected: 0/41 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: 0.86
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.00303341  0.18473298] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 269, Avg Reward: -3.597, Episode Reward: -967.5
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3132)'), ('usv_1', '(227,4125)'), ('usv_2', '(224,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.680626287047343), 'usv_1': np.float64(-1.5812801511927317)}
    Episode time: 26.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 1269, Avg Reward: -0.596, Episode Reward: -755.9
    æ£€æµ‹è¿›åº¦: 2/29 (6.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3147)'), ('usv_1', '(235,4088)'), ('usv_2', '(233,5168)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3101143904359598), 'usv_1': np.float64(0.4232262264669968)}
    Episode time: 126.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 2269, Avg Reward: 4.231, Episode Reward: 9600.6
    æ£€æµ‹è¿›åº¦: 2/51 (3.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3124)'), ('usv_1', '(201,4082)'), ('usv_2', '(229,5206)')]...
    Recent rewards sample: {'usv_0': np.float64(1.317462938841361), 'usv_1': np.float64(0.4192882603617123)}
    Episode time: 226.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 10984.9
  Targets Detected: 2/53 (3.8%)
  Steps: 2403
  Episode Time: 240.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 4.57
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 866, Avg Reward: -3.940, Episode Reward: -3412.4
    æ£€æµ‹è¿›åº¦: 0/25 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3148)'), ('usv_1', '(259,4117)'), ('usv_2', '(244,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6893592789871275), 'usv_1': np.float64(-1.580226507174597)}
    Episode time: 86.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 1866, Avg Reward: 6.716, Episode Reward: 12532.5
    æ£€æµ‹è¿›åº¦: 3/53 (5.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3133)'), ('usv_1', '(228,4100)'), ('usv_2', '(286,5157)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3114309449659878), 'usv_1': np.float64(1.4225206442198028)}
    Episode time: 186.6s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.18143496 -0.03427978] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 2866, Avg Reward: 10.267, Episode Reward: 29426.1
    æ£€æµ‹è¿›åº¦: 4/78 (5.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3139)'), ('usv_1', '(233,4136)'), ('usv_2', '(301,5214)')]...
    Recent rewards sample: {'usv_0': np.float64(2.315276305751513), 'usv_1': np.float64(1.4217983585783185)}
    Episode time: 286.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 31639.6
  Targets Detected: 4/83 (4.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.54
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 865, Avg Reward: 0.435, Episode Reward: 376.5
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3142)'), ('usv_1', '(246,4109)'), ('usv_2', '(246,5161)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3171668332690267), 'usv_1': np.float64(0.41888536531017184)}
    Episode time: 86.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 1865, Avg Reward: 10.531, Episode Reward: 19640.2
    æ£€æµ‹è¿›åº¦: 5/47 (10.6%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3129)'), ('usv_1', '(226,4054)'), ('usv_2', '(231,5175)')]...
    Recent rewards sample: {'usv_0': np.float64(2.31324039823313), 'usv_1': np.float64(3.4181832907433973)}
    Episode time: 186.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 2865, Avg Reward: 13.143, Episode Reward: 37653.3
    æ£€æµ‹è¿›åº¦: 6/62 (9.7%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3104)'), ('usv_1', '(201,4036)'), ('usv_2', '(209,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3296856333871725), 'usv_1': np.float64(3.4194785834688215)}
    Episode time: 286.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 40147.6
  Targets Detected: 6/64 (9.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.38
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 864, Avg Reward: 3.134, Episode Reward: 2707.6
    æ£€æµ‹è¿›åº¦: 0/22 (0.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3148)'), ('usv_1', '(235,4104)'), ('usv_2', '(232,5154)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3180663845647675), 'usv_1': np.float64(2.418024011348683)}
    Episode time: 86.4s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.08747696  0.04931989] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 1864, Avg Reward: 13.009, Episode Reward: 24249.4
    æ£€æµ‹è¿›åº¦: 2/33 (6.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3137)'), ('usv_1', '(223,4068)'), ('usv_2', '(204,5180)')]...
    Recent rewards sample: {'usv_0': np.float64(4.311175264098741), 'usv_1': np.float64(3.4230977638053544)}
    Episode time: 186.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 32054.8
  Targets Detected: 3/39 (5.1%)
  Steps: 2247
  Episode Time: 224.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.27
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 617, Avg Reward: -4.547, Episode Reward: -2805.6
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3152)'), ('usv_1', '(240,4113)'), ('usv_2', '(235,5163)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6842652995844418), 'usv_1': np.float64(-1.579631445236768)}
    Episode time: 61.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 1617, Avg Reward: -1.116, Episode Reward: -1805.3
    æ£€æµ‹è¿›åº¦: 1/36 (2.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3139)'), ('usv_1', '(249,4057)'), ('usv_2', '(216,5208)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31461296502591596), 'usv_1': np.float64(-0.5801673806252735)}
    Episode time: 161.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 2617, Avg Reward: 1.316, Episode Reward: 3442.9
    æ£€æµ‹è¿›åº¦: 2/63 (3.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3160)'), ('usv_1', '(200,4041)'), ('usv_2', '(206,5220)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3208192740498128), 'usv_1': np.float64(0.4260446329204881)}
    Episode time: 261.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 9917.3
  Targets Detected: 3/78 (3.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 3.30
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 616, Avg Reward: -3.068, Episode Reward: -1890.0
    æ£€æµ‹è¿›åº¦: 1/14 (7.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3145)'), ('usv_1', '(248,4122)'), ('usv_2', '(225,5153)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6875812422214167), 'usv_1': np.float64(-1.5779172581953202)}
    Episode time: 61.6s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.14888039 -0.05565273] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 1616, Avg Reward: 0.432, Episode Reward: 697.3
    æ£€æµ‹è¿›åº¦: 2/34 (5.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(204,3133)'), ('usv_1', '(264,4088)'), ('usv_2', '(204,5185)')]...
    Recent rewards sample: {'usv_0': np.float64(1.315587302222545), 'usv_1': np.float64(0.4204259010565665)}
    Episode time: 161.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 2616, Avg Reward: 6.692, Episode Reward: 17505.8
    æ£€æµ‹è¿›åº¦: 5/56 (8.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3114)'), ('usv_1', '(227,4087)'), ('usv_2', '(210,5156)')]...
    Recent rewards sample: {'usv_0': np.float64(2.315864911414274), 'usv_1': np.float64(1.421332500525748)}
    Episode time: 261.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 26531.5
  Targets Detected: 7/65 (9.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.84
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 615, Avg Reward: 1.516, Episode Reward: 932.2
    æ£€æµ‹è¿›åº¦: 1/20 (5.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3144)'), ('usv_1', '(234,4115)'), ('usv_2', '(227,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31563379106477285), 'usv_1': np.float64(1.417912727015472)}
    Episode time: 61.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 1615, Avg Reward: 9.014, Episode Reward: 14557.7
    æ£€æµ‹è¿›åº¦: 4/55 (7.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3142)'), ('usv_1', '(209,4095)'), ('usv_2', '(254,5182)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3099190871759987), 'usv_1': np.float64(3.416553718057494)}
    Episode time: 161.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 2615, Avg Reward: 13.271, Episode Reward: 34704.8
    æ£€æµ‹è¿›åº¦: 5/72 (6.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3155)'), ('usv_1', '(209,4134)'), ('usv_2', '(226,5226)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3156175137665045), 'usv_1': np.float64(3.415982373111275)}
    Episode time: 261.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 42306.5
  Targets Detected: 7/80 (6.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.10

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 22620.0
Last 10 episodes average detections: 3.9
Best episode reward so far: 58650.0
Best detection count so far: 10
Learning trend: Declining (22620.0 vs 33609.8)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.23037149 -0.04758626] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 614, Avg Reward: 2.677, Episode Reward: 1643.5
    æ£€æµ‹è¿›åº¦: 2/15 (13.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3133)'), ('usv_1', '(234,4118)'), ('usv_2', '(233,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3159556646364782), 'usv_1': np.float64(-0.5771193380003139)}
    Episode time: 61.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 1614, Avg Reward: 8.934, Episode Reward: 14418.7
    æ£€æµ‹è¿›åº¦: 3/30 (10.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3165)'), ('usv_1', '(233,4077)'), ('usv_2', '(266,5182)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3134894067862453), 'usv_1': np.float64(1.4182196774862574)}
    Episode time: 161.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 19478.9
  Targets Detected: 3/36 (5.6%)
  Steps: 1964
  Episode Time: 196.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 9.92
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 650, Avg Reward: 6.024, Episode Reward: 3915.6
    æ£€æµ‹è¿›åº¦: 2/24 (8.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3144)'), ('usv_1', '(244,4111)'), ('usv_2', '(232,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3169581932462613), 'usv_1': np.float64(0.42323845679995786)}
    Episode time: 65.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 1650, Avg Reward: 14.718, Episode Reward: 24284.5
    æ£€æµ‹è¿›åº¦: 6/50 (12.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3137)'), ('usv_1', '(266,4051)'), ('usv_2', '(205,5197)')]...
    Recent rewards sample: {'usv_0': np.float64(4.311876788187087), 'usv_1': np.float64(3.431612390812287)}
    Episode time: 165.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 2650, Avg Reward: 16.987, Episode Reward: 45016.4
    æ£€æµ‹è¿›åº¦: 7/67 (10.4%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3118)'), ('usv_1', '(277,3990)'), ('usv_2', '(202,5209)')]...
    Recent rewards sample: {'usv_0': np.float64(4.326925835378655), 'usv_1': np.float64(3.4236942967139106)}
    Episode time: 265.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 54781.8
  Targets Detected: 10/84 (11.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.25
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.04431792  0.12490779] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 649, Avg Reward: 2.390, Episode Reward: 1551.2
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3141)'), ('usv_1', '(248,4118)'), ('usv_2', '(249,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3134042849455927), 'usv_1': np.float64(-0.5800626752838237)}
    Episode time: 64.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 1649, Avg Reward: 13.082, Episode Reward: 21572.2
    æ£€æµ‹è¿›åº¦: 3/60 (5.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3151)'), ('usv_1', '(300,4070)'), ('usv_2', '(290,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(4.310246013738499), 'usv_1': np.float64(3.423528097234575)}
    Episode time: 164.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 39968.2
  Targets Detected: 6/75 (4.0%)
  Steps: 2535
  Episode Time: 253.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.77
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 114, Avg Reward: -0.167, Episode Reward: -19.1
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(217,4129)'), ('usv_2', '(220,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3134034005004397), 'usv_1': np.float64(-0.583421077342265)}
    Episode time: 11.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 1114, Avg Reward: 5.385, Episode Reward: 5999.3
    æ£€æµ‹è¿›åº¦: 2/26 (7.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3145)'), ('usv_1', '(242,4087)'), ('usv_2', '(275,5150)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3124070356501), 'usv_1': np.float64(0.418768635207597)}
    Episode time: 111.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 2114, Avg Reward: 8.236, Episode Reward: 17411.0
    æ£€æµ‹è¿›åº¦: 4/51 (7.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(203,4114)'), ('usv_2', '(264,5203)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3135895798738846), 'usv_1': np.float64(0.41555482745179306)}
    Episode time: 211.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 38133.2
  Targets Detected: 8/75 (9.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.71
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.02861077 -0.10762561] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 113, Avg Reward: -3.560, Episode Reward: -402.2
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(216,4130)'), ('usv_2', '(218,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.686736651976722), 'usv_1': np.float64(-1.5808439298133867)}
    Episode time: 11.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 1113, Avg Reward: 3.322, Episode Reward: 3697.6
    æ£€æµ‹è¿›åº¦: 1/24 (4.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3161)'), ('usv_1', '(265,4112)'), ('usv_2', '(257,5158)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3123177810299249), 'usv_1': np.float64(-0.5784489520308085)}
    Episode time: 111.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 6031.2
  Targets Detected: 1/33 (3.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_137s
  Average Reward/Step: 3.35
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 312, Avg Reward: -3.967, Episode Reward: -1237.6
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3135)'), ('usv_1', '(222,4126)'), ('usv_2', '(226,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.687189431339309), 'usv_1': np.float64(-1.583078130077972)}
    Episode time: 31.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 1312, Avg Reward: -3.708, Episode Reward: -4864.6
    æ£€æµ‹è¿›åº¦: 0/23 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3137)'), ('usv_1', '(256,4080)'), ('usv_2', '(262,5158)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6899257059938959), 'usv_1': np.float64(-1.5800751301038012)}
    Episode time: 131.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: -6579.5
  Targets Detected: 0/35 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.65
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 511, Avg Reward: -3.609, Episode Reward: -1844.3
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3141)'), ('usv_1', '(229,4115)'), ('usv_2', '(226,5153)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6842420121895286), 'usv_1': np.float64(-1.5824443982197824)}
    Episode time: 51.1s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.0541229  0.37372121] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 1511, Avg Reward: -0.937, Episode Reward: -1415.4
    æ£€æµ‹è¿›åº¦: 3/21 (14.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3162)'), ('usv_1', '(250,4073)'), ('usv_2', '(204,5191)')]...
    Recent rewards sample: {'usv_0': np.float64(1.312593523040993), 'usv_1': np.float64(2.4197463422998107)}
    Episode time: 151.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 2511, Avg Reward: 6.116, Episode Reward: 15358.2
    æ£€æµ‹è¿›åº¦: 4/39 (10.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3137)'), ('usv_1', '(205,4068)'), ('usv_2', '(206,5183)')]...
    Recent rewards sample: {'usv_0': np.float64(2.310005231429981), 'usv_1': np.float64(3.420866784541353)}
    Episode time: 251.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 23755.1
  Targets Detected: 4/48 (8.3%)
  Steps: 2969
  Episode Time: 296.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 8.00
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 542, Avg Reward: -3.618, Episode Reward: -1961.1
    æ£€æµ‹è¿›åº¦: 0/17 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3148)'), ('usv_1', '(224,4122)'), ('usv_2', '(230,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.688229988621627), 'usv_1': np.float64(-1.5829000307271106)}
    Episode time: 54.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 1542, Avg Reward: -1.067, Episode Reward: -1645.8
    æ£€æµ‹è¿›åº¦: 2/35 (5.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(204,3131)'), ('usv_1', '(246,4070)'), ('usv_2', '(252,5178)')]...
    Recent rewards sample: {'usv_0': np.float64(2.310464502344341), 'usv_1': np.float64(3.4203319659546443)}
    Episode time: 154.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 2542, Avg Reward: 7.156, Episode Reward: 18190.5
    æ£€æµ‹è¿›åº¦: 3/43 (7.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3116)'), ('usv_1', '(208,4043)'), ('usv_2', '(211,5198)')]...
    Recent rewards sample: {'usv_0': np.float64(2.321885226850618), 'usv_1': np.float64(3.4239521790560152)}
    Episode time: 254.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 25703.9
  Targets Detected: 4/54 (3.7%)
  Steps: 2923
  Episode Time: 292.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 8.79
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.27524477 -0.21536617] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 619, Avg Reward: 0.563, Episode Reward: 348.7
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3145)'), ('usv_1', '(241,4120)'), ('usv_2', '(236,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3142732710735947), 'usv_1': np.float64(-0.5815525263655448)}
    Episode time: 61.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 1619, Avg Reward: 2.918, Episode Reward: 4724.8
    æ£€æµ‹è¿›åº¦: 1/45 (2.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3140)'), ('usv_1', '(230,4074)'), ('usv_2', '(275,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(2.313245950141491), 'usv_1': np.float64(-0.5819199421055943)}
    Episode time: 161.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 5522.8
  Targets Detected: 1/47 (2.1%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_132s
  Average Reward/Step: 3.07
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 818, Avg Reward: 3.823, Episode Reward: 3127.1
    æ£€æµ‹è¿›åº¦: 2/24 (8.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3143)'), ('usv_1', '(246,4117)'), ('usv_2', '(249,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(4.31311761767797), 'usv_1': np.float64(1.4220080272910498)}
    Episode time: 81.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 1818, Avg Reward: 13.212, Episode Reward: 24018.8
    æ£€æµ‹è¿›åº¦: 3/47 (6.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3120)'), ('usv_1', '(206,4079)'), ('usv_2', '(233,5190)')]...
    Recent rewards sample: {'usv_0': np.float64(4.312263120568967), 'usv_1': np.float64(1.416192807622986)}
    Episode time: 181.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: 28559.9
  Targets Detected: 3/55 (1.8%)
  Steps: 2065
  Episode Time: 206.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.83

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 23535.6
Last 10 episodes average detections: 4.0
Best episode reward so far: 58650.0
Best detection count so far: 10
Learning trend: Improving (23535.6 vs 22620.0)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 753, Avg Reward: -3.915, Episode Reward: -2948.1
    æ£€æµ‹è¿›åº¦: 0/24 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3146)'), ('usv_1', '(238,4123)'), ('usv_2', '(251,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7389334467389528), 'usv_1': np.float64(-1.6313594262523594)}
    Episode time: 75.3s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.13607263 0.12112757] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 1753, Avg Reward: 4.617, Episode Reward: 8093.1
    æ£€æµ‹è¿›åº¦: 3/48 (6.2%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,3144)'), ('usv_1', '(231,4074)'), ('usv_2', '(235,5182)')]...
    Recent rewards sample: {'usv_0': np.float64(4.262491862207231), 'usv_1': np.float64(1.3681685287691443)}
    Episode time: 175.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 2753, Avg Reward: 12.096, Episode Reward: 33301.6
    æ£€æµ‹è¿›åº¦: 11/76 (14.5%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3174)'), ('usv_1', '(218,4103)'), ('usv_2', '(205,5191)')]...
    Recent rewards sample: {'usv_0': np.float64(4.256664222747702), 'usv_1': np.float64(3.366782069919437)}
    Episode time: 275.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 38491.0
  Targets Detected: 12/86 (14.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.83
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 752, Avg Reward: -3.798, Episode Reward: -2856.0
    æ£€æµ‹è¿›åº¦: 0/23 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3142)'), ('usv_1', '(245,4132)'), ('usv_2', '(243,5156)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26092768735871663), 'usv_1': np.float64(-0.6312988527950627)}
    Episode time: 75.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 1752, Avg Reward: 4.172, Episode Reward: 7310.1
    æ£€æµ‹è¿›åº¦: 3/54 (5.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3141)'), ('usv_1', '(267,4110)'), ('usv_2', '(210,5165)')]...
    Recent rewards sample: {'usv_0': np.float64(4.265988940901522), 'usv_1': np.float64(3.370416895405617)}
    Episode time: 175.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 2752, Avg Reward: 8.838, Episode Reward: 24321.8
    æ£€æµ‹è¿›åº¦: 3/68 (4.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3158)'), ('usv_1', '(228,4131)'), ('usv_2', '(202,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(4.259542138234695), 'usv_1': np.float64(1.3682548486646717)}
    Episode time: 275.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 30533.5
  Targets Detected: 6/74 (6.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.17
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.13393136  0.24496268] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 751, Avg Reward: 6.702, Episode Reward: 5033.5
    æ£€æµ‹è¿›åº¦: 2/23 (8.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3143)'), ('usv_1', '(248,4126)'), ('usv_2', '(237,5160)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2613039255045098), 'usv_1': np.float64(2.372721562105267)}
    Episode time: 75.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 1751, Avg Reward: 13.972, Episode Reward: 24464.6
    æ£€æµ‹è¿›åº¦: 4/57 (7.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3139)'), ('usv_1', '(294,4095)'), ('usv_2', '(204,5200)')]...
    Recent rewards sample: {'usv_0': np.float64(2.263406390116838), 'usv_1': np.float64(1.3754249255516444)}
    Episode time: 175.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 32243.2
  Targets Detected: 5/80 (3.8%)
  Steps: 2175
  Episode Time: 217.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.82
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 576, Avg Reward: 2.405, Episode Reward: 1385.5
    æ£€æµ‹è¿›åº¦: 2/24 (8.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3146)'), ('usv_1', '(240,4127)'), ('usv_2', '(237,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2620898073505042), 'usv_1': np.float64(0.37226936773991826)}
    Episode time: 57.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 1576, Avg Reward: 13.806, Episode Reward: 21758.3
    æ£€æµ‹è¿›åº¦: 7/52 (13.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3169)'), ('usv_1', '(247,4086)'), ('usv_2', '(287,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2563818871521897), 'usv_1': np.float64(3.3724180072532626)}
    Episode time: 157.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 2576, Avg Reward: 18.818, Episode Reward: 48474.5
    æ£€æµ‹è¿›åº¦: 15/93 (16.1%), Episode total: 15
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3156)'), ('usv_1', '(208,4052)'), ('usv_2', '(268,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(4.260203476138149), 'usv_1': np.float64(3.366984925763564)}
    Episode time: 257.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 57825.4
  Targets Detected: 15/102 (13.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.27
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.20994762 -0.01567134] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 575, Avg Reward: -3.061, Episode Reward: -1759.9
    æ£€æµ‹è¿›åº¦: 0/24 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3143)'), ('usv_1', '(238,4118)'), ('usv_2', '(250,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2631267885653124), 'usv_1': np.float64(-0.6318327566178399)}
    Episode time: 57.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 1575, Avg Reward: 6.171, Episode Reward: 9720.0
    æ£€æµ‹è¿›åº¦: 2/56 (3.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3144)'), ('usv_1', '(251,4074)'), ('usv_2', '(274,5175)')]...
    Recent rewards sample: {'usv_0': np.float64(4.258197099305755), 'usv_1': np.float64(3.3776896563059537)}
    Episode time: 157.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 2575, Avg Reward: 12.859, Episode Reward: 33112.5
    æ£€æµ‹è¿›åº¦: 7/90 (7.8%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3115)'), ('usv_1', '(244,4019)'), ('usv_2', '(248,5206)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2629704175827055), 'usv_1': np.float64(3.370462483015725)}
    Episode time: 257.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 43419.8
  Targets Detected: 10/102 (7.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.47
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 574, Avg Reward: -3.928, Episode Reward: -2254.6
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3144)'), ('usv_1', '(250,4125)'), ('usv_2', '(240,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7340345968187493), 'usv_1': np.float64(-1.6219085607398236)}
    Episode time: 57.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 1574, Avg Reward: 4.003, Episode Reward: 6301.1
    æ£€æµ‹è¿›åº¦: 3/42 (7.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3141)'), ('usv_1', '(272,4083)'), ('usv_2', '(216,5171)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2666283416808746), 'usv_1': np.float64(1.3753493737853706)}
    Episode time: 157.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.05997883 -0.11720763] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 2574, Avg Reward: 10.366, Episode Reward: 26683.1
    æ£€æµ‹è¿›åº¦: 4/61 (6.6%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3118)'), ('usv_1', '(238,4039)'), ('usv_2', '(205,5163)')]...
    Recent rewards sample: {'usv_0': np.float64(4.266939000703419), 'usv_1': np.float64(1.3702161584695847)}
    Episode time: 257.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 36307.9
  Targets Detected: 7/72 (8.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.10
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 573, Avg Reward: 18.085, Episode Reward: 10362.6
    æ£€æµ‹è¿›åº¦: 3/16 (18.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3140)'), ('usv_1', '(239,4125)'), ('usv_2', '(235,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(4.264413728775702), 'usv_1': np.float64(1.3682749242264012)}
    Episode time: 57.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 1573, Avg Reward: 19.073, Episode Reward: 30001.8
    æ£€æµ‹è¿›åº¦: 5/37 (13.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(200,3140)'), ('usv_1', '(266,4089)'), ('usv_2', '(234,5186)')]...
    Recent rewards sample: {'usv_0': np.float64(4.258232161787481), 'usv_1': np.float64(3.379483952027181)}
    Episode time: 157.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 2573, Avg Reward: 20.522, Episode Reward: 52804.0
    æ£€æµ‹è¿›åº¦: 7/64 (10.9%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3123)'), ('usv_1', '(253,4028)'), ('usv_2', '(205,5243)')]...
    Recent rewards sample: {'usv_0': np.float64(4.272589470841702), 'usv_1': np.float64(3.371814028686239)}
    Episode time: 257.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 64431.2
  Targets Detected: 14/78 (14.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.47
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 572, Avg Reward: -3.318, Episode Reward: -1898.2
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3138)'), ('usv_1', '(236,4128)'), ('usv_2', '(245,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7343254032961178), 'usv_1': np.float64(-1.6319949344464106)}
    Episode time: 57.2s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.18685095 0.1777462 ] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 100000, Episode Steps: 1572, Avg Reward: 4.867, Episode Reward: 7650.5
    æ£€æµ‹è¿›åº¦: 3/40 (7.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3131)'), ('usv_1', '(237,4096)'), ('usv_2', '(283,5184)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2664984090032947), 'usv_1': np.float64(0.3690436708980809)}
    Episode time: 157.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 13986.5
  Targets Detected: 4/66 (4.5%)
  Steps: 2193
  Episode Time: 219.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 6.38
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 101000, Episode Steps: 379, Avg Reward: 6.695, Episode Reward: 2537.4
    æ£€æµ‹è¿›åº¦: 1/19 (5.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3137)'), ('usv_1', '(233,4129)'), ('usv_2', '(229,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2667189239568235), 'usv_1': np.float64(0.36782250826737606)}
    Episode time: 37.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 102000, Episode Steps: 1379, Avg Reward: 14.543, Episode Reward: 20055.1
    æ£€æµ‹è¿›åº¦: 2/49 (4.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3166)'), ('usv_1', '(246,4087)'), ('usv_2', '(258,5182)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2585497079502757), 'usv_1': np.float64(1.3703579285782723)}
    Episode time: 137.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 103000, Episode Steps: 2379, Avg Reward: 16.298, Episode Reward: 38773.4
    æ£€æµ‹è¿›åº¦: 6/67 (9.0%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3155)'), ('usv_1', '(210,4060)'), ('usv_2', '(215,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(2.262059005800211), 'usv_1': np.float64(1.3687761906724503)}
    Episode time: 237.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 50175.9
  Targets Detected: 10/79 (10.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.72
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 104000, Episode Steps: 378, Avg Reward: -3.934, Episode Reward: -1487.2
    æ£€æµ‹è¿›åº¦: 0/17 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3133)'), ('usv_1', '(235,4120)'), ('usv_2', '(230,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7351867856299399), 'usv_1': np.float64(-1.6250050663868194)}
    Episode time: 37.8s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.21389486  0.22047242] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 105000, Episode Steps: 1378, Avg Reward: 9.498, Episode Reward: 13088.1
    æ£€æµ‹è¿›åº¦: 3/53 (5.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3137)'), ('usv_1', '(273,4084)'), ('usv_2', '(275,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(4.261881423355392), 'usv_1': np.float64(1.3717524653785542)}
    Episode time: 137.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 106000, Episode Steps: 2378, Avg Reward: 13.428, Episode Reward: 31931.6
    æ£€æµ‹è¿›åº¦: 4/77 (5.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3130)'), ('usv_1', '(277,4024)'), ('usv_2', '(237,5183)')]...
    Recent rewards sample: {'usv_0': np.float64(4.268669424982957), 'usv_1': np.float64(1.3751827328933586)}
    Episode time: 237.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 33358.8
  Targets Detected: 5/80 (5.0%)
  Steps: 2453
  Episode Time: 245.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.60

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 40077.3
Last 10 episodes average detections: 8.8
Best episode reward so far: 64431.2
Best detection count so far: 15
Learning trend: Improving (40077.3 vs 23535.6)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 107000, Episode Steps: 925, Avg Reward: 4.825, Episode Reward: 4462.7
    æ£€æµ‹è¿›åº¦: 3/19 (15.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3147)'), ('usv_1', '(229,4101)'), ('usv_2', '(254,5157)')]...
    Recent rewards sample: {'usv_0': np.float64(2.259683639616047), 'usv_1': np.float64(3.368447158988703)}
    Episode time: 92.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 108000, Episode Steps: 1925, Avg Reward: 15.985, Episode Reward: 30771.7
    æ£€æµ‹è¿›åº¦: 8/48 (16.7%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3129)'), ('usv_1', '(226,4066)'), ('usv_2', '(249,5201)')]...
    Recent rewards sample: {'usv_0': np.float64(4.264197074137446), 'usv_1': np.float64(3.3709607931300347)}
    Episode time: 192.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 109000, Episode Steps: 2925, Avg Reward: 18.261, Episode Reward: 53412.2
    æ£€æµ‹è¿›åº¦: 10/73 (13.7%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3132)'), ('usv_1', '(201,4096)'), ('usv_2', '(221,5179)')]...
    Recent rewards sample: {'usv_0': np.float64(4.263820037621263), 'usv_1': np.float64(3.3715930704495367)}
    Episode time: 292.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 55078.1
  Targets Detected: 10/75 (13.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.35
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.07556889  0.20654539] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 110000, Episode Steps: 924, Avg Reward: -0.616, Episode Reward: -569.0
    æ£€æµ‹è¿›åº¦: 1/34 (2.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3151)'), ('usv_1', '(250,4118)'), ('usv_2', '(259,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2641813109134399), 'usv_1': np.float64(0.3719262719634213)}
    Episode time: 92.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 111000, Episode Steps: 1924, Avg Reward: 12.034, Episode Reward: 23152.6
    æ£€æµ‹è¿›åº¦: 8/70 (11.4%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3144)'), ('usv_1', '(280,4086)'), ('usv_2', '(273,5179)')]...
    Recent rewards sample: {'usv_0': np.float64(4.265410171079644), 'usv_1': np.float64(3.371616700763317)}
    Episode time: 192.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 112000, Episode Steps: 2924, Avg Reward: 15.778, Episode Reward: 46134.4
    æ£€æµ‹è¿›åº¦: 12/92 (13.0%), Episode total: 14
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3158)'), ('usv_1', '(238,4083)'), ('usv_2', '(242,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(4.263742220293523), 'usv_1': np.float64(3.3684969593119174)}
    Episode time: 292.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 47682.5
  Targets Detected: 14/94 (12.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.89
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 113000, Episode Steps: 923, Avg Reward: 5.784, Episode Reward: 5338.9
    æ£€æµ‹è¿›åº¦: 3/29 (10.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3137)'), ('usv_1', '(266,4129)'), ('usv_2', '(252,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(2.269080016350578), 'usv_1': np.float64(3.3703091969883383)}
    Episode time: 92.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 114000, Episode Steps: 1923, Avg Reward: 13.580, Episode Reward: 26115.2
    æ£€æµ‹è¿›åº¦: 6/65 (9.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3141)'), ('usv_1', '(308,4102)'), ('usv_2', '(222,5188)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2646217063838576), 'usv_1': np.float64(3.373586698509901)}
    Episode time: 192.3s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.08006241  0.23509834] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 115000, Episode Steps: 2923, Avg Reward: 17.060, Episode Reward: 49866.2
    æ£€æµ‹è¿›åº¦: 11/98 (11.2%), Episode total: 13
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3157)'), ('usv_1', '(329,4064)'), ('usv_2', '(210,5165)')]...
    Recent rewards sample: {'usv_0': np.float64(4.267086526341848), 'usv_1': np.float64(3.3779690512460796)}
    Episode time: 292.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 51431.1
  Targets Detected: 13/103 (10.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.14
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 116000, Episode Steps: 922, Avg Reward: 3.910, Episode Reward: 3605.1
    æ£€æµ‹è¿›åº¦: 2/26 (7.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3134)'), ('usv_1', '(250,4109)'), ('usv_2', '(246,5153)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2603475136046773), 'usv_1': np.float64(2.372295158732163)}
    Episode time: 92.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 117000, Episode Steps: 1922, Avg Reward: 10.383, Episode Reward: 19956.7
    æ£€æµ‹è¿›åº¦: 4/42 (9.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3108)'), ('usv_1', '(222,4068)'), ('usv_2', '(229,5193)')]...
    Recent rewards sample: {'usv_0': np.float64(4.268968983286386), 'usv_1': np.float64(3.3789456779314406)}
    Episode time: 192.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 118000, Episode Steps: 2922, Avg Reward: 13.235, Episode Reward: 38671.9
    æ£€æµ‹è¿›åº¦: 4/69 (5.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3131)'), ('usv_1', '(206,4062)'), ('usv_2', '(203,5183)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2688869282011614), 'usv_1': np.float64(3.3723958507640894)}
    Episode time: 292.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 39757.5
  Targets Detected: 4/70 (5.7%)
  Steps: 2976
  Episode Time: 297.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.36
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 119000, Episode Steps: 946, Avg Reward: 3.637, Episode Reward: 3440.9
    æ£€æµ‹è¿›åº¦: 1/30 (3.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3143)'), ('usv_1', '(257,4128)'), ('usv_2', '(256,5162)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2694401220620839), 'usv_1': np.float64(-0.6303684674337143)}
    Episode time: 94.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.3593755  -0.06663007] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 120000, Episode Steps: 1946, Avg Reward: 6.809, Episode Reward: 13250.5
    æ£€æµ‹è¿›åº¦: 2/61 (3.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3136)'), ('usv_1', '(280,4092)'), ('usv_2', '(261,5211)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2601921318752247), 'usv_1': np.float64(0.3716115831335123)}
    Episode time: 194.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 121000, Episode Steps: 2946, Avg Reward: 10.596, Episode Reward: 31217.1
    æ£€æµ‹è¿›åº¦: 7/79 (8.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3115)'), ('usv_1', '(256,4040)'), ('usv_2', '(213,5254)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2648040938619367), 'usv_1': np.float64(3.3724084884911996)}
    Episode time: 294.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 32359.3
  Targets Detected: 7/83 (8.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.78
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 122000, Episode Steps: 945, Avg Reward: 10.711, Episode Reward: 10122.3
    æ£€æµ‹è¿›åº¦: 3/39 (7.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3138)'), ('usv_1', '(256,4111)'), ('usv_2', '(217,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2636506129519973), 'usv_1': np.float64(3.3695791882567496)}
    Episode time: 94.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 123000, Episode Steps: 1945, Avg Reward: 15.506, Episode Reward: 30160.1
    æ£€æµ‹è¿›åº¦: 7/64 (10.9%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3121)'), ('usv_1', '(242,4073)'), ('usv_2', '(203,5160)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2663240080314795), 'usv_1': np.float64(1.3743892510216038)}
    Episode time: 194.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 124000, Episode Steps: 2945, Avg Reward: 18.350, Episode Reward: 54041.5
    æ£€æµ‹è¿›åº¦: 13/94 (13.8%), Episode total: 14
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3129)'), ('usv_1', '(211,4078)'), ('usv_2', '(201,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2684413629909246), 'usv_1': np.float64(3.3665657046991697)}
    Episode time: 294.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 55430.9
  Targets Detected: 15/94 (14.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.47
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.11315213 -0.16314471] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 125000, Episode Steps: 944, Avg Reward: 8.773, Episode Reward: 8281.9
    æ£€æµ‹è¿›åº¦: 3/30 (10.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3140)'), ('usv_1', '(249,4114)'), ('usv_2', '(267,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(4.260834068875002), 'usv_1': np.float64(1.3690176604261177)}
    Episode time: 94.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 23191.0
  Targets Detected: 4/59 (3.4%)
  Steps: 1827
  Episode Time: 182.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.69
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 126000, Episode Steps: 117, Avg Reward: -3.988, Episode Reward: -466.6
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3130)'), ('usv_1', '(216,4129)'), ('usv_2', '(218,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7361068792916793), 'usv_1': np.float64(-1.630917184538888)}
    Episode time: 11.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 127000, Episode Steps: 1117, Avg Reward: 10.869, Episode Reward: 12140.6
    æ£€æµ‹è¿›åº¦: 3/47 (6.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3154)'), ('usv_1', '(251,4108)'), ('usv_2', '(246,5177)')]...
    Recent rewards sample: {'usv_0': np.float64(3.260242624409128), 'usv_1': np.float64(0.37076987393849903)}
    Episode time: 111.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 18623.3
  Targets Detected: 3/68 (4.4%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_147s
  Average Reward/Step: 10.34
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 128000, Episode Steps: 316, Avg Reward: -2.853, Episode Reward: -901.4
    æ£€æµ‹è¿›åº¦: 1/12 (8.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3132)'), ('usv_1', '(227,4131)'), ('usv_2', '(228,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7353512723897583), 'usv_1': np.float64(-1.6326306044889123)}
    Episode time: 31.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 129000, Episode Steps: 1316, Avg Reward: 1.455, Episode Reward: 1914.2
    æ£€æµ‹è¿›åº¦: 2/36 (5.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3156)'), ('usv_1', '(274,4108)'), ('usv_2', '(271,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(0.25892367184633003), 'usv_1': np.float64(1.374685902424642)}
    Episode time: 131.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.12925881 -0.05299202] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 130000, Episode Steps: 2316, Avg Reward: 6.947, Episode Reward: 16089.9
    æ£€æµ‹è¿›åº¦: 4/58 (6.9%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3138)'), ('usv_1', '(266,4078)'), ('usv_2', '(236,5167)')]...
    Recent rewards sample: {'usv_0': np.float64(4.260812834829153), 'usv_1': np.float64(3.370718775707118)}
    Episode time: 231.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 30339.9
  Targets Detected: 8/72 (11.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.11
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 131000, Episode Steps: 315, Avg Reward: 5.189, Episode Reward: 1634.4
    æ£€æµ‹è¿›åº¦: 2/19 (10.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3132)'), ('usv_1', '(235,4130)'), ('usv_2', '(218,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(2.264667827657088), 'usv_1': np.float64(-0.624802542273837)}
    Episode time: 31.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 132000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 132000, Episode Steps: 1315, Avg Reward: 4.553, Episode Reward: 5987.5
    æ£€æµ‹è¿›åº¦: 2/50 (4.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3123)'), ('usv_1', '(251,4091)'), ('usv_2', '(239,5178)')]...
    Recent rewards sample: {'usv_0': np.float64(1.268607090250794), 'usv_1': np.float64(2.3694138137167506)}
    Episode time: 131.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 133000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0324, Avg Critic Loss: 8.7233
    Step 133000, Episode Steps: 2315, Avg Reward: 10.640, Episode Reward: 24632.7
    æ£€æµ‹è¿›åº¦: 5/81 (6.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3128)'), ('usv_1', '(201,4068)'), ('usv_2', '(218,5216)')]...
    Recent rewards sample: {'usv_0': np.float64(4.273606085765591), 'usv_1': np.float64(1.3660870961201734)}
    Episode time: 231.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 38388.4
  Targets Detected: 5/101 (4.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.79

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 39228.2
Last 10 episodes average detections: 8.3
Best episode reward so far: 64431.2
Best detection count so far: 15
Learning trend: Declining (39228.2 vs 40077.3)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 64431.2
Final 10 episodes average: 39228.2
Best detection performance: 15 targets
Average detections (final 10): 8.3
============================================================
{"final_avg_reward": 39228.1985316853, "final_detection_rate": 8.3, "best_episode_reward": 64431.230380447894, "best_detection_count": 15, "total_episodes": 50}
Simulation finished.
