D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: -2.252, Episode Reward: -2251.7
    æ£€æµ‹è¿›åº¦: 0/19 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3074)'), ('usv_1', '(320,4088)'), ('usv_2', '(268,5205)')]...
    Recent rewards sample: {'usv_0': np.float64(3.970097807853575), 'usv_1': np.float64(-0.5240359166990781)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 2.932, Episode Reward: 5863.2
    æ£€æµ‹è¿›åº¦: 2/26 (7.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3053)'), ('usv_1', '(384,4020)'), ('usv_2', '(237,5307)')]...
    Recent rewards sample: {'usv_0': np.float64(4.966897551820069), 'usv_1': np.float64(-4.512910414332886)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 3000, Avg Reward: 5.302, Episode Reward: 15904.6
    æ£€æµ‹è¿›åº¦: 2/38 (5.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3111)'), ('usv_1', '(437,3913)'), ('usv_2', '(201,5324)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3732641046530136), 'usv_1': np.float64(0.4891510302562967)}
    Episode time: 300.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 15913.4
  Targets Detected: 2/38 (5.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.30
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 999, Avg Reward: 0.859, Episode Reward: 857.8
    æ£€æµ‹è¿›åº¦: 1/18 (5.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3090)'), ('usv_1', '(311,4131)'), ('usv_2', '(272,5167)')]...
    Recent rewards sample: {'usv_0': np.float64(3.381769653646343), 'usv_1': np.float64(0.4777230321059014)}
    Episode time: 99.9s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.26414558 0.07390855] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 1999, Avg Reward: 12.744, Episode Reward: 25474.7
    æ£€æµ‹è¿›åº¦: 3/32 (9.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(266,3017)'), ('usv_1', '(435,4116)'), ('usv_2', '(250,5281)')]...
    Recent rewards sample: {'usv_0': np.float64(7.980171520984182), 'usv_1': np.float64(1.4864309121123749)}
    Episode time: 199.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 43723.9
  Targets Detected: 6/36 (8.3%)
  Steps: 2728
  Episode Time: 272.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.03
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 271, Avg Reward: -3.223, Episode Reward: -873.5
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3129)'), ('usv_1', '(243,4132)'), ('usv_2', '(242,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6302208543634362), 'usv_1': np.float64(-1.526664740110069)}
    Episode time: 27.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 1271, Avg Reward: 2.489, Episode Reward: 3163.4
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(268,3056)'), ('usv_1', '(334,4125)'), ('usv_2', '(333,5201)')]...
    Recent rewards sample: {'usv_0': np.float64(3.975676092765204), 'usv_1': np.float64(-0.5179845029698982)}
    Episode time: 127.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 2271, Avg Reward: 7.904, Episode Reward: 17950.3
    æ£€æµ‹è¿›åº¦: 2/32 (6.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3025)'), ('usv_1', '(387,4049)'), ('usv_2', '(321,5294)')]...
    Recent rewards sample: {'usv_0': np.float64(4.968497233094646), 'usv_1': np.float64(0.48317362731006575)}
    Episode time: 227.1s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 23481.1
  Targets Detected: 2/36 (5.6%)
  Steps: 2656
  Episode Time: 265.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 8.84
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 615, Avg Reward: 3.034, Episode Reward: 1866.1
    æ£€æµ‹è¿›åº¦: 2/14 (14.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3113)'), ('usv_1', '(288,4132)'), ('usv_2', '(289,5156)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3783991446552952), 'usv_1': np.float64(1.4816971326061612)}
    Episode time: 61.5s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.36552638 -0.18691316] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 1615, Avg Reward: 13.493, Episode Reward: 21791.0
    æ£€æµ‹è¿›åº¦: 3/27 (11.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3048)'), ('usv_1', '(379,4147)'), ('usv_2', '(330,5233)')]...
    Recent rewards sample: {'usv_0': np.float64(5.979789004928351), 'usv_1': np.float64(1.481055051528998)}
    Episode time: 161.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 31120.3
  Targets Detected: 6/32 (12.5%)
  Steps: 2042
  Episode Time: 204.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.24
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 573, Avg Reward: 5.961, Episode Reward: 3415.4
    æ£€æµ‹è¿›åº¦: 1/4 (25.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3124)'), ('usv_1', '(269,4134)'), ('usv_2', '(276,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3797788500477137), 'usv_1': np.float64(-0.5225240724805718)}
    Episode time: 57.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 1573, Avg Reward: 9.021, Episode Reward: 14190.4
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(320,3077)'), ('usv_1', '(338,4067)'), ('usv_2', '(301,5272)')]...
    Recent rewards sample: {'usv_0': np.float64(4.978745932321667), 'usv_1': np.float64(0.47715517825500253)}
    Episode time: 157.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 2573, Avg Reward: 10.720, Episode Reward: 27582.1
    æ£€æµ‹è¿›åº¦: 5/41 (12.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3018)'), ('usv_1', '(399,3975)'), ('usv_2', '(212,5302)')]...
    Recent rewards sample: {'usv_0': np.float64(5.97359908100635), 'usv_1': np.float64(1.4826458801716735)}
    Episode time: 257.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 37613.3
  Targets Detected: 6/47 (12.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.53
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 572, Avg Reward: -3.297, Episode Reward: -1885.9
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3129)'), ('usv_1', '(269,4118)'), ('usv_2', '(293,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.617689852546638), 'usv_1': np.float64(-1.5248197827030556)}
    Episode time: 57.2s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.10714613 -0.26605787] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 1572, Avg Reward: 3.311, Episode Reward: 5204.4
    æ£€æµ‹è¿›åº¦: 2/22 (9.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(289,3060)'), ('usv_1', '(341,4048)'), ('usv_2', '(352,5219)')]...
    Recent rewards sample: {'usv_0': np.float64(4.973680694997878), 'usv_1': np.float64(2.4871937890839373)}
    Episode time: 157.2s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 18392.5
  Targets Detected: 2/33 (3.0%)
  Steps: 2479
  Episode Time: 247.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.42
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 93, Avg Reward: -3.146, Episode Reward: -292.6
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3130)'), ('usv_1', '(225,4130)'), ('usv_2', '(220,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6290271138397346), 'usv_1': np.float64(-1.5312290325971878)}
    Episode time: 9.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 1093, Avg Reward: 8.081, Episode Reward: 8832.5
    æ£€æµ‹è¿›åº¦: 3/31 (9.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(281,3068)'), ('usv_1', '(334,4122)'), ('usv_2', '(307,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(7.9743996424486685), 'usv_1': np.float64(3.4832794210366034)}
    Episode time: 109.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 2093, Avg Reward: 15.066, Episode Reward: 31532.9
    æ£€æµ‹è¿›åº¦: 4/42 (9.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3014)'), ('usv_1', '(441,4119)'), ('usv_2', '(286,5287)')]...
    Recent rewards sample: {'usv_0': np.float64(6.085112148147941), 'usv_1': np.float64(3.4946952247067955)}
    Episode time: 209.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 42761.1
  Targets Detected: 4/47 (8.5%)
  Steps: 2683
  Episode Time: 268.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.94
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 410, Avg Reward: 0.948, Episode Reward: 388.6
    æ£€æµ‹è¿›åº¦: 1/4 (25.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3122)'), ('usv_1', '(256,4137)'), ('usv_2', '(261,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(0.37480213297174103), 'usv_1': np.float64(-0.5304348123751047)}
    Episode time: 41.0s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.12506774 0.22794564] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 1410, Avg Reward: 3.119, Episode Reward: 4398.3
    æ£€æµ‹è¿›åº¦: 1/24 (4.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(266,3056)'), ('usv_1', '(350,4108)'), ('usv_2', '(358,5183)')]...
    Recent rewards sample: {'usv_0': np.float64(3.980677829051889), 'usv_1': np.float64(-0.52290314737879)}
    Episode time: 141.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 6464.7
  Targets Detected: 1/30 (3.3%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_152s
  Average Reward/Step: 3.59
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 609, Avg Reward: 4.442, Episode Reward: 2705.1
    æ£€æµ‹è¿›åº¦: 3/10 (30.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3109)'), ('usv_1', '(264,4115)'), ('usv_2', '(270,5150)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3780631803424276), 'usv_1': np.float64(-0.5207975547847347)}
    Episode time: 60.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 1609, Avg Reward: 10.239, Episode Reward: 16474.3
    æ£€æµ‹è¿›åº¦: 5/24 (20.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(307,3047)'), ('usv_1', '(337,4064)'), ('usv_2', '(355,5237)')]...
    Recent rewards sample: {'usv_0': np.float64(5.974275290531352), 'usv_1': np.float64(1.4761909528150539)}
    Episode time: 160.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 2609, Avg Reward: 11.248, Episode Reward: 29346.7
    æ£€æµ‹è¿›åº¦: 7/45 (15.6%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,2961)'), ('usv_1', '(384,3963)'), ('usv_2', '(387,5351)')]...
    Recent rewards sample: {'usv_0': np.float64(6.003694611953353), 'usv_1': np.float64(-1.5140381609609053)}
    Episode time: 260.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 39669.4
  Targets Detected: 8/54 (14.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.22
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 608, Avg Reward: -3.258, Episode Reward: -1980.6
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3100)'), ('usv_1', '(265,4106)'), ('usv_2', '(261,5152)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.606605895404268), 'usv_1': np.float64(-1.5297042607021745)}
    Episode time: 60.8s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.10207227 -0.11273906] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 1608, Avg Reward: 3.161, Episode Reward: 5082.7
    æ£€æµ‹è¿›åº¦: 4/28 (14.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(249,3019)'), ('usv_1', '(269,4017)'), ('usv_2', '(291,5280)')]...
    Recent rewards sample: {'usv_0': np.float64(4.977288382813541), 'usv_1': np.float64(-2.5234249790331953)}
    Episode time: 160.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 2608, Avg Reward: 6.270, Episode Reward: 16351.6
    æ£€æµ‹è¿›åº¦: 4/37 (10.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3001)'), ('usv_1', '(266,3918)'), ('usv_2', '(269,5371)')]...
    Recent rewards sample: {'usv_0': np.float64(5.970654944703002), 'usv_1': np.float64(-1.5230190620642974)}
    Episode time: 260.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 17195.4
  Targets Detected: 6/37 (10.8%)
  Steps: 2689
  Episode Time: 268.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 6.39

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 27633.5
Last 10 episodes average detections: 4.3
Best episode reward so far: 43723.9
Best detection count so far: 8
Buffer size: 26081
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 919, Avg Reward: 16.258, Episode Reward: 14940.7
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3099)'), ('usv_1', '(310,4154)'), ('usv_2', '(283,5175)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3430495867549146), 'usv_1': np.float64(3.4302850646172507)}
    Episode time: 91.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 1919, Avg Reward: 20.645, Episode Reward: 39617.9
    æ£€æµ‹è¿›åº¦: 5/40 (12.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(316,3028)'), ('usv_1', '(404,4149)'), ('usv_2', '(320,5263)')]...
    Recent rewards sample: {'usv_0': np.float64(7.93453620528309), 'usv_1': np.float64(-4.554927521607267)}
    Episode time: 191.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 2919, Avg Reward: 20.824, Episode Reward: 60784.2
    æ£€æµ‹è¿›åº¦: 6/62 (9.7%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(269,2982)'), ('usv_1', '(527,4171)'), ('usv_2', '(247,5343)')]...
    Recent rewards sample: {'usv_0': np.float64(8.317970098696435), 'usv_1': np.float64(1.445975554038573)}
    Episode time: 291.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 62795.7
  Targets Detected: 8/63 (9.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.92
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.17388066 -0.07637969] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 918, Avg Reward: 11.680, Episode Reward: 10722.7
    æ£€æµ‹è¿›åº¦: 2/22 (9.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3079)'), ('usv_1', '(298,4111)'), ('usv_2', '(285,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(6.929418930963478), 'usv_1': np.float64(0.42790597194181323)}
    Episode time: 91.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 1918, Avg Reward: 15.709, Episode Reward: 30129.7
    æ£€æµ‹è¿›åº¦: 6/49 (12.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3003)'), ('usv_1', '(373,4034)'), ('usv_2', '(315,5252)')]...
    Recent rewards sample: {'usv_0': np.float64(5.9341281998025055), 'usv_1': np.float64(-4.569914838011879)}
    Episode time: 191.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 2918, Avg Reward: 16.117, Episode Reward: 47030.8
    æ£€æµ‹è¿›åº¦: 6/66 (9.1%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,2966)'), ('usv_1', '(441,3957)'), ('usv_2', '(238,5273)')]...
    Recent rewards sample: {'usv_0': np.float64(5.9640384343414325), 'usv_1': np.float64(3.443299549149817)}
    Episode time: 291.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 48865.5
  Targets Detected: 8/71 (8.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.28
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 917, Avg Reward: -3.364, Episode Reward: -3084.7
    æ£€æµ‹è¿›åº¦: 0/22 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3081)'), ('usv_1', '(316,4103)'), ('usv_2', '(290,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(2.929419913859941), 'usv_1': np.float64(-1.5658702153305541)}
    Episode time: 91.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 1917, Avg Reward: 6.969, Episode Reward: 13359.5
    æ£€æµ‹è¿›åº¦: 4/39 (10.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(240,3015)'), ('usv_1', '(395,4062)'), ('usv_2', '(293,5280)')]...
    Recent rewards sample: {'usv_0': np.float64(7.999615826074931), 'usv_1': np.float64(-6.5652144103094585)}
    Episode time: 191.7s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.159059  -0.3067129] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 2917, Avg Reward: 9.517, Episode Reward: 27760.1
    æ£€æµ‹è¿›åº¦: 7/64 (10.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3028)'), ('usv_1', '(469,3998)'), ('usv_2', '(212,5355)')]...
    Recent rewards sample: {'usv_0': np.float64(7.933497933689308), 'usv_1': np.float64(3.439819809952173)}
    Episode time: 291.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 30305.6
  Targets Detected: 8/64 (12.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.10
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 916, Avg Reward: 2.293, Episode Reward: 2100.7
    æ£€æµ‹è¿›åº¦: 1/19 (5.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(272,3079)'), ('usv_1', '(293,4109)'), ('usv_2', '(291,5183)')]...
    Recent rewards sample: {'usv_0': np.float64(3.924932037734665), 'usv_1': np.float64(-0.565377743907435)}
    Episode time: 91.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 1916, Avg Reward: 3.950, Episode Reward: 7568.1
    æ£€æµ‹è¿›åº¦: 2/41 (4.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(269,2994)'), ('usv_1', '(411,4066)'), ('usv_2', '(310,5295)')]...
    Recent rewards sample: {'usv_0': np.float64(6.063859054671429), 'usv_1': np.float64(1.438360033878113)}
    Episode time: 191.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 2916, Avg Reward: 10.496, Episode Reward: 30606.0
    æ£€æµ‹è¿›åº¦: 4/65 (6.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3021)'), ('usv_1', '(497,4014)'), ('usv_2', '(241,5360)')]...
    Recent rewards sample: {'usv_0': np.float64(5.9741931366184176), 'usv_1': np.float64(1.4404461568364888)}
    Episode time: 291.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 32488.2
  Targets Detected: 4/68 (5.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.83
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 915, Avg Reward: -0.520, Episode Reward: -476.2
    æ£€æµ‹è¿›åº¦: 1/19 (5.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3098)'), ('usv_1', '(295,4110)'), ('usv_2', '(281,5195)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33231419569689735), 'usv_1': np.float64(-0.5734229827034164)}
    Episode time: 91.5s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.047593  -0.3113678] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 1915, Avg Reward: 4.952, Episode Reward: 9483.8
    æ£€æµ‹è¿›åº¦: 3/39 (7.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3026)'), ('usv_1', '(365,4060)'), ('usv_2', '(242,5284)')]...
    Recent rewards sample: {'usv_0': np.float64(6.970468760129677), 'usv_1': np.float64(0.4311530684056788)}
    Episode time: 191.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 2915, Avg Reward: 9.274, Episode Reward: 27035.1
    æ£€æµ‹è¿›åº¦: 3/66 (4.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,2935)'), ('usv_1', '(441,3994)'), ('usv_2', '(202,5329)')]...
    Recent rewards sample: {'usv_0': np.float64(8.098806931951763), 'usv_1': np.float64(1.4352683708711869)}
    Episode time: 291.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 28783.5
  Targets Detected: 4/66 (4.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.59
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 914, Avg Reward: 4.506, Episode Reward: 4118.8
    æ£€æµ‹è¿›åº¦: 2/15 (13.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,3070)'), ('usv_1', '(309,4086)'), ('usv_2', '(290,5193)')]...
    Recent rewards sample: {'usv_0': np.float64(4.926734287180583), 'usv_1': np.float64(0.4238037723623249)}
    Episode time: 91.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 1914, Avg Reward: 14.230, Episode Reward: 27235.8
    æ£€æµ‹è¿›åº¦: 5/35 (14.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(204,3012)'), ('usv_1', '(368,3978)'), ('usv_2', '(256,5275)')]...
    Recent rewards sample: {'usv_0': np.float64(5.93127750991691), 'usv_1': np.float64(1.4382615103854186)}
    Episode time: 191.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 2914, Avg Reward: 17.357, Episode Reward: 50579.1
    æ£€æµ‹è¿›åº¦: 5/52 (9.6%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,2983)'), ('usv_1', '(368,3881)'), ('usv_2', '(206,5228)')]...
    Recent rewards sample: {'usv_0': np.float64(5.919552669199214), 'usv_1': np.float64(1.4339172536211793)}
    Episode time: 291.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 51980.9
  Targets Detected: 6/53 (9.4%)
  Steps: 2977
  Episode Time: 297.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 17.46
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.17282392 0.05478941] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 937, Avg Reward: -0.878, Episode Reward: -822.4
    æ£€æµ‹è¿›åº¦: 1/20 (5.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3084)'), ('usv_1', '(324,4124)'), ('usv_2', '(300,5167)')]...
    Recent rewards sample: {'usv_0': np.float64(4.930281735202603), 'usv_1': np.float64(0.4296203115812125)}
    Episode time: 93.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 1937, Avg Reward: 9.164, Episode Reward: 17750.3
    æ£€æµ‹è¿›åº¦: 4/41 (9.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3044)'), ('usv_1', '(447,4107)'), ('usv_2', '(296,5271)')]...
    Recent rewards sample: {'usv_0': np.float64(7.917947630268989), 'usv_1': np.float64(-6.56389123892545)}
    Episode time: 193.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 2937, Avg Reward: 11.442, Episode Reward: 33605.4
    æ£€æµ‹è¿›åº¦: 7/56 (12.5%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3132)'), ('usv_1', '(551,4047)'), ('usv_2', '(203,5329)')]...
    Recent rewards sample: {'usv_0': np.float64(4.319922351423049), 'usv_1': np.float64(1.4525837100764596)}
    Episode time: 293.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 34783.8
  Targets Detected: 8/56 (12.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.59
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 936, Avg Reward: 7.416, Episode Reward: 6941.6
    æ£€æµ‹è¿›åº¦: 2/25 (8.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3109)'), ('usv_1', '(308,4115)'), ('usv_2', '(272,5191)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3386792828456615), 'usv_1': np.float64(0.42552689215030126)}
    Episode time: 93.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 1936, Avg Reward: 12.452, Episode Reward: 24106.2
    æ£€æµ‹è¿›åº¦: 3/55 (5.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(298,3028)'), ('usv_1', '(408,4086)'), ('usv_2', '(228,5296)')]...
    Recent rewards sample: {'usv_0': np.float64(5.924659963655682), 'usv_1': np.float64(-6.566714594047449)}
    Episode time: 193.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 27817.9
  Targets Detected: 3/65 (4.6%)
  Steps: 2554
  Episode Time: 255.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.89
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.26226858 -0.13028763] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 382, Avg Reward: 3.273, Episode Reward: 1250.4
    æ£€æµ‹è¿›åº¦: 1/13 (7.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3115)'), ('usv_1', '(252,4126)'), ('usv_2', '(246,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3364294187401269), 'usv_1': np.float64(1.4264716499584416)}
    Episode time: 38.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 1382, Avg Reward: 6.467, Episode Reward: 8937.3
    æ£€æµ‹è¿›åº¦: 1/30 (3.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3046)'), ('usv_1', '(379,4113)'), ('usv_2', '(286,5212)')]...
    Recent rewards sample: {'usv_0': np.float64(4.921811569639319), 'usv_1': np.float64(0.42903033937824153)}
    Episode time: 138.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 2382, Avg Reward: 9.288, Episode Reward: 22123.9
    æ£€æµ‹è¿›åº¦: 3/62 (4.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3003)'), ('usv_1', '(457,4056)'), ('usv_2', '(208,5243)')]...
    Recent rewards sample: {'usv_0': np.float64(6.029645163252891), 'usv_1': np.float64(-6.555786946931519)}
    Episode time: 238.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 24632.5
  Targets Detected: 4/67 (4.5%)
  Steps: 2720
  Episode Time: 272.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 9.06
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 662, Avg Reward: -3.587, Episode Reward: -2374.8
    æ£€æµ‹è¿›åº¦: 0/17 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3128)'), ('usv_1', '(277,4110)'), ('usv_2', '(235,5166)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6747287787600266), 'usv_1': np.float64(-1.5742104515207747)}
    Episode time: 66.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 1662, Avg Reward: -1.313, Episode Reward: -2182.1
    æ£€æµ‹è¿›åº¦: 1/38 (2.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(316,3063)'), ('usv_1', '(360,4098)'), ('usv_2', '(202,5250)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9269789929659), 'usv_1': np.float64(-0.5647838358019429)}
    Episode time: 166.2s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.15339408 -0.09284124] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 2662, Avg Reward: 7.582, Episode Reward: 20184.4
    æ£€æµ‹è¿›åº¦: 4/65 (6.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3007)'), ('usv_1', '(472,4081)'), ('usv_2', '(209,5253)')]...
    Recent rewards sample: {'usv_0': np.float64(5.927578371635946), 'usv_1': np.float64(3.436219331325356)}
    Episode time: 266.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 29376.3
  Targets Detected: 6/73 (6.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.79

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 37183.0
Last 10 episodes average detections: 5.9
Best episode reward so far: 62795.7
Best detection count so far: 8
Learning trend: Improving (37183.0 vs 27633.5)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 661, Avg Reward: 13.728, Episode Reward: 9074.5
    æ£€æµ‹è¿›åº¦: 3/13 (23.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3114)'), ('usv_1', '(244,4103)'), ('usv_2', '(277,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3257142739044387), 'usv_1': np.float64(3.4187790465301546)}
    Episode time: 66.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 1661, Avg Reward: 17.846, Episode Reward: 29641.4
    æ£€æµ‹è¿›åº¦: 3/45 (6.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3052)'), ('usv_1', '(254,3997)'), ('usv_2', '(303,5241)')]...
    Recent rewards sample: {'usv_0': np.float64(5.928915882794971), 'usv_1': np.float64(3.4284680188982115)}
    Episode time: 166.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 2661, Avg Reward: 19.848, Episode Reward: 52815.8
    æ£€æµ‹è¿›åº¦: 6/67 (9.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3007)'), ('usv_1', '(245,3890)'), ('usv_2', '(236,5281)')]...
    Recent rewards sample: {'usv_0': np.float64(7.92005446481807), 'usv_1': np.float64(3.4413189882713198)}
    Episode time: 266.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 62063.4
  Targets Detected: 7/80 (7.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.68
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 660, Avg Reward: 18.715, Episode Reward: 12352.0
    æ£€æµ‹è¿›åº¦: 4/18 (22.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3092)'), ('usv_1', '(277,4127)'), ('usv_2', '(268,5160)')]...
    Recent rewards sample: {'usv_0': np.float64(4.337304527941173), 'usv_1': np.float64(3.430873884366819)}
    Episode time: 66.0s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.04949563 -0.23718013] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 1660, Avg Reward: 20.704, Episode Reward: 34368.4
    æ£€æµ‹è¿›åº¦: 4/41 (9.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(200,3007)'), ('usv_1', '(368,4053)'), ('usv_2', '(255,5246)')]...
    Recent rewards sample: {'usv_0': np.float64(7.917933543645724), 'usv_1': np.float64(-4.570270489333817)}
    Episode time: 166.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 30835.0
  Targets Detected: 5/50 (8.0%)
  Steps: 2141
  Episode Time: 214.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.40
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 519, Avg Reward: 2.683, Episode Reward: 1392.6
    æ£€æµ‹è¿›åº¦: 1/13 (7.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3112)'), ('usv_1', '(269,4121)'), ('usv_2', '(265,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3221297783215642), 'usv_1': np.float64(-0.5759590156034398)}
    Episode time: 51.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 1519, Avg Reward: 5.472, Episode Reward: 8312.6
    æ£€æµ‹è¿›åº¦: 1/31 (3.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3045)'), ('usv_1', '(350,4062)'), ('usv_2', '(294,5229)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9207184632015784), 'usv_1': np.float64(-0.5696555844656682)}
    Episode time: 151.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 10601.1
  Targets Detected: 1/37 (2.7%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_150s
  Average Reward/Step: 5.89
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 718, Avg Reward: -3.576, Episode Reward: -2567.5
    æ£€æµ‹è¿›åº¦: 0/15 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3099)'), ('usv_1', '(279,4108)'), ('usv_2', '(294,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6672519058561445), 'usv_1': np.float64(-1.5653863106768307)}
    Episode time: 71.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 1718, Avg Reward: 1.375, Episode Reward: 2362.6
    æ£€æµ‹è¿›åº¦: 1/28 (3.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(269,3030)'), ('usv_1', '(377,4031)'), ('usv_2', '(358,5234)')]...
    Recent rewards sample: {'usv_0': np.float64(4.924167964426581), 'usv_1': np.float64(0.4445819289825257)}
    Episode time: 171.8s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.27577859 -0.20057313] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 2718, Avg Reward: 0.966, Episode Reward: 2626.7
    æ£€æµ‹è¿›åº¦: 2/48 (4.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,2997)'), ('usv_1', '(417,3973)'), ('usv_2', '(296,5292)')]...
    Recent rewards sample: {'usv_0': np.float64(5.925685029390581), 'usv_1': np.float64(1.4393557129289154)}
    Episode time: 271.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 8370.8
  Targets Detected: 2/53 (3.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 2.79
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 717, Avg Reward: 3.047, Episode Reward: 2184.4
    æ£€æµ‹è¿›åº¦: 2/20 (10.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3115)'), ('usv_1', '(283,4119)'), ('usv_2', '(251,5162)')]...
    Recent rewards sample: {'usv_0': np.float64(1.333929811315374), 'usv_1': np.float64(0.4235951490506691)}
    Episode time: 71.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 1717, Avg Reward: 12.887, Episode Reward: 22126.5
    æ£€æµ‹è¿›åº¦: 2/29 (6.9%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3057)'), ('usv_1', '(375,4036)'), ('usv_2', '(208,5279)')]...
    Recent rewards sample: {'usv_0': np.float64(7.922258500299865), 'usv_1': np.float64(1.4295424369060408)}
    Episode time: 171.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 32377.4
  Targets Detected: 4/43 (7.0%)
  Steps: 2136
  Episode Time: 213.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.16
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 581, Avg Reward: -0.409, Episode Reward: -237.7
    æ£€æµ‹è¿›åº¦: 1/9 (11.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3121)'), ('usv_1', '(267,4126)'), ('usv_2', '(269,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32915970272218853), 'usv_1': np.float64(-0.5771198057181431)}
    Episode time: 58.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 1581, Avg Reward: 11.566, Episode Reward: 18285.1
    æ£€æµ‹è¿›åº¦: 1/27 (3.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(286,3044)'), ('usv_1', '(349,4108)'), ('usv_2', '(324,5189)')]...
    Recent rewards sample: {'usv_0': np.float64(5.926846685449682), 'usv_1': np.float64(-4.567988749122138)}
    Episode time: 158.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 22426.0
  Targets Detected: 3/43 (2.3%)
  Steps: 2206
  Episode Time: 220.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.17
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.05950736 -0.10216379] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 375, Avg Reward: 5.027, Episode Reward: 1885.3
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3130)'), ('usv_1', '(247,4125)'), ('usv_2', '(246,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3222342806377776), 'usv_1': np.float64(-0.5731488507780299)}
    Episode time: 37.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 1375, Avg Reward: 10.295, Episode Reward: 14156.3
    æ£€æµ‹è¿›åº¦: 4/41 (9.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(322,3105)'), ('usv_1', '(341,4104)'), ('usv_2', '(234,5224)')]...
    Recent rewards sample: {'usv_0': np.float64(2.350136970910673), 'usv_1': np.float64(1.432342911293497)}
    Episode time: 137.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 2375, Avg Reward: 11.573, Episode Reward: 27486.4
    æ£€æµ‹è¿›åº¦: 5/60 (8.3%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(348,3041)'), ('usv_1', '(442,4058)'), ('usv_2', '(203,5204)')]...
    Recent rewards sample: {'usv_0': np.float64(5.971394514532168), 'usv_1': np.float64(1.4341738708195675)}
    Episode time: 237.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 35740.6
  Targets Detected: 7/62 (6.5%)
  Steps: 2816
  Episode Time: 281.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.69
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 559, Avg Reward: 3.251, Episode Reward: 1817.3
    æ£€æµ‹è¿›åº¦: 1/21 (4.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3101)'), ('usv_1', '(262,4116)'), ('usv_2', '(270,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33305798636336403), 'usv_1': np.float64(-0.5785157794156428)}
    Episode time: 55.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 1559, Avg Reward: 13.471, Episode Reward: 21000.6
    æ£€æµ‹è¿›åº¦: 4/43 (9.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3020)'), ('usv_1', '(353,4090)'), ('usv_2', '(281,5229)')]...
    Recent rewards sample: {'usv_0': np.float64(5.928820873263733), 'usv_1': np.float64(3.430069930738421)}
    Episode time: 155.9s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.17010924 -0.04105965] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 2559, Avg Reward: 17.652, Episode Reward: 45172.5
    æ£€æµ‹è¿›åº¦: 5/69 (7.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3007)'), ('usv_1', '(458,4013)'), ('usv_2', '(205,5236)')]...
    Recent rewards sample: {'usv_0': np.float64(5.920544070220674), 'usv_1': np.float64(3.4418964887793164)}
    Episode time: 255.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 50751.7
  Targets Detected: 6/74 (6.8%)
  Steps: 2868
  Episode Time: 286.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 17.70
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 691, Avg Reward: 1.754, Episode Reward: 1212.1
    æ£€æµ‹è¿›åº¦: 1/14 (7.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(266,3097)'), ('usv_1', '(270,4112)'), ('usv_2', '(264,5176)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33949920707152503), 'usv_1': np.float64(-0.5765459315178367)}
    Episode time: 69.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 1691, Avg Reward: -0.806, Episode Reward: -1363.2
    æ£€æµ‹è¿›åº¦: 1/24 (4.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3030)'), ('usv_1', '(356,4037)'), ('usv_2', '(235,5299)')]...
    Recent rewards sample: {'usv_0': np.float64(4.949723953919952), 'usv_1': np.float64(-7.562268217290422)}
    Episode time: 169.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: -1774.8
  Targets Detected: 1/25 (4.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_159s
  Average Reward/Step: -0.99
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 890, Avg Reward: -3.626, Episode Reward: -3227.4
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3094)'), ('usv_1', '(297,4108)'), ('usv_2', '(271,5177)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6588587071090316), 'usv_1': np.float64(-1.5718640128325692)}
    Episode time: 89.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: -8036.3
  Targets Detected: 0/31 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -4.46

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 24335.5
Last 10 episodes average detections: 3.6
Best episode reward so far: 62795.7
Best detection count so far: 8
Learning trend: Declining (24335.5 vs 37183.0)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 89, Avg Reward: -4.779, Episode Reward: -425.3
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3130)'), ('usv_1', '(224,4131)'), ('usv_2', '(224,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7279208984679412), 'usv_1': np.float64(-1.6271465821408366)}
    Episode time: 8.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.02222453 0.24945073] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 1089, Avg Reward: 2.992, Episode Reward: 3258.2
    æ£€æµ‹è¿›åº¦: 1/37 (2.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3101)'), ('usv_1', '(343,4116)'), ('usv_2', '(272,5184)')]...
    Recent rewards sample: {'usv_0': np.float64(0.28751079211856434), 'usv_1': np.float64(-0.6207857967242401)}
    Episode time: 108.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 2089, Avg Reward: 5.969, Episode Reward: 12468.7
    æ£€æµ‹è¿›åº¦: 5/70 (7.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3042)'), ('usv_1', '(425,4070)'), ('usv_2', '(218,5281)')]...
    Recent rewards sample: {'usv_0': np.float64(7.92004877466956), 'usv_1': np.float64(-6.614026055299167)}
    Episode time: 208.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 26619.5
  Targets Detected: 6/92 (5.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.87
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 88, Avg Reward: 2.161, Episode Reward: 190.2
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(219,4130)'), ('usv_2', '(224,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2696126361054314), 'usv_1': np.float64(-0.633271675539059)}
    Episode time: 8.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 1088, Avg Reward: 15.799, Episode Reward: 17189.8
    æ£€æµ‹è¿›åº¦: 5/36 (13.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3077)'), ('usv_1', '(319,4118)'), ('usv_2', '(308,5158)')]...
    Recent rewards sample: {'usv_0': np.float64(5.876274608240245), 'usv_1': np.float64(3.3753703810665305)}
    Episode time: 108.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 2088, Avg Reward: 15.850, Episode Reward: 33095.4
    æ£€æµ‹è¿›åº¦: 7/72 (9.7%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3019)'), ('usv_1', '(426,4124)'), ('usv_2', '(319,5260)')]...
    Recent rewards sample: {'usv_0': np.float64(7.994622105208638), 'usv_1': np.float64(-6.604190418793586)}
    Episode time: 208.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 55248.4
  Targets Detected: 11/100 (8.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.41
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.43984425 -0.20742794] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 87, Avg Reward: -3.894, Episode Reward: -338.8
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3130)'), ('usv_1', '(221,4130)'), ('usv_2', '(226,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7179591052670984), 'usv_1': np.float64(-1.628163986734953)}
    Episode time: 8.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 1087, Avg Reward: 2.662, Episode Reward: 2893.1
    æ£€æµ‹è¿›åº¦: 1/48 (2.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3062)'), ('usv_1', '(300,4096)'), ('usv_2', '(279,5197)')]...
    Recent rewards sample: {'usv_0': np.float64(3.88121817084526), 'usv_1': np.float64(-0.6229662524397587)}
    Episode time: 108.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 2087, Avg Reward: 3.844, Episode Reward: 8022.6
    æ£€æµ‹è¿›åº¦: 3/84 (3.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3038)'), ('usv_1', '(400,4028)'), ('usv_2', '(219,5302)')]...
    Recent rewards sample: {'usv_0': np.float64(5.893816349318105), 'usv_1': np.float64(1.3857122065344285)}
    Episode time: 208.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 14741.2
  Targets Detected: 4/102 (2.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 4.91
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 86, Avg Reward: 4.096, Episode Reward: 352.2
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3130)'), ('usv_1', '(217,4130)'), ('usv_2', '(221,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2669191783326923), 'usv_1': np.float64(-0.6288600732952265)}
    Episode time: 8.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 1086, Avg Reward: 11.008, Episode Reward: 11954.6
    æ£€æµ‹è¿›åº¦: 4/31 (12.9%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(286,3087)'), ('usv_1', '(311,4110)'), ('usv_2', '(270,5211)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2910197146214464), 'usv_1': np.float64(3.373825177946232)}
    Episode time: 108.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.15768113 -0.1834424 ] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 2086, Avg Reward: 19.182, Episode Reward: 40012.8
    æ£€æµ‹è¿›åº¦: 9/58 (15.5%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3097)'), ('usv_1', '(414,4097)'), ('usv_2', '(234,5305)')]...
    Recent rewards sample: {'usv_0': np.float64(4.274426787990045), 'usv_1': np.float64(3.3886799312197438)}
    Episode time: 208.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 61714.9
  Targets Detected: 14/83 (10.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.56
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 85, Avg Reward: 4.081, Episode Reward: 346.9
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3130)'), ('usv_1', '(217,4130)'), ('usv_2', '(225,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(2.27413110445114), 'usv_1': np.float64(-0.6215184118857571)}
    Episode time: 8.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 1085, Avg Reward: 18.301, Episode Reward: 19857.0
    æ£€æµ‹è¿›åº¦: 6/44 (13.6%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(328,3085)'), ('usv_1', '(329,4139)'), ('usv_2', '(312,5181)')]...
    Recent rewards sample: {'usv_0': np.float64(7.883160080785336), 'usv_1': np.float64(3.383874236164865)}
    Episode time: 108.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 2085, Avg Reward: 21.164, Episode Reward: 44126.5
    æ£€æµ‹è¿›åº¦: 8/75 (10.7%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(348,3007)'), ('usv_1', '(426,4118)'), ('usv_2', '(289,5270)')]...
    Recent rewards sample: {'usv_0': np.float64(7.985573720902053), 'usv_1': np.float64(3.399674453045879)}
    Episode time: 208.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 72825.9
  Targets Detected: 18/104 (12.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 24.27
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 84, Avg Reward: -3.929, Episode Reward: -330.1
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(219,4130)'), ('usv_2', '(219,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7364407262852394), 'usv_1': np.float64(-1.6318213808565811)}
    Episode time: 8.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.39121698 0.01612018] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 1084, Avg Reward: 3.606, Episode Reward: 3908.7
    æ£€æµ‹è¿›åº¦: 1/29 (3.4%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(283,3061)'), ('usv_1', '(308,4105)'), ('usv_2', '(295,5211)')]...
    Recent rewards sample: {'usv_0': np.float64(3.8890816514466864), 'usv_1': np.float64(-0.6214538202551455)}
    Episode time: 108.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 2084, Avg Reward: 9.876, Episode Reward: 20580.6
    æ£€æµ‹è¿›åº¦: 8/63 (12.7%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(281,2965)'), ('usv_1', '(423,4112)'), ('usv_2', '(290,5307)')]...
    Recent rewards sample: {'usv_0': np.float64(7.977084545695297), 'usv_1': np.float64(-8.60808245033309)}
    Episode time: 208.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 45812.1
  Targets Detected: 11/83 (10.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.27
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 83, Avg Reward: -3.930, Episode Reward: -326.2
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3129)'), ('usv_1', '(216,4130)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7258193238636955), 'usv_1': np.float64(-1.6312629963006562)}
    Episode time: 8.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 1083, Avg Reward: 8.082, Episode Reward: 8753.3
    æ£€æµ‹è¿›åº¦: 2/41 (4.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3071)'), ('usv_1', '(274,4061)'), ('usv_2', '(276,5218)')]...
    Recent rewards sample: {'usv_0': np.float64(4.875754598475931), 'usv_1': np.float64(0.37161021776486325)}
    Episode time: 108.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 2083, Avg Reward: 7.534, Episode Reward: 15694.1
    æ£€æµ‹è¿›åº¦: 3/69 (4.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3005)'), ('usv_1', '(309,3976)'), ('usv_2', '(212,5311)')]...
    Recent rewards sample: {'usv_0': np.float64(5.873101472809712), 'usv_1': np.float64(1.3763751517978133)}
    Episode time: 208.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 24056.9
  Targets Detected: 6/97 (6.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.02
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.11865226 -0.18410457] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 100000, Episode Steps: 82, Avg Reward: -3.894, Episode Reward: -319.3
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3130)'), ('usv_1', '(223,4130)'), ('usv_2', '(220,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.729405079216933), 'usv_1': np.float64(-1.6266658693725624)}
    Episode time: 8.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 101000, Episode Steps: 1082, Avg Reward: -3.283, Episode Reward: -3551.7
    æ£€æµ‹è¿›åº¦: 0/32 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(298,3074)'), ('usv_1', '(312,4104)'), ('usv_2', '(312,5169)')]...
    Recent rewards sample: {'usv_0': np.float64(2.8880641332989057), 'usv_1': np.float64(-1.6236729810858646)}
    Episode time: 108.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 102000, Episode Steps: 2082, Avg Reward: -0.081, Episode Reward: -167.9
    æ£€æµ‹è¿›åº¦: 2/65 (3.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(272,2981)'), ('usv_1', '(351,4032)'), ('usv_2', '(333,5250)')]...
    Recent rewards sample: {'usv_0': np.float64(3.8854158796977063), 'usv_1': np.float64(-0.6124833556469063)}
    Episode time: 208.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 15417.8
  Targets Detected: 7/96 (6.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.14
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 103000, Episode Steps: 81, Avg Reward: -3.901, Episode Reward: -316.0
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3129)'), ('usv_1', '(216,4130)'), ('usv_2', '(218,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7318254190536774), 'usv_1': np.float64(-1.6244954287808349)}
    Episode time: 8.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 104000, Episode Steps: 1081, Avg Reward: 9.251, Episode Reward: 10000.7
    æ£€æµ‹è¿›åº¦: 2/29 (6.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3067)'), ('usv_1', '(310,4122)'), ('usv_2', '(278,5218)')]...
    Recent rewards sample: {'usv_0': np.float64(4.876535104959469), 'usv_1': np.float64(0.3779014341141891)}
    Episode time: 108.1s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.03665554 -0.23171479] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 105000, Episode Steps: 2081, Avg Reward: 16.606, Episode Reward: 34557.3
    æ£€æµ‹è¿›åº¦: 5/49 (10.2%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(204,3020)'), ('usv_1', '(417,4098)'), ('usv_2', '(200,5317)')]...
    Recent rewards sample: {'usv_0': np.float64(7.869519036951928), 'usv_1': np.float64(1.3853678766549185)}
    Episode time: 208.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 58206.5
  Targets Detected: 14/72 (15.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.40
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 106000, Episode Steps: 80, Avg Reward: 1.997, Episode Reward: 159.8
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3130)'), ('usv_1', '(219,4130)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2651121088447768), 'usv_1': np.float64(0.3689522236668057)}
    Episode time: 8.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 107000, Episode Steps: 1080, Avg Reward: 22.098, Episode Reward: 23865.4
    æ£€æµ‹è¿›åº¦: 5/31 (16.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3052)'), ('usv_1', '(295,4093)'), ('usv_2', '(289,5183)')]...
    Recent rewards sample: {'usv_0': np.float64(7.879832744795811), 'usv_1': np.float64(3.3802999870687156)}
    Episode time: 108.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 108000, Episode Steps: 2080, Avg Reward: 18.845, Episode Reward: 39197.0
    æ£€æµ‹è¿›åº¦: 9/68 (13.2%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,2981)'), ('usv_1', '(370,4040)'), ('usv_2', '(250,5286)')]...
    Recent rewards sample: {'usv_0': np.float64(8.010743919412164), 'usv_1': np.float64(3.384756041656546)}
    Episode time: 208.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 57186.2
  Targets Detected: 12/80 (12.5%)
  Steps: 2797
  Episode Time: 279.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 20.45

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 43183.0
Last 10 episodes average detections: 10.3
Best episode reward so far: 72825.9
Best detection count so far: 18
Learning trend: Improving (43183.0 vs 24335.5)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 109000, Episode Steps: 283, Avg Reward: -2.728, Episode Reward: -772.0
    æ£€æµ‹è¿›åº¦: 1/17 (5.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3125)'), ('usv_1', '(231,4130)'), ('usv_2', '(254,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7232321622288224), 'usv_1': np.float64(-1.62971260525311)}
    Episode time: 28.3s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.00692204 -0.04223944] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 110000, Episode Steps: 1283, Avg Reward: 9.209, Episode Reward: 11815.6
    æ£€æµ‹è¿›åº¦: 5/49 (10.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(330,3060)'), ('usv_1', '(326,4105)'), ('usv_2', '(289,5210)')]...
    Recent rewards sample: {'usv_0': np.float64(5.876865622869294), 'usv_1': np.float64(3.376658592967779)}
    Episode time: 128.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 111000, Episode Steps: 2283, Avg Reward: 16.986, Episode Reward: 38779.2
    æ£€æµ‹è¿›åº¦: 8/73 (11.0%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,2966)'), ('usv_1', '(420,4043)'), ('usv_2', '(208,5239)')]...
    Recent rewards sample: {'usv_0': np.float64(5.886275139714181), 'usv_1': np.float64(3.382737430057004)}
    Episode time: 228.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 42428.6
  Targets Detected: 11/90 (10.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.14
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 112000, Episode Steps: 282, Avg Reward: 9.650, Episode Reward: 2721.4
    æ£€æµ‹è¿›åº¦: 2/6 (33.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(243,3128)'), ('usv_1', '(248,4129)'), ('usv_2', '(241,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(3.270937247173909), 'usv_1': np.float64(0.3769995384451226)}
    Episode time: 28.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 113000, Episode Steps: 1282, Avg Reward: 17.838, Episode Reward: 22868.2
    æ£€æµ‹è¿›åº¦: 2/40 (5.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3071)'), ('usv_1', '(343,4105)'), ('usv_2', '(296,5195)')]...
    Recent rewards sample: {'usv_0': np.float64(7.873280077252739), 'usv_1': np.float64(1.3762663493417087)}
    Episode time: 128.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 26750.1
  Targets Detected: 6/70 (5.7%)
  Steps: 1958
  Episode Time: 195.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.66
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 114000, Episode Steps: 324, Avg Reward: 4.773, Episode Reward: 1546.4
    æ£€æµ‹è¿›åº¦: 2/13 (15.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3126)'), ('usv_1', '(241,4127)'), ('usv_2', '(242,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27263285250579683), 'usv_1': np.float64(1.3830101312811802)}
    Episode time: 32.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.54151877 -0.16118627] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 115000, Episode Steps: 1324, Avg Reward: 13.331, Episode Reward: 17650.4
    æ£€æµ‹è¿›åº¦: 3/38 (7.9%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(240,3044)'), ('usv_1', '(354,4096)'), ('usv_2', '(303,5197)')]...
    Recent rewards sample: {'usv_0': np.float64(7.880960165838267), 'usv_1': np.float64(3.3801346594838044)}
    Episode time: 132.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 116000, Episode Steps: 2324, Avg Reward: 12.050, Episode Reward: 28004.3
    æ£€æµ‹è¿›åº¦: 7/66 (10.6%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,3006)'), ('usv_1', '(453,4040)'), ('usv_2', '(250,5265)')]...
    Recent rewards sample: {'usv_0': np.float64(7.996282597562105), 'usv_1': np.float64(-6.608705655439108)}
    Episode time: 232.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 39933.0
  Targets Detected: 8/79 (8.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.31
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 117000, Episode Steps: 323, Avg Reward: 5.040, Episode Reward: 1628.0
    æ£€æµ‹è¿›åº¦: 2/9 (22.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3124)'), ('usv_1', '(239,4125)'), ('usv_2', '(234,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26928869639839803), 'usv_1': np.float64(-0.6317235776629163)}
    Episode time: 32.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 118000, Episode Steps: 1323, Avg Reward: 9.604, Episode Reward: 12705.6
    æ£€æµ‹è¿›åº¦: 3/26 (11.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3030)'), ('usv_1', '(314,4094)'), ('usv_2', '(267,5221)')]...
    Recent rewards sample: {'usv_0': np.float64(6.870108859299689), 'usv_1': np.float64(0.3822837637819001)}
    Episode time: 132.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 119000, Episode Steps: 2323, Avg Reward: 15.653, Episode Reward: 36362.2
    æ£€æµ‹è¿›åº¦: 6/53 (11.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,2994)'), ('usv_1', '(392,4013)'), ('usv_2', '(220,5325)')]...
    Recent rewards sample: {'usv_0': np.float64(7.941631098760412), 'usv_1': np.float64(1.3843909715478828)}
    Episode time: 232.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 52929.4
  Targets Detected: 8/66 (12.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.64
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.0161177  -0.12418188] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 120000, Episode Steps: 322, Avg Reward: 5.494, Episode Reward: 1769.2
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3122)'), ('usv_1', '(238,4127)'), ('usv_2', '(249,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(3.269410464965342), 'usv_1': np.float64(2.381363714550064)}
    Episode time: 32.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 121000, Episode Steps: 1322, Avg Reward: 12.845, Episode Reward: 16981.6
    æ£€æµ‹è¿›åº¦: 2/28 (7.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3058)'), ('usv_1', '(334,4069)'), ('usv_2', '(329,5185)')]...
    Recent rewards sample: {'usv_0': np.float64(6.867554198124351), 'usv_1': np.float64(2.379956940671873)}
    Episode time: 132.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 24566.4
  Targets Detected: 2/48 (4.2%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_147s
  Average Reward/Step: 13.64
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 122000, Episode Steps: 521, Avg Reward: 18.020, Episode Reward: 9388.4
    æ£€æµ‹è¿›åº¦: 3/19 (15.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3101)'), ('usv_1', '(260,4117)'), ('usv_2', '(285,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(2.282284923739116), 'usv_1': np.float64(3.369958818999459)}
    Episode time: 52.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 123000, Episode Steps: 1521, Avg Reward: 22.741, Episode Reward: 34588.3
    æ£€æµ‹è¿›åº¦: 6/49 (12.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3024)'), ('usv_1', '(350,4059)'), ('usv_2', '(378,5184)')]...
    Recent rewards sample: {'usv_0': np.float64(5.8716331504851205), 'usv_1': np.float64(3.384794909678516)}
    Episode time: 152.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 124000, Episode Steps: 2521, Avg Reward: 18.940, Episode Reward: 47747.1
    æ£€æµ‹è¿›åº¦: 7/62 (11.3%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3024)'), ('usv_1', '(441,4011)'), ('usv_2', '(386,5273)')]...
    Recent rewards sample: {'usv_0': np.float64(5.900833033599342), 'usv_1': np.float64(3.391375265650826)}
    Episode time: 252.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 61528.8
  Targets Detected: 11/85 (10.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.50
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.09084348 0.01787142] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 125000, Episode Steps: 520, Avg Reward: 2.311, Episode Reward: 1201.7
    æ£€æµ‹è¿›åº¦: 1/27 (3.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3105)'), ('usv_1', '(270,4125)'), ('usv_2', '(251,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27297323814505947), 'usv_1': np.float64(-0.6230142809572389)}
    Episode time: 52.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 126000, Episode Steps: 1520, Avg Reward: 4.468, Episode Reward: 6791.2
    æ£€æµ‹è¿›åº¦: 2/65 (3.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3049)'), ('usv_1', '(352,4085)'), ('usv_2', '(296,5220)')]...
    Recent rewards sample: {'usv_0': np.float64(3.869690766126465), 'usv_1': np.float64(-0.6216795719315851)}
    Episode time: 152.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 127000, Episode Steps: 2520, Avg Reward: 8.062, Episode Reward: 20315.3
    æ£€æµ‹è¿›åº¦: 4/101 (4.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3118)'), ('usv_1', '(433,3997)'), ('usv_2', '(271,5318)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2639229261420937), 'usv_1': np.float64(-8.608845995654006)}
    Episode time: 252.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 22291.0
  Targets Detected: 6/107 (5.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.43
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 128000, Episode Steps: 519, Avg Reward: 6.420, Episode Reward: 3332.1
    æ£€æµ‹è¿›åº¦: 2/20 (10.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3112)'), ('usv_1', '(260,4138)'), ('usv_2', '(253,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(3.291658980499976), 'usv_1': np.float64(0.37200903117112327)}
    Episode time: 51.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 129000, Episode Steps: 1519, Avg Reward: 14.559, Episode Reward: 22114.6
    æ£€æµ‹è¿›åº¦: 5/57 (8.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(285,3023)'), ('usv_1', '(368,4142)'), ('usv_2', '(316,5218)')]...
    Recent rewards sample: {'usv_0': np.float64(7.874216377397597), 'usv_1': np.float64(1.3819170519448902)}
    Episode time: 151.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.23153278 -0.06614115] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 130000, Episode Steps: 2519, Avg Reward: 13.243, Episode Reward: 33358.0
    æ£€æµ‹è¿›åº¦: 5/69 (7.2%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3066)'), ('usv_1', '(483,4132)'), ('usv_2', '(291,5326)')]...
    Recent rewards sample: {'usv_0': np.float64(8.065740866101143), 'usv_1': np.float64(1.3982591661900443)}
    Episode time: 251.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 43124.3
  Targets Detected: 9/77 (9.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.37
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 131000, Episode Steps: 518, Avg Reward: 4.865, Episode Reward: 2520.1
    æ£€æµ‹è¿›åº¦: 1/23 (4.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3114)'), ('usv_1', '(253,4117)'), ('usv_2', '(266,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(1.284158019183569), 'usv_1': np.float64(2.3733145077100324)}
    Episode time: 51.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 132000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 132000, Episode Steps: 1518, Avg Reward: 17.045, Episode Reward: 25874.6
    æ£€æµ‹è¿›åº¦: 4/50 (8.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,3040)'), ('usv_1', '(357,4061)'), ('usv_2', '(309,5194)')]...
    Recent rewards sample: {'usv_0': np.float64(7.875093219745287), 'usv_1': np.float64(3.3869325416681066)}
    Episode time: 151.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 133000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 133000, Episode Steps: 2518, Avg Reward: 19.970, Episode Reward: 50285.4
    æ£€æµ‹è¿›åº¦: 5/61 (8.2%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3070)'), ('usv_1', '(453,3995)'), ('usv_2', '(263,5267)')]...
    Recent rewards sample: {'usv_0': np.float64(7.870998341584029), 'usv_1': np.float64(3.3892016477937847)}
    Episode time: 251.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 58211.3
  Targets Detected: 8/72 (6.9%)
  Steps: 2839
  Episode Time: 283.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 20.50
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 134000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 134000, Episode Steps: 679, Avg Reward: -3.958, Episode Reward: -2687.2
    æ£€æµ‹è¿›åº¦: 0/17 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3100)'), ('usv_1', '(273,4124)'), ('usv_2', '(277,5172)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7164747542705224), 'usv_1': np.float64(-1.6241470517893926)}
    Episode time: 67.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.17856502 -0.22187858] (agent usv_0)
    MADDPG UPDATING at time_step 135000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 135000, Episode Steps: 1679, Avg Reward: 10.372, Episode Reward: 17414.1
    æ£€æµ‹è¿›åº¦: 6/37 (16.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(262,2998)'), ('usv_1', '(354,4058)'), ('usv_2', '(352,5269)')]...
    Recent rewards sample: {'usv_0': np.float64(5.875156236808952), 'usv_1': np.float64(1.3933517614341113)}
    Episode time: 167.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 136000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0254, Avg Critic Loss: 15.6328
    Step 136000, Episode Steps: 2679, Avg Reward: 15.280, Episode Reward: 40936.4
    æ£€æµ‹è¿›åº¦: 8/64 (12.5%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,2981)'), ('usv_1', '(392,3957)'), ('usv_2', '(320,5381)')]...
    Recent rewards sample: {'usv_0': np.float64(5.872041047359083), 'usv_1': np.float64(1.385182155080233)}
    Episode time: 267.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 47903.2
  Targets Detected: 8/71 (11.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.96

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 41966.6
Last 10 episodes average detections: 7.7
Best episode reward so far: 72825.9
Best detection count so far: 18
Learning trend: Declining (41966.6 vs 43183.0)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 72825.9
Final 10 episodes average: 41966.6
Best detection performance: 18 targets
Average detections (final 10): 7.7
============================================================
{"final_avg_reward": 41966.60708074456, "final_detection_rate": 7.7, "best_episode_reward": 72825.89334865844, "best_detection_count": 18, "total_episodes": 50}
Simulation finished.
