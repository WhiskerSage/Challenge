D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: 0.684, Episode Reward: 684.4
    æ£€æµ‹è¿›åº¦: 2/12 (16.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(286,3089)'), ('usv_1', '(225,4112)'), ('usv_2', '(231,5106)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3913508744532723), 'usv_1': np.float64(-0.5327778108890969)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 5.353, Episode Reward: 10706.3
    æ£€æµ‹è¿›åº¦: 2/35 (5.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(284,3027)'), ('usv_1', '(207,4109)'), ('usv_2', '(209,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(5.977448799988893), 'usv_1': np.float64(1.4658857434853498)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 11730.0
  Targets Detected: 3/35 (5.7%)
  Steps: 2056
  Episode Time: 205.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 5.71
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 944, Avg Reward: -3.270, Episode Reward: -3086.9
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3108)'), ('usv_1', '(210,4125)'), ('usv_2', '(227,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6144663422662187), 'usv_1': np.float64(-1.533929524209656)}
    Episode time: 94.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 1944, Avg Reward: 1.404, Episode Reward: 2729.4
    æ£€æµ‹è¿›åº¦: 2/30 (6.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(349,3047)'), ('usv_1', '(204,4139)'), ('usv_2', '(213,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(4.981100807007049), 'usv_1': np.float64(0.466587090425435)}
    Episode time: 194.4s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.0668695  0.16985066] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 2944, Avg Reward: 8.225, Episode Reward: 24213.2
    æ£€æµ‹è¿›åº¦: 4/43 (9.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(393,2970)'), ('usv_1', '(208,4169)'), ('usv_2', '(240,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(5.985741260999691), 'usv_1': np.float64(3.4661276217770824)}
    Episode time: 294.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 25486.3
  Targets Detected: 4/45 (8.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.49
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 943, Avg Reward: 15.720, Episode Reward: 14823.6
    æ£€æµ‹è¿›åº¦: 3/16 (18.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3118)'), ('usv_1', '(213,4112)'), ('usv_2', '(213,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3879821390074807), 'usv_1': np.float64(3.4693221424955203)}
    Episode time: 94.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 1943, Avg Reward: 18.538, Episode Reward: 36019.1
    æ£€æµ‹è¿›åº¦: 3/22 (13.6%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(297,3042)'), ('usv_1', '(202,4119)'), ('usv_2', '(204,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(5.976653966912259), 'usv_1': np.float64(3.4694573490834406)}
    Episode time: 194.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 40527.7
  Targets Detected: 5/24 (12.5%)
  Steps: 2165
  Episode Time: 216.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.72
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 778, Avg Reward: 2.884, Episode Reward: 2244.1
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3112)'), ('usv_1', '(219,4114)'), ('usv_2', '(229,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(0.38722149466813993), 'usv_1': np.float64(-0.533242495520795)}
    Episode time: 77.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 1778, Avg Reward: 9.156, Episode Reward: 16279.3
    æ£€æµ‹è¿›åº¦: 3/29 (10.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(351,3046)'), ('usv_1', '(201,4114)'), ('usv_2', '(210,5103)')]...
    Recent rewards sample: {'usv_0': np.float64(5.979229296454464), 'usv_1': np.float64(1.4653731821267417)}
    Episode time: 177.8s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.12954793 -0.2213663 ] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 2778, Avg Reward: 14.292, Episode Reward: 39702.2
    æ£€æµ‹è¿›åº¦: 6/46 (13.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(369,2957)'), ('usv_1', '(215,4127)'), ('usv_2', '(212,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(5.984082427697593), 'usv_1': np.float64(1.4674219201015406)}
    Episode time: 277.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 44668.6
  Targets Detected: 6/47 (10.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.88
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 777, Avg Reward: -3.275, Episode Reward: -2544.4
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3122)'), ('usv_1', '(219,4112)'), ('usv_2', '(235,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6110254664649477), 'usv_1': np.float64(-1.529195548106213)}
    Episode time: 77.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 1777, Avg Reward: -3.252, Episode Reward: -5778.6
    æ£€æµ‹è¿›åº¦: 0/25 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(366,3090)'), ('usv_1', '(201,4118)'), ('usv_2', '(225,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.5851989932234021), 'usv_1': np.float64(-1.5338091341099784)}
    Episode time: 177.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: -5714.2
  Targets Detected: 0/28 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.17
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 976, Avg Reward: -2.821, Episode Reward: -2753.3
    æ£€æµ‹è¿›åº¦: 0/15 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3068)'), ('usv_1', '(212,4115)'), ('usv_2', '(213,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(2.971596807156445), 'usv_1': np.float64(-1.5337484914276442)}
    Episode time: 97.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 1976, Avg Reward: 1.081, Episode Reward: 2136.8
    æ£€æµ‹è¿›åº¦: 1/34 (2.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,2966)'), ('usv_1', '(206,4127)'), ('usv_2', '(208,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9735112885702906), 'usv_1': np.float64(-0.5342455567634101)}
    Episode time: 197.6s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.04203354 -0.09003524] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 2976, Avg Reward: 5.513, Episode Reward: 16406.0
    æ£€æµ‹è¿›åº¦: 2/45 (4.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,2891)'), ('usv_1', '(208,4157)'), ('usv_2', '(241,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(4.97550167006545), 'usv_1': np.float64(0.4660387894889664)}
    Episode time: 297.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 16763.5
  Targets Detected: 2/45 (4.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.59
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 975, Avg Reward: -3.050, Episode Reward: -2973.7
    æ£€æµ‹è¿›åº¦: 0/15 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3084)'), ('usv_1', '(216,4113)'), ('usv_2', '(224,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(2.9753412048481263), 'usv_1': np.float64(-1.5314179455173198)}
    Episode time: 97.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 1975, Avg Reward: 4.504, Episode Reward: 8895.8
    æ£€æµ‹è¿›åº¦: 4/36 (11.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(365,3037)'), ('usv_1', '(204,4119)'), ('usv_2', '(200,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(7.983231852866881), 'usv_1': np.float64(3.4679367886272647)}
    Episode time: 197.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 2975, Avg Reward: 11.561, Episode Reward: 34393.4
    æ£€æµ‹è¿›åº¦: 4/44 (9.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(420,2958)'), ('usv_1', '(217,4132)'), ('usv_2', '(226,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(5.988676335130671), 'usv_1': np.float64(1.4675355117357722)}
    Episode time: 297.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 34973.9
  Targets Detected: 5/44 (9.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.65
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 974, Avg Reward: 8.197, Episode Reward: 7983.5
    æ£€æµ‹è¿›åº¦: 4/27 (14.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(295,3117)'), ('usv_1', '(215,4115)'), ('usv_2', '(245,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3921347777171516), 'usv_1': np.float64(1.466446655776418)}
    Episode time: 97.4s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.05064866 0.25743477] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 1974, Avg Reward: 15.029, Episode Reward: 29667.6
    æ£€æµ‹è¿›åº¦: 8/50 (16.0%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(374,3074)'), ('usv_1', '(205,4119)'), ('usv_2', '(217,5100)')]...
    Recent rewards sample: {'usv_0': np.float64(7.981347512120719), 'usv_1': np.float64(3.465712306284848)}
    Episode time: 197.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 2974, Avg Reward: 18.453, Episode Reward: 54878.0
    æ£€æµ‹è¿›åº¦: 7/60 (11.7%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(418,3016)'), ('usv_1', '(212,4144)'), ('usv_2', '(225,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(7.983113321548807), 'usv_1': np.float64(1.4662331816860315)}
    Episode time: 297.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 55534.4
  Targets Detected: 10/60 (11.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.51
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 973, Avg Reward: 5.231, Episode Reward: 5089.5
    æ£€æµ‹è¿›åº¦: 3/17 (17.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(285,3093)'), ('usv_1', '(227,4123)'), ('usv_2', '(248,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3910315625525191), 'usv_1': np.float64(2.4673216765204833)}
    Episode time: 97.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 1973, Avg Reward: 12.986, Episode Reward: 25621.2
    æ£€æµ‹è¿›åº¦: 4/35 (11.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(341,3023)'), ('usv_1', '(214,4112)'), ('usv_2', '(229,5089)')]...
    Recent rewards sample: {'usv_0': np.float64(5.977312109047455), 'usv_1': np.float64(1.4664093083564844)}
    Episode time: 197.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 2973, Avg Reward: 17.162, Episode Reward: 51022.5
    æ£€æµ‹è¿›åº¦: 6/54 (11.1%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(365,2935)'), ('usv_1', '(209,4120)'), ('usv_2', '(224,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(5.9841515549233595), 'usv_1': np.float64(1.4659806453597186)}
    Episode time: 297.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 51644.8
  Targets Detected: 7/54 (11.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.21
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.20166403 0.24615603] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 972, Avg Reward: -2.921, Episode Reward: -2839.5
    æ£€æµ‹è¿›åº¦: 1/17 (5.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(291,3105)'), ('usv_1', '(216,4117)'), ('usv_2', '(226,5105)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6034988207838577), 'usv_1': np.float64(-1.5334720199531053)}
    Episode time: 97.2s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 1972, Avg Reward: 1.262, Episode Reward: 2488.2
    æ£€æµ‹è¿›åº¦: 3/31 (9.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(364,3111)'), ('usv_1', '(207,4113)'), ('usv_2', '(208,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(3.4045247327653048), 'usv_1': np.float64(0.4658402838375657)}
    Episode time: 197.2s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 2972, Avg Reward: 5.625, Episode Reward: 16718.9
    æ£€æµ‹è¿›åº¦: 4/41 (9.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(452,3087)'), ('usv_1', '(202,4137)'), ('usv_2', '(234,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(4.430507597141106), 'usv_1': np.float64(1.4690290719797772)}
    Episode time: 297.2s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 17295.2
  Targets Detected: 4/41 (9.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.76

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 29291.0
Last 10 episodes average detections: 4.6
Best episode reward so far: 55534.4
Best detection count so far: 10
Buffer size: 27029
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 971, Avg Reward: 1.497, Episode Reward: 1453.4
    æ£€æµ‹è¿›åº¦: 2/20 (10.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(294,3092)'), ('usv_1', '(217,4115)'), ('usv_2', '(245,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(4.349650437845811), 'usv_1': np.float64(3.419489127572466)}
    Episode time: 97.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 1971, Avg Reward: 12.522, Episode Reward: 24680.7
    æ£€æµ‹è¿›åº¦: 4/44 (9.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(325,3015)'), ('usv_1', '(202,4124)'), ('usv_2', '(243,5068)')]...
    Recent rewards sample: {'usv_0': np.float64(7.926300793060624), 'usv_1': np.float64(3.4154593112739393)}
    Episode time: 197.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 31044.6
  Targets Detected: 4/50 (8.0%)
  Steps: 2267
  Episode Time: 226.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.69
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.32131444 0.08118833] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 704, Avg Reward: -3.598, Episode Reward: -2533.3
    æ£€æµ‹è¿›åº¦: 0/15 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3120)'), ('usv_1', '(219,4119)'), ('usv_2', '(224,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6656482981163099), 'usv_1': np.float64(-1.5812819111014182)}
    Episode time: 70.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 1704, Avg Reward: 0.718, Episode Reward: 1223.1
    æ£€æµ‹è¿›åº¦: 1/34 (2.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(365,3090)'), ('usv_1', '(204,4108)'), ('usv_2', '(214,5077)')]...
    Recent rewards sample: {'usv_0': np.float64(4.360890792830498), 'usv_1': np.float64(1.4156566737872578)}
    Episode time: 170.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 2704, Avg Reward: 8.423, Episode Reward: 22776.9
    æ£€æµ‹è¿›åº¦: 3/53 (5.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(442,3065)'), ('usv_1', '(212,4125)'), ('usv_2', '(215,5092)')]...
    Recent rewards sample: {'usv_0': np.float64(5.946042114176156), 'usv_1': np.float64(1.416164233455048)}
    Episode time: 270.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 27222.0
  Targets Detected: 3/58 (5.2%)
  Steps: 2946
  Episode Time: 294.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 9.24
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 758, Avg Reward: 0.908, Episode Reward: 688.0
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(281,3141)'), ('usv_1', '(224,4123)'), ('usv_2', '(208,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3309324699975695), 'usv_1': np.float64(-0.5803297975304628)}
    Episode time: 75.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 1758, Avg Reward: 8.117, Episode Reward: 14270.4
    æ£€æµ‹è¿›åº¦: 2/47 (4.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(381,3125)'), ('usv_1', '(228,4092)'), ('usv_2', '(230,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3589199213260876), 'usv_1': np.float64(0.41963913750676407)}
    Episode time: 175.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 18144.3
  Targets Detected: 3/54 (3.7%)
  Steps: 2083
  Episode Time: 208.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 8.71
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.30217691 0.32554333] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 675, Avg Reward: -3.595, Episode Reward: -2426.8
    æ£€æµ‹è¿›åº¦: 0/17 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3109)'), ('usv_1', '(224,4122)'), ('usv_2', '(234,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6615879047173567), 'usv_1': np.float64(-1.5828731300726877)}
    Episode time: 67.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 1675, Avg Reward: 6.298, Episode Reward: 10549.2
    æ£€æµ‹è¿›åº¦: 3/35 (8.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3029)'), ('usv_1', '(206,4106)'), ('usv_2', '(203,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(7.9282315082132175), 'usv_1': np.float64(1.415865213056862)}
    Episode time: 167.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 2675, Avg Reward: 12.409, Episode Reward: 33193.6
    æ£€æµ‹è¿›åº¦: 4/59 (6.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,2952)'), ('usv_1', '(214,4121)'), ('usv_2', '(205,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(7.923646332841952), 'usv_1': np.float64(1.4177750078487827)}
    Episode time: 267.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 40362.0
  Targets Detected: 4/68 (5.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.45
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 674, Avg Reward: -3.383, Episode Reward: -2279.8
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3123)'), ('usv_1', '(224,4117)'), ('usv_2', '(231,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3355057968986518), 'usv_1': np.float64(-0.5818305712993094)}
    Episode time: 67.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 1674, Avg Reward: 4.052, Episode Reward: 6783.5
    æ£€æµ‹è¿›åº¦: 2/36 (5.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(356,3079)'), ('usv_1', '(208,4098)'), ('usv_2', '(205,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(4.930248280710537), 'usv_1': np.float64(0.41903800358857257)}
    Episode time: 167.4s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.08469437 -0.29477752] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 2674, Avg Reward: 10.612, Episode Reward: 28377.3
    æ£€æµ‹è¿›åº¦: 4/59 (6.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(452,3020)'), ('usv_1', '(202,4099)'), ('usv_2', '(208,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(5.9355257909399946), 'usv_1': np.float64(3.415637608758514)}
    Episode time: 267.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 35651.5
  Targets Detected: 6/68 (7.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.88
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 673, Avg Reward: 17.378, Episode Reward: 11695.3
    æ£€æµ‹è¿›åº¦: 4/29 (13.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3121)'), ('usv_1', '(225,4119)'), ('usv_2', '(222,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(4.325546665709979), 'usv_1': np.float64(1.4172327699061116)}
    Episode time: 67.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 1673, Avg Reward: 19.933, Episode Reward: 33348.2
    æ£€æµ‹è¿›åº¦: 6/51 (11.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(338,3059)'), ('usv_1', '(205,4110)'), ('usv_2', '(207,5086)')]...
    Recent rewards sample: {'usv_0': np.float64(7.934789479333974), 'usv_1': np.float64(3.415721985969105)}
    Episode time: 167.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 2673, Avg Reward: 20.501, Episode Reward: 54798.8
    æ£€æµ‹è¿›åº¦: 5/69 (7.2%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(340,2999)'), ('usv_1', '(204,4130)'), ('usv_2', '(220,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(5.927826562106935), 'usv_1': np.float64(1.4156615985838412)}
    Episode time: 267.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 57000.7
  Targets Detected: 7/69 (7.2%)
  Steps: 2780
  Episode Time: 278.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 20.50
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 893, Avg Reward: 7.352, Episode Reward: 6565.2
    æ£€æµ‹è¿›åº¦: 3/28 (10.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(294,3106)'), ('usv_1', '(224,4112)'), ('usv_2', '(232,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3407489615927286), 'usv_1': np.float64(1.418128201975697)}
    Episode time: 89.3s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.12627519 -0.05757539] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 1893, Avg Reward: 15.320, Episode Reward: 29000.1
    æ£€æµ‹è¿›åº¦: 6/51 (11.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(334,3029)'), ('usv_1', '(209,4092)'), ('usv_2', '(214,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(5.931851562261291), 'usv_1': np.float64(3.4161840481208117)}
    Episode time: 189.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 2893, Avg Reward: 19.529, Episode Reward: 56497.8
    æ£€æµ‹è¿›åº¦: 7/78 (9.0%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(308,2953)'), ('usv_1', '(204,4104)'), ('usv_2', '(239,5109)')]...
    Recent rewards sample: {'usv_0': np.float64(7.928525540468975), 'usv_1': np.float64(3.4156707304912732)}
    Episode time: 289.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 59305.4
  Targets Detected: 9/78 (7.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.76
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 892, Avg Reward: 5.403, Episode Reward: 4819.7
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3127)'), ('usv_1', '(220,4122)'), ('usv_2', '(235,5096)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3264423657974471), 'usv_1': np.float64(2.4168436032189797)}
    Episode time: 89.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 1892, Avg Reward: 9.929, Episode Reward: 18786.1
    æ£€æµ‹è¿›åº¦: 4/47 (8.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(334,3098)'), ('usv_1', '(207,4131)'), ('usv_2', '(210,5076)')]...
    Recent rewards sample: {'usv_0': np.float64(2.34882354732055), 'usv_1': np.float64(3.4158037854333383)}
    Episode time: 189.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 2892, Avg Reward: 13.152, Episode Reward: 38035.7
    æ£€æµ‹è¿›åº¦: 5/75 (6.7%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(386,3026)'), ('usv_1', '(226,4145)'), ('usv_2', '(219,5100)')]...
    Recent rewards sample: {'usv_0': np.float64(7.930519515028936), 'usv_1': np.float64(1.41731056673098)}
    Episode time: 289.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 40218.2
  Targets Detected: 7/76 (6.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.40
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.25015872 0.0724735 ] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 891, Avg Reward: 18.071, Episode Reward: 16101.2
    æ£€æµ‹è¿›åº¦: 3/28 (10.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(301,3113)'), ('usv_1', '(222,4124)'), ('usv_2', '(237,5095)')]...
    Recent rewards sample: {'usv_0': np.float64(4.348573383180158), 'usv_1': np.float64(3.4169285303313846)}
    Episode time: 89.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 1891, Avg Reward: 20.582, Episode Reward: 38921.3
    æ£€æµ‹è¿›åº¦: 5/50 (10.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(387,3060)'), ('usv_1', '(210,4108)'), ('usv_2', '(202,5084)')]...
    Recent rewards sample: {'usv_0': np.float64(5.937611033796981), 'usv_1': np.float64(3.416104041618535)}
    Episode time: 189.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 2891, Avg Reward: 22.264, Episode Reward: 64366.0
    æ£€æµ‹è¿›åº¦: 9/73 (12.3%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(444,2978)'), ('usv_1', '(206,4116)'), ('usv_2', '(215,5106)')]...
    Recent rewards sample: {'usv_0': np.float64(5.941724212702964), 'usv_1': np.float64(3.4157549504725573)}
    Episode time: 289.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 67005.0
  Targets Detected: 10/76 (11.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 22.33
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 890, Avg Reward: 16.049, Episode Reward: 14283.4
    æ£€æµ‹è¿›åº¦: 3/16 (18.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3093)'), ('usv_1', '(229,4121)'), ('usv_2', '(226,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(4.335668265523015), 'usv_1': np.float64(3.4205007556102025)}
    Episode time: 89.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 1890, Avg Reward: 21.448, Episode Reward: 40536.1
    æ£€æµ‹è¿›åº¦: 5/37 (13.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(313,3015)'), ('usv_1', '(230,4106)'), ('usv_2', '(229,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(7.926490521573795), 'usv_1': np.float64(3.4205581942666976)}
    Episode time: 189.0s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.15935745 0.10757773] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 2890, Avg Reward: 24.062, Episode Reward: 69540.2
    æ£€æµ‹è¿›åº¦: 8/57 (14.0%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,2948)'), ('usv_1', '(209,4107)'), ('usv_2', '(226,5081)')]...
    Recent rewards sample: {'usv_0': np.float64(7.935057493245944), 'usv_1': np.float64(3.4160325058841785)}
    Episode time: 289.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 72427.2
  Targets Detected: 9/58 (13.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 24.13

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 44838.1
Last 10 episodes average detections: 6.2
Best episode reward so far: 72427.2
Best detection count so far: 10
Learning trend: Improving (44838.1 vs 29291.0)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 889, Avg Reward: 2.565, Episode Reward: 2280.2
    æ£€æµ‹è¿›åº¦: 1/32 (3.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(283,3113)'), ('usv_1', '(224,4121)'), ('usv_2', '(230,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3460502550554605), 'usv_1': np.float64(-0.5798494117565542)}
    Episode time: 88.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 5252.2
  Targets Detected: 1/45 (2.2%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_167s
  Average Reward/Step: 2.92
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 88, Avg Reward: -3.533, Episode Reward: -310.9
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3130)'), ('usv_1', '(213,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6780382815335183), 'usv_1': np.float64(-1.5836983752861176)}
    Episode time: 8.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 1088, Avg Reward: 0.087, Episode Reward: 94.1
    æ£€æµ‹è¿›åº¦: 1/29 (3.4%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(315,3101)'), ('usv_1', '(232,4120)'), ('usv_2', '(214,5107)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3470408727145395), 'usv_1': np.float64(0.41957415830182665)}
    Episode time: 108.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 2088, Avg Reward: 10.158, Episode Reward: 21210.0
    æ£€æµ‹è¿›åº¦: 4/58 (6.9%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(375,3041)'), ('usv_1', '(227,4099)'), ('usv_2', '(208,5106)')]...
    Recent rewards sample: {'usv_0': np.float64(7.930288878587401), 'usv_1': np.float64(3.417487158319636)}
    Episode time: 208.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 32995.6
  Targets Detected: 5/80 (6.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.99
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.00929543 -0.04444786] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 87, Avg Reward: 4.294, Episode Reward: 373.6
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3129)'), ('usv_1', '(214,4130)'), ('usv_2', '(218,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3217945673809774), 'usv_1': np.float64(-0.5828309248142175)}
    Episode time: 8.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 1087, Avg Reward: 13.815, Episode Reward: 15017.3
    æ£€æµ‹è¿›åº¦: 3/24 (12.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(310,3093)'), ('usv_1', '(230,4111)'), ('usv_2', '(242,5109)')]...
    Recent rewards sample: {'usv_0': np.float64(4.343295622300479), 'usv_1': np.float64(3.419510044074962)}
    Episode time: 108.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 31284.8
  Targets Detected: 3/39 (7.7%)
  Steps: 1852
  Episode Time: 185.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.89
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 235, Avg Reward: 10.408, Episode Reward: 2446.0
    æ£€æµ‹è¿›åº¦: 2/12 (16.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3129)'), ('usv_1', '(222,4128)'), ('usv_2', '(223,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31569434441570865), 'usv_1': np.float64(-0.5830434198411543)}
    Episode time: 23.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 1235, Avg Reward: 15.172, Episode Reward: 18737.8
    æ£€æµ‹è¿›åº¦: 5/39 (12.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(303,3123)'), ('usv_1', '(212,4121)'), ('usv_2', '(209,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(2.348395933997387), 'usv_1': np.float64(3.4200806828774164)}
    Episode time: 123.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 2235, Avg Reward: 19.122, Episode Reward: 42737.0
    æ£€æµ‹è¿›åº¦: 7/64 (10.9%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(360,3046)'), ('usv_1', '(210,4148)'), ('usv_2', '(220,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(7.928216958322771), 'usv_1': np.float64(3.4160753136236437)}
    Episode time: 223.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 62648.9
  Targets Detected: 8/77 (9.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.88
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.10463678 -0.08211426] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 234, Avg Reward: -3.588, Episode Reward: -839.7
    æ£€æµ‹è¿›åº¦: 0/9 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3128)'), ('usv_1', '(214,4130)'), ('usv_2', '(220,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6809217872296918), 'usv_1': np.float64(-1.5796609409371207)}
    Episode time: 23.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 1234, Avg Reward: 5.003, Episode Reward: 6173.6
    æ£€æµ‹è¿›åº¦: 3/32 (9.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(329,3105)'), ('usv_1', '(228,4125)'), ('usv_2', '(209,5107)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3464878426042466), 'usv_1': np.float64(3.417400153032659)}
    Episode time: 123.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 2234, Avg Reward: 12.608, Episode Reward: 28166.2
    æ£€æµ‹è¿›åº¦: 5/55 (9.1%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(393,3050)'), ('usv_1', '(220,4109)'), ('usv_2', '(224,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(5.9306591573408225), 'usv_1': np.float64(3.418869755852173)}
    Episode time: 223.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 45756.3
  Targets Detected: 7/79 (6.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.25
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 233, Avg Reward: -3.594, Episode Reward: -837.5
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3127)'), ('usv_1', '(216,4131)'), ('usv_2', '(227,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6840638446315495), 'usv_1': np.float64(-1.5834725231697655)}
    Episode time: 23.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 1233, Avg Reward: 10.948, Episode Reward: 13498.6
    æ£€æµ‹è¿›åº¦: 6/31 (19.4%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3122)'), ('usv_1', '(236,4117)'), ('usv_2', '(212,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(2.338763631234174), 'usv_1': np.float64(3.41804013839229)}
    Episode time: 123.3s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.15345306 -0.21335557] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 2233, Avg Reward: 15.971, Episode Reward: 35662.9
    æ£€æµ‹è¿›åº¦: 9/58 (15.5%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(375,3101)'), ('usv_1', '(233,4091)'), ('usv_2', '(223,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(2.366475605583682), 'usv_1': np.float64(3.4180551389559817)}
    Episode time: 223.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 45261.4
  Targets Detected: 9/68 (10.3%)
  Steps: 2715
  Episode Time: 271.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.67
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 518, Avg Reward: -3.598, Episode Reward: -1863.6
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3130)'), ('usv_1', '(217,4126)'), ('usv_2', '(229,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6751623394046232), 'usv_1': np.float64(-1.5821218297723676)}
    Episode time: 51.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 1518, Avg Reward: 4.585, Episode Reward: 6959.7
    æ£€æµ‹è¿›åº¦: 2/35 (5.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(332,3063)'), ('usv_1', '(205,4121)'), ('usv_2', '(204,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(6.939274613628909), 'usv_1': np.float64(0.4256324765804145)}
    Episode time: 151.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 17058.2
  Targets Detected: 2/44 (4.5%)
  Steps: 2186
  Episode Time: 218.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.80
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 332, Avg Reward: 6.695, Episode Reward: 2222.8
    æ£€æµ‹è¿›åº¦: 1/8 (12.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3123)'), ('usv_1', '(222,4128)'), ('usv_2', '(217,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(2.334204958616425), 'usv_1': np.float64(-0.5830749500327963)}
    Episode time: 33.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 1332, Avg Reward: 5.619, Episode Reward: 7484.7
    æ£€æµ‹è¿›åº¦: 0/20 (0.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(326,3072)'), ('usv_1', '(237,4112)'), ('usv_2', '(207,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(5.927417489145777), 'usv_1': np.float64(-0.5812171474750436)}
    Episode time: 133.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 11184.6
  Targets Detected: 1/32 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_170s
  Average Reward/Step: 6.21
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.17680539 0.12678045] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 531, Avg Reward: 15.213, Episode Reward: 8078.1
    æ£€æµ‹è¿›åº¦: 4/17 (23.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3112)'), ('usv_1', '(221,4124)'), ('usv_2', '(234,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(4.330667304362935), 'usv_1': np.float64(1.4168749874527635)}
    Episode time: 53.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 1531, Avg Reward: 20.174, Episode Reward: 30886.2
    æ£€æµ‹è¿›åº¦: 4/37 (10.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(333,3052)'), ('usv_1', '(205,4116)'), ('usv_2', '(204,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(7.9363135753323455), 'usv_1': np.float64(1.4156696677915743)}
    Episode time: 153.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 37397.0
  Targets Detected: 5/43 (9.3%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_127s
  Average Reward/Step: 20.76
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 730, Avg Reward: 2.593, Episode Reward: 1892.6
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3129)'), ('usv_1', '(217,4120)'), ('usv_2', '(222,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(0.33233832133828123), 'usv_1': np.float64(-0.5813800373421095)}
    Episode time: 73.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 1730, Avg Reward: 5.275, Episode Reward: 9125.7
    æ£€æµ‹è¿›åº¦: 1/41 (2.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(364,3081)'), ('usv_1', '(207,4111)'), ('usv_2', '(209,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(5.9362607782131676), 'usv_1': np.float64(1.417894061118345)}
    Episode time: 173.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 2730, Avg Reward: 11.587, Episode Reward: 31633.8
    æ£€æµ‹è¿›åº¦: 3/62 (4.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(420,3001)'), ('usv_1', '(202,4131)'), ('usv_2', '(227,5164)')]...
    Recent rewards sample: {'usv_0': np.float64(5.9338769688010515), 'usv_1': np.float64(1.415438900625698)}
    Episode time: 273.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: 37389.9
  Targets Detected: 5/64 (4.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.46

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 32622.9
Last 10 episodes average detections: 4.6
Best episode reward so far: 72427.2
Best detection count so far: 10
Learning trend: Declining (32622.9 vs 44838.1)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.09641572 -0.15081262] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 729, Avg Reward: -3.899, Episode Reward: -2842.2
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3111)'), ('usv_1', '(225,4123)'), ('usv_2', '(218,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7188067200378543), 'usv_1': np.float64(-1.6327771316601887)}
    Episode time: 72.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 1729, Avg Reward: 9.966, Episode Reward: 17231.8
    æ£€æµ‹è¿›åº¦: 5/49 (10.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(308,3039)'), ('usv_1', '(213,4120)'), ('usv_2', '(205,5103)')]...
    Recent rewards sample: {'usv_0': np.float64(7.882499464316588), 'usv_1': np.float64(3.366313126695456)}
    Episode time: 172.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 2729, Avg Reward: 16.941, Episode Reward: 46232.2
    æ£€æµ‹è¿›åº¦: 10/74 (13.5%), Episode total: 13
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(323,2956)'), ('usv_1', '(223,4116)'), ('usv_2', '(221,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(7.88149978406101), 'usv_1': np.float64(3.367064205397388)}
    Episode time: 272.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 53204.3
  Targets Detected: 13/79 (11.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.73
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 728, Avg Reward: -3.900, Episode Reward: -2839.2
    æ£€æµ‹è¿›åº¦: 0/16 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3120)'), ('usv_1', '(228,4110)'), ('usv_2', '(223,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7154020617122099), 'usv_1': np.float64(-1.6325553714245884)}
    Episode time: 72.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 1728, Avg Reward: 5.520, Episode Reward: 9538.5
    æ£€æµ‹è¿›åº¦: 4/52 (7.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(364,3087)'), ('usv_1', '(203,4110)'), ('usv_2', '(209,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3212494984437315), 'usv_1': np.float64(1.3655928110247317)}
    Episode time: 172.8s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.1328376  -0.09072216] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 2728, Avg Reward: 15.011, Episode Reward: 40950.8
    æ£€æµ‹è¿›åº¦: 6/90 (6.7%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(449,3040)'), ('usv_1', '(213,4111)'), ('usv_2', '(232,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(7.891592024584194), 'usv_1': np.float64(3.3663134877012606)}
    Episode time: 272.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 47959.4
  Targets Detected: 10/100 (6.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.98
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 727, Avg Reward: 6.222, Episode Reward: 4523.7
    æ£€æµ‹è¿›åº¦: 3/15 (20.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3127)'), ('usv_1', '(214,4114)'), ('usv_2', '(227,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(1.280985804182103), 'usv_1': np.float64(0.36637577074947036)}
    Episode time: 72.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 1727, Avg Reward: 14.556, Episode Reward: 25138.6
    æ£€æµ‹è¿›åº¦: 6/45 (13.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(359,3094)'), ('usv_1', '(205,4112)'), ('usv_2', '(206,5109)')]...
    Recent rewards sample: {'usv_0': np.float64(2.316109976262031), 'usv_1': np.float64(3.365684583386191)}
    Episode time: 172.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 2727, Avg Reward: 18.383, Episode Reward: 50131.7
    æ£€æµ‹è¿›åº¦: 9/76 (11.8%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(403,3053)'), ('usv_1', '(219,4122)'), ('usv_2', '(220,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(5.883361258919498), 'usv_1': np.float64(3.3692815135783993)}
    Episode time: 272.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 57335.4
  Targets Detected: 11/82 (13.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.11
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 726, Avg Reward: 8.147, Episode Reward: 5914.9
    æ£€æµ‹è¿›åº¦: 2/15 (13.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3136)'), ('usv_1', '(222,4130)'), ('usv_2', '(231,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(3.279027933782377), 'usv_1': np.float64(2.3729550790747105)}
    Episode time: 72.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.02384665  0.03412353] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 1726, Avg Reward: 13.934, Episode Reward: 24050.3
    æ£€æµ‹è¿›åº¦: 4/40 (10.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(359,3114)'), ('usv_1', '(234,4111)'), ('usv_2', '(217,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3027522172154375), 'usv_1': np.float64(1.3679095532612746)}
    Episode time: 172.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 2726, Avg Reward: 16.556, Episode Reward: 45131.7
    æ£€æµ‹è¿›åº¦: 6/55 (10.9%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(374,3051)'), ('usv_1', '(220,4083)'), ('usv_2', '(247,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(7.880856342080088), 'usv_1': np.float64(1.3671572940908598)}
    Episode time: 272.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 52200.9
  Targets Detected: 8/69 (11.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.39
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 725, Avg Reward: 5.286, Episode Reward: 3832.5
    æ£€æµ‹è¿›åº¦: 2/29 (6.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3097)'), ('usv_1', '(227,4123)'), ('usv_2', '(231,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2901491562437486), 'usv_1': np.float64(2.367319458273859)}
    Episode time: 72.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 1725, Avg Reward: 15.558, Episode Reward: 26838.0
    æ£€æµ‹è¿›åº¦: 6/56 (10.7%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(336,3048)'), ('usv_1', '(214,4112)'), ('usv_2', '(203,5105)')]...
    Recent rewards sample: {'usv_0': np.float64(5.880742688449344), 'usv_1': np.float64(3.3664200583086625)}
    Episode time: 172.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 2725, Avg Reward: 19.288, Episode Reward: 52559.1
    æ£€æµ‹è¿›åº¦: 7/81 (8.6%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(337,2953)'), ('usv_1', '(218,4128)'), ('usv_2', '(236,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(5.8842902133790425), 'usv_1': np.float64(3.3666271405165578)}
    Episode time: 272.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 58540.1
  Targets Detected: 9/82 (8.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.51
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.00933641 0.09706261] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 724, Avg Reward: -3.434, Episode Reward: -2486.5
    æ£€æµ‹è¿›åº¦: 1/20 (5.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3104)'), ('usv_1', '(222,4119)'), ('usv_2', '(222,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7148271986594311), 'usv_1': np.float64(-1.6330017198187736)}
    Episode time: 72.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 1724, Avg Reward: 0.051, Episode Reward: 88.6
    æ£€æµ‹è¿›åº¦: 2/40 (5.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(351,3058)'), ('usv_1', '(204,4113)'), ('usv_2', '(205,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(3.8773954746733423), 'usv_1': np.float64(-0.6333320025739847)}
    Episode time: 172.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 2724, Avg Reward: 6.441, Episode Reward: 17546.2
    æ£€æµ‹è¿›åº¦: 5/64 (7.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(393,2981)'), ('usv_1', '(206,4129)'), ('usv_2', '(220,5105)')]...
    Recent rewards sample: {'usv_0': np.float64(7.884093889517477), 'usv_1': np.float64(3.372588447302867)}
    Episode time: 272.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 24613.0
  Targets Detected: 6/74 (8.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.20
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 723, Avg Reward: 3.875, Episode Reward: 2801.9
    æ£€æµ‹è¿›åº¦: 2/19 (10.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3140)'), ('usv_1', '(218,4119)'), ('usv_2', '(220,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2842173221310162), 'usv_1': np.float64(2.3666789243847637)}
    Episode time: 72.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 1723, Avg Reward: 15.986, Episode Reward: 27543.7
    æ£€æµ‹è¿›åº¦: 7/52 (13.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(341,3105)'), ('usv_1', '(200,4114)'), ('usv_2', '(215,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(4.303991053371712), 'usv_1': np.float64(3.3653512191351416)}
    Episode time: 172.3s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.16557995 -0.13446368] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Step 100000, Episode Steps: 2723, Avg Reward: 18.836, Episode Reward: 51289.6
    æ£€æµ‹è¿›åº¦: 6/77 (7.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(326,3021)'), ('usv_1', '(204,4128)'), ('usv_2', '(230,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(7.878428337586895), 'usv_1': np.float64(3.365540730851782)}
    Episode time: 272.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 54431.5
  Targets Detected: 7/84 (7.1%)
  Steps: 2868
  Episode Time: 286.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.98
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Step 101000, Episode Steps: 855, Avg Reward: -3.897, Episode Reward: -3332.3
    æ£€æµ‹è¿›åº¦: 0/16 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3106)'), ('usv_1', '(234,4119)'), ('usv_2', '(225,5107)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7045431725154203), 'usv_1': np.float64(-1.6321016395624344)}
    Episode time: 85.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Step 102000, Episode Steps: 1855, Avg Reward: -2.143, Episode Reward: -3974.8
    æ£€æµ‹è¿›åº¦: 1/54 (1.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(349,3037)'), ('usv_1', '(237,4098)'), ('usv_2', '(207,5107)')]...
    Recent rewards sample: {'usv_0': np.float64(2.8849302472584726), 'usv_1': np.float64(-1.6317244678648075)}
    Episode time: 185.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: -4105.8
  Targets Detected: 1/62 (1.6%)
  Steps: 2215
  Episode Time: 221.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: -1.85
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Step 103000, Episode Steps: 640, Avg Reward: 7.114, Episode Reward: 4553.0
    æ£€æµ‹è¿›åº¦: 2/22 (9.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3142)'), ('usv_1', '(226,4118)'), ('usv_2', '(228,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2889545637970445), 'usv_1': np.float64(0.3672472688744248)}
    Episode time: 64.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Step 104000, Episode Steps: 1640, Avg Reward: 14.261, Episode Reward: 23387.5
    æ£€æµ‹è¿›åº¦: 4/50 (8.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(344,3134)'), ('usv_1', '(209,4105)'), ('usv_2', '(201,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(4.295972789575677), 'usv_1': np.float64(1.3672677157793327)}
    Episode time: 164.0s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.11768638 0.22038555] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Step 105000, Episode Steps: 2640, Avg Reward: 17.485, Episode Reward: 46160.3
    æ£€æµ‹è¿›åº¦: 6/71 (8.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(440,3142)'), ('usv_1', '(223,4102)'), ('usv_2', '(226,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3250384550747127), 'usv_1': np.float64(3.368195063247005)}
    Episode time: 264.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 53433.2
  Targets Detected: 7/77 (7.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.81
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Step 106000, Episode Steps: 639, Avg Reward: 14.807, Episode Reward: 9461.8
    æ£€æµ‹è¿›åº¦: 3/20 (15.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(268,3131)'), ('usv_1', '(222,4123)'), ('usv_2', '(223,5109)')]...
    Recent rewards sample: {'usv_0': np.float64(4.278692023549259), 'usv_1': np.float64(1.3669371341950036)}
    Episode time: 63.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Step 107000, Episode Steps: 1639, Avg Reward: 17.784, Episode Reward: 29148.5
    æ£€æµ‹è¿›åº¦: 5/45 (11.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(366,3111)'), ('usv_1', '(218,4117)'), ('usv_2', '(207,5096)')]...
    Recent rewards sample: {'usv_0': np.float64(4.305689498589851), 'usv_1': np.float64(1.3716964479718272)}
    Episode time: 163.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Step 108000, Episode Steps: 2639, Avg Reward: 21.191, Episode Reward: 55923.0
    æ£€æµ‹è¿›åº¦: 8/71 (11.3%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(361,3031)'), ('usv_1', '(224,4142)'), ('usv_2', '(224,5107)')]...
    Recent rewards sample: {'usv_0': np.float64(7.882455204836792), 'usv_1': np.float64(1.3671487121792851)}
    Episode time: 263.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 64508.8
  Targets Detected: 10/77 (10.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.50

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 46212.1
Last 10 episodes average detections: 8.2
Best episode reward so far: 72427.2
Best detection count so far: 13
Learning trend: Improving (46212.1 vs 32622.9)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Step 109000, Episode Steps: 638, Avg Reward: 7.407, Episode Reward: 4725.5
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3111)'), ('usv_1', '(224,4124)'), ('usv_2', '(224,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2751700116412525), 'usv_1': np.float64(0.3671241765781834)}
    Episode time: 63.8s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.11357417 -0.19533087] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Step 110000, Episode Steps: 1638, Avg Reward: 14.394, Episode Reward: 23577.6
    æ£€æµ‹è¿›åº¦: 6/39 (15.4%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3010)'), ('usv_1', '(216,4102)'), ('usv_2', '(203,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(5.873067346299983), 'usv_1': np.float64(1.3666104910386143)}
    Episode time: 163.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Step 111000, Episode Steps: 2638, Avg Reward: 17.133, Episode Reward: 45197.2
    æ£€æµ‹è¿›åº¦: 6/65 (9.2%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,2957)'), ('usv_1', '(209,4103)'), ('usv_2', '(237,5160)')]...
    Recent rewards sample: {'usv_0': np.float64(5.875943274228268), 'usv_1': np.float64(1.3752566899462977)}
    Episode time: 263.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 53934.1
  Targets Detected: 9/83 (9.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.97
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Step 112000, Episode Steps: 637, Avg Reward: 1.359, Episode Reward: 865.7
    æ£€æµ‹è¿›åº¦: 1/14 (7.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3115)'), ('usv_1', '(218,4118)'), ('usv_2', '(222,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2785123119861147), 'usv_1': np.float64(1.3736708169227767)}
    Episode time: 63.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Step 113000, Episode Steps: 1637, Avg Reward: 6.652, Episode Reward: 10889.3
    æ£€æµ‹è¿›åº¦: 2/45 (4.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(324,3041)'), ('usv_1', '(206,4109)'), ('usv_2', '(208,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(6.880575442080702), 'usv_1': np.float64(2.365830184757585)}
    Episode time: 163.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Step 114000, Episode Steps: 2637, Avg Reward: 11.772, Episode Reward: 31043.5
    æ£€æµ‹è¿›åº¦: 4/64 (6.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(368,2965)'), ('usv_1', '(219,4120)'), ('usv_2', '(228,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(7.884827005590485), 'usv_1': np.float64(1.3667715919576704)}
    Episode time: 263.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 40318.0
  Targets Detected: 5/77 (6.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.43
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.15143342 0.16926421] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Step 115000, Episode Steps: 636, Avg Reward: 13.141, Episode Reward: 8358.0
    æ£€æµ‹è¿›åº¦: 3/31 (9.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3108)'), ('usv_1', '(225,4128)'), ('usv_2', '(239,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(4.283095200805627), 'usv_1': np.float64(1.3671655353954222)}
    Episode time: 63.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Step 116000, Episode Steps: 1636, Avg Reward: 18.203, Episode Reward: 29780.3
    æ£€æµ‹è¿›åº¦: 5/46 (10.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3026)'), ('usv_1', '(236,4117)'), ('usv_2', '(222,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(7.876732453116843), 'usv_1': np.float64(1.3690317540499422)}
    Episode time: 163.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 50645.3
  Targets Detected: 5/61 (8.2%)
  Steps: 2611
  Episode Time: 261.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 19.40
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Step 117000, Episode Steps: 25, Avg Reward: -3.850, Episode Reward: -96.3
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(212,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7340637070098616), 'usv_1': np.float64(-1.6337907838500545)}
    Episode time: 2.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Step 118000, Episode Steps: 1025, Avg Reward: 4.611, Episode Reward: 4726.7
    æ£€æµ‹è¿›åº¦: 2/31 (6.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(295,3097)'), ('usv_1', '(226,4113)'), ('usv_2', '(210,5096)')]...
    Recent rewards sample: {'usv_0': np.float64(2.290759747191701), 'usv_1': np.float64(3.3699337916281094)}
    Episode time: 102.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Step 119000, Episode Steps: 2025, Avg Reward: 15.568, Episode Reward: 31525.3
    æ£€æµ‹è¿›åº¦: 6/67 (9.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(366,3054)'), ('usv_1', '(214,4106)'), ('usv_2', '(209,5106)')]...
    Recent rewards sample: {'usv_0': np.float64(5.882576784246838), 'usv_1': np.float64(3.3716320476452326)}
    Episode time: 202.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 53891.2
  Targets Detected: 8/90 (6.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.96
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.07093135  0.24005757] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Step 120000, Episode Steps: 24, Avg Reward: -3.834, Episode Reward: -92.0
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(212,4130)'), ('usv_2', '(215,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7327399371971294), 'usv_1': np.float64(-1.633796097118264)}
    Episode time: 2.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Step 121000, Episode Steps: 1024, Avg Reward: 3.155, Episode Reward: 3230.5
    æ£€æµ‹è¿›åº¦: 3/32 (9.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(306,3136)'), ('usv_1', '(226,4121)'), ('usv_2', '(209,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2908017698414198), 'usv_1': np.float64(0.36927410286701523)}
    Episode time: 102.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Step 122000, Episode Steps: 2024, Avg Reward: 9.631, Episode Reward: 19493.9
    æ£€æµ‹è¿›åº¦: 4/67 (6.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(381,3128)'), ('usv_1', '(204,4126)'), ('usv_2', '(222,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(2.308647527546885), 'usv_1': np.float64(3.369699690199268)}
    Episode time: 202.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 42419.1
  Targets Detected: 9/96 (7.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.14
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Step 123000, Episode Steps: 23, Avg Reward: -3.931, Episode Reward: -90.4
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(212,4130)'), ('usv_2', '(212,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.728944807894451), 'usv_1': np.float64(-1.633792839563456)}
    Episode time: 2.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Step 124000, Episode Steps: 1023, Avg Reward: 3.934, Episode Reward: 4024.7
    æ£€æµ‹è¿›åº¦: 2/40 (5.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(284,3092)'), ('usv_1', '(220,4115)'), ('usv_2', '(220,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(1.286603859146361), 'usv_1': np.float64(2.3668018375843216)}
    Episode time: 102.3s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.23994103 0.10076005] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Step 125000, Episode Steps: 2023, Avg Reward: 11.845, Episode Reward: 23961.9
    æ£€æµ‹è¿›åº¦: 3/68 (4.4%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3000)'), ('usv_1', '(205,4129)'), ('usv_2', '(219,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(5.8826031464842625), 'usv_1': np.float64(3.369817077192585)}
    Episode time: 202.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 34783.5
  Targets Detected: 7/81 (4.9%)
  Steps: 2483
  Episode Time: 248.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.01
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Step 126000, Episode Steps: 540, Avg Reward: 7.220, Episode Reward: 3899.1
    æ£€æµ‹è¿›åº¦: 3/13 (23.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(249,3117)'), ('usv_1', '(223,4125)'), ('usv_2', '(236,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(3.274459465620626), 'usv_1': np.float64(0.36702030716698353)}
    Episode time: 54.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Step 127000, Episode Steps: 1540, Avg Reward: 19.266, Episode Reward: 29669.6
    æ£€æµ‹è¿›åº¦: 7/32 (21.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(301,3065)'), ('usv_1', '(216,4107)'), ('usv_2', '(234,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(7.875300405904086), 'usv_1': np.float64(3.36659824020059)}
    Episode time: 154.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Step 128000, Episode Steps: 2540, Avg Reward: 22.245, Episode Reward: 56501.8
    æ£€æµ‹è¿›åº¦: 6/52 (11.5%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(368,3014)'), ('usv_1', '(207,4103)'), ('usv_2', '(215,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(7.879487167378828), 'usv_1': np.float64(3.367489774819581)}
    Episode time: 254.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 59145.8
  Targets Detected: 8/55 (10.9%)
  Steps: 2643
  Episode Time: 264.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 22.38
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Step 129000, Episode Steps: 897, Avg Reward: 0.219, Episode Reward: 196.7
    æ£€æµ‹è¿›åº¦: 1/36 (2.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(310,3127)'), ('usv_1', '(232,4122)'), ('usv_2', '(207,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(0.29456773619927634), 'usv_1': np.float64(-0.6322524926474333)}
    Episode time: 89.7s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.07082626 -0.16214658] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Step 130000, Episode Steps: 1897, Avg Reward: 8.032, Episode Reward: 15236.4
    æ£€æµ‹è¿›åº¦: 5/69 (7.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(380,3095)'), ('usv_1', '(225,4118)'), ('usv_2', '(220,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3111019000266433), 'usv_1': np.float64(1.3672190019818187)}
    Episode time: 189.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Step 131000, Episode Steps: 2897, Avg Reward: 13.997, Episode Reward: 40550.0
    æ£€æµ‹è¿›åº¦: 8/93 (8.6%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(437,3040)'), ('usv_1', '(237,4133)'), ('usv_2', '(243,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(5.893831137779919), 'usv_1': np.float64(3.371101370017713)}
    Episode time: 289.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 42808.7
  Targets Detected: 9/95 (8.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.26
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 132000...
    MADDPG UPDATE finished.
    Step 132000, Episode Steps: 896, Avg Reward: 8.006, Episode Reward: 7173.0
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(305,3121)'), ('usv_1', '(242,4128)'), ('usv_2', '(232,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2991475830725379), 'usv_1': np.float64(2.368463265438296)}
    Episode time: 89.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 133000...
    MADDPG UPDATE finished.
    Step 133000, Episode Steps: 1896, Avg Reward: 10.885, Episode Reward: 20637.1
    æ£€æµ‹è¿›åº¦: 3/36 (8.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(376,3063)'), ('usv_1', '(244,4115)'), ('usv_2', '(217,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(5.8855251837577045), 'usv_1': np.float64(3.3714603047846827)}
    Episode time: 189.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 28247.1
  Targets Detected: 3/48 (6.2%)
  Steps: 2307
  Episode Time: 230.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.24
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 134000...
    MADDPG UPDATE finished.
    Step 134000, Episode Steps: 589, Avg Reward: -3.286, Episode Reward: -1935.7
    æ£€æµ‹è¿›åº¦: 1/18 (5.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3098)'), ('usv_1', '(223,4119)'), ('usv_2', '(230,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7223951836668923), 'usv_1': np.float64(-1.6319703386443598)}
    Episode time: 58.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.01831601 -0.39113075] (agent usv_0)
    MADDPG UPDATING at time_step 135000...
    MADDPG UPDATE finished.
    Step 135000, Episode Steps: 1589, Avg Reward: 8.350, Episode Reward: 13267.4
    æ£€æµ‹è¿›åº¦: 3/39 (7.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3006)'), ('usv_1', '(211,4099)'), ('usv_2', '(215,5074)')]...
    Recent rewards sample: {'usv_0': np.float64(7.872587538286998), 'usv_1': np.float64(1.3662918717404664)}
    Episode time: 158.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 136000...
    MADDPG UPDATE finished.
    Step 136000, Episode Steps: 2589, Avg Reward: 14.401, Episode Reward: 37283.9
    æ£€æµ‹è¿›åº¦: 7/66 (10.6%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,2925)'), ('usv_1', '(227,4112)'), ('usv_2', '(227,5059)')]...
    Recent rewards sample: {'usv_0': np.float64(7.874530385688129), 'usv_1': np.float64(1.3674078889674357)}
    Episode time: 258.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 47366.6
  Targets Detected: 9/93 (8.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.78

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 45355.9
Last 10 episodes average detections: 7.2
Best episode reward so far: 72427.2
Best detection count so far: 13
Learning trend: Declining (45355.9 vs 46212.1)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 72427.2
Final 10 episodes average: 45355.9
Best detection performance: 13 targets
Average detections (final 10): 7.2
============================================================
{"final_avg_reward": 45355.930761978896, "final_detection_rate": 7.2, "best_episode_reward": 72427.18050152063, "best_detection_count": 13, "total_episodes": 50}
Simulation finished.
