D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: 9.823, Episode Reward: 9823.1
    æ£€æµ‹è¿›åº¦: 3/16 (18.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(240,3133)'), ('usv_1', '(235,4119)'), ('usv_2', '(276,5181)')]...
    Recent rewards sample: {'usv_0': np.float64(4.36940775265457), 'usv_1': np.float64(3.4679786037171514)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 14.454, Episode Reward: 28907.5
    æ£€æµ‹è¿›åº¦: 4/25 (16.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(266,3139)'), ('usv_1', '(264,4099)'), ('usv_2', '(287,5249)')]...
    Recent rewards sample: {'usv_0': np.float64(4.375475553808718), 'usv_1': np.float64(3.4702706164096764)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 38945.5
  Targets Detected: 4/29 (13.8%)
  Steps: 2537
  Episode Time: 253.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.35
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 463, Avg Reward: -2.991, Episode Reward: -1384.7
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3133)'), ('usv_1', '(232,4127)'), ('usv_2', '(243,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.364931856254862), 'usv_1': np.float64(-0.5322618252948191)}
    Episode time: 46.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 1463, Avg Reward: 6.561, Episode Reward: 9599.2
    æ£€æµ‹è¿›åº¦: 4/28 (14.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3144)'), ('usv_1', '(250,4104)'), ('usv_2', '(314,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(4.372410043741328), 'usv_1': np.float64(1.4694855093820527)}
    Episode time: 146.3s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.21349776 -0.04116788] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 2463, Avg Reward: 8.369, Episode Reward: 20613.8
    æ£€æµ‹è¿›åº¦: 4/37 (10.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(269,3156)'), ('usv_1', '(235,4057)'), ('usv_2', '(386,5171)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6183163464996028), 'usv_1': np.float64(1.4714947956511901)}
    Episode time: 246.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 24792.9
  Targets Detected: 5/41 (9.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.26
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 462, Avg Reward: 9.828, Episode Reward: 4540.3
    æ£€æµ‹è¿›åº¦: 2/9 (22.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3134)'), ('usv_1', '(231,4131)'), ('usv_2', '(244,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3659877165183554), 'usv_1': np.float64(0.46919755643249794)}
    Episode time: 46.2s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 1462, Avg Reward: 15.966, Episode Reward: 23342.2
    æ£€æµ‹è¿›åº¦: 5/24 (20.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(243,3138)'), ('usv_1', '(266,4130)'), ('usv_2', '(321,5079)')]...
    Recent rewards sample: {'usv_0': np.float64(4.373683666135681), 'usv_1': np.float64(1.4703005167123107)}
    Episode time: 146.2s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 31255.5
  Targets Detected: 5/27 (11.1%)
  Steps: 2091
  Episode Time: 209.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.95
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 371, Avg Reward: 0.429, Episode Reward: 159.1
    æ£€æµ‹è¿›åº¦: 1/4 (25.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3133)'), ('usv_1', '(224,4131)'), ('usv_2', '(251,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3688874944899242), 'usv_1': np.float64(-0.5313492252436176)}
    Episode time: 37.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 1371, Avg Reward: 9.087, Episode Reward: 12457.9
    æ£€æµ‹è¿›åº¦: 5/22 (22.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3150)'), ('usv_1', '(251,4115)'), ('usv_2', '(303,5198)')]...
    Recent rewards sample: {'usv_0': np.float64(4.372215174343716), 'usv_1': np.float64(1.4692144433247)}
    Episode time: 137.1s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.02364884 0.05874081] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 2371, Avg Reward: 14.038, Episode Reward: 33283.5
    æ£€æµ‹è¿›åº¦: 8/42 (19.0%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3165)'), ('usv_1', '(274,4090)'), ('usv_2', '(391,5246)')]...
    Recent rewards sample: {'usv_0': np.float64(4.372865095665926), 'usv_1': np.float64(1.4788594311041954)}
    Episode time: 237.1s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 45489.7
  Targets Detected: 9/57 (12.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.16
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 370, Avg Reward: -3.260, Episode Reward: -1206.4
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3129)'), ('usv_1', '(224,4132)'), ('usv_2', '(241,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.63399089233574), 'usv_1': np.float64(-1.5322958494668355)}
    Episode time: 37.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 1370, Avg Reward: 2.047, Episode Reward: 2805.0
    æ£€æµ‹è¿›åº¦: 3/19 (15.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3135)'), ('usv_1', '(249,4118)'), ('usv_2', '(311,5152)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3705317441581), 'usv_1': np.float64(1.4700187087255983)}
    Episode time: 137.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 2370, Avg Reward: 10.815, Episode Reward: 25631.5
    æ£€æµ‹è¿›åº¦: 8/40 (20.0%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(262,3141)'), ('usv_1', '(276,4092)'), ('usv_2', '(402,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3751790692005885), 'usv_1': np.float64(1.4799699395597266)}
    Episode time: 237.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 38662.5
  Targets Detected: 8/44 (18.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.88
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 369, Avg Reward: -3.945, Episode Reward: -1455.8
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3131)'), ('usv_1', '(224,4132)'), ('usv_2', '(249,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.634092303315683), 'usv_1': np.float64(-1.529901840659379)}
    Episode time: 36.9s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.20969067 -0.35461394] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 1369, Avg Reward: -3.559, Episode Reward: -4872.6
    æ£€æµ‹è¿›åº¦: 0/15 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3142)'), ('usv_1', '(254,4140)'), ('usv_2', '(321,5203)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6276728820902677), 'usv_1': np.float64(-1.530598092482023)}
    Episode time: 136.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 2369, Avg Reward: -0.274, Episode Reward: -648.4
    æ£€æµ‹è¿›åº¦: 2/31 (6.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3163)'), ('usv_1', '(288,4136)'), ('usv_2', '(343,5254)')]...
    Recent rewards sample: {'usv_0': np.float64(-2.6259200333866444), 'usv_1': np.float64(1.4740276948515127)}
    Episode time: 236.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 8357.5
  Targets Detected: 5/40 (10.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 2.78
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 368, Avg Reward: 2.918, Episode Reward: 1073.9
    æ£€æµ‹è¿›åº¦: 1/3 (33.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3131)'), ('usv_1', '(219,4126)'), ('usv_2', '(238,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(2.36404919028537), 'usv_1': np.float64(-0.5332400118264192)}
    Episode time: 36.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 1368, Avg Reward: 8.842, Episode Reward: 12095.4
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3127)'), ('usv_1', '(246,4103)'), ('usv_2', '(335,5158)')]...
    Recent rewards sample: {'usv_0': np.float64(3.373816371370721), 'usv_1': np.float64(2.4688680897560324)}
    Episode time: 136.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 21423.4
  Targets Detected: 3/27 (7.4%)
  Steps: 1842
  Episode Time: 184.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 11.63
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 526, Avg Reward: 2.786, Episode Reward: 1465.2
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3137)'), ('usv_1', '(231,4118)'), ('usv_2', '(265,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(1.371967188133822), 'usv_1': np.float64(0.4676820421074952)}
    Episode time: 52.6s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.05887161  0.14993972] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 1526, Avg Reward: 14.704, Episode Reward: 22438.2
    æ£€æµ‹è¿›åº¦: 6/16 (37.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3149)'), ('usv_1', '(252,4084)'), ('usv_2', '(352,5172)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3632088114825422), 'usv_1': np.float64(1.4695941276729747)}
    Episode time: 152.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 30990.5
  Targets Detected: 6/20 (30.0%)
  Steps: 2161
  Episode Time: 216.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.34
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 365, Avg Reward: -1.662, Episode Reward: -606.6
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3130)'), ('usv_1', '(221,4128)'), ('usv_2', '(249,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3674502118757671), 'usv_1': np.float64(-0.5320930376127373)}
    Episode time: 36.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 1365, Avg Reward: 3.963, Episode Reward: 5409.8
    æ£€æµ‹è¿›åº¦: 2/22 (9.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3146)'), ('usv_1', '(257,4134)'), ('usv_2', '(338,5161)')]...
    Recent rewards sample: {'usv_0': np.float64(1.373837446309674), 'usv_1': np.float64(0.46964155875363867)}
    Episode time: 136.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 2365, Avg Reward: 7.836, Episode Reward: 18532.6
    æ£€æµ‹è¿›åº¦: 5/51 (9.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3163)'), ('usv_1', '(285,4142)'), ('usv_2', '(402,5198)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6316067788962101), 'usv_1': np.float64(1.4737484811426609)}
    Episode time: 236.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 23821.4
  Targets Detected: 6/53 (9.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.94
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 364, Avg Reward: 3.606, Episode Reward: 1312.5
    æ£€æµ‹è¿›åº¦: 2/9 (22.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3131)'), ('usv_1', '(225,4130)'), ('usv_2', '(233,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(2.365978100253803), 'usv_1': np.float64(-0.5328189772029945)}
    Episode time: 36.4s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.03815764 -0.03312188] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 1364, Avg Reward: 9.927, Episode Reward: 13539.8
    æ£€æµ‹è¿›åº¦: 4/18 (22.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3145)'), ('usv_1', '(258,4122)'), ('usv_2', '(293,5185)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3717411873489542), 'usv_1': np.float64(3.4767194942330697)}
    Episode time: 136.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 2364, Avg Reward: 14.398, Episode Reward: 34037.3
    æ£€æµ‹è¿›åº¦: 5/23 (21.7%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3161)'), ('usv_1', '(274,4094)'), ('usv_2', '(282,5240)')]...
    Recent rewards sample: {'usv_0': np.float64(4.374030048345583), 'usv_1': np.float64(3.472061470103773)}
    Episode time: 236.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 46621.2
  Targets Detected: 8/33 (21.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.54

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 31036.0
Last 10 episodes average detections: 5.9
Best episode reward so far: 46621.2
Best detection count so far: 9
Buffer size: 26637
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 363, Avg Reward: -3.237, Episode Reward: -1175.1
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3133)'), ('usv_1', '(222,4132)'), ('usv_2', '(238,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3163654023534717), 'usv_1': np.float64(-0.5830656752543071)}
    Episode time: 36.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 1363, Avg Reward: 2.600, Episode Reward: 3543.8
    æ£€æµ‹è¿›åº¦: 0/32 (0.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3156)'), ('usv_1', '(253,4153)'), ('usv_2', '(332,5186)')]...
    Recent rewards sample: {'usv_0': np.float64(2.320414205359123), 'usv_1': np.float64(-0.5795804825879527)}
    Episode time: 136.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 7964.3
  Targets Detected: 2/41 (2.4%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_135s
  Average Reward/Step: 4.42
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 562, Avg Reward: 2.408, Episode Reward: 1353.5
    æ£€æµ‹è¿›åº¦: 1/21 (4.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3131)'), ('usv_1', '(225,4124)'), ('usv_2', '(240,5153)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3158223509211575), 'usv_1': np.float64(0.4191244330034778)}
    Episode time: 56.2s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.2951352   0.31623231] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 1562, Avg Reward: 14.312, Episode Reward: 22356.1
    æ£€æµ‹è¿›åº¦: 6/61 (9.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3149)'), ('usv_1', '(256,4090)'), ('usv_2', '(319,5208)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3106905309436763), 'usv_1': np.float64(3.4205675693392745)}
    Episode time: 156.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 2562, Avg Reward: 13.894, Episode Reward: 35596.2
    æ£€æµ‹è¿›åº¦: 8/80 (10.0%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3154)'), ('usv_1', '(288,4062)'), ('usv_2', '(356,5284)')]...
    Recent rewards sample: {'usv_0': np.float64(-3.6915106613709696), 'usv_1': np.float64(1.4270676405663716)}
    Episode time: 256.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 37413.2
  Targets Detected: 8/89 (9.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.47
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 561, Avg Reward: -3.600, Episode Reward: -2019.5
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3128)'), ('usv_1', '(236,4128)'), ('usv_2', '(259,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6842855318124325), 'usv_1': np.float64(-1.5819585078727034)}
    Episode time: 56.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 1561, Avg Reward: -1.102, Episode Reward: -1720.1
    æ£€æµ‹è¿›åº¦: 1/28 (3.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(269,3133)'), ('usv_1', '(267,4108)'), ('usv_2', '(330,5176)')]...
    Recent rewards sample: {'usv_0': np.float64(0.336084113523048), 'usv_1': np.float64(1.4267548424954666)}
    Episode time: 156.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 2561, Avg Reward: 3.126, Episode Reward: 8005.9
    æ£€æµ‹è¿›åº¦: 2/41 (4.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(291,3139)'), ('usv_1', '(285,4080)'), ('usv_2', '(401,5227)')]...
    Recent rewards sample: {'usv_0': np.float64(3.331782556028819), 'usv_1': np.float64(2.4241210456540982)}
    Episode time: 256.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 13406.2
  Targets Detected: 2/49 (4.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 4.47
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.16743003  0.08050453] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 560, Avg Reward: 3.836, Episode Reward: 2148.4
    æ£€æµ‹è¿›åº¦: 1/14 (7.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3130)'), ('usv_1', '(232,4134)'), ('usv_2', '(267,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(2.316389834794671), 'usv_1': np.float64(-0.5822665075099662)}
    Episode time: 56.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 1560, Avg Reward: 12.932, Episode Reward: 20174.0
    æ£€æµ‹è¿›åº¦: 4/36 (11.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3146)'), ('usv_1', '(261,4106)'), ('usv_2', '(347,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(2.317076539803784), 'usv_1': np.float64(3.4199909762783456)}
    Episode time: 156.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 2560, Avg Reward: 14.983, Episode Reward: 38356.9
    æ£€æµ‹è¿›åº¦: 4/54 (7.4%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3173)'), ('usv_1', '(249,4072)'), ('usv_2', '(397,5183)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3112133565022606), 'usv_1': np.float64(3.41953956411224)}
    Episode time: 256.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 46480.9
  Targets Detected: 5/63 (6.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.49
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 559, Avg Reward: -3.708, Episode Reward: -2072.7
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3137)'), ('usv_1', '(229,4132)'), ('usv_2', '(263,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.680663016336495), 'usv_1': np.float64(-1.5825202807485232)}
    Episode time: 55.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 1559, Avg Reward: -1.997, Episode Reward: -3113.6
    æ£€æµ‹è¿›åº¦: 1/30 (3.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3145)'), ('usv_1', '(258,4138)'), ('usv_2', '(343,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3216025906310406), 'usv_1': np.float64(-0.5782685612629064)}
    Episode time: 155.9s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.11138932  0.3188373 ] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 2559, Avg Reward: 4.106, Episode Reward: 10506.0
    æ£€æµ‹è¿›åº¦: 3/61 (4.9%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3168)'), ('usv_1', '(287,4135)'), ('usv_2', '(400,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(4.322011195843869), 'usv_1': np.float64(3.4233728090490807)}
    Episode time: 255.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 19470.0
  Targets Detected: 3/69 (4.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 6.49
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 558, Avg Reward: 8.017, Episode Reward: 4473.8
    æ£€æµ‹è¿›åº¦: 2/15 (13.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3126)'), ('usv_1', '(224,4126)'), ('usv_2', '(276,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(3.317064434617651), 'usv_1': np.float64(0.4170855303745742)}
    Episode time: 55.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 1558, Avg Reward: 13.498, Episode Reward: 21030.6
    æ£€æµ‹è¿›åº¦: 2/27 (7.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3122)'), ('usv_1', '(257,4108)'), ('usv_2', '(337,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(4.331737910352786), 'usv_1': np.float64(1.4197424682849933)}
    Episode time: 155.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 25008.9
  Targets Detected: 3/39 (5.1%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_121s
  Average Reward/Step: 13.89
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 757, Avg Reward: 2.920, Episode Reward: 2210.7
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3137)'), ('usv_1', '(230,4127)'), ('usv_2', '(277,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3154732369405597), 'usv_1': np.float64(2.4175618017403844)}
    Episode time: 75.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 1757, Avg Reward: 12.563, Episode Reward: 22072.9
    æ£€æµ‹è¿›åº¦: 5/40 (12.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3150)'), ('usv_1', '(257,4095)'), ('usv_2', '(354,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(4.325474911027082), 'usv_1': np.float64(1.4258244692472024)}
    Episode time: 175.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 30934.6
  Targets Detected: 5/54 (9.3%)
  Steps: 2322
  Episode Time: 232.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.32
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.31764631 -0.04130851] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 435, Avg Reward: -3.595, Episode Reward: -1563.7
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3132)'), ('usv_1', '(228,4136)'), ('usv_2', '(253,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6808395688340738), 'usv_1': np.float64(-1.5809529330406258)}
    Episode time: 43.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 1435, Avg Reward: -3.596, Episode Reward: -5160.9
    æ£€æµ‹è¿›åº¦: 0/24 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3150)'), ('usv_1', '(255,4158)'), ('usv_2', '(308,5052)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6818928613099434), 'usv_1': np.float64(-1.5734967874542816)}
    Episode time: 143.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: -6481.1
  Targets Detected: 0/36 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.60
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 634, Avg Reward: -3.611, Episode Reward: -2289.7
    æ£€æµ‹è¿›åº¦: 0/16 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3136)'), ('usv_1', '(235,4134)'), ('usv_2', '(261,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6824220172855179), 'usv_1': np.float64(-1.58128863885401)}
    Episode time: 63.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 1634, Avg Reward: 1.433, Episode Reward: 2341.1
    æ£€æµ‹è¿›åº¦: 4/28 (14.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3151)'), ('usv_1', '(277,4127)'), ('usv_2', '(318,5181)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3181588208030615), 'usv_1': np.float64(1.4251676120496333)}
    Episode time: 163.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 2634, Avg Reward: 8.819, Episode Reward: 23229.8
    æ£€æµ‹è¿›åº¦: 6/60 (10.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3180)'), ('usv_1', '(299,4100)'), ('usv_2', '(347,5273)')]...
    Recent rewards sample: {'usv_0': np.float64(4.322326088487302), 'usv_1': np.float64(1.4229317399342394)}
    Episode time: 263.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 29976.1
  Targets Detected: 6/63 (7.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.99
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.13113763 -0.15999269] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 633, Avg Reward: 3.165, Episode Reward: 2003.5
    æ£€æµ‹è¿›åº¦: 1/16 (6.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3121)'), ('usv_1', '(243,4122)'), ('usv_2', '(256,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31939332765075035), 'usv_1': np.float64(-0.5781796571675758)}
    Episode time: 63.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 1633, Avg Reward: 13.146, Episode Reward: 21467.5
    æ£€æµ‹è¿›åº¦: 5/48 (10.4%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3119)'), ('usv_1', '(278,4110)'), ('usv_2', '(329,5167)')]...
    Recent rewards sample: {'usv_0': np.float64(4.328356832641994), 'usv_1': np.float64(1.4294198486532328)}
    Episode time: 163.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 39174.9
  Targets Detected: 5/63 (7.9%)
  Steps: 2522
  Episode Time: 252.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.53

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 24334.8
Last 10 episodes average detections: 3.9
Best episode reward so far: 46621.2
Best detection count so far: 9
Learning trend: Declining (24334.8 vs 31036.0)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 111, Avg Reward: -2.794, Episode Reward: -310.2
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(224,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31398082974103536), 'usv_1': np.float64(-0.5836681427248095)}
    Episode time: 11.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 1111, Avg Reward: 7.855, Episode Reward: 8727.4
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(204,3151)'), ('usv_1', '(247,4108)'), ('usv_2', '(309,5152)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3076768031443375), 'usv_1': np.float64(2.420922453902376)}
    Episode time: 111.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 2111, Avg Reward: 7.955, Episode Reward: 16793.6
    æ£€æµ‹è¿›åº¦: 3/48 (6.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3141)'), ('usv_1', '(248,4078)'), ('usv_2', '(385,5188)')]...
    Recent rewards sample: {'usv_0': np.float64(-3.687873790903687), 'usv_1': np.float64(3.419374898072533)}
    Episode time: 211.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 26676.3
  Targets Detected: 7/72 (8.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.89
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.06521183 -0.00649586] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 110, Avg Reward: -3.550, Episode Reward: -390.5
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3130)'), ('usv_1', '(222,4130)'), ('usv_2', '(224,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.683404630148084), 'usv_1': np.float64(-1.57820241853117)}
    Episode time: 11.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 1110, Avg Reward: 8.352, Episode Reward: 9270.4
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3136)'), ('usv_1', '(239,4109)'), ('usv_2', '(285,5195)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3235703676326898), 'usv_1': np.float64(0.41935571010598327)}
    Episode time: 111.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 15985.0
  Targets Detected: 2/30 (6.7%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_133s
  Average Reward/Step: 8.88
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 309, Avg Reward: -3.602, Episode Reward: -1112.9
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3132)'), ('usv_1', '(222,4127)'), ('usv_2', '(238,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6833426317600724), 'usv_1': np.float64(-1.5810439731177144)}
    Episode time: 30.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 1309, Avg Reward: -3.599, Episode Reward: -4711.1
    æ£€æµ‹è¿›åº¦: 0/23 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3153)'), ('usv_1', '(253,4125)'), ('usv_2', '(328,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6820211944233696), 'usv_1': np.float64(-1.579937473932312)}
    Episode time: 130.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: -6498.6
  Targets Detected: 0/26 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.61
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 508, Avg Reward: -3.611, Episode Reward: -1834.2
    æ£€æµ‹è¿›åº¦: 0/9 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3134)'), ('usv_1', '(226,4131)'), ('usv_2', '(255,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.685876377467981), 'usv_1': np.float64(-1.58069772277614)}
    Episode time: 50.8s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.05002627  0.3914454 ] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 1508, Avg Reward: 0.122, Episode Reward: 184.3
    æ£€æµ‹è¿›åº¦: 2/30 (6.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3167)'), ('usv_1', '(262,4170)'), ('usv_2', '(342,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3092266528275278), 'usv_1': np.float64(0.42027194112767297)}
    Episode time: 150.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 2508, Avg Reward: 5.546, Episode Reward: 13908.8
    æ£€æµ‹è¿›åº¦: 3/50 (6.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3175)'), ('usv_1', '(301,4194)'), ('usv_2', '(406,5201)')]...
    Recent rewards sample: {'usv_0': np.float64(2.305930060291967), 'usv_1': np.float64(1.428409292358086)}
    Episode time: 250.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 23984.1
  Targets Detected: 4/64 (6.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.99
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 507, Avg Reward: -3.661, Episode Reward: -1856.2
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3134)'), ('usv_1', '(232,4134)'), ('usv_2', '(247,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6829395355397679), 'usv_1': np.float64(-1.5822930212346298)}
    Episode time: 50.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 1507, Avg Reward: 2.841, Episode Reward: 4281.3
    æ£€æµ‹è¿›åº¦: 1/43 (2.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3152)'), ('usv_1', '(264,4145)'), ('usv_2', '(337,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(1.312905887811385), 'usv_1': np.float64(0.4201742607267063)}
    Episode time: 150.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 2507, Avg Reward: 1.839, Episode Reward: 4611.2
    æ£€æµ‹è¿›åº¦: 2/59 (3.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3170)'), ('usv_1', '(291,4149)'), ('usv_2', '(423,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(-5.692996424921762), 'usv_1': np.float64(1.4222436805485987)}
    Episode time: 250.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 8998.6
  Targets Detected: 4/66 (6.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 3.00
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.26443294  0.10664142] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 506, Avg Reward: 16.511, Episode Reward: 8354.7
    æ£€æµ‹è¿›åº¦: 3/10 (30.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3134)'), ('usv_1', '(228,4126)'), ('usv_2', '(247,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(4.31612239682404), 'usv_1': np.float64(1.4278386275653108)}
    Episode time: 50.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 1506, Avg Reward: 17.831, Episode Reward: 26853.1
    æ£€æµ‹è¿›åº¦: 3/36 (8.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3145)'), ('usv_1', '(273,4133)'), ('usv_2', '(288,5221)')]...
    Recent rewards sample: {'usv_0': np.float64(4.324456820333318), 'usv_1': np.float64(1.4218108781055911)}
    Episode time: 150.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 2506, Avg Reward: 17.069, Episode Reward: 42774.1
    æ£€æµ‹è¿›åº¦: 6/50 (12.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3165)'), ('usv_1', '(328,4141)'), ('usv_2', '(326,5299)')]...
    Recent rewards sample: {'usv_0': np.float64(4.324566459228289), 'usv_1': np.float64(1.4250471153267181)}
    Episode time: 250.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 47206.4
  Targets Detected: 7/59 (10.2%)
  Steps: 2777
  Episode Time: 277.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 17.00
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 729, Avg Reward: 6.361, Episode Reward: 4637.1
    æ£€æµ‹è¿›åº¦: 3/19 (15.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3142)'), ('usv_1', '(236,4136)'), ('usv_2', '(260,5152)')]...
    Recent rewards sample: {'usv_0': np.float64(2.316436602448453), 'usv_1': np.float64(3.418061650558518)}
    Episode time: 72.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 1729, Avg Reward: 14.492, Episode Reward: 25057.0
    æ£€æµ‹è¿›åº¦: 3/38 (7.9%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3161)'), ('usv_1', '(264,4160)'), ('usv_2', '(300,5222)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3214601132810198), 'usv_1': np.float64(3.420256531443524)}
    Episode time: 172.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 29109.9
  Targets Detected: 3/44 (6.8%)
  Steps: 1928
  Episode Time: 192.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.10
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.02552305 -0.05351134] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 801, Avg Reward: 14.233, Episode Reward: 11400.9
    æ£€æµ‹è¿›åº¦: 3/15 (20.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3130)'), ('usv_1', '(244,4120)'), ('usv_2', '(270,5173)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3220182498688469), 'usv_1': np.float64(2.425634931225466)}
    Episode time: 80.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 1801, Avg Reward: 17.553, Episode Reward: 31613.3
    æ£€æµ‹è¿›åº¦: 4/44 (9.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3131)'), ('usv_1', '(265,4097)'), ('usv_2', '(303,5253)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3271838566738285), 'usv_1': np.float64(1.421592037328613)}
    Episode time: 180.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 40034.6
  Targets Detected: 4/51 (7.8%)
  Steps: 2262
  Episode Time: 226.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 17.70
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 539, Avg Reward: -2.979, Episode Reward: -1605.5
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3133)'), ('usv_1', '(227,4131)'), ('usv_2', '(247,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6840715368971205), 'usv_1': np.float64(-1.5756945144680194)}
    Episode time: 53.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 1539, Avg Reward: 0.041, Episode Reward: 63.0
    æ£€æµ‹è¿›åº¦: 2/28 (7.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3159)'), ('usv_1', '(249,4141)'), ('usv_2', '(328,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3128896806240049), 'usv_1': np.float64(-0.5788173297380778)}
    Episode time: 153.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 2539, Avg Reward: 4.045, Episode Reward: 10269.8
    æ£€æµ‹è¿›åº¦: 2/46 (4.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3179)'), ('usv_1', '(272,4171)'), ('usv_2', '(423,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3058175008751198), 'usv_1': np.float64(0.43039462419993146)}
    Episode time: 253.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 19569.5
  Targets Detected: 6/59 (6.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 6.52
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.09918104  0.06303934] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 538, Avg Reward: -3.601, Episode Reward: -1937.3
    æ£€æµ‹è¿›åº¦: 0/16 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3128)'), ('usv_1', '(228,4134)'), ('usv_2', '(240,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6833306397169311), 'usv_1': np.float64(-1.582619875945074)}
    Episode time: 53.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 1538, Avg Reward: 0.008, Episode Reward: 12.0
    æ£€æµ‹è¿›åº¦: 1/28 (3.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3150)'), ('usv_1', '(259,4135)'), ('usv_2', '(311,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(2.316304342249353), 'usv_1': np.float64(-0.5766386378600539)}
    Episode time: 153.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 2538, Avg Reward: 3.674, Episode Reward: 9324.7
    æ£€æµ‹è¿›åº¦: 1/49 (2.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3169)'), ('usv_1', '(291,4135)'), ('usv_2', '(391,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(4.307824649913217), 'usv_1': np.float64(3.4222714064194406)}
    Episode time: 253.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: 19987.0
  Targets Detected: 5/58 (3.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 6.66

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 22505.3
Last 10 episodes average detections: 4.2
Best episode reward so far: 47206.4
Best detection count so far: 9
Learning trend: Declining (22505.3 vs 24334.8)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 537, Avg Reward: -3.930, Episode Reward: -2110.5
    æ£€æµ‹è¿›åº¦: 0/17 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3132)'), ('usv_1', '(222,4123)'), ('usv_2', '(267,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7313401736816841), 'usv_1': np.float64(-1.6330245564059913)}
    Episode time: 53.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 1537, Avg Reward: 3.866, Episode Reward: 5942.6
    æ£€æµ‹è¿›åº¦: 2/49 (4.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3157)'), ('usv_1', '(250,4104)'), ('usv_2', '(360,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2701301934666773), 'usv_1': np.float64(2.3691656947586828)}
    Episode time: 153.7s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.09554223 -0.05672332] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 2537, Avg Reward: 9.574, Episode Reward: 24290.5
    æ£€æµ‹è¿›åº¦: 7/77 (9.1%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3181)'), ('usv_1', '(272,4090)'), ('usv_2', '(444,5192)')]...
    Recent rewards sample: {'usv_0': np.float64(2.268868260270427), 'usv_1': np.float64(3.37101054397111)}
    Episode time: 253.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 32692.9
  Targets Detected: 9/85 (9.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.89
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 536, Avg Reward: 14.073, Episode Reward: 7542.9
    æ£€æµ‹è¿›åº¦: 5/36 (13.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3131)'), ('usv_1', '(222,4133)'), ('usv_2', '(255,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(4.265550563293187), 'usv_1': np.float64(3.3689858196769826)}
    Episode time: 53.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 1536, Avg Reward: 22.621, Episode Reward: 34745.4
    æ£€æµ‹è¿›åº¦: 14/68 (20.6%), Episode total: 14
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3158)'), ('usv_1', '(256,4140)'), ('usv_2', '(330,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(4.26488334870594), 'usv_1': np.float64(3.3695872451250004)}
    Episode time: 153.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 2536, Avg Reward: 21.767, Episode Reward: 55200.0
    æ£€æµ‹è¿›åº¦: 15/89 (16.9%), Episode total: 16
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3182)'), ('usv_1', '(293,4140)'), ('usv_2', '(405,5164)')]...
    Recent rewards sample: {'usv_0': np.float64(2.261383402086949), 'usv_1': np.float64(3.372397114632575)}
    Episode time: 253.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 64512.7
  Targets Detected: 18/100 (16.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.50
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 535, Avg Reward: 5.872, Episode Reward: 3141.7
    æ£€æµ‹è¿›åº¦: 1/24 (4.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3129)'), ('usv_1', '(229,4130)'), ('usv_2', '(265,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2668094598002404), 'usv_1': np.float64(-0.6245030211643371)}
    Episode time: 53.5s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.18881137  0.12992556] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 1535, Avg Reward: 14.346, Episode Reward: 22020.8
    æ£€æµ‹è¿›åº¦: 3/53 (5.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3126)'), ('usv_1', '(258,4122)'), ('usv_2', '(296,5196)')]...
    Recent rewards sample: {'usv_0': np.float64(2.273706661450629), 'usv_1': np.float64(1.3697021773264089)}
    Episode time: 153.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 2535, Avg Reward: 17.828, Episode Reward: 45193.7
    æ£€æµ‹è¿›åº¦: 5/80 (6.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(281,3134)'), ('usv_1', '(296,4116)'), ('usv_2', '(322,5289)')]...
    Recent rewards sample: {'usv_0': np.float64(4.280070542649965), 'usv_1': np.float64(3.3726331040294912)}
    Episode time: 253.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 55192.8
  Targets Detected: 8/92 (6.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.39
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 534, Avg Reward: -2.081, Episode Reward: -1111.0
    æ£€æµ‹è¿›åº¦: 1/19 (5.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3132)'), ('usv_1', '(237,4120)'), ('usv_2', '(274,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2719285724026683), 'usv_1': np.float64(-0.6267578490523318)}
    Episode time: 53.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 1534, Avg Reward: 8.972, Episode Reward: 13762.6
    æ£€æµ‹è¿›åº¦: 5/53 (9.4%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,3145)'), ('usv_1', '(258,4080)'), ('usv_2', '(313,5195)')]...
    Recent rewards sample: {'usv_0': np.float64(2.268348351798183), 'usv_1': np.float64(1.3700629860878535)}
    Episode time: 153.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 2534, Avg Reward: 13.077, Episode Reward: 33136.7
    æ£€æµ‹è¿›åº¦: 7/84 (8.3%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3155)'), ('usv_1', '(275,4050)'), ('usv_2', '(296,5256)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2723909421779402), 'usv_1': np.float64(1.3728359847709855)}
    Episode time: 253.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 41580.9
  Targets Detected: 7/95 (7.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.86
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.18456332  0.44347337] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 533, Avg Reward: 2.895, Episode Reward: 1543.1
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3133)'), ('usv_1', '(235,4125)'), ('usv_2', '(275,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2654453196368056), 'usv_1': np.float64(2.371549960500338)}
    Episode time: 53.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 1533, Avg Reward: 15.631, Episode Reward: 23962.5
    æ£€æµ‹è¿›åº¦: 10/54 (18.5%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3150)'), ('usv_1', '(264,4115)'), ('usv_2', '(349,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(2.259625010463873), 'usv_1': np.float64(3.370163017608549)}
    Episode time: 153.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 2533, Avg Reward: 18.431, Episode Reward: 46685.0
    æ£€æµ‹è¿›åº¦: 10/79 (12.7%), Episode total: 13
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(204,3128)'), ('usv_1', '(297,4121)'), ('usv_2', '(431,5112)')]...
    Recent rewards sample: {'usv_0': np.float64(4.260923124287677), 'usv_1': np.float64(3.3726942275267824)}
    Episode time: 253.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 58883.0
  Targets Detected: 16/89 (12.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.62
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 532, Avg Reward: -4.166, Episode Reward: -2216.2
    æ£€æµ‹è¿›åº¦: 0/19 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3129)'), ('usv_1', '(227,4127)'), ('usv_2', '(276,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7308605864365476), 'usv_1': np.float64(-1.6326512373798736)}
    Episode time: 53.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 1532, Avg Reward: -2.852, Episode Reward: -4369.6
    æ£€æµ‹è¿›åº¦: 1/40 (2.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3140)'), ('usv_1', '(255,4122)'), ('usv_2', '(308,5205)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2712730617549672), 'usv_1': np.float64(0.3694555956494121)}
    Episode time: 153.2s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.08107216 -0.04945903] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 2532, Avg Reward: 5.658, Episode Reward: 14326.1
    æ£€æµ‹è¿›åº¦: 4/62 (6.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3165)'), ('usv_1', '(289,4116)'), ('usv_2', '(300,5293)')]...
    Recent rewards sample: {'usv_0': np.float64(4.272518944297363), 'usv_1': np.float64(3.37308634918789)}
    Episode time: 253.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 22826.2
  Targets Detected: 4/73 (4.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.61
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 531, Avg Reward: 3.383, Episode Reward: 1796.4
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3135)'), ('usv_1', '(221,4130)'), ('usv_2', '(260,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26559302683314323), 'usv_1': np.float64(-0.6331423810065255)}
    Episode time: 53.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 1531, Avg Reward: 12.975, Episode Reward: 19865.2
    æ£€æµ‹è¿›åº¦: 5/46 (10.9%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(240,3149)'), ('usv_1', '(248,4118)'), ('usv_2', '(303,5185)')]...
    Recent rewards sample: {'usv_0': np.float64(4.267214181188571), 'usv_1': np.float64(3.3710790073231713)}
    Episode time: 153.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 2531, Avg Reward: 15.997, Episode Reward: 40489.2
    æ£€æµ‹è¿›åº¦: 10/72 (13.9%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(240,3181)'), ('usv_1', '(283,4104)'), ('usv_2', '(266,5279)')]...
    Recent rewards sample: {'usv_0': np.float64(-5.7286102999938375), 'usv_1': np.float64(3.3756036844866797)}
    Episode time: 253.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 42111.0
  Targets Detected: 12/83 (13.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.03
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 530, Avg Reward: -0.003, Episode Reward: -1.8
    æ£€æµ‹è¿›åº¦: 1/16 (6.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3138)'), ('usv_1', '(235,4133)'), ('usv_2', '(282,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(3.267246411976055), 'usv_1': np.float64(0.36891653887381937)}
    Episode time: 53.0s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.21966469  0.29545855] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 100000, Episode Steps: 1530, Avg Reward: 11.728, Episode Reward: 17943.9
    æ£€æµ‹è¿›åº¦: 5/39 (12.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3142)'), ('usv_1', '(253,4158)'), ('usv_2', '(357,5173)')]...
    Recent rewards sample: {'usv_0': np.float64(4.274173046920384), 'usv_1': np.float64(1.3774687213764083)}
    Episode time: 153.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 101000, Episode Steps: 2530, Avg Reward: 11.627, Episode Reward: 29416.8
    æ£€æµ‹è¿›åº¦: 4/68 (5.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(284,3153)'), ('usv_1', '(275,4186)'), ('usv_2', '(417,5234)')]...
    Recent rewards sample: {'usv_0': np.float64(-5.72185199338798), 'usv_1': np.float64(1.3714225082891418)}
    Episode time: 253.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 29109.1
  Targets Detected: 7/74 (4.1%)
  Steps: 2802
  Episode Time: 280.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.39
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 102000, Episode Steps: 728, Avg Reward: -3.904, Episode Reward: -2841.9
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3139)'), ('usv_1', '(232,4112)'), ('usv_2', '(274,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7356108499962952), 'usv_1': np.float64(-1.6302684255797175)}
    Episode time: 72.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 103000, Episode Steps: 1728, Avg Reward: 2.975, Episode Reward: 5141.5
    æ£€æµ‹è¿›åº¦: 4/31 (12.9%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3163)'), ('usv_1', '(210,4083)'), ('usv_2', '(336,5205)')]...
    Recent rewards sample: {'usv_0': np.float64(2.263138750941386), 'usv_1': np.float64(3.36640833813804)}
    Episode time: 172.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 104000, Episode Steps: 2728, Avg Reward: 9.855, Episode Reward: 26885.2
    æ£€æµ‹è¿›åº¦: 6/64 (9.4%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3175)'), ('usv_1', '(208,4064)'), ('usv_2', '(335,5281)')]...
    Recent rewards sample: {'usv_0': np.float64(-5.729970174773651), 'usv_1': np.float64(3.3689021788774225)}
    Episode time: 272.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 27633.2
  Targets Detected: 9/73 (9.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.21
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.5256159   0.36137172] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 105000, Episode Steps: 727, Avg Reward: 1.770, Episode Reward: 1286.5
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3133)'), ('usv_1', '(235,4138)'), ('usv_2', '(268,5157)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2666187696319247), 'usv_1': np.float64(0.3683379664971784)}
    Episode time: 72.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 106000, Episode Steps: 1727, Avg Reward: 13.023, Episode Reward: 22490.3
    æ£€æµ‹è¿›åº¦: 7/50 (14.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3155)'), ('usv_1', '(264,4147)'), ('usv_2', '(211,5204)')]...
    Recent rewards sample: {'usv_0': np.float64(4.269565178195224), 'usv_1': np.float64(1.3702380174904647)}
    Episode time: 172.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 107000, Episode Steps: 2727, Avg Reward: 9.879, Episode Reward: 26941.0
    æ£€æµ‹è¿›åº¦: 7/76 (9.2%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3172)'), ('usv_1', '(296,4149)'), ('usv_2', '(204,5178)')]...
    Recent rewards sample: {'usv_0': np.float64(4.256019924346448), 'usv_1': np.float64(1.3726356872656948)}
    Episode time: 272.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 34667.8
  Targets Detected: 12/88 (9.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.55

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 40921.0
Last 10 episodes average detections: 10.2
Best episode reward so far: 64512.7
Best detection count so far: 18
Learning trend: Improving (40921.0 vs 22505.3)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 108000, Episode Steps: 726, Avg Reward: 9.048, Episode Reward: 6568.6
    æ£€æµ‹è¿›åº¦: 3/19 (15.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3143)'), ('usv_1', '(239,4138)'), ('usv_2', '(261,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2636627260835844), 'usv_1': np.float64(3.3682431239989556)}
    Episode time: 72.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 109000, Episode Steps: 1726, Avg Reward: 16.010, Episode Reward: 27632.5
    æ£€æµ‹è¿›åº¦: 7/42 (16.7%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3161)'), ('usv_1', '(265,4165)'), ('usv_2', '(334,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(4.260297777155269), 'usv_1': np.float64(3.3703877378346174)}
    Episode time: 172.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.01382841 -0.1908376 ] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 110000, Episode Steps: 2726, Avg Reward: 18.122, Episode Reward: 49400.0
    æ£€æµ‹è¿›åº¦: 8/64 (12.5%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3151)'), ('usv_1', '(296,4189)'), ('usv_2', '(384,5230)')]...
    Recent rewards sample: {'usv_0': np.float64(4.261648024387683), 'usv_1': np.float64(3.373015921737079)}
    Episode time: 272.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 54905.5
  Targets Detected: 9/65 (12.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.30
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 111000, Episode Steps: 725, Avg Reward: 1.736, Episode Reward: 1258.5
    æ£€æµ‹è¿›åº¦: 1/25 (4.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3140)'), ('usv_1', '(239,4124)'), ('usv_2', '(274,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2656104944957365), 'usv_1': np.float64(-0.6317746518339479)}
    Episode time: 72.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 112000, Episode Steps: 1725, Avg Reward: 7.232, Episode Reward: 12475.7
    æ£€æµ‹è¿›åº¦: 3/49 (6.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3169)'), ('usv_1', '(269,4123)'), ('usv_2', '(351,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2644168443594763), 'usv_1': np.float64(3.3719408699859885)}
    Episode time: 172.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 113000, Episode Steps: 2725, Avg Reward: 9.951, Episode Reward: 27115.9
    æ£€æµ‹è¿›åº¦: 5/82 (6.1%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3172)'), ('usv_1', '(305,4130)'), ('usv_2', '(390,5214)')]...
    Recent rewards sample: {'usv_0': np.float64(2.259199888721168), 'usv_1': np.float64(1.3765452740906277)}
    Episode time: 272.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 31544.8
  Targets Detected: 6/90 (4.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.51
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 114000, Episode Steps: 724, Avg Reward: -3.931, Episode Reward: -2845.8
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3128)'), ('usv_1', '(228,4128)'), ('usv_2', '(266,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7293746776623721), 'usv_1': np.float64(-1.6325646937504645)}
    Episode time: 72.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.13959066  0.06629254] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 115000, Episode Steps: 1724, Avg Reward: 7.608, Episode Reward: 13116.9
    æ£€æµ‹è¿›åº¦: 4/41 (9.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(258,3129)'), ('usv_1', '(283,4116)'), ('usv_2', '(245,5212)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2747090652141644), 'usv_1': np.float64(3.371643443152342)}
    Episode time: 172.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 116000, Episode Steps: 2724, Avg Reward: 8.185, Episode Reward: 22295.8
    æ£€æµ‹è¿›åº¦: 4/70 (5.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3138)'), ('usv_1', '(334,4117)'), ('usv_2', '(202,5251)')]...
    Recent rewards sample: {'usv_0': np.float64(-7.7173753688495275), 'usv_1': np.float64(3.3770918506529943)}
    Episode time: 272.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 22168.4
  Targets Detected: 5/71 (5.6%)
  Steps: 2786
  Episode Time: 278.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.96
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 117000, Episode Steps: 938, Avg Reward: 10.887, Episode Reward: 10211.6
    æ£€æµ‹è¿›åº¦: 4/46 (8.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3156)'), ('usv_1', '(242,4127)'), ('usv_2', '(277,5160)')]...
    Recent rewards sample: {'usv_0': np.float64(4.261013731737044), 'usv_1': np.float64(1.3716882121273177)}
    Episode time: 93.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 118000, Episode Steps: 1938, Avg Reward: 13.937, Episode Reward: 27009.9
    æ£€æµ‹è¿›åº¦: 4/71 (5.6%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3177)'), ('usv_1', '(282,4095)'), ('usv_2', '(314,5255)')]...
    Recent rewards sample: {'usv_0': np.float64(-5.745033440890818), 'usv_1': np.float64(3.3810034108249605)}
    Episode time: 193.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 30452.1
  Targets Detected: 6/83 (6.0%)
  Steps: 2249
  Episode Time: 224.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.54
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 119000, Episode Steps: 689, Avg Reward: 5.022, Episode Reward: 3460.5
    æ£€æµ‹è¿›åº¦: 2/32 (6.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3125)'), ('usv_1', '(228,4115)'), ('usv_2', '(272,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2747761977175984), 'usv_1': np.float64(1.3678209133389858)}
    Episode time: 68.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.06159508 -0.2068431 ] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 120000, Episode Steps: 1689, Avg Reward: 14.309, Episode Reward: 24167.5
    æ£€æµ‹è¿›åº¦: 6/58 (10.3%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3113)'), ('usv_1', '(252,4086)'), ('usv_2', '(352,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(4.278869453893432), 'usv_1': np.float64(3.3714155180754837)}
    Episode time: 168.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 121000, Episode Steps: 2689, Avg Reward: 17.964, Episode Reward: 48306.5
    æ£€æµ‹è¿›åº¦: 10/87 (11.5%), Episode total: 12
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3113)'), ('usv_1', '(296,4084)'), ('usv_2', '(423,5200)')]...
    Recent rewards sample: {'usv_0': np.float64(4.280425066775066), 'usv_1': np.float64(3.3734195933100466)}
    Episode time: 268.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 55194.6
  Targets Detected: 12/98 (10.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.39
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 122000, Episode Steps: 688, Avg Reward: 7.453, Episode Reward: 5127.5
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3130)'), ('usv_1', '(237,4133)'), ('usv_2', '(270,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(1.267611139284452), 'usv_1': np.float64(2.374608923061442)}
    Episode time: 68.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 123000, Episode Steps: 1688, Avg Reward: 16.782, Episode Reward: 28328.7
    æ£€æµ‹è¿›åº¦: 5/51 (9.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3136)'), ('usv_1', '(279,4135)'), ('usv_2', '(368,5154)')]...
    Recent rewards sample: {'usv_0': np.float64(4.273753324942273), 'usv_1': np.float64(3.377259547959704)}
    Episode time: 168.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 124000, Episode Steps: 2688, Avg Reward: 15.524, Episode Reward: 41728.5
    æ£€æµ‹è¿›åº¦: 9/88 (10.2%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3169)'), ('usv_1', '(285,4108)'), ('usv_2', '(444,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(-5.724102041208911), 'usv_1': np.float64(3.3758179044005994)}
    Episode time: 268.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 41719.0
  Targets Detected: 9/94 (9.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.90
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.01372215 -0.07805171] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 125000, Episode Steps: 687, Avg Reward: 15.162, Episode Reward: 10416.4
    æ£€æµ‹è¿›åº¦: 4/23 (17.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3137)'), ('usv_1', '(237,4129)'), ('usv_2', '(260,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(4.263743011716959), 'usv_1': np.float64(3.3701254798434235)}
    Episode time: 68.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 126000, Episode Steps: 1687, Avg Reward: 19.456, Episode Reward: 32822.6
    æ£€æµ‹è¿›åº¦: 8/54 (14.8%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3161)'), ('usv_1', '(267,4108)'), ('usv_2', '(360,5094)')]...
    Recent rewards sample: {'usv_0': np.float64(4.257090539099223), 'usv_1': np.float64(1.372782432396492)}
    Episode time: 168.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 127000, Episode Steps: 2687, Avg Reward: 20.011, Episode Reward: 53768.7
    æ£€æµ‹è¿›åº¦: 9/71 (12.7%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(201,3156)'), ('usv_1', '(289,4085)'), ('usv_2', '(454,5079)')]...
    Recent rewards sample: {'usv_0': np.float64(4.25634981987332), 'usv_1': np.float64(3.3723048760568712)}
    Episode time: 268.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 61102.5
  Targets Detected: 11/82 (12.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.36
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 128000, Episode Steps: 686, Avg Reward: -3.471, Episode Reward: -2380.8
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3138)'), ('usv_1', '(235,4135)'), ('usv_2', '(255,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7338620261213127), 'usv_1': np.float64(-1.628079024775732)}
    Episode time: 68.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 129000, Episode Steps: 1686, Avg Reward: 2.196, Episode Reward: 3701.7
    æ£€æµ‹è¿›åº¦: 2/42 (4.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3168)'), ('usv_1', '(263,4150)'), ('usv_2', '(353,5176)')]...
    Recent rewards sample: {'usv_0': np.float64(2.263100107356378), 'usv_1': np.float64(1.371150599581847)}
    Episode time: 168.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.14270151 -0.04517397] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 130000, Episode Steps: 2686, Avg Reward: 10.516, Episode Reward: 28244.9
    æ£€æµ‹è¿›åº¦: 6/76 (7.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3183)'), ('usv_1', '(292,4162)'), ('usv_2', '(402,5233)')]...
    Recent rewards sample: {'usv_0': np.float64(4.258121004495066), 'usv_1': np.float64(3.372404668572834)}
    Episode time: 268.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 36262.9
  Targets Detected: 9/86 (8.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.08
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 131000, Episode Steps: 685, Avg Reward: 8.503, Episode Reward: 5824.7
    æ£€æµ‹è¿›åº¦: 3/18 (16.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3134)'), ('usv_1', '(238,4132)'), ('usv_2', '(262,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(3.267496634489392), 'usv_1': np.float64(0.37516839898227006)}
    Episode time: 68.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 132000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 132000, Episode Steps: 1685, Avg Reward: 11.213, Episode Reward: 18894.3
    æ£€æµ‹è¿›åº¦: 3/48 (6.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3143)'), ('usv_1', '(270,4128)'), ('usv_2', '(329,5188)')]...
    Recent rewards sample: {'usv_0': np.float64(4.271066305257515), 'usv_1': np.float64(3.374044373180366)}
    Episode time: 168.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 133000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 133000, Episode Steps: 2685, Avg Reward: 9.801, Episode Reward: 26315.2
    æ£€æµ‹è¿›åº¦: 5/71 (7.0%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3161)'), ('usv_1', '(302,4140)'), ('usv_2', '(323,5261)')]...
    Recent rewards sample: {'usv_0': np.float64(-5.730337100879244), 'usv_1': np.float64(3.373956668541349)}
    Episode time: 268.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 27038.6
  Targets Detected: 10/77 (7.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.01
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 134000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 134000, Episode Steps: 684, Avg Reward: 7.820, Episode Reward: 5349.2
    æ£€æµ‹è¿›åº¦: 3/22 (13.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3129)'), ('usv_1', '(235,4131)'), ('usv_2', '(261,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(3.266416255741272), 'usv_1': np.float64(0.3743012086412618)}
    Episode time: 68.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.26790366 -0.09587349] (agent usv_0)
    MADDPG UPDATING at time_step 135000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 135000, Episode Steps: 1684, Avg Reward: 10.707, Episode Reward: 18030.0
    æ£€æµ‹è¿›åº¦: 5/37 (13.5%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3126)'), ('usv_1', '(270,4111)'), ('usv_2', '(323,5179)')]...
    Recent rewards sample: {'usv_0': np.float64(4.27357375047654), 'usv_1': np.float64(3.37170323529177)}
    Episode time: 168.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 136000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0128, Avg Critic Loss: 10.3278
    Step 136000, Episode Steps: 2684, Avg Reward: 14.444, Episode Reward: 38767.9
    æ£€æµ‹è¿›åº¦: 7/67 (10.4%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3138)'), ('usv_1', '(309,4120)'), ('usv_2', '(362,5262)')]...
    Recent rewards sample: {'usv_0': np.float64(4.27388273145523), 'usv_1': np.float64(3.377785852513802)}
    Episode time: 268.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 46005.9
  Targets Detected: 9/73 (11.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.33

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 40639.4
Last 10 episodes average detections: 8.6
Best episode reward so far: 64512.7
Best detection count so far: 18
Learning trend: Declining (40639.4 vs 40921.0)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 64512.7
Final 10 episodes average: 40639.4
Best detection performance: 18 targets
Average detections (final 10): 8.6
============================================================
{"final_avg_reward": 40639.42178762914, "final_detection_rate": 8.6, "best_episode_reward": 64512.677047676916, "best_detection_count": 18, "total_episodes": 50}
Simulation finished.
