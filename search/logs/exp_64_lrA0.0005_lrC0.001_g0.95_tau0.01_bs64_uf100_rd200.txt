D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: 0.691, Episode Reward: 690.6
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3146)'), ('usv_1', '(312,4182)'), ('usv_2', '(292,5095)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3657657181176973), 'usv_1': np.float64(-0.5184770430579141)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 5.530, Episode Reward: 11060.2
    æ£€æµ‹è¿›åº¦: 3/26 (11.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3139)'), ('usv_1', '(326,4279)'), ('usv_2', '(310,5015)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3729606146650704), 'usv_1': np.float64(3.491501997811895)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 3000, Avg Reward: 10.609, Episode Reward: 31826.3
    æ£€æµ‹è¿›åº¦: 3/40 (7.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3120)'), ('usv_1', '(248,4298)'), ('usv_2', '(283,4930)')]...
    Recent rewards sample: {'usv_0': np.float64(4.373079071913353), 'usv_1': np.float64(3.47442140634017)}
    Episode time: 300.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 31847.0
  Targets Detected: 4/40 (7.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.61
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 999, Avg Reward: -1.317, Episode Reward: -1315.7
    æ£€æµ‹è¿›åº¦: 1/18 (5.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3114)'), ('usv_1', '(266,4202)'), ('usv_2', '(294,5081)')]...
    Recent rewards sample: {'usv_0': np.float64(0.37266617201016516), 'usv_1': np.float64(-0.5283282457816312)}
    Episode time: 99.9s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.03130897 -0.01514027] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 1999, Avg Reward: 2.901, Episode Reward: 5800.1
    æ£€æµ‹è¿›åº¦: 2/35 (5.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3082)'), ('usv_1', '(253,4316)'), ('usv_2', '(347,4988)')]...
    Recent rewards sample: {'usv_0': np.float64(3.970897972368996), 'usv_1': np.float64(1.4764275429302285)}
    Episode time: 199.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 2999, Avg Reward: 4.972, Episode Reward: 14910.2
    æ£€æµ‹è¿›åº¦: 2/45 (4.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3064)'), ('usv_1', '(200,4318)'), ('usv_2', '(353,4909)')]...
    Recent rewards sample: {'usv_0': np.float64(3.967264608300919), 'usv_1': np.float64(-0.527390667297662)}
    Episode time: 299.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 14926.7
  Targets Detected: 2/45 (4.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 4.97
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 998, Avg Reward: 2.705, Episode Reward: 2699.6
    æ£€æµ‹è¿›åº¦: 2/12 (16.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3106)'), ('usv_1', '(292,4180)'), ('usv_2', '(302,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(0.36979183172693764), 'usv_1': np.float64(-0.5237613839302993)}
    Episode time: 99.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 1998, Avg Reward: 9.010, Episode Reward: 18001.7
    æ£€æµ‹è¿›åº¦: 3/18 (16.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3087)'), ('usv_1', '(313,4279)'), ('usv_2', '(376,5065)')]...
    Recent rewards sample: {'usv_0': np.float64(2.371541040401135), 'usv_1': np.float64(1.484526100973294)}
    Episode time: 199.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 28307.1
  Targets Detected: 5/26 (11.5%)
  Steps: 2597
  Episode Time: 259.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.90
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 401, Avg Reward: 7.422, Episode Reward: 2976.2
    æ£€æµ‹è¿›åº¦: 1/12 (8.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3134)'), ('usv_1', '(256,4139)'), ('usv_2', '(238,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3646247567193481), 'usv_1': np.float64(2.476245375919681)}
    Episode time: 40.1s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.29127064  0.01170626] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 1401, Avg Reward: 14.511, Episode Reward: 20330.1
    æ£€æµ‹è¿›åº¦: 4/29 (13.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3121)'), ('usv_1', '(320,4210)'), ('usv_2', '(247,5046)')]...
    Recent rewards sample: {'usv_0': np.float64(4.369493466301606), 'usv_1': np.float64(3.4840879515789442)}
    Episode time: 140.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 2401, Avg Reward: 16.577, Episode Reward: 39801.9
    æ£€æµ‹è¿›åº¦: 6/43 (14.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3107)'), ('usv_1', '(348,4316)'), ('usv_2', '(206,5005)')]...
    Recent rewards sample: {'usv_0': np.float64(4.365730109758051), 'usv_1': np.float64(3.4930397335426777)}
    Episode time: 240.1s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 51003.5
  Targets Detected: 6/52 (11.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.00
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 400, Avg Reward: -1.782, Episode Reward: -712.7
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3130)'), ('usv_1', '(267,4143)'), ('usv_2', '(250,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(0.36505998181362886), 'usv_1': np.float64(1.4725341368214986)}
    Episode time: 40.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 1400, Avg Reward: 12.308, Episode Reward: 17230.7
    æ£€æµ‹è¿›åº¦: 5/21 (23.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3129)'), ('usv_1', '(303,4251)'), ('usv_2', '(330,5082)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3734326353136384), 'usv_1': np.float64(3.4792379556290083)}
    Episode time: 140.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 2400, Avg Reward: 15.755, Episode Reward: 37811.0
    æ£€æµ‹è¿›åº¦: 6/29 (20.7%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3119)'), ('usv_1', '(216,4310)'), ('usv_2', '(367,5013)')]...
    Recent rewards sample: {'usv_0': np.float64(4.374370861612051), 'usv_1': np.float64(3.4724794913208195)}
    Episode time: 240.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 52647.6
  Targets Detected: 8/40 (17.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.54
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.31403766  0.02200479] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 399, Avg Reward: -3.325, Episode Reward: -1326.7
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3128)'), ('usv_1', '(257,4139)'), ('usv_2', '(239,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6337687961514998), 'usv_1': np.float64(-1.5215570162340208)}
    Episode time: 39.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 1399, Avg Reward: -3.065, Episode Reward: -4288.5
    æ£€æµ‹è¿›åº¦: 0/18 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3116)'), ('usv_1', '(341,4213)'), ('usv_2', '(325,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3744881623115695), 'usv_1': np.float64(-0.5213506265832982)}
    Episode time: 139.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 2399, Avg Reward: 0.101, Episode Reward: 242.1
    æ£€æµ‹è¿›åº¦: 0/34 (0.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3101)'), ('usv_1', '(322,4293)'), ('usv_2', '(412,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(4.382787092892529), 'usv_1': np.float64(1.4789628762227673)}
    Episode time: 239.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 3318.0
  Targets Detected: 2/42 (2.4%)
  Steps: 2663
  Episode Time: 266.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 1.25
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 736, Avg Reward: -1.539, Episode Reward: -1132.4
    æ£€æµ‹è¿›åº¦: 1/7 (14.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3133)'), ('usv_1', '(284,4169)'), ('usv_2', '(273,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3662057051285956), 'usv_1': np.float64(-0.5202925761008246)}
    Episode time: 73.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 1736, Avg Reward: 3.196, Episode Reward: 5547.7
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3117)'), ('usv_1', '(277,4268)'), ('usv_2', '(367,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3717361105233445), 'usv_1': np.float64(0.47665481695996026)}
    Episode time: 173.6s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.26368932 -0.11014717] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 2736, Avg Reward: 8.680, Episode Reward: 23747.7
    æ£€æµ‹è¿›åº¦: 4/39 (10.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3108)'), ('usv_1', '(200,4294)'), ('usv_2', '(418,5093)')]...
    Recent rewards sample: {'usv_0': np.float64(4.365734342765247), 'usv_1': np.float64(1.475177699578511)}
    Episode time: 273.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 29218.1
  Targets Detected: 6/45 (11.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.74
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 735, Avg Reward: -0.115, Episode Reward: -84.2
    æ£€æµ‹è¿›åº¦: 1/7 (14.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3130)'), ('usv_1', '(274,4159)'), ('usv_2', '(286,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3689286051776015), 'usv_1': np.float64(1.4751215361477135)}
    Episode time: 73.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 1735, Avg Reward: 2.950, Episode Reward: 5118.3
    æ£€æµ‹è¿›åº¦: 1/26 (3.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3108)'), ('usv_1', '(286,4246)'), ('usv_2', '(366,5160)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3721647524216998), 'usv_1': np.float64(2.4775323506246805)}
    Episode time: 173.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 2735, Avg Reward: 4.866, Episode Reward: 13309.8
    æ£€æµ‹è¿›åº¦: 4/47 (8.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3104)'), ('usv_1', '(204,4261)'), ('usv_2', '(458,5181)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3673574398414945), 'usv_1': np.float64(3.480601311657221)}
    Episode time: 273.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 15624.8
  Targets Detected: 4/50 (8.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.21
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 734, Avg Reward: -1.350, Episode Reward: -991.3
    æ£€æµ‹è¿›åº¦: 1/9 (11.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3136)'), ('usv_1', '(275,4147)'), ('usv_2', '(283,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(0.37139259501848876), 'usv_1': np.float64(-0.5268303970665605)}
    Episode time: 73.4s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.04277322  0.06377432] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 1734, Avg Reward: 8.101, Episode Reward: 14046.7
    æ£€æµ‹è¿›åº¦: 4/24 (16.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3149)'), ('usv_1', '(316,4227)'), ('usv_2', '(362,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(2.37254197166934), 'usv_1': np.float64(1.4862735528872562)}
    Episode time: 173.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 2734, Avg Reward: 11.642, Episode Reward: 31829.4
    æ£€æµ‹è¿›åº¦: 5/37 (13.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(281,3152)'), ('usv_1', '(248,4276)'), ('usv_2', '(449,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6175909266558229), 'usv_1': np.float64(1.4720154945361181)}
    Episode time: 273.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 34635.3
  Targets Detected: 9/43 (14.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.54
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 733, Avg Reward: 1.362, Episode Reward: 998.4
    æ£€æµ‹è¿›åº¦: 2/7 (28.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3130)'), ('usv_1', '(274,4154)'), ('usv_2', '(286,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(3.368694953018333), 'usv_1': np.float64(0.47290511774360255)}
    Episode time: 73.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 1733, Avg Reward: 7.036, Episode Reward: 12194.2
    æ£€æµ‹è¿›åº¦: 2/19 (10.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3111)'), ('usv_1', '(274,4230)'), ('usv_2', '(328,5051)')]...
    Recent rewards sample: {'usv_0': np.float64(4.372306275442582), 'usv_1': np.float64(1.473607148946996)}
    Episode time: 173.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 2733, Avg Reward: 10.643, Episode Reward: 29086.2
    æ£€æµ‹è¿›åº¦: 1/27 (3.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3099)'), ('usv_1', '(208,4277)'), ('usv_2', '(357,4968)')]...
    Recent rewards sample: {'usv_0': np.float64(4.366882057137762), 'usv_1': np.float64(1.475961782215626)}
    Episode time: 273.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 32671.8
  Targets Detected: 3/31 (3.2%)
  Steps: 2948
  Episode Time: 294.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 11.08

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 29420.0
Last 10 episodes average detections: 4.9
Best episode reward so far: 52647.6
Best detection count so far: 9
Buffer size: 29215
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.15172064 -0.03225665] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 785, Avg Reward: -3.594, Episode Reward: -2821.2
    æ£€æµ‹è¿›åº¦: 0/15 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3115)'), ('usv_1', '(270,4154)'), ('usv_2', '(273,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6763504839915602), 'usv_1': np.float64(-1.5790975712340127)}
    Episode time: 78.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 1785, Avg Reward: 3.324, Episode Reward: 5932.6
    æ£€æµ‹è¿›åº¦: 2/45 (4.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3086)'), ('usv_1', '(250,4251)'), ('usv_2', '(366,5097)')]...
    Recent rewards sample: {'usv_0': np.float64(6.917496824627054), 'usv_1': np.float64(0.43118064631427466)}
    Episode time: 178.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 2785, Avg Reward: 11.639, Episode Reward: 32413.7
    æ£€æµ‹è¿›åº¦: 6/76 (7.9%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3089)'), ('usv_1', '(208,4190)'), ('usv_2', '(428,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(4.324223728397639), 'usv_1': np.float64(3.425382678860453)}
    Episode time: 278.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 37763.0
  Targets Detected: 7/82 (8.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.58
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 784, Avg Reward: 5.550, Episode Reward: 4351.6
    æ£€æµ‹è¿›åº¦: 3/24 (12.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3121)'), ('usv_1', '(279,4169)'), ('usv_2', '(273,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3176807353270115), 'usv_1': np.float64(3.42149189459335)}
    Episode time: 78.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 1784, Avg Reward: 13.373, Episode Reward: 23858.2
    æ£€æµ‹è¿›åº¦: 5/38 (13.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3104)'), ('usv_1', '(253,4266)'), ('usv_2', '(348,5072)')]...
    Recent rewards sample: {'usv_0': np.float64(4.321728901948392), 'usv_1': np.float64(1.4279299117893163)}
    Episode time: 178.4s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.09247504 -0.06161959] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 2784, Avg Reward: 15.640, Episode Reward: 43541.2
    æ£€æµ‹è¿›åº¦: 7/71 (9.9%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3095)'), ('usv_1', '(204,4306)'), ('usv_2', '(401,5002)')]...
    Recent rewards sample: {'usv_0': np.float64(4.318824874232788), 'usv_1': np.float64(3.426387129542187)}
    Episode time: 278.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 49391.5
  Targets Detected: 10/74 (12.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.46
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 783, Avg Reward: 3.072, Episode Reward: 2405.1
    æ£€æµ‹è¿›åº¦: 2/9 (22.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3116)'), ('usv_1', '(311,4161)'), ('usv_2', '(289,5100)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31798053314270325), 'usv_1': np.float64(-0.5647701008249706)}
    Episode time: 78.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 1783, Avg Reward: 10.094, Episode Reward: 17996.8
    æ£€æµ‹è¿›åº¦: 4/36 (11.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3096)'), ('usv_1', '(374,4237)'), ('usv_2', '(393,5058)')]...
    Recent rewards sample: {'usv_0': np.float64(4.320268584680787), 'usv_1': np.float64(1.4356957411627436)}
    Episode time: 178.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 2783, Avg Reward: 13.269, Episode Reward: 36928.2
    æ£€æµ‹è¿›åº¦: 4/55 (7.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3114)'), ('usv_1', '(369,4323)'), ('usv_2', '(494,5043)')]...
    Recent rewards sample: {'usv_0': np.float64(4.316827234492609), 'usv_1': np.float64(1.4350812787504488)}
    Episode time: 278.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 40510.0
  Targets Detected: 5/58 (6.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.50
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 782, Avg Reward: 1.317, Episode Reward: 1029.9
    æ£€æµ‹è¿›åº¦: 3/26 (11.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3124)'), ('usv_1', '(302,4150)'), ('usv_2', '(265,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3202154519554936), 'usv_1': np.float64(0.42525391992377415)}
    Episode time: 78.2s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.00141137 -0.2210831 ] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 1782, Avg Reward: 10.142, Episode Reward: 18072.6
    æ£€æµ‹è¿›åº¦: 6/51 (11.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3104)'), ('usv_1', '(318,4231)'), ('usv_2', '(347,5095)')]...
    Recent rewards sample: {'usv_0': np.float64(4.327201367221676), 'usv_1': np.float64(3.4266707341430847)}
    Episode time: 178.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 2782, Avg Reward: 14.174, Episode Reward: 39432.3
    æ£€æµ‹è¿›åº¦: 7/72 (9.7%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3083)'), ('usv_1', '(240,4295)'), ('usv_2', '(411,5039)')]...
    Recent rewards sample: {'usv_0': np.float64(7.9200860672029725), 'usv_1': np.float64(3.425879234288823)}
    Episode time: 278.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 44668.9
  Targets Detected: 7/77 (9.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.88
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 781, Avg Reward: 4.526, Episode Reward: 3534.5
    æ£€æµ‹è¿›åº¦: 1/14 (7.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3121)'), ('usv_1', '(268,4165)'), ('usv_2', '(268,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3207970027053006), 'usv_1': np.float64(-0.5711601278883045)}
    Episode time: 78.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 1781, Avg Reward: 7.103, Episode Reward: 12649.9
    æ£€æµ‹è¿›åº¦: 3/30 (10.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3108)'), ('usv_1', '(243,4273)'), ('usv_2', '(318,5018)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3246363830486465), 'usv_1': np.float64(0.42873415520917235)}
    Episode time: 178.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 19215.3
  Targets Detected: 3/43 (7.0%)
  Steps: 2422
  Episode Time: 242.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 7.93
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 359, Avg Reward: 7.055, Episode Reward: 2532.8
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3129)'), ('usv_1', '(248,4139)'), ('usv_2', '(251,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3149416909786416), 'usv_1': np.float64(0.4189417700579938)}
    Episode time: 35.9s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.05117164  0.18502917] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 1359, Avg Reward: 14.064, Episode Reward: 19113.5
    æ£€æµ‹è¿›åº¦: 4/40 (10.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3123)'), ('usv_1', '(270,4230)'), ('usv_2', '(329,5094)')]...
    Recent rewards sample: {'usv_0': np.float64(2.319812608575836), 'usv_1': np.float64(3.428791573579746)}
    Episode time: 135.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 2359, Avg Reward: 16.862, Episode Reward: 39778.3
    æ£€æµ‹è¿›åº¦: 7/62 (11.3%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(262,3102)'), ('usv_1', '(202,4250)'), ('usv_2', '(410,5030)')]...
    Recent rewards sample: {'usv_0': np.float64(4.332613383522135), 'usv_1': np.float64(3.420981511066355)}
    Episode time: 235.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 52401.8
  Targets Detected: 8/68 (5.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.46
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 358, Avg Reward: -3.588, Episode Reward: -1284.5
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3131)'), ('usv_1', '(241,4138)'), ('usv_2', '(237,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6843912200521792), 'usv_1': np.float64(-1.5765513466014063)}
    Episode time: 35.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 1358, Avg Reward: -3.584, Episode Reward: -4866.5
    æ£€æµ‹è¿›åº¦: 0/24 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3111)'), ('usv_1', '(294,4211)'), ('usv_2', '(324,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6736978926143922), 'usv_1': np.float64(-1.5760816251657117)}
    Episode time: 135.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 2358, Avg Reward: 0.579, Episode Reward: 1366.2
    æ£€æµ‹è¿›åº¦: 2/48 (4.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3101)'), ('usv_1', '(264,4285)'), ('usv_2', '(415,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3185198333824395), 'usv_1': np.float64(0.4283933546157568)}
    Episode time: 235.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 7224.2
  Targets Detected: 3/56 (3.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 2.41
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.24327679  0.02548365] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 357, Avg Reward: -3.585, Episode Reward: -1279.8
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3129)'), ('usv_1', '(246,4131)'), ('usv_2', '(235,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6852421337538386), 'usv_1': np.float64(-1.5788639093736632)}
    Episode time: 35.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 1357, Avg Reward: -0.906, Episode Reward: -1229.7
    æ£€æµ‹è¿›åº¦: 2/29 (6.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3112)'), ('usv_1', '(257,4229)'), ('usv_2', '(322,5073)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3206579234743137), 'usv_1': np.float64(0.42298247125629596)}
    Episode time: 135.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 2357, Avg Reward: 6.877, Episode Reward: 16208.5
    æ£€æµ‹è¿›åº¦: 2/49 (4.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3090)'), ('usv_1', '(204,4251)'), ('usv_2', '(322,4993)')]...
    Recent rewards sample: {'usv_0': np.float64(4.324292749118829), 'usv_1': np.float64(1.423250308710534)}
    Episode time: 235.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 26867.1
  Targets Detected: 3/56 (3.6%)
  Steps: 2868
  Episode Time: 286.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 9.37
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 489, Avg Reward: 2.882, Episode Reward: 1409.5
    æ£€æµ‹è¿›åº¦: 1/16 (6.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3127)'), ('usv_1', '(252,4149)'), ('usv_2', '(247,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31546237326258275), 'usv_1': np.float64(-0.5717538605631068)}
    Episode time: 48.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 1489, Avg Reward: 13.037, Episode Reward: 19412.3
    æ£€æµ‹è¿›åº¦: 4/43 (9.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3138)'), ('usv_1', '(304,4242)'), ('usv_2', '(343,5186)')]...
    Recent rewards sample: {'usv_0': np.float64(4.318523188755164), 'usv_1': np.float64(3.43358876094596)}
    Episode time: 148.9s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.02979205 -0.05769986] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 2489, Avg Reward: 17.687, Episode Reward: 44023.2
    æ£€æµ‹è¿›åº¦: 9/71 (12.7%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3129)'), ('usv_1', '(279,4333)'), ('usv_2', '(391,5264)')]...
    Recent rewards sample: {'usv_0': np.float64(4.327054923263718), 'usv_1': np.float64(3.4263413953464035)}
    Episode time: 248.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 53545.7
  Targets Detected: 12/85 (11.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.84
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 488, Avg Reward: -3.575, Episode Reward: -1744.5
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3127)'), ('usv_1', '(252,4142)'), ('usv_2', '(266,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6828015819297695), 'usv_1': np.float64(-1.5757447410716345)}
    Episode time: 48.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 1488, Avg Reward: 4.066, Episode Reward: 6049.5
    æ£€æµ‹è¿›åº¦: 3/25 (12.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3107)'), ('usv_1', '(278,4246)'), ('usv_2', '(345,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(2.322292315804011), 'usv_1': np.float64(1.4229866936441389)}
    Episode time: 148.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 2488, Avg Reward: 9.053, Episode Reward: 22524.1
    æ£€æµ‹è¿›åº¦: 6/60 (10.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3094)'), ('usv_1', '(201,4280)'), ('usv_2', '(436,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(2.323915276597023), 'usv_1': np.float64(1.4217142502576356)}
    Episode time: 248.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 30645.1
  Targets Detected: 8/71 (9.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.21

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 36223.3
Last 10 episodes average detections: 6.6
Best episode reward so far: 53545.7
Best detection count so far: 12
Learning trend: Improving (36223.3 vs 29420.0)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 487, Avg Reward: -2.439, Episode Reward: -1188.0
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3123)'), ('usv_1', '(251,4133)'), ('usv_2', '(265,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3165236460970906), 'usv_1': np.float64(-0.5798662384901059)}
    Episode time: 48.7s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.28555879 -0.00711082] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 1487, Avg Reward: 3.639, Episode Reward: 5410.7
    æ£€æµ‹è¿›åº¦: 1/39 (2.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3108)'), ('usv_1', '(319,4224)'), ('usv_2', '(293,5054)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3263902199441557), 'usv_1': np.float64(0.427491159134332)}
    Episode time: 148.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 8066.4
  Targets Detected: 1/41 (2.4%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_131s
  Average Reward/Step: 4.48
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 686, Avg Reward: -3.593, Episode Reward: -2465.1
    æ£€æµ‹è¿›åº¦: 0/9 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3116)'), ('usv_1', '(279,4142)'), ('usv_2', '(250,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6807152157543602), 'usv_1': np.float64(-1.5786662931240554)}
    Episode time: 68.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 1686, Avg Reward: 4.137, Episode Reward: 6975.5
    æ£€æµ‹è¿›åº¦: 4/42 (9.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3095)'), ('usv_1', '(336,4214)'), ('usv_2', '(310,5027)')]...
    Recent rewards sample: {'usv_0': np.float64(2.316156779312932), 'usv_1': np.float64(3.4345257885377363)}
    Episode time: 168.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 2686, Avg Reward: 10.076, Episode Reward: 27063.6
    æ£€æµ‹è¿›åº¦: 4/59 (6.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3120)'), ('usv_1', '(280,4263)'), ('usv_2', '(342,4960)')]...
    Recent rewards sample: {'usv_0': np.float64(4.312502970871287), 'usv_1': np.float64(3.434505069639151)}
    Episode time: 268.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 34213.3
  Targets Detected: 8/70 (8.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.40
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 685, Avg Reward: -2.604, Episode Reward: -1784.0
    æ£€æµ‹è¿›åº¦: 0/22 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3123)'), ('usv_1', '(267,4140)'), ('usv_2', '(290,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3220966262975522), 'usv_1': np.float64(-0.5712794045227833)}
    Episode time: 68.5s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.09318695 -0.07518658] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 1685, Avg Reward: 2.611, Episode Reward: 4399.7
    æ£€æµ‹è¿›åº¦: 1/39 (2.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3107)'), ('usv_1', '(318,4193)'), ('usv_2', '(365,5074)')]...
    Recent rewards sample: {'usv_0': np.float64(1.326307834666352), 'usv_1': np.float64(2.4327752104550244)}
    Episode time: 168.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 2685, Avg Reward: 9.145, Episode Reward: 24554.2
    æ£€æµ‹è¿›åº¦: 3/65 (4.6%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3069)'), ('usv_1', '(252,4258)'), ('usv_2', '(385,4983)')]...
    Recent rewards sample: {'usv_0': np.float64(5.9227993321478385), 'usv_1': np.float64(3.42445478193544)}
    Episode time: 268.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 31980.2
  Targets Detected: 5/73 (5.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.66
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 684, Avg Reward: -0.996, Episode Reward: -681.5
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3119)'), ('usv_1', '(269,4142)'), ('usv_2', '(273,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3199667938781442), 'usv_1': np.float64(-0.573452556352357)}
    Episode time: 68.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 1684, Avg Reward: 2.938, Episode Reward: 4948.1
    æ£€æµ‹è¿›åº¦: 0/42 (0.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3093)'), ('usv_1', '(273,4223)'), ('usv_2', '(374,5089)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3228718322126602), 'usv_1': np.float64(0.42664331400522704)}
    Episode time: 168.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 6186.6
  Targets Detected: 1/45 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_127s
  Average Reward/Step: 3.44
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 883, Avg Reward: 4.519, Episode Reward: 3990.6
    æ£€æµ‹è¿›åº¦: 1/21 (4.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3127)'), ('usv_1', '(298,4171)'), ('usv_2', '(276,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3201298105991217), 'usv_1': np.float64(1.4296375203213159)}
    Episode time: 88.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 7308.6
  Targets Detected: 2/45 (2.2%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_162s
  Average Reward/Step: 4.06
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.02020056  0.16858986] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 82, Avg Reward: -3.513, Episode Reward: -288.1
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(218,4130)'), ('usv_2', '(218,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6865104748362675), 'usv_1': np.float64(-1.575420213879731)}
    Episode time: 8.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 1082, Avg Reward: 7.442, Episode Reward: 8052.5
    æ£€æµ‹è¿›åº¦: 2/25 (8.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3105)'), ('usv_1', '(289,4191)'), ('usv_2', '(320,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3161368008713423), 'usv_1': np.float64(0.42803339876310087)}
    Episode time: 108.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 2082, Avg Reward: 12.814, Episode Reward: 26679.0
    æ£€æµ‹è¿›åº¦: 4/48 (8.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3103)'), ('usv_1', '(281,4298)'), ('usv_2', '(415,5088)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3157548009214866), 'usv_1': np.float64(3.4354962446210635)}
    Episode time: 208.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 45765.6
  Targets Detected: 7/66 (9.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.25
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 81, Avg Reward: -3.522, Episode Reward: -285.2
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(216,4130)'), ('usv_2', '(218,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6856937477724228), 'usv_1': np.float64(-1.5834840235426388)}
    Episode time: 8.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 1081, Avg Reward: 5.814, Episode Reward: 6284.5
    æ£€æµ‹è¿›åº¦: 3/24 (12.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3111)'), ('usv_1', '(284,4193)'), ('usv_2', '(310,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(2.31975707085824), 'usv_1': np.float64(1.422217234474871)}
    Episode time: 108.1s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.02666404  0.17963289] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 2081, Avg Reward: 10.456, Episode Reward: 21758.0
    æ£€æµ‹è¿›åº¦: 6/47 (12.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3091)'), ('usv_1', '(225,4256)'), ('usv_2', '(415,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3237443036011083), 'usv_1': np.float64(1.4196597453222184)}
    Episode time: 208.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 36540.5
  Targets Detected: 7/69 (5.8%)
  Steps: 2960
  Episode Time: 296.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.34
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 121, Avg Reward: -4.151, Episode Reward: -502.3
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(221,4130)'), ('usv_2', '(226,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6837319741837741), 'usv_1': np.float64(-1.581071791124186)}
    Episode time: 12.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 1121, Avg Reward: -0.794, Episode Reward: -890.2
    æ£€æµ‹è¿›åº¦: 1/26 (3.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3113)'), ('usv_1', '(284,4202)'), ('usv_2', '(323,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3193153259406415), 'usv_1': np.float64(1.4287494621657277)}
    Episode time: 112.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 2121, Avg Reward: 6.412, Episode Reward: 13600.5
    æ£€æµ‹è¿›åº¦: 4/52 (7.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3083)'), ('usv_1', '(226,4292)'), ('usv_2', '(419,5075)')]...
    Recent rewards sample: {'usv_0': np.float64(7.918431070915007), 'usv_1': np.float64(3.422219754129795)}
    Episode time: 212.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 27591.1
  Targets Detected: 4/64 (6.2%)
  Steps: 2738
  Episode Time: 273.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.08
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 383, Avg Reward: 6.590, Episode Reward: 2524.0
    æ£€æµ‹è¿›åº¦: 1/14 (7.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3133)'), ('usv_1', '(241,4141)'), ('usv_2', '(240,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31927550330385945), 'usv_1': np.float64(-0.581579093721995)}
    Episode time: 38.3s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.00202174  0.01884551] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 1383, Avg Reward: 7.291, Episode Reward: 10083.7
    æ£€æµ‹è¿›åº¦: 2/33 (6.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3118)'), ('usv_1', '(236,4213)'), ('usv_2', '(330,5100)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3229829560389743), 'usv_1': np.float64(0.427662163188254)}
    Episode time: 138.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 2383, Avg Reward: 10.773, Episode Reward: 25671.8
    æ£€æµ‹è¿›åº¦: 3/59 (5.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3112)'), ('usv_1', '(201,4243)'), ('usv_2', '(399,5049)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3134471134305734), 'usv_1': np.float64(3.4229383976813716)}
    Episode time: 238.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 38505.4
  Targets Detected: 5/73 (4.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.83
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 382, Avg Reward: -3.580, Episode Reward: -1367.5
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3126)'), ('usv_1', '(264,4143)'), ('usv_2', '(243,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.680272976483609), 'usv_1': np.float64(-1.5704435871458988)}
    Episode time: 38.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 1382, Avg Reward: -3.581, Episode Reward: -4949.5
    æ£€æµ‹è¿›åº¦: 0/28 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3115)'), ('usv_1', '(343,4212)'), ('usv_2', '(326,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6776795812556661), 'usv_1': np.float64(-1.5648672144728677)}
    Episode time: 138.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: -6449.8
  Targets Detected: 0/35 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.58

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 22970.8
Last 10 episodes average detections: 4.0
Best episode reward so far: 53545.7
Best detection count so far: 12
Learning trend: Declining (22970.8 vs 36223.3)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 581, Avg Reward: 4.915, Episode Reward: 2855.5
    æ£€æµ‹è¿›åº¦: 1/13 (7.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3128)'), ('usv_1', '(265,4144)'), ('usv_2', '(258,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2659250329857814), 'usv_1': np.float64(-0.629725586641775)}
    Episode time: 58.1s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.01064673 0.10183248] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 1581, Avg Reward: 16.620, Episode Reward: 26275.5
    æ£€æµ‹è¿›åº¦: 4/51 (7.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3124)'), ('usv_1', '(263,4261)'), ('usv_2', '(287,5044)')]...
    Recent rewards sample: {'usv_0': np.float64(4.27497102871646), 'usv_1': np.float64(3.3774550898349958)}
    Episode time: 158.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 2581, Avg Reward: 18.883, Episode Reward: 48737.8
    æ£€æµ‹è¿›åº¦: 9/77 (11.7%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(269,3118)'), ('usv_1', '(204,4274)'), ('usv_2', '(288,4945)')]...
    Recent rewards sample: {'usv_0': np.float64(4.279112018467021), 'usv_1': np.float64(3.3690432016990304)}
    Episode time: 258.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 57688.6
  Targets Detected: 12/93 (9.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.22
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 580, Avg Reward: 1.785, Episode Reward: 1035.4
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3138)'), ('usv_1', '(259,4153)'), ('usv_2', '(246,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(3.264816479247291), 'usv_1': np.float64(0.3702054744198213)}
    Episode time: 58.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 1580, Avg Reward: 12.547, Episode Reward: 19823.6
    æ£€æµ‹è¿›åº¦: 6/46 (13.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3142)'), ('usv_1', '(298,4256)'), ('usv_2', '(326,5060)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2749121476541125), 'usv_1': np.float64(3.3780756596014285)}
    Episode time: 158.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 2580, Avg Reward: 15.402, Episode Reward: 39737.8
    æ£€æµ‹è¿›åº¦: 10/75 (13.3%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3131)'), ('usv_1', '(228,4332)'), ('usv_2', '(371,4998)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2757088360759585), 'usv_1': np.float64(1.382648067324744)}
    Episode time: 258.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 47343.7
  Targets Detected: 10/83 (12.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.78
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.43131514 -0.09503529] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 579, Avg Reward: 2.655, Episode Reward: 1537.3
    æ£€æµ‹è¿›åº¦: 1/9 (11.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3126)'), ('usv_1', '(265,4153)'), ('usv_2', '(257,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2659987535678182), 'usv_1': np.float64(1.3777619972063389)}
    Episode time: 57.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 1579, Avg Reward: 5.627, Episode Reward: 8885.5
    æ£€æµ‹è¿›åº¦: 4/35 (11.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3124)'), ('usv_1', '(249,4247)'), ('usv_2', '(312,5063)')]...
    Recent rewards sample: {'usv_0': np.float64(2.272417225050769), 'usv_1': np.float64(3.373186776080539)}
    Episode time: 157.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 21703.8
  Targets Detected: 5/60 (5.0%)
  Steps: 2438
  Episode Time: 243.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 8.90
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 141, Avg Reward: -3.915, Episode Reward: -552.1
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(229,4131)'), ('usv_2', '(222,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7331778491240605), 'usv_1': np.float64(-1.617631486069376)}
    Episode time: 14.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 1141, Avg Reward: 3.774, Episode Reward: 4305.7
    æ£€æµ‹è¿›åº¦: 2/29 (6.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3127)'), ('usv_1', '(327,4184)'), ('usv_2', '(291,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2744840003301876), 'usv_1': np.float64(0.38267781300222103)}
    Episode time: 114.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 2141, Avg Reward: 9.284, Episode Reward: 19877.5
    æ£€æµ‹è¿›åº¦: 3/51 (5.9%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3108)'), ('usv_1', '(365,4300)'), ('usv_2', '(380,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(4.274485600665016), 'usv_1': np.float64(3.3877190230681036)}
    Episode time: 214.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 40857.8
  Targets Detected: 8/71 (9.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.61
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.02260848 0.04547013] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 140, Avg Reward: 0.549, Episode Reward: 76.9
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3130)'), ('usv_1', '(223,4131)'), ('usv_2', '(223,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2649958589732273), 'usv_1': np.float64(-0.6319973824035617)}
    Episode time: 14.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 1140, Avg Reward: 10.561, Episode Reward: 12040.1
    æ£€æµ‹è¿›åº¦: 3/40 (7.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3112)'), ('usv_1', '(233,4194)'), ('usv_2', '(314,5076)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2652892161264493), 'usv_1': np.float64(1.3754702945971253)}
    Episode time: 114.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 2140, Avg Reward: 15.625, Episode Reward: 33438.2
    æ£€æµ‹è¿›åº¦: 7/74 (9.5%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3102)'), ('usv_1', '(205,4132)'), ('usv_2', '(398,5022)')]...
    Recent rewards sample: {'usv_0': np.float64(4.26489676613946), 'usv_1': np.float64(1.3705248951641091)}
    Episode time: 214.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 54059.8
  Targets Detected: 11/104 (9.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.01
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 139, Avg Reward: -3.912, Episode Reward: -543.8
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3130)'), ('usv_1', '(224,4130)'), ('usv_2', '(226,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7355933292240255), 'usv_1': np.float64(-1.6318747542529546)}
    Episode time: 13.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 1139, Avg Reward: -1.301, Episode Reward: -1481.6
    æ£€æµ‹è¿›åº¦: 2/36 (5.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(249,3126)'), ('usv_1', '(261,4213)'), ('usv_2', '(299,5109)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2728297827845916), 'usv_1': np.float64(0.37812053132568657)}
    Episode time: 113.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.3172041   0.16397073] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 100000, Episode Steps: 2139, Avg Reward: 9.187, Episode Reward: 19651.3
    æ£€æµ‹è¿›åº¦: 4/71 (5.6%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3113)'), ('usv_1', '(204,4287)'), ('usv_2', '(348,5035)')]...
    Recent rewards sample: {'usv_0': np.float64(4.275869916538308), 'usv_1': np.float64(3.3790023857834015)}
    Episode time: 213.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 40669.5
  Targets Detected: 7/98 (7.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.55
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 101000, Episode Steps: 138, Avg Reward: -1.764, Episode Reward: -243.5
    æ£€æµ‹è¿›åº¦: 0/14 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(229,4132)'), ('usv_2', '(219,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2648468078450201), 'usv_1': np.float64(2.381246443559492)}
    Episode time: 13.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 102000, Episode Steps: 1138, Avg Reward: 18.376, Episode Reward: 20911.7
    æ£€æµ‹è¿›åº¦: 6/55 (10.9%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3122)'), ('usv_1', '(242,4237)'), ('usv_2', '(306,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(4.268359314552361), 'usv_1': np.float64(3.3752405165714805)}
    Episode time: 113.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 38583.1
  Targets Detected: 6/79 (7.6%)
  Steps: 2020
  Episode Time: 202.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 19.10
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 103000, Episode Steps: 118, Avg Reward: -3.204, Episode Reward: -378.0
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3129)'), ('usv_1', '(224,4131)'), ('usv_2', '(220,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26379496288646487), 'usv_1': np.float64(-0.6276260809399343)}
    Episode time: 11.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 104000, Episode Steps: 1118, Avg Reward: 8.146, Episode Reward: 9107.1
    æ£€æµ‹è¿›åº¦: 5/44 (11.4%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3115)'), ('usv_1', '(286,4187)'), ('usv_2', '(300,5100)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2653045011441715), 'usv_1': np.float64(1.3738371528715243)}
    Episode time: 111.8s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.02805265  0.18629268] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 105000, Episode Steps: 2118, Avg Reward: 12.262, Episode Reward: 25970.3
    æ£€æµ‹è¿›åº¦: 5/71 (7.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3128)'), ('usv_1', '(230,4267)'), ('usv_2', '(341,5040)')]...
    Recent rewards sample: {'usv_0': np.float64(2.260290814832694), 'usv_1': np.float64(1.382105225160768)}
    Episode time: 211.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 27175.1
  Targets Detected: 5/73 (5.5%)
  Steps: 2193
  Episode Time: 219.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.39
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 106000, Episode Steps: 925, Avg Reward: 13.034, Episode Reward: 12056.1
    æ£€æµ‹è¿›åº¦: 1/37 (2.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3130)'), ('usv_1', '(223,4195)'), ('usv_2', '(304,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2672340066280507), 'usv_1': np.float64(2.3767301139265054)}
    Episode time: 92.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 21737.8
  Targets Detected: 2/61 (1.6%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_165s
  Average Reward/Step: 12.07
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 107000, Episode Steps: 124, Avg Reward: 2.993, Episode Reward: 371.1
    æ£€æµ‹è¿›åº¦: 1/8 (12.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(217,4130)'), ('usv_2', '(227,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2629884393068018), 'usv_1': np.float64(-0.6315826407943368)}
    Episode time: 12.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 108000, Episode Steps: 1124, Avg Reward: 10.808, Episode Reward: 12148.2
    æ£€æµ‹è¿›åº¦: 3/30 (10.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3131)'), ('usv_1', '(324,4162)'), ('usv_2', '(311,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(4.269050279154932), 'usv_1': np.float64(1.3788675785621676)}
    Episode time: 112.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 109000, Episode Steps: 2124, Avg Reward: 16.078, Episode Reward: 34149.2
    æ£€æµ‹è¿›åº¦: 6/70 (8.6%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(266,3115)'), ('usv_1', '(373,4230)'), ('usv_2', '(381,5095)')]...
    Recent rewards sample: {'usv_0': np.float64(4.278767893017358), 'usv_1': np.float64(3.389123626978977)}
    Episode time: 212.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 46352.8
  Targets Detected: 6/84 (6.0%)
  Steps: 2729
  Episode Time: 272.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.99

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 39617.2
Last 10 episodes average detections: 7.2
Best episode reward so far: 57688.6
Best detection count so far: 12
Learning trend: Improving (39617.2 vs 22970.8)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.21559024 -0.17031058] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 110000, Episode Steps: 395, Avg Reward: 5.501, Episode Reward: 2172.8
    æ£€æµ‹è¿›åº¦: 1/18 (5.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(222,3129)'), ('usv_1', '(262,4135)'), ('usv_2', '(251,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2657578735947762), 'usv_1': np.float64(-0.6201253470891104)}
    Episode time: 39.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 111000, Episode Steps: 1395, Avg Reward: 16.520, Episode Reward: 23045.5
    æ£€æµ‹è¿›åº¦: 8/49 (16.3%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3122)'), ('usv_1', '(301,4216)'), ('usv_2', '(332,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(4.270165259419907), 'usv_1': np.float64(3.3805256360976834)}
    Episode time: 139.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 112000, Episode Steps: 2395, Avg Reward: 19.324, Episode Reward: 46281.9
    æ£€æµ‹è¿›åº¦: 9/81 (11.1%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3105)'), ('usv_1', '(231,4281)'), ('usv_2', '(389,5029)')]...
    Recent rewards sample: {'usv_0': np.float64(4.271319821546968), 'usv_1': np.float64(3.3819373066461065)}
    Episode time: 239.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 62920.3
  Targets Detected: 15/96 (13.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.97
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 113000, Episode Steps: 394, Avg Reward: 1.313, Episode Reward: 517.1
    æ£€æµ‹è¿›åº¦: 1/18 (5.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3124)'), ('usv_1', '(242,4138)'), ('usv_2', '(252,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26741585541404844), 'usv_1': np.float64(1.37172528985002)}
    Episode time: 39.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 114000, Episode Steps: 1394, Avg Reward: 15.587, Episode Reward: 21728.3
    æ£€æµ‹è¿›åº¦: 7/47 (14.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(228,3102)'), ('usv_1', '(288,4207)'), ('usv_2', '(347,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(4.2707252967654314), 'usv_1': np.float64(3.3799588571886474)}
    Episode time: 139.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.17950683 -0.14656092] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 115000, Episode Steps: 2394, Avg Reward: 16.881, Episode Reward: 40413.8
    æ£€æµ‹è¿›åº¦: 11/71 (15.5%), Episode total: 12
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3102)'), ('usv_1', '(221,4291)'), ('usv_2', '(426,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(4.265449308338474), 'usv_1': np.float64(3.374857366352746)}
    Episode time: 239.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 55747.8
  Targets Detected: 16/86 (16.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.58
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 116000, Episode Steps: 393, Avg Reward: -3.914, Episode Reward: -1538.3
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3127)'), ('usv_1', '(255,4136)'), ('usv_2', '(243,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7349557440745044), 'usv_1': np.float64(-1.6215740238806398)}
    Episode time: 39.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 117000, Episode Steps: 1393, Avg Reward: 2.559, Episode Reward: 3565.2
    æ£€æµ‹è¿›åº¦: 2/40 (5.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3118)'), ('usv_1', '(280,4227)'), ('usv_2', '(313,5056)')]...
    Recent rewards sample: {'usv_0': np.float64(1.264571984370103), 'usv_1': np.float64(2.372604160508196)}
    Episode time: 139.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 118000, Episode Steps: 2393, Avg Reward: 7.240, Episode Reward: 17324.3
    æ£€æµ‹è¿›åº¦: 3/62 (4.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3131)'), ('usv_1', '(218,4230)'), ('usv_2', '(369,4982)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2641064324084765), 'usv_1': np.float64(3.3722761598408706)}
    Episode time: 239.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 24869.9
  Targets Detected: 4/69 (2.9%)
  Steps: 2863
  Episode Time: 286.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 8.69
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 119000, Episode Steps: 530, Avg Reward: 10.240, Episode Reward: 5427.3
    æ£€æµ‹è¿›åº¦: 2/7 (28.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3113)'), ('usv_1', '(266,4156)'), ('usv_2', '(262,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(1.268109964901515), 'usv_1': np.float64(0.3788649586124455)}
    Episode time: 53.0s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.01068098 -0.1068088 ] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 120000, Episode Steps: 1530, Avg Reward: 13.564, Episode Reward: 20753.5
    æ£€æµ‹è¿›åº¦: 3/40 (7.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3104)'), ('usv_1', '(256,4227)'), ('usv_2', '(349,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2655850118209493), 'usv_1': np.float64(1.3815786614760075)}
    Episode time: 153.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 28482.0
  Targets Detected: 5/56 (7.1%)
  Steps: 2039
  Episode Time: 203.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.97
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 121000, Episode Steps: 491, Avg Reward: 14.123, Episode Reward: 6934.4
    æ£€æµ‹è¿›åº¦: 3/24 (12.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3132)'), ('usv_1', '(250,4135)'), ('usv_2', '(251,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(4.267854009093369), 'usv_1': np.float64(1.3704681390095623)}
    Episode time: 49.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 122000, Episode Steps: 1491, Avg Reward: 19.117, Episode Reward: 28503.2
    æ£€æµ‹è¿›åº¦: 4/57 (7.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3114)'), ('usv_1', '(293,4215)'), ('usv_2', '(350,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(4.273964077331038), 'usv_1': np.float64(3.378178316238607)}
    Episode time: 149.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 123000, Episode Steps: 2491, Avg Reward: 19.964, Episode Reward: 49731.1
    æ£€æµ‹è¿›åº¦: 6/81 (7.4%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3123)'), ('usv_1', '(204,4247)'), ('usv_2', '(418,5066)')]...
    Recent rewards sample: {'usv_0': np.float64(4.268162313568965), 'usv_1': np.float64(3.3714378575653896)}
    Episode time: 249.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 56341.4
  Targets Detected: 8/85 (7.1%)
  Steps: 2822
  Episode Time: 282.2s
  Termination Reason: no_progress_120s
  Average Reward/Step: 19.97
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 124000, Episode Steps: 669, Avg Reward: -3.914, Episode Reward: -2618.4
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3121)'), ('usv_1', '(293,4140)'), ('usv_2', '(270,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7320986946454047), 'usv_1': np.float64(-1.6225221698675847)}
    Episode time: 66.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.12682205 -0.00439413] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 125000, Episode Steps: 1669, Avg Reward: 5.033, Episode Reward: 8400.0
    æ£€æµ‹è¿›åº¦: 5/49 (10.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3095)'), ('usv_1', '(334,4226)'), ('usv_2', '(368,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2753999492518395), 'usv_1': np.float64(3.3803758284351746)}
    Episode time: 166.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 126000, Episode Steps: 2669, Avg Reward: 11.818, Episode Reward: 31542.7
    æ£€æµ‹è¿›åº¦: 6/76 (7.9%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(240,3080)'), ('usv_1', '(299,4317)'), ('usv_2', '(459,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(7.869999303926882), 'usv_1': np.float64(3.3812183926391883)}
    Episode time: 266.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 39127.2
  Targets Detected: 8/88 (6.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.04
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 127000, Episode Steps: 668, Avg Reward: 7.482, Episode Reward: 4998.1
    æ£€æµ‹è¿›åº¦: 2/15 (13.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3119)'), ('usv_1', '(277,4149)'), ('usv_2', '(278,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2666354115277207), 'usv_1': np.float64(0.3791728456807715)}
    Episode time: 66.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 128000, Episode Steps: 1668, Avg Reward: 13.747, Episode Reward: 22929.5
    æ£€æµ‹è¿›åº¦: 5/46 (10.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3104)'), ('usv_1', '(264,4214)'), ('usv_2', '(358,5091)')]...
    Recent rewards sample: {'usv_0': np.float64(4.267457721298954), 'usv_1': np.float64(3.3767843532486506)}
    Episode time: 166.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 129000, Episode Steps: 2668, Avg Reward: 17.690, Episode Reward: 47197.0
    æ£€æµ‹è¿›åº¦: 8/74 (10.8%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3103)'), ('usv_1', '(207,4188)'), ('usv_2', '(433,5054)')]...
    Recent rewards sample: {'usv_0': np.float64(4.265591735141849), 'usv_1': np.float64(3.376457863271165)}
    Episode time: 266.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 55042.8
  Targets Detected: 9/80 (10.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.34
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.3403876  0.0490147] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 130000, Episode Steps: 667, Avg Reward: -3.901, Episode Reward: -2602.1
    æ£€æµ‹è¿›åº¦: 0/16 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(219,3122)'), ('usv_1', '(273,4148)'), ('usv_2', '(286,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7343501010972504), 'usv_1': np.float64(-1.6242831816642684)}
    Episode time: 66.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 131000, Episode Steps: 1667, Avg Reward: -0.144, Episode Reward: -239.8
    æ£€æµ‹è¿›åº¦: 1/37 (2.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(201,3112)'), ('usv_1', '(311,4244)'), ('usv_2', '(380,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2622911751617233), 'usv_1': np.float64(-0.6199224245063705)}
    Episode time: 166.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 132000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 132000, Episode Steps: 2667, Avg Reward: 5.913, Episode Reward: 15770.9
    æ£€æµ‹è¿›åº¦: 3/61 (4.9%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,3121)'), ('usv_1', '(210,4266)'), ('usv_2', '(439,5056)')]...
    Recent rewards sample: {'usv_0': np.float64(2.261330010580199), 'usv_1': np.float64(3.371987350640194)}
    Episode time: 266.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 23345.7
  Targets Detected: 5/72 (5.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.78
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 133000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 133000, Episode Steps: 666, Avg Reward: 2.743, Episode Reward: 1827.0
    æ£€æµ‹è¿›åº¦: 1/21 (4.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3132)'), ('usv_1', '(280,4170)'), ('usv_2', '(280,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2647581970390456), 'usv_1': np.float64(-0.6184320744883166)}
    Episode time: 66.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 134000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 134000, Episode Steps: 1666, Avg Reward: 10.631, Episode Reward: 17711.6
    æ£€æµ‹è¿›åº¦: 3/43 (7.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3112)'), ('usv_1', '(271,4272)'), ('usv_2', '(357,5065)')]...
    Recent rewards sample: {'usv_0': np.float64(4.267099596978938), 'usv_1': np.float64(3.3824126202082816)}
    Episode time: 166.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.32134293 -0.30917623] (agent usv_0)
    MADDPG UPDATING at time_step 135000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 135000, Episode Steps: 2666, Avg Reward: 14.818, Episode Reward: 39504.0
    æ£€æµ‹è¿›åº¦: 6/71 (8.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3137)'), ('usv_1', '(203,4282)'), ('usv_2', '(398,4999)')]...
    Recent rewards sample: {'usv_0': np.float64(4.261319612769625), 'usv_1': np.float64(3.386000114367288)}
    Episode time: 266.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 48385.2
  Targets Detected: 9/74 (10.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.12
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 136000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 136000, Episode Steps: 665, Avg Reward: 1.339, Episode Reward: 890.5
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3124)'), ('usv_1', '(262,4154)'), ('usv_2', '(262,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(0.26645672044089286), 'usv_1': np.float64(-0.6299353245967964)}
    Episode time: 66.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 137000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 137000, Episode Steps: 1665, Avg Reward: 1.798, Episode Reward: 2994.0
    æ£€æµ‹è¿›åº¦: 1/29 (3.4%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3114)'), ('usv_1', '(289,4242)'), ('usv_2', '(337,5068)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2673440768109723), 'usv_1': np.float64(-0.6173266275102791)}
    Episode time: 166.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 138000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0534, Avg Critic Loss: 9.4000
    Step 138000, Episode Steps: 2665, Avg Reward: 6.532, Episode Reward: 17407.7
    æ£€æµ‹è¿›åº¦: 3/52 (5.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,3126)'), ('usv_1', '(202,4293)'), ('usv_2', '(390,4993)')]...
    Recent rewards sample: {'usv_0': np.float64(4.264177864043807), 'usv_1': np.float64(1.371896152959954)}
    Episode time: 266.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 25892.0
  Targets Detected: 6/68 (8.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.63

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 42015.4
Last 10 episodes average detections: 8.5
Best episode reward so far: 62920.3
Best detection count so far: 16
Learning trend: Improving (42015.4 vs 39617.2)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 62920.3
Final 10 episodes average: 42015.4
Best detection performance: 16 targets
Average detections (final 10): 8.5
============================================================
{"final_avg_reward": 42015.442926692725, "final_detection_rate": 8.5, "best_episode_reward": 62920.30624768713, "best_detection_count": 16, "total_episodes": 50}
Simulation finished.
