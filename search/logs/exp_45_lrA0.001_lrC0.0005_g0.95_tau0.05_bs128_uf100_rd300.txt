D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: 5.957, Episode Reward: 5957.2
    æ£€æµ‹è¿›åº¦: 2/10 (20.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3111)'), ('usv_1', '(233,4168)'), ('usv_2', '(237,5106)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3946803229149265), 'usv_1': np.float64(0.4686381528329764)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 12.186, Episode Reward: 24372.9
    æ£€æµ‹è¿›åº¦: 3/28 (10.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(368,3045)'), ('usv_1', '(203,4198)'), ('usv_2', '(233,5075)')]...
    Recent rewards sample: {'usv_0': np.float64(5.978903269316691), 'usv_1': np.float64(3.468892344577692)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 3000, Avg Reward: 15.702, Episode Reward: 47105.1
    æ£€æµ‹è¿›åº¦: 3/36 (8.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(391,2960)'), ('usv_1', '(200,4186)'), ('usv_2', '(227,5045)')]...
    Recent rewards sample: {'usv_0': np.float64(5.998623690291966), 'usv_1': np.float64(3.4688949916055885)}
    Episode time: 300.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 47127.6
  Targets Detected: 4/36 (8.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.70
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 999, Avg Reward: 0.899, Episode Reward: 898.4
    æ£€æµ‹è¿›åº¦: 1/17 (5.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(301,3099)'), ('usv_1', '(206,4155)'), ('usv_2', '(233,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(0.39015703004255975), 'usv_1': np.float64(-0.5341311591237814)}
    Episode time: 99.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 5354.0
  Targets Detected: 1/23 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_170s
  Average Reward/Step: 2.97
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.08656361  0.19026994] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 198, Avg Reward: 4.786, Episode Reward: 947.7
    æ£€æµ‹è¿›åº¦: 1/5 (20.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,3130)'), ('usv_1', '(221,4128)'), ('usv_2', '(218,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(2.372355790460025), 'usv_1': np.float64(-0.5331312505157688)}
    Episode time: 19.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 1198, Avg Reward: 10.866, Episode Reward: 13017.9
    æ£€æµ‹è¿›åº¦: 3/28 (10.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(313,3137)'), ('usv_1', '(269,4133)'), ('usv_2', '(254,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(4.387709475440304), 'usv_1': np.float64(1.4705691945346566)}
    Episode time: 119.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 30473.1
  Targets Detected: 3/40 (7.5%)
  Steps: 2127
  Episode Time: 212.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.33
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 71, Avg Reward: -2.989, Episode Reward: -212.2
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6290607043323673), 'usv_1': np.float64(-1.5317718569939567)}
    Episode time: 7.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 1071, Avg Reward: 3.430, Episode Reward: 3673.3
    æ£€æµ‹è¿›åº¦: 1/18 (5.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(306,3096)'), ('usv_1', '(267,4111)'), ('usv_2', '(238,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(0.39723436753825225), 'usv_1': np.float64(-0.5295661184268117)}
    Episode time: 107.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 2071, Avg Reward: 7.696, Episode Reward: 15937.8
    æ£€æµ‹è¿›åº¦: 2/31 (6.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(369,3048)'), ('usv_1', '(260,4127)'), ('usv_2', '(207,5070)')]...
    Recent rewards sample: {'usv_0': np.float64(4.982499415000502), 'usv_1': np.float64(0.4698655804061054)}
    Episode time: 207.1s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 37370.9
  Targets Detected: 3/44 (6.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.45
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.10230928 0.1325754 ] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 70, Avg Reward: -3.024, Episode Reward: -211.7
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.634042611191741), 'usv_1': np.float64(-1.5266676110253663)}
    Episode time: 7.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 1070, Avg Reward: -3.280, Episode Reward: -3509.4
    æ£€æµ‹è¿›åº¦: 0/19 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(305,3124)'), ('usv_1', '(221,4150)'), ('usv_2', '(210,5088)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6048670037543016), 'usv_1': np.float64(-1.5252259420768204)}
    Episode time: 107.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 2070, Avg Reward: -0.215, Episode Reward: -444.3
    æ£€æµ‹è¿›åº¦: 3/36 (8.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(413,3124)'), ('usv_1', '(202,4145)'), ('usv_2', '(208,5063)')]...
    Recent rewards sample: {'usv_0': np.float64(1.424470580880933), 'usv_1': np.float64(0.4702649061050308)}
    Episode time: 207.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 9612.2
  Targets Detected: 3/50 (4.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 3.20
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 69, Avg Reward: 4.943, Episode Reward: 341.1
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3129)'), ('usv_1', '(213,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3683239851287271), 'usv_1': np.float64(-0.5325889251875898)}
    Episode time: 6.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 1069, Avg Reward: 19.112, Episode Reward: 20431.1
    æ£€æµ‹è¿›åº¦: 5/20 (25.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(301,3094)'), ('usv_1', '(250,4145)'), ('usv_2', '(226,5109)')]...
    Recent rewards sample: {'usv_0': np.float64(4.39090234070026), 'usv_1': np.float64(1.471176934819892)}
    Episode time: 106.9s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.27536563 0.03539793] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 2069, Avg Reward: 21.764, Episode Reward: 45028.9
    æ£€æµ‹è¿›åº¦: 7/39 (17.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(379,3025)'), ('usv_1', '(254,4174)'), ('usv_2', '(214,5081)')]...
    Recent rewards sample: {'usv_0': np.float64(7.986058809514407), 'usv_1': np.float64(3.4697140756112628)}
    Episode time: 206.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 69141.5
  Targets Detected: 10/57 (14.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 23.04
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 68, Avg Reward: -2.974, Episode Reward: -202.2
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3130)'), ('usv_1', '(215,4130)'), ('usv_2', '(215,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6335786241171971), 'usv_1': np.float64(-1.5331666685456347)}
    Episode time: 6.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 1068, Avg Reward: 3.986, Episode Reward: 4256.6
    æ£€æµ‹è¿›åº¦: 1/17 (5.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(319,3118)'), ('usv_1', '(219,4166)'), ('usv_2', '(234,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3982615432628299), 'usv_1': np.float64(1.4669633082002829)}
    Episode time: 106.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 8081.3
  Targets Detected: 1/22 (4.5%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_147s
  Average Reward/Step: 4.49
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 267, Avg Reward: -3.240, Episode Reward: -865.0
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3128)'), ('usv_1', '(227,4131)'), ('usv_2', '(218,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6133031694822986), 'usv_1': np.float64(-1.5289980984649727)}
    Episode time: 26.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 1267, Avg Reward: -0.959, Episode Reward: -1215.1
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(349,3114)'), ('usv_1', '(222,4164)'), ('usv_2', '(241,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(0.4086848309233383), 'usv_1': np.float64(-0.532832731281844)}
    Episode time: 126.7s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.31133538 0.24730512] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 2267, Avg Reward: 3.930, Episode Reward: 8909.6
    æ£€æµ‹è¿›åº¦: 2/44 (4.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(419,3064)'), ('usv_1', '(202,4160)'), ('usv_2', '(232,5053)')]...
    Recent rewards sample: {'usv_0': np.float64(4.995270237320074), 'usv_1': np.float64(0.47429081179639)}
    Episode time: 226.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 26419.2
  Targets Detected: 4/50 (8.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.80
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 266, Avg Reward: -3.008, Episode Reward: -800.2
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3129)'), ('usv_1', '(218,4132)'), ('usv_2', '(218,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(0.36827209818695616), 'usv_1': np.float64(-0.5333820833179215)}
    Episode time: 26.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 1266, Avg Reward: 1.799, Episode Reward: 2277.8
    æ£€æµ‹è¿›åº¦: 1/17 (5.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(329,3113)'), ('usv_1', '(241,4163)'), ('usv_2', '(230,5093)')]...
    Recent rewards sample: {'usv_0': np.float64(0.396357518210416), 'usv_1': np.float64(-0.5264663125973408)}
    Episode time: 126.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 3776.3
  Targets Detected: 1/26 (3.8%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_145s
  Average Reward/Step: 2.10
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 465, Avg Reward: 15.855, Episode Reward: 7372.4
    æ£€æµ‹è¿›åº¦: 4/10 (40.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3126)'), ('usv_1', '(235,4138)'), ('usv_2', '(231,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3791033558176835), 'usv_1': np.float64(1.467968676201418)}
    Episode time: 46.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 1465, Avg Reward: 20.046, Episode Reward: 29367.4
    æ£€æµ‹è¿›åº¦: 8/33 (24.2%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(331,3126)'), ('usv_1', '(207,4157)'), ('usv_2', '(269,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(4.397218964803477), 'usv_1': np.float64(3.4677353959102097)}
    Episode time: 146.5s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.53262375 -0.09310507] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 2465, Avg Reward: 21.510, Episode Reward: 53022.2
    æ£€æµ‹è¿›åº¦: 11/49 (22.4%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(430,3112)'), ('usv_1', '(204,4135)'), ('usv_2', '(275,5087)')]...
    Recent rewards sample: {'usv_0': np.float64(4.435634421744133), 'usv_1': np.float64(3.4726083087915827)}
    Episode time: 246.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 65722.4
  Targets Detected: 12/62 (16.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.90

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 30307.8
Last 10 episodes average detections: 4.2
Best episode reward so far: 69141.5
Best detection count so far: 12
Buffer size: 25536
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 464, Avg Reward: -3.607, Episode Reward: -1673.6
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(251,3125)'), ('usv_1', '(240,4135)'), ('usv_2', '(228,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6716705246989261), 'usv_1': np.float64(-1.5761754636682521)}
    Episode time: 46.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 1464, Avg Reward: 0.057, Episode Reward: 83.6
    æ£€æµ‹è¿›åº¦: 2/30 (6.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(315,3065)'), ('usv_1', '(260,4165)'), ('usv_2', '(235,5092)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9285177406690797), 'usv_1': np.float64(-0.571810754886078)}
    Episode time: 146.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 7493.7
  Targets Detected: 4/47 (6.4%)
  Steps: 2216
  Episode Time: 221.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 3.38
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 248, Avg Reward: -3.594, Episode Reward: -891.4
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3124)'), ('usv_1', '(218,4131)'), ('usv_2', '(218,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.680199671996812), 'usv_1': np.float64(-1.5833162288472495)}
    Episode time: 24.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 1248, Avg Reward: 6.279, Episode Reward: 7835.8
    æ£€æµ‹è¿›åº¦: 6/42 (14.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3067)'), ('usv_1', '(223,4161)'), ('usv_2', '(237,5103)')]...
    Recent rewards sample: {'usv_0': np.float64(5.923983378249583), 'usv_1': np.float64(1.4258405672139287)}
    Episode time: 124.8s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.38909922 -0.1516161 ] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 2248, Avg Reward: 12.519, Episode Reward: 28142.8
    æ£€æµ‹è¿›åº¦: 7/65 (10.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(300,2953)'), ('usv_1', '(208,4175)'), ('usv_2', '(206,5073)')]...
    Recent rewards sample: {'usv_0': np.float64(5.939032238137319), 'usv_1': np.float64(1.4226668310779558)}
    Episode time: 224.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 35955.8
  Targets Detected: 7/68 (10.3%)
  Steps: 2641
  Episode Time: 264.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.61
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 607, Avg Reward: 1.936, Episode Reward: 1175.3
    æ£€æµ‹è¿›åº¦: 1/6 (16.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3104)'), ('usv_1', '(240,4128)'), ('usv_2', '(237,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(2.338925237877485), 'usv_1': np.float64(-0.5817053161282141)}
    Episode time: 60.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 1607, Avg Reward: 5.103, Episode Reward: 8200.0
    æ£€æµ‹è¿›åº¦: 0/25 (0.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(343,3047)'), ('usv_1', '(267,4147)'), ('usv_2', '(248,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(5.929939281769596), 'usv_1': np.float64(-0.579214008990237)}
    Episode time: 160.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 9761.9
  Targets Detected: 1/31 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_142s
  Average Reward/Step: 5.42
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 806, Avg Reward: 10.031, Episode Reward: 8085.3
    æ£€æµ‹è¿›åº¦: 3/20 (15.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(286,3108)'), ('usv_1', '(220,4146)'), ('usv_2', '(252,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3422785432058717), 'usv_1': np.float64(3.4168669869757053)}
    Episode time: 80.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 1806, Avg Reward: 16.783, Episode Reward: 30310.7
    æ£€æµ‹è¿›åº¦: 6/46 (13.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(369,3075)'), ('usv_1', '(204,4159)'), ('usv_2', '(284,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(7.930445263161805), 'usv_1': np.float64(3.4157040551745546)}
    Episode time: 180.6s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.14942188 -0.09617935] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 2806, Avg Reward: 20.609, Episode Reward: 57828.3
    æ£€æµ‹è¿›åº¦: 11/76 (14.5%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(403,3005)'), ('usv_1', '(205,4138)'), ('usv_2', '(310,5151)')]...
    Recent rewards sample: {'usv_0': np.float64(7.938901505117551), 'usv_1': np.float64(3.4160941884174845)}
    Episode time: 280.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 62895.0
  Targets Detected: 12/80 (15.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.96
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 805, Avg Reward: -0.221, Episode Reward: -177.5
    æ£€æµ‹è¿›åº¦: 1/28 (3.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3088)'), ('usv_1', '(266,4135)'), ('usv_2', '(221,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3355706393639942), 'usv_1': np.float64(1.421280959617309)}
    Episode time: 80.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 1805, Avg Reward: 10.276, Episode Reward: 18548.6
    æ£€æµ‹è¿›åº¦: 2/45 (4.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(285,2994)'), ('usv_1', '(302,4133)'), ('usv_2', '(205,5090)')]...
    Recent rewards sample: {'usv_0': np.float64(5.930009117732256), 'usv_1': np.float64(3.423095259742299)}
    Episode time: 180.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 32767.2
  Targets Detected: 3/62 (3.2%)
  Steps: 2450
  Episode Time: 245.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.37
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 355, Avg Reward: -1.206, Episode Reward: -428.1
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3128)'), ('usv_1', '(223,4130)'), ('usv_2', '(221,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3400959302509655), 'usv_1': np.float64(-0.5829808241860474)}
    Episode time: 35.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 1355, Avg Reward: 2.093, Episode Reward: 2836.7
    æ£€æµ‹è¿›åº¦: 1/28 (3.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(344,3097)'), ('usv_1', '(237,4181)'), ('usv_2', '(249,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3517305423763037), 'usv_1': np.float64(-0.5814908730634707)}
    Episode time: 135.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 5478.0
  Targets Detected: 2/37 (2.7%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_121s
  Average Reward/Step: 3.04
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.01782599 0.33233302] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 554, Avg Reward: -3.941, Episode Reward: -2183.2
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3132)'), ('usv_1', '(229,4130)'), ('usv_2', '(236,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6648428993837939), 'usv_1': np.float64(-1.5824908509805353)}
    Episode time: 55.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 1554, Avg Reward: 6.396, Episode Reward: 9939.1
    æ£€æµ‹è¿›åº¦: 3/33 (9.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(352,3142)'), ('usv_1', '(219,4171)'), ('usv_2', '(258,5088)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3530868358106964), 'usv_1': np.float64(3.419111234118425)}
    Episode time: 155.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 2554, Avg Reward: 12.057, Episode Reward: 30793.2
    æ£€æµ‹è¿›åº¦: 4/47 (8.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(453,3152)'), ('usv_1', '(212,4160)'), ('usv_2', '(264,5055)')]...
    Recent rewards sample: {'usv_0': np.float64(4.370870402121501), 'usv_1': np.float64(3.417477490650514)}
    Episode time: 255.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 36957.5
  Targets Detected: 4/52 (7.7%)
  Steps: 2890
  Episode Time: 289.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.79
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 664, Avg Reward: 9.270, Episode Reward: 6155.5
    æ£€æµ‹è¿›åº¦: 2/19 (10.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3109)'), ('usv_1', '(233,4136)'), ('usv_2', '(225,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3332383485469776), 'usv_1': np.float64(2.4198651375141633)}
    Episode time: 66.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 1664, Avg Reward: 17.338, Episode Reward: 28850.0
    æ£€æµ‹è¿›åº¦: 6/45 (13.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(330,3049)'), ('usv_1', '(209,4134)'), ('usv_2', '(240,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(7.930800256896265), 'usv_1': np.float64(3.415945747646558)}
    Episode time: 166.4s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.00443871 -0.06680504] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 2664, Avg Reward: 20.072, Episode Reward: 53471.7
    æ£€æµ‹è¿›åº¦: 7/66 (10.6%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(394,2983)'), ('usv_1', '(213,4087)'), ('usv_2', '(232,5074)')]...
    Recent rewards sample: {'usv_0': np.float64(7.938046682575333), 'usv_1': np.float64(3.4165988006957226)}
    Episode time: 266.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 62937.7
  Targets Detected: 8/68 (10.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.97
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 663, Avg Reward: 4.407, Episode Reward: 2922.2
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(268,3108)'), ('usv_1', '(234,4144)'), ('usv_2', '(237,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3306363779007784), 'usv_1': np.float64(0.41787238697512974)}
    Episode time: 66.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 1663, Avg Reward: 11.072, Episode Reward: 18413.3
    æ£€æµ‹è¿›åº¦: 2/28 (7.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(311,3020)'), ('usv_1', '(268,4184)'), ('usv_2', '(272,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(6.925208101800484), 'usv_1': np.float64(2.42216652521732)}
    Episode time: 166.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 20804.6
  Targets Detected: 2/31 (6.5%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_122s
  Average Reward/Step: 11.55
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 862, Avg Reward: -3.593, Episode Reward: -3097.2
    æ£€æµ‹è¿›åº¦: 0/24 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(289,3130)'), ('usv_1', '(243,4115)'), ('usv_2', '(231,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6673011136504592), 'usv_1': np.float64(-1.5813922437618881)}
    Episode time: 86.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 1862, Avg Reward: 1.785, Episode Reward: 3323.8
    æ£€æµ‹è¿›åº¦: 1/46 (2.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(401,3120)'), ('usv_1', '(270,4145)'), ('usv_2', '(265,5071)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3671044891045563), 'usv_1': np.float64(0.42625211904125804)}
    Episode time: 186.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 18483.2
  Targets Detected: 3/61 (3.3%)
  Steps: 2846
  Episode Time: 284.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 6.49

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 29353.4
Last 10 episodes average detections: 4.6
Best episode reward so far: 69141.5
Best detection count so far: 12
Learning trend: Declining (29353.4 vs 30307.8)
Buffer size: 49984
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.26877348 -0.15069876] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 16, Avg Reward: -3.038, Episode Reward: -48.6
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(212,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6766072104777456), 'usv_1': np.float64(-1.5837991643433722)}
    Episode time: 1.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 1016, Avg Reward: 5.358, Episode Reward: 5444.0
    æ£€æµ‹è¿›åº¦: 2/33 (6.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(322,3124)'), ('usv_1', '(235,4154)'), ('usv_2', '(238,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3477784162962614), 'usv_1': np.float64(0.4188758728265758)}
    Episode time: 101.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 2016, Avg Reward: 11.454, Episode Reward: 23091.0
    æ£€æµ‹è¿›åº¦: 3/55 (5.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(399,3104)'), ('usv_1', '(224,4192)'), ('usv_2', '(269,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(4.373181194007139), 'usv_1': np.float64(1.4224761046634695)}
    Episode time: 201.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 46126.7
  Targets Detected: 5/63 (6.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.37
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 15, Avg Reward: -3.008, Episode Reward: -45.1
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(213,4130)'), ('usv_2', '(212,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6816854999373027), 'usv_1': np.float64(-1.578624040292522)}
    Episode time: 1.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 1015, Avg Reward: -2.046, Episode Reward: -2076.6
    æ£€æµ‹è¿›åº¦: 1/31 (3.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3114)'), ('usv_1', '(249,4120)'), ('usv_2', '(250,5153)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3358378720357501), 'usv_1': np.float64(-0.57994065546967)}
    Episode time: 101.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: -138.4
  Targets Detected: 1/39 (2.6%)
  Steps: 1804
  Episode Time: 180.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: -0.08
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.08419908 0.07078836] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 211, Avg Reward: -3.593, Episode Reward: -758.0
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3128)'), ('usv_1', '(219,4130)'), ('usv_2', '(218,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6724123726362663), 'usv_1': np.float64(-1.5813066868297716)}
    Episode time: 21.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 1211, Avg Reward: -3.362, Episode Reward: -4071.7
    æ£€æµ‹è¿›åº¦: 0/21 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(311,3110)'), ('usv_1', '(237,4147)'), ('usv_2', '(241,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(0.34119008363111414), 'usv_1': np.float64(1.426529651639536)}
    Episode time: 121.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 2211, Avg Reward: 5.052, Episode Reward: 11170.0
    æ£€æµ‹è¿›åº¦: 3/48 (6.2%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(369,3066)'), ('usv_1', '(205,4179)'), ('usv_2', '(210,5077)')]...
    Recent rewards sample: {'usv_0': np.float64(7.930190607537627), 'usv_1': np.float64(3.418363812110009)}
    Episode time: 221.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 16684.4
  Targets Detected: 5/61 (6.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.56
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 210, Avg Reward: -3.598, Episode Reward: -755.7
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3128)'), ('usv_1', '(221,4131)'), ('usv_2', '(223,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.68172213311062), 'usv_1': np.float64(-1.5780948711640332)}
    Episode time: 21.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 1210, Avg Reward: 0.979, Episode Reward: 1185.2
    æ£€æµ‹è¿›åº¦: 1/37 (2.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(306,3061)'), ('usv_1', '(246,4161)'), ('usv_2', '(213,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(3.927934356007883), 'usv_1': np.float64(-0.5810366220444606)}
    Episode time: 121.0s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.02139848 0.00737832] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 2210, Avg Reward: 10.618, Episode Reward: 23465.3
    æ£€æµ‹è¿›åº¦: 2/57 (3.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(360,2992)'), ('usv_1', '(208,4148)'), ('usv_2', '(205,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(5.930481284584284), 'usv_1': np.float64(3.4169204090652014)}
    Episode time: 221.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 39245.2
  Targets Detected: 5/71 (4.2%)
  Steps: 2923
  Episode Time: 292.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.43
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 287, Avg Reward: -3.593, Episode Reward: -1031.1
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(243,3125)'), ('usv_1', '(223,4133)'), ('usv_2', '(226,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6732920411682614), 'usv_1': np.float64(-1.5825427791934084)}
    Episode time: 28.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 1287, Avg Reward: 11.162, Episode Reward: 14365.0
    æ£€æµ‹è¿›åº¦: 3/31 (9.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(342,3088)'), ('usv_1', '(255,4162)'), ('usv_2', '(261,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(4.361279064592968), 'usv_1': np.float64(1.4278645531153829)}
    Episode time: 128.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 2287, Avg Reward: 17.410, Episode Reward: 39817.7
    æ£€æµ‹è¿›åº¦: 5/58 (8.6%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(387,3010)'), ('usv_1', '(240,4192)'), ('usv_2', '(274,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(7.93095677049467), 'usv_1': np.float64(3.419669213592413)}
    Episode time: 228.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 58758.0
  Targets Detected: 7/70 (5.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.58
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 286, Avg Reward: 8.078, Episode Reward: 2310.4
    æ£€æµ‹è¿›åº¦: 1/4 (25.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3129)'), ('usv_1', '(223,4132)'), ('usv_2', '(219,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32184188411043757), 'usv_1': np.float64(1.4193939983506976)}
    Episode time: 28.6s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.2535017 -0.1156258] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 1286, Avg Reward: 11.306, Episode Reward: 14539.1
    æ£€æµ‹è¿›åº¦: 3/27 (11.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(340,3110)'), ('usv_1', '(224,4161)'), ('usv_2', '(226,5097)')]...
    Recent rewards sample: {'usv_0': np.float64(3.357502802621062), 'usv_1': np.float64(0.42095478633175576)}
    Episode time: 128.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 20918.5
  Targets Detected: 3/37 (5.4%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_129s
  Average Reward/Step: 11.61
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 485, Avg Reward: -3.599, Episode Reward: -1745.5
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3118)'), ('usv_1', '(221,4134)'), ('usv_2', '(225,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6630651300537918), 'usv_1': np.float64(-1.5831284256403393)}
    Episode time: 48.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 1485, Avg Reward: 7.640, Episode Reward: 11345.5
    æ£€æµ‹è¿›åº¦: 2/34 (5.9%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(356,3074)'), ('usv_1', '(221,4177)'), ('usv_2', '(219,5066)')]...
    Recent rewards sample: {'usv_0': np.float64(6.933819077343527), 'usv_1': np.float64(0.4222460610591532)}
    Episode time: 148.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 2485, Avg Reward: 13.731, Episode Reward: 34122.8
    æ£€æµ‹è¿›åº¦: 3/63 (4.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(450,3009)'), ('usv_1', '(204,4183)'), ('usv_2', '(203,5032)')]...
    Recent rewards sample: {'usv_0': np.float64(5.947070356669735), 'usv_1': np.float64(1.418101768030842)}
    Episode time: 248.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 46949.6
  Targets Detected: 8/69 (7.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.64
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 484, Avg Reward: 22.077, Episode Reward: 10685.0
    æ£€æµ‹è¿›åº¦: 5/17 (29.4%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3124)'), ('usv_1', '(227,4136)'), ('usv_2', '(232,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3266592965577813), 'usv_1': np.float64(3.4173507990836285)}
    Episode time: 48.4s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.09490516 0.01317812] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 1484, Avg Reward: 20.369, Episode Reward: 30228.0
    æ£€æµ‹è¿›åº¦: 3/31 (9.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(332,3066)'), ('usv_1', '(247,4166)'), ('usv_2', '(257,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(5.926822295126902), 'usv_1': np.float64(3.422043587654959)}
    Episode time: 148.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 37224.5
  Targets Detected: 5/38 (7.9%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_152s
  Average Reward/Step: 20.67
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 683, Avg Reward: -2.427, Episode Reward: -1657.6
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3108)'), ('usv_1', '(236,4139)'), ('usv_2', '(218,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3342149282203243), 'usv_1': np.float64(-0.5809466070019494)}
    Episode time: 68.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 1683, Avg Reward: 10.144, Episode Reward: 17071.6
    æ£€æµ‹è¿›åº¦: 3/41 (7.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(335,3028)'), ('usv_1', '(253,4163)'), ('usv_2', '(216,5086)')]...
    Recent rewards sample: {'usv_0': np.float64(7.926745907444026), 'usv_1': np.float64(1.4228998652639309)}
    Episode time: 168.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 29231.0
  Targets Detected: 6/47 (6.4%)
  Steps: 2191
  Episode Time: 219.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.34
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 492, Avg Reward: -3.596, Episode Reward: -1769.1
    æ£€æµ‹è¿›åº¦: 0/9 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3128)'), ('usv_1', '(225,4134)'), ('usv_2', '(223,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6765298828392373), 'usv_1': np.float64(-1.580798675734932)}
    Episode time: 49.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 1492, Avg Reward: -3.586, Episode Reward: -5350.2
    æ£€æµ‹è¿›åº¦: 0/30 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(337,3141)'), ('usv_1', '(250,4160)'), ('usv_2', '(247,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6530393877250629), 'usv_1': np.float64(-1.578764288026261)}
    Episode time: 149.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: -6444.7
  Targets Detected: 0/39 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.58

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 28855.5
Last 10 episodes average detections: 4.5
Best episode reward so far: 69141.5
Best detection count so far: 12
Learning trend: Declining (28855.5 vs 29353.4)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.28508739 -0.19634531] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 691, Avg Reward: 9.912, Episode Reward: 6849.2
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3117)'), ('usv_1', '(241,4140)'), ('usv_2', '(232,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(4.28702626454154), 'usv_1': np.float64(1.3686451021674353)}
    Episode time: 69.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 1691, Avg Reward: 16.138, Episode Reward: 27289.5
    æ£€æµ‹è¿›åº¦: 5/51 (9.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(365,3092)'), ('usv_1', '(257,4168)'), ('usv_2', '(276,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(4.316437294363338), 'usv_1': np.float64(1.3726893814385894)}
    Episode time: 169.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 2691, Avg Reward: 17.646, Episode Reward: 47484.7
    æ£€æµ‹è¿›åº¦: 9/82 (11.0%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(451,3037)'), ('usv_1', '(249,4154)'), ('usv_2', '(299,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(7.886447858815622), 'usv_1': np.float64(3.370981229203915)}
    Episode time: 269.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 50511.7
  Targets Detected: 13/90 (12.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.83
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 690, Avg Reward: 4.588, Episode Reward: 3165.4
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3116)'), ('usv_1', '(224,4148)'), ('usv_2', '(226,5114)')]...
    Recent rewards sample: {'usv_0': np.float64(0.28982298026773967), 'usv_1': np.float64(-0.6328747170852589)}
    Episode time: 69.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 1690, Avg Reward: 8.682, Episode Reward: 14671.9
    æ£€æµ‹è¿›åº¦: 3/45 (6.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(378,3054)'), ('usv_1', '(205,4184)'), ('usv_2', '(211,5076)')]...
    Recent rewards sample: {'usv_0': np.float64(5.895217795511661), 'usv_1': np.float64(1.371688090076567)}
    Episode time: 169.0s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.14076221 0.13343183] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 2690, Avg Reward: 15.329, Episode Reward: 41234.0
    æ£€æµ‹è¿›åº¦: 8/72 (11.1%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(428,2977)'), ('usv_1', '(206,4172)'), ('usv_2', '(200,5046)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8917826120030785), 'usv_1': np.float64(3.3671419043852824)}
    Episode time: 269.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 50790.4
  Targets Detected: 10/81 (11.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.92
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 689, Avg Reward: 6.093, Episode Reward: 4197.8
    æ£€æµ‹è¿›åº¦: 3/27 (11.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3110)'), ('usv_1', '(238,4146)'), ('usv_2', '(237,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2840463362065697), 'usv_1': np.float64(2.36822086286337)}
    Episode time: 68.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 1689, Avg Reward: 15.361, Episode Reward: 25944.9
    æ£€æµ‹è¿›åº¦: 5/57 (8.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(361,3052)'), ('usv_1', '(234,4185)'), ('usv_2', '(268,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(5.889191417021656), 'usv_1': np.float64(3.3683904446056863)}
    Episode time: 168.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 2689, Avg Reward: 18.114, Episode Reward: 48707.4
    æ£€æµ‹è¿›åº¦: 6/76 (7.9%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(384,2963)'), ('usv_1', '(211,4174)'), ('usv_2', '(274,5071)')]...
    Recent rewards sample: {'usv_0': np.float64(5.888004869609435), 'usv_1': np.float64(3.366431397367058)}
    Episode time: 268.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 55430.9
  Targets Detected: 8/84 (7.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.47
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 688, Avg Reward: 3.838, Episode Reward: 2640.9
    æ£€æµ‹è¿›åº¦: 2/27 (7.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3108)'), ('usv_1', '(236,4126)'), ('usv_2', '(244,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(0.28389045812633407), 'usv_1': np.float64(1.368459915235233)}
    Episode time: 68.8s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.20632242 -0.01129941] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 1688, Avg Reward: 9.214, Episode Reward: 15552.9
    æ£€æµ‹è¿›åº¦: 3/51 (5.9%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(375,3063)'), ('usv_1', '(219,4170)'), ('usv_2', '(276,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(7.886037836821706), 'usv_1': np.float64(3.3711393736588118)}
    Episode time: 168.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 2688, Avg Reward: 10.341, Episode Reward: 27796.3
    æ£€æµ‹è¿›åº¦: 7/81 (8.6%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(433,2986)'), ('usv_1', '(206,4163)'), ('usv_2', '(294,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(7.897949685031504), 'usv_1': np.float64(1.365930080927503)}
    Episode time: 268.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 33985.4
  Targets Detected: 7/86 (8.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.32
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 687, Avg Reward: -3.950, Episode Reward: -2713.7
    æ£€æµ‹è¿›åº¦: 0/21 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(272,3144)'), ('usv_1', '(228,4149)'), ('usv_2', '(235,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7158063034994189), 'usv_1': np.float64(-1.6284997082978099)}
    Episode time: 68.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 1687, Avg Reward: -0.606, Episode Reward: -1023.0
    æ£€æµ‹è¿›åº¦: 1/52 (1.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(320,3077)'), ('usv_1', '(224,4188)'), ('usv_2', '(279,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(3.879233994364229), 'usv_1': np.float64(-0.6313187301731652)}
    Episode time: 168.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 2687, Avg Reward: 4.336, Episode Reward: 11650.0
    æ£€æµ‹è¿›åº¦: 4/74 (5.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(343,2976)'), ('usv_1', '(204,4193)'), ('usv_2', '(314,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(4.881500229066649), 'usv_1': np.float64(2.375115874230649)}
    Episode time: 268.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 17468.1
  Targets Detected: 4/84 (4.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 5.82
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.25063593 -0.19345793] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 686, Avg Reward: 4.763, Episode Reward: 3267.4
    æ£€æµ‹è¿›åº¦: 2/38 (5.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3131)'), ('usv_1', '(237,4131)'), ('usv_2', '(236,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2887405925524327), 'usv_1': np.float64(0.36907826360364826)}
    Episode time: 68.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 1686, Avg Reward: 14.494, Episode Reward: 24437.0
    æ£€æµ‹è¿›åº¦: 7/66 (10.6%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(371,3080)'), ('usv_1', '(258,4149)'), ('usv_2', '(275,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(7.880619894130438), 'usv_1': np.float64(3.372999947795571)}
    Episode time: 168.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 2686, Avg Reward: 19.457, Episode Reward: 52260.9
    æ£€æµ‹è¿›åº¦: 11/99 (11.1%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(447,3005)'), ('usv_1', '(242,4165)'), ('usv_2', '(314,5105)')]...
    Recent rewards sample: {'usv_0': np.float64(7.896466446557688), 'usv_1': np.float64(3.3686393010161817)}
    Episode time: 268.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 61776.1
  Targets Detected: 13/108 (12.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.59
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 685, Avg Reward: 16.563, Episode Reward: 11345.3
    æ£€æµ‹è¿›åº¦: 6/30 (20.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(291,3127)'), ('usv_1', '(226,4137)'), ('usv_2', '(243,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(4.283661201847541), 'usv_1': np.float64(3.367298195090969)}
    Episode time: 68.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 1685, Avg Reward: 18.872, Episode Reward: 31798.5
    æ£€æµ‹è¿›åº¦: 5/64 (7.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(369,3090)'), ('usv_1', '(242,4190)'), ('usv_2', '(273,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(4.3099109210582345), 'usv_1': np.float64(3.378664712128818)}
    Episode time: 168.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 35042.2
  Targets Detected: 8/71 (8.5%)
  Steps: 1825
  Episode Time: 182.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 19.20
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.16754821 -0.08371927] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 860, Avg Reward: -3.637, Episode Reward: -3127.4
    æ£€æµ‹è¿›åº¦: 0/28 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(298,3138)'), ('usv_1', '(226,4154)'), ('usv_2', '(255,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2907650977088656), 'usv_1': np.float64(-0.6326144483452367)}
    Episode time: 86.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 1860, Avg Reward: 0.467, Episode Reward: 869.5
    æ£€æµ‹è¿›åº¦: 1/50 (2.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(408,3125)'), ('usv_1', '(207,4188)'), ('usv_2', '(260,5085)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3145787547506942), 'usv_1': np.float64(-0.6328625936650212)}
    Episode time: 186.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 1458.6
  Targets Detected: 1/57 (1.8%)
  Steps: 2133
  Episode Time: 213.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 0.68
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 727, Avg Reward: 8.444, Episode Reward: 6138.9
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3125)'), ('usv_1', '(239,4139)'), ('usv_2', '(227,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2784377942362894), 'usv_1': np.float64(3.3682476713753484)}
    Episode time: 72.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 1727, Avg Reward: 15.864, Episode Reward: 27396.4
    æ£€æµ‹è¿›åº¦: 3/38 (7.9%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(344,3065)'), ('usv_1', '(215,4156)'), ('usv_2', '(211,5092)')]...
    Recent rewards sample: {'usv_0': np.float64(5.881760402318519), 'usv_1': np.float64(3.366545455022843)}
    Episode time: 172.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 33715.3
  Targets Detected: 4/51 (5.9%)
  Steps: 2019
  Episode Time: 201.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.70
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 708, Avg Reward: 8.306, Episode Reward: 5880.4
    æ£€æµ‹è¿›åº¦: 5/36 (13.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(281,3126)'), ('usv_1', '(238,4140)'), ('usv_2', '(241,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2866339058808536), 'usv_1': np.float64(0.3682206862146502)}
    Episode time: 70.8s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.1140958  -0.01474173] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 100000, Episode Steps: 1708, Avg Reward: 11.465, Episode Reward: 19581.8
    æ£€æµ‹è¿›åº¦: 4/67 (6.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(349,3065)'), ('usv_1', '(221,4154)'), ('usv_2', '(267,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(7.886421479087023), 'usv_1': np.float64(1.367984386210963)}
    Episode time: 170.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 21609.3
  Targets Detected: 5/68 (5.9%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_121s
  Average Reward/Step: 12.00

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 36178.8
Last 10 episodes average detections: 7.3
Best episode reward so far: 69141.5
Best detection count so far: 13
Learning trend: Improving (36178.8 vs 28855.5)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 101000, Episode Steps: 907, Avg Reward: 12.797, Episode Reward: 11606.6
    æ£€æµ‹è¿›åº¦: 3/22 (13.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(324,3099)'), ('usv_1', '(239,4155)'), ('usv_2', '(239,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(4.297100623843818), 'usv_1': np.float64(3.3683633681406677)}
    Episode time: 90.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 102000, Episode Steps: 1907, Avg Reward: 19.575, Episode Reward: 37329.8
    æ£€æµ‹è¿›åº¦: 4/50 (8.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(400,3042)'), ('usv_1', '(221,4147)'), ('usv_2', '(244,5070)')]...
    Recent rewards sample: {'usv_0': np.float64(13.194760422173376), 'usv_1': np.float64(3.3683720554610623)}
    Episode time: 190.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 103000, Episode Steps: 2907, Avg Reward: 21.271, Episode Reward: 61833.8
    æ£€æµ‹è¿›åº¦: 7/73 (9.6%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(431,2954)'), ('usv_1', '(239,4119)'), ('usv_2', '(235,5017)')]...
    Recent rewards sample: {'usv_0': np.float64(5.8979779385792614), 'usv_1': np.float64(3.368283352232753)}
    Episode time: 290.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 64231.1
  Targets Detected: 8/75 (9.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.40
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 104000, Episode Steps: 906, Avg Reward: 0.560, Episode Reward: 507.5
    æ£€æµ‹è¿›åº¦: 2/24 (8.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(310,3103)'), ('usv_1', '(221,4153)'), ('usv_2', '(239,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2919396495707738), 'usv_1': np.float64(-0.6330050244170987)}
    Episode time: 90.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.06672777 0.08276147] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 105000, Episode Steps: 1906, Avg Reward: 6.404, Episode Reward: 12205.1
    æ£€æµ‹è¿›åº¦: 4/56 (7.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(342,3007)'), ('usv_1', '(205,4175)'), ('usv_2', '(230,5087)')]...
    Recent rewards sample: {'usv_0': np.float64(5.8871511244405195), 'usv_1': np.float64(3.3726402046953003)}
    Episode time: 190.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 106000, Episode Steps: 2906, Avg Reward: 9.180, Episode Reward: 26676.4
    æ£€æµ‹è¿›åº¦: 8/84 (9.5%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,2908)'), ('usv_1', '(211,4135)'), ('usv_2', '(208,5089)')]...
    Recent rewards sample: {'usv_0': np.float64(7.885181194756576), 'usv_1': np.float64(3.372827993720777)}
    Episode time: 290.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 27080.4
  Targets Detected: 11/86 (9.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.02
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 107000, Episode Steps: 905, Avg Reward: 4.723, Episode Reward: 4273.9
    æ£€æµ‹è¿›åº¦: 2/28 (7.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(289,3086)'), ('usv_1', '(243,4147)'), ('usv_2', '(236,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(3.8747915136939985), 'usv_1': np.float64(-0.6284696087821973)}
    Episode time: 90.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 108000, Episode Steps: 1905, Avg Reward: 15.392, Episode Reward: 29322.4
    æ£€æµ‹è¿›åº¦: 7/60 (11.7%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(311,2970)'), ('usv_1', '(218,4169)'), ('usv_2', '(218,5066)')]...
    Recent rewards sample: {'usv_0': np.float64(5.878753991143468), 'usv_1': np.float64(3.368947236690641)}
    Episode time: 190.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 47017.4
  Targets Detected: 9/78 (6.4%)
  Steps: 2605
  Episode Time: 260.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.05
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 109000, Episode Steps: 300, Avg Reward: -3.916, Episode Reward: -1174.8
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3126)'), ('usv_1', '(225,4132)'), ('usv_2', '(222,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7161832220313975), 'usv_1': np.float64(-1.6308678997226647)}
    Episode time: 30.0s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.03668312 -0.0708853 ] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 110000, Episode Steps: 1300, Avg Reward: 3.261, Episode Reward: 4238.7
    æ£€æµ‹è¿›åº¦: 1/33 (3.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(325,3043)'), ('usv_1', '(227,4156)'), ('usv_2', '(249,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(6.877527726741129), 'usv_1': np.float64(0.3674438124384569)}
    Episode time: 130.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 111000, Episode Steps: 2300, Avg Reward: 12.275, Episode Reward: 28232.1
    æ£€æµ‹è¿›åº¦: 6/61 (9.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(320,2948)'), ('usv_1', '(201,4185)'), ('usv_2', '(244,5073)')]...
    Recent rewards sample: {'usv_0': np.float64(7.878083930941752), 'usv_1': np.float64(1.3659153653891423)}
    Episode time: 230.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 44232.5
  Targets Detected: 8/75 (9.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.74
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 112000, Episode Steps: 299, Avg Reward: -2.689, Episode Reward: -804.1
    æ£€æµ‹è¿›åº¦: 1/8 (12.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3126)'), ('usv_1', '(223,4131)'), ('usv_2', '(222,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7217453456775255), 'usv_1': np.float64(-1.6328641477504722)}
    Episode time: 29.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 113000, Episode Steps: 1299, Avg Reward: 6.332, Episode Reward: 8225.7
    æ£€æµ‹è¿›åº¦: 5/43 (11.6%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(331,3084)'), ('usv_1', '(237,4164)'), ('usv_2', '(206,5087)')]...
    Recent rewards sample: {'usv_0': np.float64(7.878491786271012), 'usv_1': np.float64(1.3682610298561517)}
    Episode time: 129.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 114000, Episode Steps: 2299, Avg Reward: 13.385, Episode Reward: 30772.9
    æ£€æµ‹è¿›åº¦: 7/75 (9.3%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(390,2968)'), ('usv_1', '(202,4172)'), ('usv_2', '(206,5059)')]...
    Recent rewards sample: {'usv_0': np.float64(7.882256201071212), 'usv_1': np.float64(3.368934515246039)}
    Episode time: 229.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 49263.7
  Targets Detected: 9/91 (9.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.42
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.24082925 0.03113877] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 115000, Episode Steps: 298, Avg Reward: -3.544, Episode Reward: -1056.0
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3126)'), ('usv_1', '(230,4129)'), ('usv_2', '(220,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2744185501698606), 'usv_1': np.float64(-0.6271910325832575)}
    Episode time: 29.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 116000, Episode Steps: 1298, Avg Reward: 10.379, Episode Reward: 13472.1
    æ£€æµ‹è¿›åº¦: 3/29 (10.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(318,3074)'), ('usv_1', '(266,4143)'), ('usv_2', '(262,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(5.876304797904419), 'usv_1': np.float64(1.376309186339241)}
    Episode time: 129.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 117000, Episode Steps: 2298, Avg Reward: 17.810, Episode Reward: 40927.3
    æ£€æµ‹è¿›åº¦: 8/62 (12.9%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(341,2977)'), ('usv_1', '(280,4180)'), ('usv_2', '(310,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(7.878555649156521), 'usv_1': np.float64(1.371747743024367)}
    Episode time: 229.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 57658.7
  Targets Detected: 10/77 (9.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.21
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 118000, Episode Steps: 297, Avg Reward: -1.960, Episode Reward: -582.0
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3128)'), ('usv_1', '(219,4133)'), ('usv_2', '(224,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2754060353798554), 'usv_1': np.float64(1.3683345978310477)}
    Episode time: 29.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 119000, Episode Steps: 1297, Avg Reward: 12.804, Episode Reward: 16607.2
    æ£€æµ‹è¿›åº¦: 4/39 (10.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3048)'), ('usv_1', '(243,4175)'), ('usv_2', '(261,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(7.875577644070535), 'usv_1': np.float64(3.3769002293914046)}
    Episode time: 129.7s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.17342877 -0.31150514] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 120000, Episode Steps: 2297, Avg Reward: 12.456, Episode Reward: 28610.8
    æ£€æµ‹è¿›åº¦: 5/61 (8.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,2962)'), ('usv_1', '(215,4197)'), ('usv_2', '(296,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8746487426745), 'usv_1': np.float64(1.3681794577787345)}
    Episode time: 229.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 32870.2
  Targets Detected: 6/77 (6.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.95
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 121000, Episode Steps: 296, Avg Reward: -3.922, Episode Reward: -1161.0
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3128)'), ('usv_1', '(226,4131)'), ('usv_2', '(226,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7145453344801398), 'usv_1': np.float64(-1.629714113411394)}
    Episode time: 29.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 122000, Episode Steps: 1296, Avg Reward: 8.302, Episode Reward: 10759.9
    æ£€æµ‹è¿›åº¦: 4/43 (9.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(321,3042)'), ('usv_1', '(254,4161)'), ('usv_2', '(250,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8819295124608635), 'usv_1': np.float64(3.3695095840055727)}
    Episode time: 129.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 123000, Episode Steps: 2296, Avg Reward: 18.126, Episode Reward: 41617.9
    æ£€æµ‹è¿›åº¦: 9/73 (12.3%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(334,2945)'), ('usv_1', '(245,4173)'), ('usv_2', '(274,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(7.879822889626645), 'usv_1': np.float64(3.3715423529633624)}
    Episode time: 229.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 60817.7
  Targets Detected: 12/87 (10.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.27
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 124000, Episode Steps: 295, Avg Reward: -3.923, Episode Reward: -1157.2
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3128)'), ('usv_1', '(220,4134)'), ('usv_2', '(218,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7309436031376604), 'usv_1': np.float64(-1.6332254473770351)}
    Episode time: 29.5s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.36126359 0.22010872] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 125000, Episode Steps: 1295, Avg Reward: 1.521, Episode Reward: 1969.5
    æ£€æµ‹è¿›åº¦: 1/30 (3.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(329,3062)'), ('usv_1', '(225,4187)'), ('usv_2', '(235,5105)')]...
    Recent rewards sample: {'usv_0': np.float64(4.883656999903233), 'usv_1': np.float64(0.36875720314172256)}
    Episode time: 129.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 126000, Episode Steps: 2295, Avg Reward: 8.581, Episode Reward: 19692.8
    æ£€æµ‹è¿›åº¦: 5/72 (6.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(359,2968)'), ('usv_1', '(204,4190)'), ('usv_2', '(223,5079)')]...
    Recent rewards sample: {'usv_0': np.float64(5.880092426798241), 'usv_1': np.float64(1.3662814184417313)}
    Episode time: 229.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 36890.6
  Targets Detected: 6/94 (4.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.29
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 127000, Episode Steps: 294, Avg Reward: -3.817, Episode Reward: -1122.2
    æ£€æµ‹è¿›åº¦: 0/17 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3125)'), ('usv_1', '(222,4134)'), ('usv_2', '(225,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2793011834570156), 'usv_1': np.float64(-0.633027498363051)}
    Episode time: 29.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 128000, Episode Steps: 1294, Avg Reward: 8.515, Episode Reward: 11019.0
    æ£€æµ‹è¿›åº¦: 3/48 (6.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(350,3091)'), ('usv_1', '(219,4164)'), ('usv_2', '(218,5109)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3198696217236985), 'usv_1': np.float64(1.3668863804953997)}
    Episode time: 129.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0359, Avg Critic Loss: 166.9738
    Step 129000, Episode Steps: 2294, Avg Reward: 14.475, Episode Reward: 33204.8
    æ£€æµ‹è¿›åº¦: 9/77 (11.7%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(439,3023)'), ('usv_1', '(209,4142)'), ('usv_2', '(201,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(5.891426056917743), 'usv_1': np.float64(1.3739800883145121)}
    Episode time: 229.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 49755.7
  Targets Detected: 11/88 (9.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.58

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 46981.8
Last 10 episodes average detections: 9.0
Best episode reward so far: 69141.5
Best detection count so far: 13
Learning trend: Improving (46981.8 vs 36178.8)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 69141.5
Final 10 episodes average: 46981.8
Best detection performance: 13 targets
Average detections (final 10): 9.0
============================================================
{"final_avg_reward": 46981.79787078619, "final_detection_rate": 9.0, "best_episode_reward": 69141.53669193728, "best_detection_count": 13, "total_episodes": 50}
Simulation finished.
