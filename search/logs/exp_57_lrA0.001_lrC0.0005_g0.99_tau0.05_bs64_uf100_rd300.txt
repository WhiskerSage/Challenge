D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: -2.760, Episode Reward: -2759.7
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3116)'), ('usv_1', '(286,4120)'), ('usv_2', '(306,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(1.381030013679481), 'usv_1': np.float64(2.478059666631495)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 9.725, Episode Reward: 19449.3
    æ£€æµ‹è¿›åº¦: 4/20 (20.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3031)'), ('usv_1', '(360,4070)'), ('usv_2', '(379,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(5.974424595550068), 'usv_1': np.float64(3.4778934058059434)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 3000, Avg Reward: 14.254, Episode Reward: 42760.9
    æ£€æµ‹è¿›åº¦: 6/42 (14.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,2985)'), ('usv_1', '(457,4067)'), ('usv_2', '(457,5178)')]...
    Recent rewards sample: {'usv_0': np.float64(6.1850850879977815), 'usv_1': np.float64(1.5048387603198345)}
    Episode time: 300.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 42781.7
  Targets Detected: 6/42 (14.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.26
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 999, Avg Reward: 10.910, Episode Reward: 10899.5
    æ£€æµ‹è¿›åº¦: 1/14 (7.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3104)'), ('usv_1', '(306,4138)'), ('usv_2', '(271,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3855942926847034), 'usv_1': np.float64(0.4866202695284547)}
    Episode time: 99.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 24970.4
  Targets Detected: 3/25 (8.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_147s
  Average Reward/Step: 13.86
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.3272365  -0.35199542] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 198, Avg Reward: 0.287, Episode Reward: 56.8
    æ£€æµ‹è¿›åº¦: 0/9 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(223,3126)'), ('usv_1', '(235,4127)'), ('usv_2', '(221,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3772635132154343), 'usv_1': np.float64(-0.527411739711374)}
    Episode time: 19.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 1198, Avg Reward: 9.149, Episode Reward: 10961.0
    æ£€æµ‹è¿›åº¦: 3/24 (12.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3113)'), ('usv_1', '(310,4095)'), ('usv_2', '(294,5148)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3873242987908987), 'usv_1': np.float64(1.4766859941646238)}
    Episode time: 119.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 2198, Avg Reward: 12.946, Episode Reward: 28455.0
    æ£€æµ‹è¿›åº¦: 3/45 (6.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(345,3074)'), ('usv_1', '(355,4006)'), ('usv_2', '(333,5187)')]...
    Recent rewards sample: {'usv_0': np.float64(5.979312897310571), 'usv_1': np.float64(1.487821400465947)}
    Episode time: 219.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 32477.7
  Targets Detected: 3/45 (6.7%)
  Steps: 2394
  Episode Time: 239.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.57
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 804, Avg Reward: -3.234, Episode Reward: -2600.2
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(272,3132)'), ('usv_1', '(296,4114)'), ('usv_2', '(267,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6177551178938141), 'usv_1': np.float64(-1.5194538295963218)}
    Episode time: 80.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 1804, Avg Reward: 0.425, Episode Reward: 766.5
    æ£€æµ‹è¿›åº¦: 1/29 (3.4%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(334,3120)'), ('usv_1', '(386,4100)'), ('usv_2', '(331,5196)')]...
    Recent rewards sample: {'usv_0': np.float64(4.406573391166969), 'usv_1': np.float64(1.486530591638462)}
    Episode time: 180.4s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.04011146 -0.49119713] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 2804, Avg Reward: 7.624, Episode Reward: 21377.2
    æ£€æµ‹è¿›åº¦: 3/41 (7.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(380,3081)'), ('usv_1', '(469,4098)'), ('usv_2', '(388,5231)')]...
    Recent rewards sample: {'usv_0': np.float64(8.0255902096238), 'usv_1': np.float64(1.4912906218885955)}
    Episode time: 280.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 25869.8
  Targets Detected: 4/43 (7.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 8.62
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 803, Avg Reward: -3.242, Episode Reward: -2603.3
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3127)'), ('usv_1', '(304,4148)'), ('usv_2', '(263,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6193626169929041), 'usv_1': np.float64(-1.5177800491591267)}
    Episode time: 80.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 1803, Avg Reward: -0.556, Episode Reward: -1002.9
    æ£€æµ‹è¿›åº¦: 1/28 (3.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(320,3104)'), ('usv_1', '(376,4193)'), ('usv_2', '(334,5175)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3988932040403512), 'usv_1': np.float64(-0.5073910415241635)}
    Episode time: 180.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 2803, Avg Reward: 8.233, Episode Reward: 23077.8
    æ£€æµ‹è¿›åº¦: 5/43 (11.6%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(348,3057)'), ('usv_1', '(420,4257)'), ('usv_2', '(417,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(8.10659299603368), 'usv_1': np.float64(1.4864852831270965)}
    Episode time: 280.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 27615.3
  Targets Detected: 6/47 (10.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.20
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 802, Avg Reward: 4.731, Episode Reward: 3794.4
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3132)'), ('usv_1', '(301,4133)'), ('usv_2', '(268,5089)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3738145206345145), 'usv_1': np.float64(1.4771119598755589)}
    Episode time: 80.2s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.00536863 -0.28135561] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 1802, Avg Reward: 11.964, Episode Reward: 21559.1
    æ£€æµ‹è¿›åº¦: 6/31 (19.4%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(289,3104)'), ('usv_1', '(390,4143)'), ('usv_2', '(329,5096)')]...
    Recent rewards sample: {'usv_0': np.float64(4.386214399923958), 'usv_1': np.float64(1.4818791311267936)}
    Episode time: 180.2s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 2802, Avg Reward: 16.037, Episode Reward: 44935.5
    æ£€æµ‹è¿›åº¦: 9/50 (18.0%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(323,3049)'), ('usv_1', '(457,4155)'), ('usv_2', '(412,5116)')]...
    Recent rewards sample: {'usv_0': np.float64(7.975702442956071), 'usv_1': np.float64(1.494884892016573)}
    Episode time: 280.2s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 49421.2
  Targets Detected: 9/55 (16.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.47
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 801, Avg Reward: -3.251, Episode Reward: -2604.1
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3139)'), ('usv_1', '(270,4153)'), ('usv_2', '(257,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6292820449448491), 'usv_1': np.float64(-1.5221657320447615)}
    Episode time: 80.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 1801, Avg Reward: -3.210, Episode Reward: -5781.3
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(298,3140)'), ('usv_1', '(358,4186)'), ('usv_2', '(321,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6156150881076121), 'usv_1': np.float64(-1.5199264328404696)}
    Episode time: 180.1s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: -5781.3
  Targets Detected: 0/12 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.21
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 1000, Avg Reward: 15.562, Episode Reward: 15561.5
    æ£€æµ‹è¿›åº¦: 2/17 (11.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3143)'), ('usv_1', '(293,4111)'), ('usv_2', '(267,5153)')]...
    Recent rewards sample: {'usv_0': np.float64(2.379463121130999), 'usv_1': np.float64(3.475395539667642)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 30667.5
  Targets Detected: 3/19 (10.5%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_139s
  Average Reward/Step: 17.03
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.28624223 0.11376041] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 199, Avg Reward: 1.823, Episode Reward: 362.8
    æ£€æµ‹è¿›åº¦: 1/6 (16.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3130)'), ('usv_1', '(227,4131)'), ('usv_2', '(220,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(0.370210404668181), 'usv_1': np.float64(-0.5306656314763837)}
    Episode time: 19.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 1199, Avg Reward: 9.850, Episode Reward: 11810.6
    æ£€æµ‹è¿›åº¦: 3/23 (13.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(281,3117)'), ('usv_1', '(319,4149)'), ('usv_2', '(277,5100)')]...
    Recent rewards sample: {'usv_0': np.float64(2.383212943594909), 'usv_1': np.float64(1.478379812400961)}
    Episode time: 119.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 2199, Avg Reward: 15.421, Episode Reward: 33910.9
    æ£€æµ‹è¿›åº¦: 4/31 (12.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(294,3054)'), ('usv_1', '(387,4191)'), ('usv_2', '(332,5080)')]...
    Recent rewards sample: {'usv_0': np.float64(5.987807855800499), 'usv_1': np.float64(3.4908090956612776)}
    Episode time: 219.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 53807.1
  Targets Detected: 6/41 (9.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.93
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 198, Avg Reward: 4.288, Episode Reward: 849.0
    æ£€æµ‹è¿›åº¦: 1/3 (33.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3130)'), ('usv_1', '(236,4132)'), ('usv_2', '(224,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(0.36685564079480726), 'usv_1': np.float64(-0.5307201535619952)}
    Episode time: 19.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 1198, Avg Reward: 12.977, Episode Reward: 15547.0
    æ£€æµ‹è¿›åº¦: 3/17 (17.6%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3114)'), ('usv_1', '(321,4174)'), ('usv_2', '(286,5166)')]...
    Recent rewards sample: {'usv_0': np.float64(4.385782486225942), 'usv_1': np.float64(1.4781382435506965)}
    Episode time: 119.8s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.19634078  0.00805455] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 2198, Avg Reward: 17.191, Episode Reward: 37784.9
    æ£€æµ‹è¿›åº¦: 5/27 (18.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(283,3051)'), ('usv_1', '(397,4225)'), ('usv_2', '(347,5219)')]...
    Recent rewards sample: {'usv_0': np.float64(7.972529101851137), 'usv_1': np.float64(1.4915949619674027)}
    Episode time: 219.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 56732.3
  Targets Detected: 6/42 (11.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.90

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 33856.2
Last 10 episodes average detections: 4.6
Best episode reward so far: 56732.3
Best detection count so far: 9
Buffer size: 25803
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 197, Avg Reward: -1.958, Episode Reward: -385.7
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3132)'), ('usv_1', '(225,4129)'), ('usv_2', '(219,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(0.31871999552594665), 'usv_1': np.float64(-0.582849212668811)}
    Episode time: 19.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 1197, Avg Reward: 8.285, Episode Reward: 9917.2
    æ£€æµ‹è¿›åº¦: 3/34 (8.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3099)'), ('usv_1', '(315,4092)'), ('usv_2', '(300,5162)')]...
    Recent rewards sample: {'usv_0': np.float64(4.344212572232346), 'usv_1': np.float64(1.4272264998521975)}
    Episode time: 119.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 2197, Avg Reward: 15.014, Episode Reward: 32985.3
    æ£€æµ‹è¿›åº¦: 4/48 (8.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3026)'), ('usv_1', '(387,4050)'), ('usv_2', '(341,5210)')]...
    Recent rewards sample: {'usv_0': np.float64(7.921510175641435), 'usv_1': np.float64(1.4301681006574434)}
    Episode time: 219.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 55466.9
  Targets Detected: 13/72 (16.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.48
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 196, Avg Reward: -3.571, Episode Reward: -699.9
    æ£€æµ‹è¿›åº¦: 0/9 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3132)'), ('usv_1', '(232,4131)'), ('usv_2', '(228,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6789293453827845), 'usv_1': np.float64(-1.5822513425821463)}
    Episode time: 19.6s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.20212458 0.12081702] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 1196, Avg Reward: 11.997, Episode Reward: 14348.7
    æ£€æµ‹è¿›åº¦: 2/37 (5.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3085)'), ('usv_1', '(303,4150)'), ('usv_2', '(282,5163)')]...
    Recent rewards sample: {'usv_0': np.float64(5.926883778862422), 'usv_1': np.float64(1.4309023438783286)}
    Episode time: 119.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 27740.6
  Targets Detected: 3/49 (2.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_141s
  Average Reward/Step: 15.40
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 395, Avg Reward: 0.987, Episode Reward: 389.7
    æ£€æµ‹è¿›åº¦: 1/12 (8.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3128)'), ('usv_1', '(244,4130)'), ('usv_2', '(239,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3189533253989714), 'usv_1': np.float64(0.42399074209398635)}
    Episode time: 39.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 1395, Avg Reward: 11.373, Episode Reward: 15864.8
    æ£€æµ‹è¿›åº¦: 3/46 (6.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(300,3099)'), ('usv_1', '(317,4137)'), ('usv_2', '(332,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(4.339740520153004), 'usv_1': np.float64(1.4308621360764349)}
    Episode time: 139.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 2395, Avg Reward: 15.940, Episode Reward: 38175.2
    æ£€æµ‹è¿›åº¦: 7/73 (9.6%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(348,3060)'), ('usv_1', '(393,4140)'), ('usv_2', '(400,5093)')]...
    Recent rewards sample: {'usv_0': np.float64(7.927136188550392), 'usv_1': np.float64(1.442394871319923)}
    Episode time: 239.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 53287.6
  Targets Detected: 11/84 (11.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.76
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 394, Avg Reward: 2.176, Episode Reward: 857.5
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3120)'), ('usv_1', '(239,4129)'), ('usv_2', '(232,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3275214356937735), 'usv_1': np.float64(-0.5817543729760829)}
    Episode time: 39.4s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.11576604 -0.24026413] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 1394, Avg Reward: 7.085, Episode Reward: 9876.2
    æ£€æµ‹è¿›åº¦: 1/33 (3.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3054)'), ('usv_1', '(314,4090)'), ('usv_2', '(306,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(7.9245985597252595), 'usv_1': np.float64(1.4315842502803307)}
    Episode time: 139.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 2394, Avg Reward: 15.567, Episode Reward: 37267.4
    æ£€æµ‹è¿›åº¦: 5/54 (9.3%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(207,3026)'), ('usv_1', '(399,4063)'), ('usv_2', '(375,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(8.031386974891085), 'usv_1': np.float64(3.432207145739092)}
    Episode time: 239.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 53207.1
  Targets Detected: 8/71 (8.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.73
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 393, Avg Reward: -3.589, Episode Reward: -1410.4
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3123)'), ('usv_1', '(247,4134)'), ('usv_2', '(232,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6754486341079794), 'usv_1': np.float64(-1.577732238458517)}
    Episode time: 39.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 1393, Avg Reward: 2.318, Episode Reward: 3228.4
    æ£€æµ‹è¿›åº¦: 4/31 (12.9%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(290,3091)'), ('usv_1', '(350,4116)'), ('usv_2', '(284,5173)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3396039001276816), 'usv_1': np.float64(0.4335891560455376)}
    Episode time: 139.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 2393, Avg Reward: 8.387, Episode Reward: 20068.9
    æ£€æµ‹è¿›åº¦: 6/61 (9.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(338,3087)'), ('usv_1', '(451,4132)'), ('usv_2', '(349,5234)')]...
    Recent rewards sample: {'usv_0': np.float64(4.353531980947107), 'usv_1': np.float64(1.4405999009282828)}
    Episode time: 239.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 33589.2
  Targets Detected: 7/71 (8.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.19
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.06048306 -0.14115127] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 392, Avg Reward: -2.193, Episode Reward: -859.8
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3125)'), ('usv_1', '(244,4135)'), ('usv_2', '(230,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32874864765458733), 'usv_1': np.float64(-0.5800737728600898)}
    Episode time: 39.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 1392, Avg Reward: 4.347, Episode Reward: 6050.4
    æ£€æµ‹è¿›åº¦: 2/26 (7.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(286,3079)'), ('usv_1', '(334,4155)'), ('usv_2', '(306,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(4.922155463812918), 'usv_1': np.float64(0.4255851206890997)}
    Episode time: 139.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 2392, Avg Reward: 10.829, Episode Reward: 25901.9
    æ£€æµ‹è¿›åº¦: 4/43 (9.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(302,3032)'), ('usv_1', '(403,4175)'), ('usv_2', '(343,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(5.929649256616361), 'usv_1': np.float64(1.4369545193998317)}
    Episode time: 239.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 39802.5
  Targets Detected: 5/50 (10.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.26
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 391, Avg Reward: -3.597, Episode Reward: -1406.6
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3120)'), ('usv_1', '(246,4132)'), ('usv_2', '(245,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6814183087953224), 'usv_1': np.float64(-1.5795057974319358)}
    Episode time: 39.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 1391, Avg Reward: -0.649, Episode Reward: -902.5
    æ£€æµ‹è¿›åº¦: 1/34 (2.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3060)'), ('usv_1', '(300,4171)'), ('usv_2', '(308,5180)')]...
    Recent rewards sample: {'usv_0': np.float64(4.920602580318424), 'usv_1': np.float64(2.425159654557159)}
    Episode time: 139.1s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.15300752 -0.08014852] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 2391, Avg Reward: 6.281, Episode Reward: 15017.5
    æ£€æµ‹è¿›åº¦: 4/52 (7.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,2988)'), ('usv_1', '(364,4251)'), ('usv_2', '(346,5232)')]...
    Recent rewards sample: {'usv_0': np.float64(6.329593205333932), 'usv_1': np.float64(3.437758367814938)}
    Episode time: 239.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 31035.9
  Targets Detected: 7/66 (9.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.34
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 390, Avg Reward: -3.595, Episode Reward: -1401.9
    æ£€æµ‹è¿›åº¦: 0/9 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3127)'), ('usv_1', '(254,4129)'), ('usv_2', '(237,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6767452450695555), 'usv_1': np.float64(-1.5789929556502345)}
    Episode time: 39.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 1390, Avg Reward: -3.555, Episode Reward: -4941.6
    æ£€æµ‹è¿›åº¦: 0/21 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(294,3108)'), ('usv_1', '(364,4170)'), ('usv_2', '(311,5154)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.657605281920142), 'usv_1': np.float64(-1.5686400690659998)}
    Episode time: 139.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: -6383.0
  Targets Detected: 0/30 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.54
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 589, Avg Reward: -3.587, Episode Reward: -2112.5
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3115)'), ('usv_1', '(259,4131)'), ('usv_2', '(244,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6754149656423969), 'usv_1': np.float64(-1.5721084362634006)}
    Episode time: 58.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 1589, Avg Reward: -0.732, Episode Reward: -1163.9
    æ£€æµ‹è¿›åº¦: 1/27 (3.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(309,3076)'), ('usv_1', '(329,4197)'), ('usv_2', '(293,5066)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9239607997757293), 'usv_1': np.float64(-0.5683624401134496)}
    Episode time: 158.9s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.21769155 -0.12046025] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 2589, Avg Reward: 5.232, Episode Reward: 13544.8
    æ£€æµ‹è¿›åº¦: 3/49 (6.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3018)'), ('usv_1', '(363,4273)'), ('usv_2', '(311,5004)')]...
    Recent rewards sample: {'usv_0': np.float64(7.93439602443334), 'usv_1': np.float64(1.438743027524998)}
    Episode time: 258.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 23377.9
  Targets Detected: 4/53 (7.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.79
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 588, Avg Reward: 4.329, Episode Reward: 2545.5
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(249,3120)'), ('usv_1', '(244,4152)'), ('usv_2', '(262,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3273361733304991), 'usv_1': np.float64(2.4193334392036236)}
    Episode time: 58.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 1588, Avg Reward: 11.236, Episode Reward: 17842.8
    æ£€æµ‹è¿›åº¦: 4/34 (11.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3068)'), ('usv_1', '(293,4228)'), ('usv_2', '(334,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(5.92657650787563), 'usv_1': np.float64(3.428095189922929)}
    Episode time: 158.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 2588, Avg Reward: 17.241, Episode Reward: 44620.4
    æ£€æµ‹è¿›åº¦: 9/57 (15.8%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(286,3025)'), ('usv_1', '(338,4279)'), ('usv_2', '(393,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(7.933031963303698), 'usv_1': np.float64(3.4282285674107493)}
    Episode time: 258.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 55566.2
  Targets Detected: 10/66 (15.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.52

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 36669.1
Last 10 episodes average detections: 6.8
Best episode reward so far: 56732.3
Best detection count so far: 13
Learning trend: Improving (36669.1 vs 33856.2)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 587, Avg Reward: 1.745, Episode Reward: 1024.0
    æ£€æµ‹è¿›åº¦: 1/12 (8.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3134)'), ('usv_1', '(272,4124)'), ('usv_2', '(253,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(3.318844260010488), 'usv_1': np.float64(0.42840772654112125)}
    Episode time: 58.7s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.04892875 -0.0314228 ] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 1587, Avg Reward: 9.700, Episode Reward: 15393.9
    æ£€æµ‹è¿›åº¦: 3/24 (12.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(312,3122)'), ('usv_1', '(349,4117)'), ('usv_2', '(330,5151)')]...
    Recent rewards sample: {'usv_0': np.float64(4.339618602847318), 'usv_1': np.float64(1.4302574983506018)}
    Episode time: 158.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 33190.8
  Targets Detected: 4/37 (8.1%)
  Steps: 2581
  Episode Time: 258.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.86
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 6, Avg Reward: -2.095, Episode Reward: -12.6
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3130)'), ('usv_1', '(211,4130)'), ('usv_2', '(211,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.676999639323334), 'usv_1': np.float64(-1.5733669383822908)}
    Episode time: 0.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 1006, Avg Reward: 10.808, Episode Reward: 10873.0
    æ£€æµ‹è¿›åº¦: 2/25 (8.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3103)'), ('usv_1', '(299,4113)'), ('usv_2', '(270,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(4.330707077678699), 'usv_1': np.float64(3.4247045501157567)}
    Episode time: 100.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 2006, Avg Reward: 17.641, Episode Reward: 35387.3
    æ£€æµ‹è¿›åº¦: 4/48 (8.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3039)'), ('usv_1', '(400,4112)'), ('usv_2', '(328,5165)')]...
    Recent rewards sample: {'usv_0': np.float64(7.933319320998159), 'usv_1': np.float64(3.4387886925570914)}
    Episode time: 200.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 64004.2
  Targets Detected: 8/63 (9.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.33
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 5, Avg Reward: -1.797, Episode Reward: -9.0
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3130)'), ('usv_1', '(211,4130)'), ('usv_2', '(211,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.676567297681232), 'usv_1': np.float64(-1.570370863912772)}
    Episode time: 0.5s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.01198541 0.08560436] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 1005, Avg Reward: -1.552, Episode Reward: -1559.4
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3089)'), ('usv_1', '(305,4130)'), ('usv_2', '(287,5118)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3304558911470338), 'usv_1': np.float64(-0.5686775182057094)}
    Episode time: 100.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 2005, Avg Reward: 12.479, Episode Reward: 25020.4
    æ£€æµ‹è¿›åº¦: 7/49 (14.3%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(234,3028)'), ('usv_1', '(379,4182)'), ('usv_2', '(346,5147)')]...
    Recent rewards sample: {'usv_0': np.float64(5.919524608055455), 'usv_1': np.float64(3.4362401827958875)}
    Episode time: 200.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 49868.3
  Targets Detected: 9/63 (12.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.62
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 4, Avg Reward: 6.651, Episode Reward: 26.6
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3130)'), ('usv_1', '(211,4130)'), ('usv_2', '(211,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3248826250493115), 'usv_1': np.float64(-0.5714015007081763)}
    Episode time: 0.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 1004, Avg Reward: 8.001, Episode Reward: 8033.5
    æ£€æµ‹è¿›åº¦: 4/24 (16.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3087)'), ('usv_1', '(264,4159)'), ('usv_2', '(272,5157)')]...
    Recent rewards sample: {'usv_0': np.float64(3.332557357678783), 'usv_1': np.float64(0.42888180144746335)}
    Episode time: 100.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 2004, Avg Reward: 16.884, Episode Reward: 33835.1
    æ£€æµ‹è¿›åº¦: 8/41 (19.5%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3037)'), ('usv_1', '(308,4218)'), ('usv_2', '(331,5186)')]...
    Recent rewards sample: {'usv_0': np.float64(7.920136140309425), 'usv_1': np.float64(1.4244664388862929)}
    Episode time: 200.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 58736.4
  Targets Detected: 10/64 (14.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.57
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.13338668  0.10595478] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 3, Avg Reward: -1.270, Episode Reward: -3.8
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3130)'), ('usv_1', '(211,4130)'), ('usv_2', '(211,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6743636537395957), 'usv_1': np.float64(-1.5704211392144987)}
    Episode time: 0.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 1003, Avg Reward: -3.569, Episode Reward: -3579.4
    æ£€æµ‹è¿›åº¦: 0/17 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3108)'), ('usv_1', '(319,4167)'), ('usv_2', '(281,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6725484039239089), 'usv_1': np.float64(-1.5707985745106292)}
    Episode time: 100.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 2003, Avg Reward: 0.437, Episode Reward: 875.7
    æ£€æµ‹è¿›åº¦: 1/35 (2.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(281,3038)'), ('usv_1', '(371,4224)'), ('usv_2', '(349,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9299074468386914), 'usv_1': np.float64(-0.5673693240058618)}
    Episode time: 200.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 6234.2
  Targets Detected: 4/50 (8.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 2.08
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 2, Avg Reward: 0.885, Episode Reward: 1.8
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3130)'), ('usv_1', '(210,4130)'), ('usv_2', '(210,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6732555828814902), 'usv_1': np.float64(-1.5694423490510774)}
    Episode time: 0.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 1002, Avg Reward: -1.017, Episode Reward: -1018.7
    æ£€æµ‹è¿›åº¦: 1/21 (4.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3114)'), ('usv_1', '(320,4142)'), ('usv_2', '(280,5076)')]...
    Recent rewards sample: {'usv_0': np.float64(2.335472842120564), 'usv_1': np.float64(-0.5730372003925723)}
    Episode time: 100.2s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.12494503  0.15678816] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 2002, Avg Reward: 4.440, Episode Reward: 8888.3
    æ£€æµ‹è¿›åº¦: 2/66 (3.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3067)'), ('usv_1', '(403,4127)'), ('usv_2', '(314,5029)')]...
    Recent rewards sample: {'usv_0': np.float64(7.921821998103478), 'usv_1': np.float64(1.434762714055946)}
    Episode time: 200.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 34765.8
  Targets Detected: 7/93 (7.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.58
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 1, Avg Reward: 3.344, Episode Reward: 3.3
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3130)'), ('usv_1', '(210,4130)'), ('usv_2', '(210,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.8131680190161639), 'usv_1': np.float64(-0.08296410107460339)}
    Episode time: 0.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 1001, Avg Reward: 7.096, Episode Reward: 7103.6
    æ£€æµ‹è¿›åº¦: 7/32 (21.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3104)'), ('usv_1', '(297,4152)'), ('usv_2', '(265,5093)')]...
    Recent rewards sample: {'usv_0': np.float64(2.331271136520435), 'usv_1': np.float64(1.4347235320506577)}
    Episode time: 100.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 2001, Avg Reward: 14.334, Episode Reward: 28682.2
    æ£€æµ‹è¿›åº¦: 7/52 (13.5%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(302,3051)'), ('usv_1', '(364,4185)'), ('usv_2', '(309,5063)')]...
    Recent rewards sample: {'usv_0': np.float64(5.924804130471175), 'usv_1': np.float64(1.429022449905636)}
    Episode time: 200.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 32404.0
  Targets Detected: 9/56 (12.5%)
  Steps: 2169
  Episode Time: 216.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.94
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 832, Avg Reward: -2.102, Episode Reward: -1748.6
    æ£€æµ‹è¿›åº¦: 0/17 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(262,3134)'), ('usv_1', '(282,4117)'), ('usv_2', '(265,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(2.339618520035196), 'usv_1': np.float64(1.4215875668862559)}
    Episode time: 83.2s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.04256999  0.07523103] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 1832, Avg Reward: 8.863, Episode Reward: 16237.5
    æ£€æµ‹è¿›åº¦: 3/47 (6.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(319,3139)'), ('usv_1', '(355,4149)'), ('usv_2', '(320,5078)')]...
    Recent rewards sample: {'usv_0': np.float64(2.338842463096965), 'usv_1': np.float64(1.4411314407925997)}
    Episode time: 183.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 2832, Avg Reward: 13.555, Episode Reward: 38387.8
    æ£€æµ‹è¿›åº¦: 10/74 (13.5%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(374,3130)'), ('usv_1', '(407,4217)'), ('usv_2', '(373,5021)')]...
    Recent rewards sample: {'usv_0': np.float64(2.379220483348046), 'usv_1': np.float64(1.4417316756228544)}
    Episode time: 283.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 42186.7
  Targets Detected: 12/80 (13.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.06
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 831, Avg Reward: 9.098, Episode Reward: 7560.6
    æ£€æµ‹è¿›åº¦: 2/22 (9.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(264,3142)'), ('usv_1', '(283,4124)'), ('usv_2', '(258,5169)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3301192114463278), 'usv_1': np.float64(0.4226405652410452)}
    Episode time: 83.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 1831, Avg Reward: 13.802, Episode Reward: 25270.6
    æ£€æµ‹è¿›åº¦: 4/50 (8.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(345,3134)'), ('usv_1', '(383,4123)'), ('usv_2', '(271,5233)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3509674084129264), 'usv_1': np.float64(3.429235478284811)}
    Episode time: 183.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 2831, Avg Reward: 16.206, Episode Reward: 45878.4
    æ£€æµ‹è¿›åº¦: 6/60 (10.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(390,3124)'), ('usv_1', '(458,4155)'), ('usv_2', '(301,5308)')]...
    Recent rewards sample: {'usv_0': np.float64(2.4308648811692093), 'usv_1': np.float64(1.4360837279439123)}
    Episode time: 283.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 49280.6
  Targets Detected: 7/68 (8.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.42
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.14650804 0.11795641] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 830, Avg Reward: 10.287, Episode Reward: 8537.8
    æ£€æµ‹è¿›åº¦: 2/23 (8.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3120)'), ('usv_1', '(285,4146)'), ('usv_2', '(271,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3353219978336965), 'usv_1': np.float64(0.4244338951422981)}
    Episode time: 83.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 1830, Avg Reward: 16.380, Episode Reward: 29975.2
    æ£€æµ‹è¿›åº¦: 5/51 (9.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(328,3109)'), ('usv_1', '(358,4206)'), ('usv_2', '(355,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3465950204846484), 'usv_1': np.float64(1.4284379401294283)}
    Episode time: 183.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 2830, Avg Reward: 16.937, Episode Reward: 47931.3
    æ£€æµ‹è¿›åº¦: 6/71 (8.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(399,3096)'), ('usv_1', '(389,4280)'), ('usv_2', '(441,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3667485376986717), 'usv_1': np.float64(3.4405483801570016)}
    Episode time: 283.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: 51477.7
  Targets Detected: 6/73 (8.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.15

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 42214.9
Last 10 episodes average detections: 7.6
Best episode reward so far: 64004.2
Best detection count so far: 13
Learning trend: Improving (42214.9 vs 36669.1)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 829, Avg Reward: 5.398, Episode Reward: 4475.1
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3118)'), ('usv_1', '(281,4133)'), ('usv_2', '(276,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2803015743010918), 'usv_1': np.float64(1.374846092376567)}
    Episode time: 82.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 1829, Avg Reward: 8.443, Episode Reward: 15441.4
    æ£€æµ‹è¿›åº¦: 2/48 (4.2%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(284,3057)'), ('usv_1', '(364,4097)'), ('usv_2', '(350,5089)')]...
    Recent rewards sample: {'usv_0': np.float64(6.872417628555754), 'usv_1': np.float64(3.387386062580804)}
    Episode time: 182.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.07873147 -0.02431445] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 2829, Avg Reward: 13.122, Episode Reward: 37123.3
    æ£€æµ‹è¿›åº¦: 5/77 (6.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3015)'), ('usv_1', '(468,4111)'), ('usv_2', '(408,5059)')]...
    Recent rewards sample: {'usv_0': np.float64(6.104193289809152), 'usv_1': np.float64(3.393771333159526)}
    Episode time: 282.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 41715.4
  Targets Detected: 7/77 (7.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.90
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 828, Avg Reward: 5.594, Episode Reward: 4631.4
    æ£€æµ‹è¿›åº¦: 2/33 (6.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3116)'), ('usv_1', '(278,4144)'), ('usv_2', '(260,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(4.279175696751339), 'usv_1': np.float64(1.3712777934836016)}
    Episode time: 82.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 1828, Avg Reward: 15.142, Episode Reward: 27679.0
    æ£€æµ‹è¿›åº¦: 9/73 (12.3%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(289,3058)'), ('usv_1', '(338,4218)'), ('usv_2', '(340,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(7.872766173909355), 'usv_1': np.float64(3.38068630797901)}
    Episode time: 182.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 2828, Avg Reward: 18.640, Episode Reward: 52714.6
    æ£€æµ‹è¿›åº¦: 13/89 (14.6%), Episode total: 14
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3001)'), ('usv_1', '(372,4299)'), ('usv_2', '(413,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(7.975660577997191), 'usv_1': np.float64(1.385971127977501)}
    Episode time: 282.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 56895.5
  Targets Detected: 14/91 (14.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.96
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 827, Avg Reward: 6.450, Episode Reward: 5334.5
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3107)'), ('usv_1', '(285,4146)'), ('usv_2', '(259,5162)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2734567868417082), 'usv_1': np.float64(2.3796076757104028)}
    Episode time: 82.7s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.04342019  0.08080462] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 1827, Avg Reward: 16.143, Episode Reward: 29492.8
    æ£€æµ‹è¿›åº¦: 6/50 (12.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3058)'), ('usv_1', '(349,4208)'), ('usv_2', '(291,5233)')]...
    Recent rewards sample: {'usv_0': np.float64(5.868115898135464), 'usv_1': np.float64(3.38629653109291)}
    Episode time: 182.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 2827, Avg Reward: 18.810, Episode Reward: 53175.9
    æ£€æµ‹è¿›åº¦: 8/79 (10.1%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,3025)'), ('usv_1', '(336,4293)'), ('usv_2', '(344,5284)')]...
    Recent rewards sample: {'usv_0': np.float64(5.868582749858182), 'usv_1': np.float64(3.3878260129617734)}
    Episode time: 282.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 56980.1
  Targets Detected: 10/84 (9.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.99
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 826, Avg Reward: 0.041, Episode Reward: 34.3
    æ£€æµ‹è¿›åº¦: 1/15 (6.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3116)'), ('usv_1', '(283,4138)'), ('usv_2', '(267,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2783699873573372), 'usv_1': np.float64(-0.6165384615213444)}
    Episode time: 82.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 1826, Avg Reward: 12.255, Episode Reward: 22377.9
    æ£€æµ‹è¿›åº¦: 3/47 (6.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(268,3054)'), ('usv_1', '(358,4205)'), ('usv_2', '(340,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(5.871279697213995), 'usv_1': np.float64(3.383087950565895)}
    Episode time: 182.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 31799.4
  Targets Detected: 4/57 (5.3%)
  Steps: 2255
  Episode Time: 225.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.10
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 571, Avg Reward: -0.997, Episode Reward: -569.5
    æ£€æµ‹è¿›åº¦: 2/24 (8.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(240,3129)'), ('usv_1', '(268,4124)'), ('usv_2', '(254,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(0.276785693715319), 'usv_1': np.float64(-0.6167668727194446)}
    Episode time: 57.1s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.04238085 0.34786968] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 1571, Avg Reward: 8.721, Episode Reward: 13701.3
    æ£€æµ‹è¿›åº¦: 4/61 (6.6%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(308,3104)'), ('usv_1', '(366,4138)'), ('usv_2', '(329,5169)')]...
    Recent rewards sample: {'usv_0': np.float64(2.292312364995509), 'usv_1': np.float64(1.380699061217502)}
    Episode time: 157.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 2571, Avg Reward: 13.357, Episode Reward: 34341.2
    æ£€æµ‹è¿›åº¦: 10/80 (12.5%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(299,3048)'), ('usv_1', '(473,4150)'), ('usv_2', '(383,5212)')]...
    Recent rewards sample: {'usv_0': np.float64(5.925152948154949), 'usv_1': np.float64(3.3952166386671117)}
    Episode time: 257.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 45390.7
  Targets Detected: 12/87 (11.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.13
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 570, Avg Reward: 10.432, Episode Reward: 5946.4
    æ£€æµ‹è¿›åº¦: 3/18 (16.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3109)'), ('usv_1', '(258,4137)'), ('usv_2', '(255,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2772852201587641), 'usv_1': np.float64(0.3720400305000675)}
    Episode time: 57.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 1570, Avg Reward: 17.855, Episode Reward: 28032.9
    æ£€æµ‹è¿›åº¦: 6/43 (14.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3051)'), ('usv_1', '(346,4166)'), ('usv_2', '(344,5135)')]...
    Recent rewards sample: {'usv_0': np.float64(5.872115132306666), 'usv_1': np.float64(3.3785578576083086)}
    Episode time: 157.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 2570, Avg Reward: 22.081, Episode Reward: 56748.7
    æ£€æµ‹è¿›åº¦: 13/65 (20.0%), Episode total: 14
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(319,3012)'), ('usv_1', '(436,4210)'), ('usv_2', '(396,5171)')]...
    Recent rewards sample: {'usv_0': np.float64(7.876010057512576), 'usv_1': np.float64(3.398194291652418)}
    Episode time: 257.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 67955.6
  Targets Detected: 14/77 (15.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 22.64
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.24104208  0.1275598 ] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 100000, Episode Steps: 569, Avg Reward: -3.245, Episode Reward: -1846.4
    æ£€æµ‹è¿›åº¦: 1/21 (4.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,3137)'), ('usv_1', '(264,4131)'), ('usv_2', '(247,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7304718119002529), 'usv_1': np.float64(-1.6252469486448933)}
    Episode time: 56.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 101000, Episode Steps: 1569, Avg Reward: 5.072, Episode Reward: 7958.6
    æ£€æµ‹è¿›åº¦: 5/52 (9.6%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(306,3147)'), ('usv_1', '(348,4146)'), ('usv_2', '(320,5166)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2905653036462), 'usv_1': np.float64(1.376624284193976)}
    Episode time: 156.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 102000, Episode Steps: 2569, Avg Reward: 11.001, Episode Reward: 28261.4
    æ£€æµ‹è¿›åº¦: 12/81 (14.8%), Episode total: 12
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(385,3166)'), ('usv_1', '(412,4180)'), ('usv_2', '(350,5229)')]...
    Recent rewards sample: {'usv_0': np.float64(4.309120110562706), 'usv_1': np.float64(1.3887673851692508)}
    Episode time: 256.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 37688.5
  Targets Detected: 13/92 (14.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.56
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 103000, Episode Steps: 568, Avg Reward: 0.485, Episode Reward: 275.7
    æ£€æµ‹è¿›åº¦: 3/25 (12.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(243,3137)'), ('usv_1', '(264,4133)'), ('usv_2', '(243,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(2.269685473125424), 'usv_1': np.float64(-0.6295963778460227)}
    Episode time: 56.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 104000, Episode Steps: 1568, Avg Reward: 9.426, Episode Reward: 14779.9
    æ£€æµ‹è¿›åº¦: 7/51 (13.7%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3190)'), ('usv_1', '(368,4165)'), ('usv_2', '(315,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(4.277231837114702), 'usv_1': np.float64(1.3803083045048505)}
    Episode time: 156.8s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.1422812   0.05592598] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 105000, Episode Steps: 2568, Avg Reward: 14.050, Episode Reward: 36080.4
    æ£€æµ‹è¿›åº¦: 12/79 (15.2%), Episode total: 13
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(357,3194)'), ('usv_1', '(461,4181)'), ('usv_2', '(379,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(4.291000526405785), 'usv_1': np.float64(1.3854311857978567)}
    Episode time: 256.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 45091.8
  Targets Detected: 16/96 (15.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.03
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 106000, Episode Steps: 567, Avg Reward: 10.020, Episode Reward: 5681.5
    æ£€æµ‹è¿›åº¦: 3/35 (8.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3130)'), ('usv_1', '(248,4138)'), ('usv_2', '(265,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(4.272594469673418), 'usv_1': np.float64(1.3765113662837076)}
    Episode time: 56.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 107000, Episode Steps: 1567, Avg Reward: 19.148, Episode Reward: 30004.7
    æ£€æµ‹è¿›åº¦: 9/61 (14.8%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(308,3106)'), ('usv_1', '(344,4159)'), ('usv_2', '(339,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(4.293029452097352), 'usv_1': np.float64(1.387575600716115)}
    Episode time: 156.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 108000, Episode Steps: 2567, Avg Reward: 20.942, Episode Reward: 53757.6
    æ£€æµ‹è¿›åº¦: 11/87 (12.6%), Episode total: 12
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(339,3055)'), ('usv_1', '(434,4178)'), ('usv_2', '(400,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(6.137539929520649), 'usv_1': np.float64(3.3889416016081224)}
    Episode time: 256.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 66030.1
  Targets Detected: 15/103 (12.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 22.00
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 109000, Episode Steps: 566, Avg Reward: -1.320, Episode Reward: -747.2
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(240,3128)'), ('usv_1', '(247,4132)'), ('usv_2', '(244,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2702618440747321), 'usv_1': np.float64(-0.6283126533226456)}
    Episode time: 56.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.05605428  0.20436612] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 110000, Episode Steps: 1566, Avg Reward: 11.168, Episode Reward: 17489.3
    æ£€æµ‹è¿›åº¦: 7/47 (14.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(289,3109)'), ('usv_1', '(313,4185)'), ('usv_2', '(304,5167)')]...
    Recent rewards sample: {'usv_0': np.float64(4.28724392116616), 'usv_1': np.float64(3.379916338017991)}
    Episode time: 156.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 111000, Episode Steps: 2566, Avg Reward: 16.626, Episode Reward: 42661.1
    æ£€æµ‹è¿›åº¦: 12/76 (15.8%), Episode total: 13
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(340,3081)'), ('usv_1', '(355,4254)'), ('usv_2', '(371,5191)')]...
    Recent rewards sample: {'usv_0': np.float64(7.881137375312923), 'usv_1': np.float64(3.3843136386492407)}
    Episode time: 256.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 54581.9
  Targets Detected: 15/87 (14.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.19

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 50412.9
Last 10 episodes average detections: 12.0
Best episode reward so far: 67955.6
Best detection count so far: 16
Learning trend: Improving (50412.9 vs 42214.9)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 112000, Episode Steps: 565, Avg Reward: 14.809, Episode Reward: 8367.2
    æ£€æµ‹è¿›åº¦: 3/23 (13.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(249,3137)'), ('usv_1', '(284,4135)'), ('usv_2', '(253,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2723839183128542), 'usv_1': np.float64(1.382450873824551)}
    Episode time: 56.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 113000, Episode Steps: 1565, Avg Reward: 17.958, Episode Reward: 28103.5
    æ£€æµ‹è¿›åº¦: 4/43 (9.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(298,3157)'), ('usv_1', '(344,4162)'), ('usv_2', '(319,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2821538522514735), 'usv_1': np.float64(3.3834921082637592)}
    Episode time: 156.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 114000, Episode Steps: 2565, Avg Reward: 19.598, Episode Reward: 50267.8
    æ£€æµ‹è¿›åº¦: 5/60 (8.3%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(344,3144)'), ('usv_1', '(426,4191)'), ('usv_2', '(369,5113)')]...
    Recent rewards sample: {'usv_0': np.float64(2.295513608685467), 'usv_1': np.float64(3.3881786691446267)}
    Episode time: 256.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 58471.2
  Targets Detected: 8/67 (7.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.48
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.11886811 0.04348112] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 115000, Episode Steps: 564, Avg Reward: 10.897, Episode Reward: 6146.0
    æ£€æµ‹è¿›åº¦: 2/15 (13.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3140)'), ('usv_1', '(265,4148)'), ('usv_2', '(250,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2757134236644792), 'usv_1': np.float64(2.375245408142802)}
    Episode time: 56.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 116000, Episode Steps: 1564, Avg Reward: 11.190, Episode Reward: 17500.6
    æ£€æµ‹è¿›åº¦: 6/48 (12.5%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(327,3137)'), ('usv_1', '(343,4191)'), ('usv_2', '(300,5150)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2913062771974655), 'usv_1': np.float64(0.3830171256059878)}
    Episode time: 156.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 117000, Episode Steps: 2564, Avg Reward: 15.505, Episode Reward: 39755.2
    æ£€æµ‹è¿›åº¦: 14/86 (16.3%), Episode total: 14
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(382,3139)'), ('usv_1', '(426,4258)'), ('usv_2', '(337,5219)')]...
    Recent rewards sample: {'usv_0': np.float64(2.312861529630248), 'usv_1': np.float64(1.3950366568673123)}
    Episode time: 256.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 50724.9
  Targets Detected: 19/94 (18.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.90
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 118000, Episode Steps: 563, Avg Reward: -4.094, Episode Reward: -2304.9
    æ£€æµ‹è¿›åº¦: 0/24 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3135)'), ('usv_1', '(270,4128)'), ('usv_2', '(240,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7249490088092073), 'usv_1': np.float64(-1.6273955027935099)}
    Episode time: 56.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 119000, Episode Steps: 1563, Avg Reward: -3.917, Episode Reward: -6121.8
    æ£€æµ‹è¿›åº¦: 0/45 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(284,3168)'), ('usv_1', '(339,4120)'), ('usv_2', '(322,5178)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7143932782490141), 'usv_1': np.float64(-1.6161093740808314)}
    Episode time: 156.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: -7018.9
  Targets Detected: 0/49 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -3.90
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.15113676 -0.13193665] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 120000, Episode Steps: 762, Avg Reward: -3.891, Episode Reward: -2965.2
    æ£€æµ‹è¿›åº¦: 0/28 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3112)'), ('usv_1', '(282,4117)'), ('usv_2', '(271,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.711399737400214), 'usv_1': np.float64(-1.625620751157052)}
    Episode time: 76.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 121000, Episode Steps: 1762, Avg Reward: 6.246, Episode Reward: 11005.8
    æ£€æµ‹è¿›åº¦: 5/66 (7.6%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(304,3069)'), ('usv_1', '(359,4126)'), ('usv_2', '(324,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(7.87465699274983), 'usv_1': np.float64(1.37742719008611)}
    Episode time: 176.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 30990.5
  Targets Detected: 5/85 (5.9%)
  Steps: 2671
  Episode Time: 267.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 11.60
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 122000, Episode Steps: 91, Avg Reward: 3.044, Episode Reward: 277.0
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(222,4130)'), ('usv_2', '(217,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2680648453190009), 'usv_1': np.float64(0.366922082599777)}
    Episode time: 9.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 123000, Episode Steps: 1091, Avg Reward: 20.607, Episode Reward: 22481.8
    æ£€æµ‹è¿›åº¦: 5/39 (12.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3111)'), ('usv_1', '(299,4116)'), ('usv_2', '(303,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2817099590383445), 'usv_1': np.float64(3.374892236634749)}
    Episode time: 109.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 124000, Episode Steps: 2091, Avg Reward: 22.021, Episode Reward: 46046.8
    æ£€æµ‹è¿›åº¦: 7/76 (9.2%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(294,3051)'), ('usv_1', '(403,4137)'), ('usv_2', '(351,5151)')]...
    Recent rewards sample: {'usv_0': np.float64(5.879230071477927), 'usv_1': np.float64(3.3907860735127855)}
    Episode time: 209.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 71278.3
  Targets Detected: 13/105 (9.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 23.75
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.11069356 -0.1712591 ] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 125000, Episode Steps: 90, Avg Reward: -3.900, Episode Reward: -351.0
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3130)'), ('usv_1', '(225,4130)'), ('usv_2', '(216,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7291788533813442), 'usv_1': np.float64(-1.631787467388308)}
    Episode time: 9.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 126000, Episode Steps: 1090, Avg Reward: 5.549, Episode Reward: 6048.8
    æ£€æµ‹è¿›åº¦: 3/27 (11.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(281,3105)'), ('usv_1', '(331,4141)'), ('usv_2', '(269,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2842310549851765), 'usv_1': np.float64(3.388288729380916)}
    Episode time: 109.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 127000, Episode Steps: 2090, Avg Reward: 12.806, Episode Reward: 26765.0
    æ£€æµ‹è¿›åº¦: 6/55 (10.9%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(318,3058)'), ('usv_1', '(410,4141)'), ('usv_2', '(333,5194)')]...
    Recent rewards sample: {'usv_0': np.float64(7.876907198080775), 'usv_1': np.float64(3.38632501678582)}
    Episode time: 209.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 50087.8
  Targets Detected: 10/74 (13.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.69
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 128000, Episode Steps: 89, Avg Reward: -4.766, Episode Reward: -424.2
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3130)'), ('usv_1', '(222,4129)'), ('usv_2', '(216,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7366613812748206), 'usv_1': np.float64(-1.6238435265012152)}
    Episode time: 8.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 129000, Episode Steps: 1089, Avg Reward: 2.412, Episode Reward: 2626.4
    æ£€æµ‹è¿›åº¦: 3/41 (7.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(289,3142)'), ('usv_1', '(310,4109)'), ('usv_2', '(263,5172)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2854358868083278), 'usv_1': np.float64(1.3737534531639906)}
    Episode time: 108.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.15886264 -0.10785522] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 130000, Episode Steps: 2089, Avg Reward: 11.829, Episode Reward: 24709.8
    æ£€æµ‹è¿›åº¦: 9/52 (17.3%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(359,3169)'), ('usv_1', '(381,4080)'), ('usv_2', '(291,5220)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2948138545048127), 'usv_1': np.float64(3.3793381063072916)}
    Episode time: 208.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 45256.1
  Targets Detected: 14/72 (16.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.08
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 131000, Episode Steps: 88, Avg Reward: -3.908, Episode Reward: -343.9
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3130)'), ('usv_1', '(216,4130)'), ('usv_2', '(218,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7296441093701155), 'usv_1': np.float64(-1.6332220752020403)}
    Episode time: 8.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 132000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 132000, Episode Steps: 1088, Avg Reward: -1.691, Episode Reward: -1839.9
    æ£€æµ‹è¿›åº¦: 2/27 (7.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(281,3155)'), ('usv_1', '(288,4151)'), ('usv_2', '(278,5093)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2769827847288415), 'usv_1': np.float64(-0.6219628436907771)}
    Episode time: 108.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 133000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 133000, Episode Steps: 2088, Avg Reward: 5.935, Episode Reward: 12392.3
    æ£€æµ‹è¿›åº¦: 6/65 (9.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(358,3169)'), ('usv_1', '(360,4198)'), ('usv_2', '(310,5026)')]...
    Recent rewards sample: {'usv_0': np.float64(4.294720738039404), 'usv_1': np.float64(1.382975872034271)}
    Episode time: 208.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 29652.2
  Targets Detected: 8/102 (4.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.88
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 134000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 134000, Episode Steps: 87, Avg Reward: 1.625, Episode Reward: 141.3
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3130)'), ('usv_1', '(217,4131)'), ('usv_2', '(215,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2666091676005856), 'usv_1': np.float64(-0.625301651905755)}
    Episode time: 8.7s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.24510852 -0.18637037] (agent usv_0)
    MADDPG UPDATING at time_step 135000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 135000, Episode Steps: 1087, Avg Reward: 5.144, Episode Reward: 5591.9
    æ£€æµ‹è¿›åº¦: 2/22 (9.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(301,3121)'), ('usv_1', '(302,4156)'), ('usv_2', '(286,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2870102592023325), 'usv_1': np.float64(0.37527221350284057)}
    Episode time: 108.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 136000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 136000, Episode Steps: 2087, Avg Reward: 12.756, Episode Reward: 26621.1
    æ£€æµ‹è¿›åº¦: 5/48 (10.4%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(320,3063)'), ('usv_1', '(354,4226)'), ('usv_2', '(341,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8749306018044445), 'usv_1': np.float64(1.3841232731512774)}
    Episode time: 208.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 48660.7
  Targets Detected: 9/72 (11.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.21
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 137000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 137000, Episode Steps: 86, Avg Reward: -2.450, Episode Reward: -210.7
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,3130)'), ('usv_1', '(220,4130)'), ('usv_2', '(223,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.270691372448588), 'usv_1': np.float64(-0.6275014014767519)}
    Episode time: 8.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 138000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 138000, Episode Steps: 1086, Avg Reward: 12.742, Episode Reward: 13837.4
    æ£€æµ‹è¿›åº¦: 2/33 (6.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3157)'), ('usv_1', '(310,4122)'), ('usv_2', '(296,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(1.275650526235311), 'usv_1': np.float64(2.3766080541484604)}
    Episode time: 108.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 139000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0367, Avg Critic Loss: 12.3259
    Step 139000, Episode Steps: 2086, Avg Reward: 18.030, Episode Reward: 37610.7
    æ£€æµ‹è¿›åº¦: 11/61 (18.0%), Episode total: 11
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(343,3182)'), ('usv_1', '(405,4113)'), ('usv_2', '(342,5178)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2979642956140864), 'usv_1': np.float64(3.380986735752553)}
    Episode time: 208.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 58469.0
  Targets Detected: 14/85 (15.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.48

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 43657.2
Last 10 episodes average detections: 10.0
Best episode reward so far: 71278.3
Best detection count so far: 19
Learning trend: Declining (43657.2 vs 50412.9)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 71278.3
Final 10 episodes average: 43657.2
Best detection performance: 19 targets
Average detections (final 10): 10.0
============================================================
{"final_avg_reward": 43657.184430951704, "final_detection_rate": 10.0, "best_episode_reward": 71278.30265477188, "best_detection_count": 19, "total_episodes": 50}
Simulation finished.
