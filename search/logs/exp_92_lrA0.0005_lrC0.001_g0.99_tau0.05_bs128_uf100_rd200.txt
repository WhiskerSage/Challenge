D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: 4.822, Episode Reward: 4821.7
    æ£€æµ‹è¿›åº¦: 2/15 (13.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3070)'), ('usv_1', '(221,4096)'), ('usv_2', '(325,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9743327463058544), 'usv_1': np.float64(-0.5329079719763629)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 2000, Avg Reward: 14.378, Episode Reward: 28756.6
    æ£€æµ‹è¿›åº¦: 6/36 (16.7%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,2961)'), ('usv_1', '(201,4073)'), ('usv_2', '(381,5017)')]...
    Recent rewards sample: {'usv_0': np.float64(7.983390621862264), 'usv_1': np.float64(3.473031817544425)}
    Episode time: 200.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 46414.1
  Targets Detected: 7/46 (10.9%)
  Steps: 2800
  Episode Time: 280.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.58
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 200, Avg Reward: 4.457, Episode Reward: 891.4
    æ£€æµ‹è¿›åº¦: 1/6 (16.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(237,3127)'), ('usv_1', '(226,4129)'), ('usv_2', '(234,5126)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3832267243815455), 'usv_1': np.float64(-0.5266210988320389)}
    Episode time: 20.0s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 1200, Avg Reward: 8.531, Episode Reward: 10236.9
    æ£€æµ‹è¿›åº¦: 4/23 (17.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(319,3093)'), ('usv_1', '(266,4104)'), ('usv_2', '(296,5067)')]...
    Recent rewards sample: {'usv_0': np.float64(4.395766044641878), 'usv_1': np.float64(1.4744269119889273)}
    Episode time: 120.0s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.13807073 0.02632655] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 2200, Avg Reward: 15.796, Episode Reward: 34750.6
    æ£€æµ‹è¿›åº¦: 7/37 (18.9%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(330,3033)'), ('usv_1', '(244,4077)'), ('usv_2', '(318,4976)')]...
    Recent rewards sample: {'usv_0': np.float64(7.977229959079487), 'usv_1': np.float64(3.469067996699655)}
    Episode time: 220.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 54235.9
  Targets Detected: 7/44 (13.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.07
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 199, Avg Reward: -3.211, Episode Reward: -639.0
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3127)'), ('usv_1', '(223,4129)'), ('usv_2', '(222,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6249389263665089), 'usv_1': np.float64(-1.5329912358386915)}
    Episode time: 19.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 1199, Avg Reward: 0.496, Episode Reward: 595.1
    æ£€æµ‹è¿›åº¦: 1/19 (5.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(312,3079)'), ('usv_1', '(259,4116)'), ('usv_2', '(330,5099)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9810797703416734), 'usv_1': np.float64(-0.5302043218511743)}
    Episode time: 119.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 2199, Avg Reward: 10.622, Episode Reward: 23357.9
    æ£€æµ‹è¿›åº¦: 6/41 (14.6%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(361,2985)'), ('usv_1', '(304,4105)'), ('usv_2', '(434,5047)')]...
    Recent rewards sample: {'usv_0': np.float64(7.9841659576285595), 'usv_1': np.float64(3.473255543144419)}
    Episode time: 219.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 43488.2
  Targets Detected: 8/47 (12.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.49
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 198, Avg Reward: 6.927, Episode Reward: 1371.6
    æ£€æµ‹è¿›åº¦: 1/2 (50.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3131)'), ('usv_1', '(220,4128)'), ('usv_2', '(226,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3749129156814437), 'usv_1': np.float64(-0.5331940475821052)}
    Episode time: 19.8s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.14500538 -0.11040694] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 1198, Avg Reward: 4.720, Episode Reward: 5654.3
    æ£€æµ‹è¿›åº¦: 1/18 (5.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(323,3098)'), ('usv_1', '(225,4082)'), ('usv_2', '(300,5084)')]...
    Recent rewards sample: {'usv_0': np.float64(2.403918863215549), 'usv_1': np.float64(-0.5285786387072401)}
    Episode time: 119.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 2198, Avg Reward: 13.690, Episode Reward: 30091.6
    æ£€æµ‹è¿›åº¦: 5/34 (14.7%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(381,3027)'), ('usv_1', '(207,4015)'), ('usv_2', '(363,4996)')]...
    Recent rewards sample: {'usv_0': np.float64(7.986845784071416), 'usv_1': np.float64(3.468045896179005)}
    Episode time: 219.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 49478.2
  Targets Detected: 7/47 (12.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.49
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 197, Avg Reward: -3.496, Episode Reward: -688.8
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3130)'), ('usv_1', '(220,4126)'), ('usv_2', '(231,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6257856922854956), 'usv_1': np.float64(-1.5332187448726913)}
    Episode time: 19.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 1197, Avg Reward: -1.646, Episode Reward: -1969.8
    æ£€æµ‹è¿›åº¦: 1/13 (7.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(319,3116)'), ('usv_1', '(261,4102)'), ('usv_2', '(331,5095)')]...
    Recent rewards sample: {'usv_0': np.float64(2.392949200413306), 'usv_1': np.float64(-0.5299528360900542)}
    Episode time: 119.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 2197, Avg Reward: 3.283, Episode Reward: 7212.3
    æ£€æµ‹è¿›åº¦: 2/27 (7.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(335,3033)'), ('usv_1', '(279,4055)'), ('usv_2', '(363,5015)')]...
    Recent rewards sample: {'usv_0': np.float64(6.979664126957947), 'usv_1': np.float64(2.4720482684728298)}
    Episode time: 219.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 23095.9
  Targets Detected: 3/40 (5.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 7.70
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.02737622 0.26429215] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 196, Avg Reward: 7.133, Episode Reward: 1398.1
    æ£€æµ‹è¿›åº¦: 1/7 (14.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3128)'), ('usv_1', '(219,4130)'), ('usv_2', '(226,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(2.3679620700180144), 'usv_1': np.float64(-0.53226726988832)}
    Episode time: 19.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 1196, Avg Reward: 11.547, Episode Reward: 13809.8
    æ£€æµ‹è¿›åº¦: 3/23 (13.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(249,3070)'), ('usv_1', '(263,4112)'), ('usv_2', '(294,5080)')]...
    Recent rewards sample: {'usv_0': np.float64(7.970573938059248), 'usv_1': np.float64(1.4709176138937852)}
    Episode time: 119.6s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 2196, Avg Reward: 16.988, Episode Reward: 37304.6
    æ£€æµ‹è¿›åº¦: 5/31 (16.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,3051)'), ('usv_1', '(252,4071)'), ('usv_2', '(326,4974)')]...
    Recent rewards sample: {'usv_0': np.float64(5.97068309904467), 'usv_1': np.float64(3.4784526830851217)}
    Episode time: 219.6s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 56860.6
  Targets Detected: 7/45 (13.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.95
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 195, Avg Reward: 7.231, Episode Reward: 1410.1
    æ£€æµ‹è¿›åº¦: 1/7 (14.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3128)'), ('usv_1', '(230,4128)'), ('usv_2', '(234,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3677370208789785), 'usv_1': np.float64(-0.5264694021975034)}
    Episode time: 19.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 1195, Avg Reward: 17.628, Episode Reward: 21065.0
    æ£€æµ‹è¿›åº¦: 4/22 (18.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3060)'), ('usv_1', '(269,4100)'), ('usv_2', '(322,5090)')]...
    Recent rewards sample: {'usv_0': np.float64(7.97588617891684), 'usv_1': np.float64(3.471664275577165)}
    Episode time: 119.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 36205.5
  Targets Detected: 4/31 (6.5%)
  Steps: 1818
  Episode Time: 181.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 19.92
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.17280181 -0.01212321] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 377, Avg Reward: -2.611, Episode Reward: -984.4
    æ£€æµ‹è¿›åº¦: 1/8 (12.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3122)'), ('usv_1', '(229,4119)'), ('usv_2', '(256,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6187950113678218), 'usv_1': np.float64(-1.5284978777863416)}
    Episode time: 37.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 1377, Avg Reward: -1.787, Episode Reward: -2461.4
    æ£€æµ‹è¿›åº¦: 1/20 (5.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3057)'), ('usv_1', '(216,4072)'), ('usv_2', '(343,5077)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9712406063694785), 'usv_1': np.float64(1.46708890953109)}
    Episode time: 137.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 2377, Avg Reward: 8.746, Episode Reward: 20790.0
    æ£€æµ‹è¿›åº¦: 4/32 (12.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,3023)'), ('usv_1', '(207,4063)'), ('usv_2', '(340,4996)')]...
    Recent rewards sample: {'usv_0': np.float64(5.978240143148783), 'usv_1': np.float64(3.4731642921745927)}
    Episode time: 237.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 28770.2
  Targets Detected: 4/34 (11.8%)
  Steps: 2749
  Episode Time: 274.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.47
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 628, Avg Reward: -3.265, Episode Reward: -2050.6
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3119)'), ('usv_1', '(233,4121)'), ('usv_2', '(266,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.614089762544219), 'usv_1': np.float64(-1.532222799810003)}
    Episode time: 62.8s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 1628, Avg Reward: 1.265, Episode Reward: 2059.3
    æ£€æµ‹è¿›åº¦: 2/23 (8.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(342,3060)'), ('usv_1', '(215,4088)'), ('usv_2', '(365,5057)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9821880361108013), 'usv_1': np.float64(-0.5332954461019076)}
    Episode time: 162.8s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.03514445 -0.32590884] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 2628, Avg Reward: 8.837, Episode Reward: 23223.8
    æ£€æµ‹è¿›åº¦: 6/43 (14.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(302,2989)'), ('usv_1', '(208,4062)'), ('usv_2', '(414,4958)')]...
    Recent rewards sample: {'usv_0': np.float64(7.981448868684657), 'usv_1': np.float64(1.4673322815337126)}
    Episode time: 262.8s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 33064.3
  Targets Detected: 9/48 (16.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.02
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 627, Avg Reward: 7.314, Episode Reward: 4585.8
    æ£€æµ‹è¿›åº¦: 2/14 (14.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3115)'), ('usv_1', '(222,4119)'), ('usv_2', '(271,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3932554380549025), 'usv_1': np.float64(2.4680001154288997)}
    Episode time: 62.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 1627, Avg Reward: 13.315, Episode Reward: 21663.2
    æ£€æµ‹è¿›åº¦: 5/33 (15.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(285,3039)'), ('usv_1', '(240,4087)'), ('usv_2', '(349,5040)')]...
    Recent rewards sample: {'usv_0': np.float64(5.973271096793445), 'usv_1': np.float64(1.468578587087213)}
    Episode time: 162.7s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 2627, Avg Reward: 17.212, Episode Reward: 45217.0
    æ£€æµ‹è¿›åº¦: 5/50 (10.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3040)'), ('usv_1', '(221,4049)'), ('usv_2', '(360,4945)')]...
    Recent rewards sample: {'usv_0': np.float64(7.967360466190806), 'usv_1': np.float64(3.4748336229979637)}
    Episode time: 262.7s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 54227.1
  Targets Detected: 6/56 (8.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.07

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 42584.0
Last 10 episodes average detections: 6.2
Best episode reward so far: 56860.6
Best detection count so far: 9
Buffer size: 28374
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 626, Avg Reward: -0.638, Episode Reward: -399.3
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3121)'), ('usv_1', '(221,4102)'), ('usv_2', '(278,5124)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32480994254948137), 'usv_1': np.float64(-0.5824001268358757)}
    Episode time: 62.6s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.20819398 -0.13875674] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 1626, Avg Reward: 3.872, Episode Reward: 6295.5
    æ£€æµ‹è¿›åº¦: 1/49 (2.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(256,3037)'), ('usv_1', '(204,4069)'), ('usv_2', '(316,5035)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9292591109318495), 'usv_1': np.float64(-0.5761302142949123)}
    Episode time: 162.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 7683.8
  Targets Detected: 1/49 (2.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_134s
  Average Reward/Step: 4.27
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 825, Avg Reward: -1.993, Episode Reward: -1643.9
    æ£€æµ‹è¿›åº¦: 1/20 (5.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3088)'), ('usv_1', '(210,4108)'), ('usv_2', '(284,5111)')]...
    Recent rewards sample: {'usv_0': np.float64(1.333858252094365), 'usv_1': np.float64(0.42014741497103003)}
    Episode time: 82.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 1825, Avg Reward: 12.155, Episode Reward: 22182.7
    æ£€æµ‹è¿›åº¦: 5/50 (10.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,2973)'), ('usv_1', '(201,4081)'), ('usv_2', '(326,5022)')]...
    Recent rewards sample: {'usv_0': np.float64(5.929725187049389), 'usv_1': np.float64(1.4192268716184122)}
    Episode time: 182.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 35598.2
  Targets Detected: 8/61 (8.2%)
  Steps: 2308
  Episode Time: 230.8s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.42
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 517, Avg Reward: -3.604, Episode Reward: -1863.2
    æ£€æµ‹è¿›åº¦: 0/12 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(260,3120)'), ('usv_1', '(233,4129)'), ('usv_2', '(260,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6678458263946121), 'usv_1': np.float64(-1.5766245507311973)}
    Episode time: 51.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 1517, Avg Reward: -2.664, Episode Reward: -4041.5
    æ£€æµ‹è¿›åº¦: 0/38 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3044)'), ('usv_1', '(252,4097)'), ('usv_2', '(321,5075)')]...
    Recent rewards sample: {'usv_0': np.float64(2.92486147903378), 'usv_1': np.float64(-1.5805816139957174)}
    Episode time: 151.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: -4043.4
  Targets Detected: 0/45 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -2.25
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.24347269 -0.15037881] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 716, Avg Reward: 2.735, Episode Reward: 1958.4
    æ£€æµ‹è¿›åº¦: 1/18 (5.6%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3098)'), ('usv_1', '(255,4134)'), ('usv_2', '(293,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3392335087916907), 'usv_1': np.float64(-0.576510012278717)}
    Episode time: 71.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 1716, Avg Reward: 7.814, Episode Reward: 13409.6
    æ£€æµ‹è¿›åº¦: 2/57 (3.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3024)'), ('usv_1', '(268,4101)'), ('usv_2', '(385,5093)')]...
    Recent rewards sample: {'usv_0': np.float64(4.92629599147231), 'usv_1': np.float64(2.4246171335194378)}
    Episode time: 171.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 2716, Avg Reward: 9.740, Episode Reward: 26453.3
    æ£€æµ‹è¿›åº¦: 3/66 (4.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,2951)'), ('usv_1', '(238,4098)'), ('usv_2', '(430,5026)')]...
    Recent rewards sample: {'usv_0': np.float64(4.92430084121158), 'usv_1': np.float64(0.420369074510331)}
    Episode time: 271.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 30142.4
  Targets Detected: 3/71 (4.2%)
  Steps: 2981
  Episode Time: 298.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.11
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 735, Avg Reward: 6.860, Episode Reward: 5041.8
    æ£€æµ‹è¿›åº¦: 2/14 (14.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3107)'), ('usv_1', '(242,4116)'), ('usv_2', '(292,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(1.331508113477547), 'usv_1': np.float64(0.4234855442635961)}
    Episode time: 73.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 1735, Avg Reward: 9.388, Episode Reward: 16287.4
    æ£€æµ‹è¿›åº¦: 2/35 (5.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3027)'), ('usv_1', '(205,4065)'), ('usv_2', '(373,5078)')]...
    Recent rewards sample: {'usv_0': np.float64(4.929967259302706), 'usv_1': np.float64(0.4186159341681823)}
    Episode time: 173.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 20337.3
  Targets Detected: 3/39 (5.1%)
  Steps: 1930
  Episode Time: 193.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.54
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.11365729  0.36298643] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 805, Avg Reward: -3.588, Episode Reward: -2888.1
    æ£€æµ‹è¿›åº¦: 0/19 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3088)'), ('usv_1', '(251,4104)'), ('usv_2', '(300,5108)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6675598245669501), 'usv_1': np.float64(-1.578725955377015)}
    Episode time: 80.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 1805, Avg Reward: 12.036, Episode Reward: 21725.6
    æ£€æµ‹è¿›åº¦: 5/46 (10.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3006)'), ('usv_1', '(235,4055)'), ('usv_2', '(351,5027)')]...
    Recent rewards sample: {'usv_0': np.float64(5.9238320368435025), 'usv_1': np.float64(3.42586720362413)}
    Episode time: 180.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 2805, Avg Reward: 16.082, Episode Reward: 45109.1
    æ£€æµ‹è¿›åº¦: 6/65 (9.2%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,2963)'), ('usv_1', '(209,4030)'), ('usv_2', '(326,4942)')]...
    Recent rewards sample: {'usv_0': np.float64(5.920322879669401), 'usv_1': np.float64(3.4220630093102775)}
    Episode time: 280.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 50045.6
  Targets Detected: 8/70 (10.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.68
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 804, Avg Reward: -3.589, Episode Reward: -2885.2
    æ£€æµ‹è¿›åº¦: 0/15 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(294,3109)'), ('usv_1', '(252,4120)'), ('usv_2', '(302,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6497359427191403), 'usv_1': np.float64(-1.5740349345626925)}
    Episode time: 80.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: -4748.1
  Targets Detected: 0/34 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -2.64
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 3, Avg Reward: -0.602, Episode Reward: -1.8
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(211,3130)'), ('usv_1', '(211,4130)'), ('usv_2', '(211,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6741833292564843), 'usv_1': np.float64(-1.5704211392710277)}
    Episode time: 0.3s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.0069253  -0.18636851] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 1003, Avg Reward: -3.432, Episode Reward: -3442.7
    æ£€æµ‹è¿›åº¦: 1/12 (8.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(294,3102)'), ('usv_1', '(229,4101)'), ('usv_2', '(322,5107)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6575191464581165), 'usv_1': np.float64(-1.5813940402756255)}
    Episode time: 100.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 2003, Avg Reward: 2.382, Episode Reward: 4770.6
    æ£€æµ‹è¿›åº¦: 4/40 (10.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(312,3015)'), ('usv_1', '(202,4064)'), ('usv_2', '(352,5037)')]...
    Recent rewards sample: {'usv_0': np.float64(5.928607568899189), 'usv_1': np.float64(1.4183733924686388)}
    Episode time: 200.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 29422.6
  Targets Detected: 7/73 (9.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.80
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 2, Avg Reward: 0.883, Episode Reward: 1.8
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3130)'), ('usv_1', '(210,4130)'), ('usv_2', '(210,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.673255620807364), 'usv_1': np.float64(-1.5699421055956102)}
    Episode time: 0.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 1002, Avg Reward: 1.513, Episode Reward: 1515.8
    æ£€æµ‹è¿›åº¦: 2/18 (11.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3082)'), ('usv_1', '(234,4096)'), ('usv_2', '(308,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(4.927778151279937), 'usv_1': np.float64(0.4180162156950784)}
    Episode time: 100.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 2002, Avg Reward: 9.349, Episode Reward: 18717.4
    æ£€æµ‹è¿›åº¦: 3/34 (8.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(220,2989)'), ('usv_1', '(252,4047)'), ('usv_2', '(369,5021)')]...
    Recent rewards sample: {'usv_0': np.float64(7.923930246745171), 'usv_1': np.float64(3.424129406103008)}
    Episode time: 200.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 46023.8
  Targets Detected: 7/61 (8.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.34
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.10248191 -0.13345638] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 1, Avg Reward: 5.342, Episode Reward: 5.3
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,3130)'), ('usv_1', '(210,4130)'), ('usv_2', '(210,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(0.8131680196925659), 'usv_1': np.float64(-0.08396410107460284)}
    Episode time: 0.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 1001, Avg Reward: 2.519, Episode Reward: 2521.2
    æ£€æµ‹è¿›åº¦: 1/24 (4.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(287,3093)'), ('usv_1', '(249,4120)'), ('usv_2', '(313,5091)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3404480369688239), 'usv_1': np.float64(2.420507246339655)}
    Episode time: 100.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 2001, Avg Reward: 10.583, Episode Reward: 21176.8
    æ£€æµ‹è¿›åº¦: 2/44 (4.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3033)'), ('usv_1', '(266,4094)'), ('usv_2', '(361,4998)')]...
    Recent rewards sample: {'usv_0': np.float64(5.932407451044517), 'usv_1': np.float64(3.4214666457076)}
    Episode time: 200.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 27694.7
  Targets Detected: 3/51 (3.9%)
  Steps: 2297
  Episode Time: 229.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.06

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 23815.7
Last 10 episodes average detections: 4.0
Best episode reward so far: 56860.6
Best detection count so far: 9
Learning trend: Declining (23815.7 vs 42584.0)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 704, Avg Reward: -3.537, Episode Reward: -2489.9
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(262,3086)'), ('usv_1', '(236,4121)'), ('usv_2', '(275,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(2.9234600449685195), 'usv_1': np.float64(-1.5809386639871272)}
    Episode time: 70.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 1704, Avg Reward: 6.445, Episode Reward: 10981.7
    æ£€æµ‹è¿›åº¦: 2/36 (5.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,2985)'), ('usv_1', '(252,4088)'), ('usv_2', '(367,5041)')]...
    Recent rewards sample: {'usv_0': np.float64(6.9325194577208915), 'usv_1': np.float64(2.4267290971700928)}
    Episode time: 170.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 23574.3
  Targets Detected: 2/48 (2.1%)
  Steps: 2491
  Episode Time: 249.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 9.46
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.20015696 -0.09437689] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 213, Avg Reward: -1.222, Episode Reward: -260.3
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(232,3126)'), ('usv_1', '(223,4131)'), ('usv_2', '(229,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(2.32398298829971), 'usv_1': np.float64(-0.5809529564608492)}
    Episode time: 21.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 1213, Avg Reward: 3.862, Episode Reward: 4684.2
    æ£€æµ‹è¿›åº¦: 1/42 (2.4%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3084)'), ('usv_1', '(275,4122)'), ('usv_2', '(299,5061)')]...
    Recent rewards sample: {'usv_0': np.float64(5.920524958466909), 'usv_1': np.float64(-0.5789943324862868)}
    Episode time: 121.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 2213, Avg Reward: 11.519, Episode Reward: 25491.3
    æ£€æµ‹è¿›åº¦: 4/80 (5.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,2998)'), ('usv_1', '(299,4095)'), ('usv_2', '(270,4964)')]...
    Recent rewards sample: {'usv_0': np.float64(5.92376291070709), 'usv_1': np.float64(1.4249705336990552)}
    Episode time: 221.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 41994.4
  Targets Detected: 5/91 (5.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.99
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 212, Avg Reward: -3.588, Episode Reward: -760.7
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,3127)'), ('usv_1', '(223,4128)'), ('usv_2', '(226,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.676842063718744), 'usv_1': np.float64(-1.5826623816726269)}
    Episode time: 21.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 1212, Avg Reward: 2.618, Episode Reward: 3172.7
    æ£€æµ‹è¿›åº¦: 1/35 (2.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3059)'), ('usv_1', '(249,4097)'), ('usv_2', '(307,5110)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9285656577998127), 'usv_1': np.float64(-0.5710240341053583)}
    Episode time: 121.2s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.02518773 0.11224792] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 2212, Avg Reward: 6.730, Episode Reward: 14887.6
    æ£€æµ‹è¿›åº¦: 2/58 (3.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,2955)'), ('usv_1', '(265,4059)'), ('usv_2', '(387,5064)')]...
    Recent rewards sample: {'usv_0': np.float64(5.925731677743477), 'usv_1': np.float64(1.4209228502739508)}
    Episode time: 221.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 31331.3
  Targets Detected: 4/81 (3.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.44
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 211, Avg Reward: -3.579, Episode Reward: -755.2
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(238,3127)'), ('usv_1', '(230,4128)'), ('usv_2', '(222,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.67500420513203), 'usv_1': np.float64(-1.5823318292192778)}
    Episode time: 21.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 1211, Avg Reward: 1.500, Episode Reward: 1816.0
    æ£€æµ‹è¿›åº¦: 1/30 (3.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(298,3050)'), ('usv_1', '(261,4089)'), ('usv_2', '(260,5059)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9275416418983737), 'usv_1': np.float64(1.4231590098753744)}
    Episode time: 121.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 2211, Avg Reward: 8.203, Episode Reward: 18136.5
    æ£€æµ‹è¿›åº¦: 4/65 (6.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(291,2968)'), ('usv_1', '(271,4054)'), ('usv_2', '(237,5013)')]...
    Recent rewards sample: {'usv_0': np.float64(5.935407341705129), 'usv_1': np.float64(3.421496489987712)}
    Episode time: 221.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 35690.1
  Targets Detected: 4/80 (5.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.89
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 210, Avg Reward: -4.269, Episode Reward: -896.6
    æ£€æµ‹è¿›åº¦: 0/5 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3128)'), ('usv_1', '(229,4124)'), ('usv_2', '(239,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6806779235040468), 'usv_1': np.float64(-1.5723097257915402)}
    Episode time: 21.0s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.25498544 -0.20700675] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 1210, Avg Reward: 1.997, Episode Reward: 2416.4
    æ£€æµ‹è¿›åº¦: 1/37 (2.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(285,3075)'), ('usv_1', '(265,4106)'), ('usv_2', '(335,5093)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9221965819770612), 'usv_1': np.float64(-0.5796599691076109)}
    Episode time: 121.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 2210, Avg Reward: 4.978, Episode Reward: 11002.0
    æ£€æµ‹è¿›åº¦: 2/57 (3.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(292,2996)'), ('usv_1', '(277,4072)'), ('usv_2', '(313,5029)')]...
    Recent rewards sample: {'usv_0': np.float64(6.926707982494167), 'usv_1': np.float64(0.4216070072095037)}
    Episode time: 221.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 27993.6
  Targets Detected: 4/73 (5.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.33
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 209, Avg Reward: -3.586, Episode Reward: -749.4
    æ£€æµ‹è¿›åº¦: 0/7 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3127)'), ('usv_1', '(218,4130)'), ('usv_2', '(236,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.679093559437562), 'usv_1': np.float64(-1.5813874525492906)}
    Episode time: 20.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 1209, Avg Reward: -2.731, Episode Reward: -3301.5
    æ£€æµ‹è¿›åº¦: 0/35 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(287,3059)'), ('usv_1', '(221,4101)'), ('usv_2', '(328,5100)')]...
    Recent rewards sample: {'usv_0': np.float64(2.9289183736401636), 'usv_1': np.float64(-1.582982252054562)}
    Episode time: 120.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: -3120.3
  Targets Detected: 0/46 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -1.73
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 408, Avg Reward: -3.607, Episode Reward: -1471.5
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,3118)'), ('usv_1', '(231,4128)'), ('usv_2', '(244,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6779235835896028), 'usv_1': np.float64(-1.5754810676807056)}
    Episode time: 40.8s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.09172827 0.05737451] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 1408, Avg Reward: 6.518, Episode Reward: 9177.6
    æ£€æµ‹è¿›åº¦: 3/46 (6.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(290,3004)'), ('usv_1', '(241,4090)'), ('usv_2', '(297,5062)')]...
    Recent rewards sample: {'usv_0': np.float64(6.927175620270246), 'usv_1': np.float64(0.42416276897386984)}
    Episode time: 140.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 2408, Avg Reward: 11.308, Episode Reward: 27229.1
    æ£€æµ‹è¿›åº¦: 3/57 (5.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(243,2914)'), ('usv_1', '(244,4045)'), ('usv_2', '(233,4979)')]...
    Recent rewards sample: {'usv_0': np.float64(7.934239755759822), 'usv_1': np.float64(1.4239414949366531)}
    Episode time: 240.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 40158.8
  Targets Detected: 6/71 (5.6%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.38
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 407, Avg Reward: -3.587, Episode Reward: -1460.0
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3124)'), ('usv_1', '(230,4123)'), ('usv_2', '(236,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6749032138433957), 'usv_1': np.float64(-1.5824436720615798)}
    Episode time: 40.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 1407, Avg Reward: 2.222, Episode Reward: 3126.1
    æ£€æµ‹è¿›åº¦: 1/27 (3.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3055)'), ('usv_1', '(243,4089)'), ('usv_2', '(299,5014)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9349446212494104), 'usv_1': np.float64(-0.5807048362557117)}
    Episode time: 140.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 2407, Avg Reward: 7.267, Episode Reward: 17490.6
    æ£€æµ‹è¿›åº¦: 1/38 (2.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(201,3023)'), ('usv_1', '(228,4058)'), ('usv_2', '(273,4911)')]...
    Recent rewards sample: {'usv_0': np.float64(4.929923378200255), 'usv_1': np.float64(0.4192761014311255)}
    Episode time: 240.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 22584.2
  Targets Detected: 2/40 (2.5%)
  Steps: 2773
  Episode Time: 277.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 8.14
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.05999255 -0.09374704] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 634, Avg Reward: 9.205, Episode Reward: 5835.8
    æ£€æµ‹è¿›åº¦: 2/13 (15.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3114)'), ('usv_1', '(238,4126)'), ('usv_2', '(274,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(3.331164361605137), 'usv_1': np.float64(0.41887783821085955)}
    Episode time: 63.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 1634, Avg Reward: 12.919, Episode Reward: 21108.9
    æ£€æµ‹è¿›åº¦: 2/31 (6.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(303,3011)'), ('usv_1', '(251,4086)'), ('usv_2', '(377,5120)')]...
    Recent rewards sample: {'usv_0': np.float64(6.935252264709497), 'usv_1': np.float64(0.42097926888095594)}
    Episode time: 163.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 30735.5
  Targets Detected: 3/45 (0.0%)
  Steps: 2184
  Episode Time: 218.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 14.07
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 450, Avg Reward: 4.916, Episode Reward: 2212.3
    æ£€æµ‹è¿›åº¦: 2/12 (16.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3120)'), ('usv_1', '(236,4128)'), ('usv_2', '(253,5122)')]...
    Recent rewards sample: {'usv_0': np.float64(0.32356448739570576), 'usv_1': np.float64(1.4199408258833213)}
    Episode time: 45.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 1450, Avg Reward: 6.072, Episode Reward: 8805.1
    æ£€æµ‹è¿›åº¦: 1/28 (3.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3047)'), ('usv_1', '(272,4119)'), ('usv_2', '(270,5044)')]...
    Recent rewards sample: {'usv_0': np.float64(4.925528921504089), 'usv_1': np.float64(2.4218118389670398)}
    Episode time: 145.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: 16003.6
  Targets Detected: 3/41 (4.9%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_160s
  Average Reward/Step: 8.89

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 26694.6
Last 10 episodes average detections: 3.3
Best episode reward so far: 56860.6
Best detection count so far: 9
Learning trend: Improving (26694.6 vs 23815.7)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 649, Avg Reward: -3.991, Episode Reward: -2589.9
    æ£€æµ‹è¿›åº¦: 0/16 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,3121)'), ('usv_1', '(242,4125)'), ('usv_2', '(258,5097)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.721399518924746), 'usv_1': np.float64(-1.627511981805307)}
    Episode time: 64.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.02241702 -0.14153418] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 1649, Avg Reward: 4.040, Episode Reward: 6661.5
    æ£€æµ‹è¿›åº¦: 4/53 (7.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(306,3065)'), ('usv_1', '(276,4101)'), ('usv_2', '(282,4996)')]...
    Recent rewards sample: {'usv_0': np.float64(7.874999071542203), 'usv_1': np.float64(1.3751763836593267)}
    Episode time: 164.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 2649, Avg Reward: 12.401, Episode Reward: 32850.5
    æ£€æµ‹è¿›åº¦: 8/91 (8.8%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3049)'), ('usv_1', '(271,4070)'), ('usv_2', '(211,4927)')]...
    Recent rewards sample: {'usv_0': np.float64(7.871901307000526), 'usv_1': np.float64(3.3731780749928113)}
    Episode time: 264.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: 41171.8
  Targets Detected: 9/100 (8.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.72
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 648, Avg Reward: 1.830, Episode Reward: 1185.7
    æ£€æµ‹è¿›åº¦: 3/27 (11.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(266,3120)'), ('usv_1', '(228,4119)'), ('usv_2', '(262,5105)')]...
    Recent rewards sample: {'usv_0': np.float64(3.2801300319550246), 'usv_1': np.float64(0.37659881690764974)}
    Episode time: 64.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 1648, Avg Reward: 15.033, Episode Reward: 24774.6
    æ£€æµ‹è¿›åº¦: 6/64 (9.4%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(325,3075)'), ('usv_1', '(221,4084)'), ('usv_2', '(304,5010)')]...
    Recent rewards sample: {'usv_0': np.float64(7.877162187451621), 'usv_1': np.float64(3.3672230666288785)}
    Episode time: 164.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 2648, Avg Reward: 18.408, Episode Reward: 48744.5
    æ£€æµ‹è¿›åº¦: 7/91 (7.7%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3019)'), ('usv_1', '(210,4058)'), ('usv_2', '(296,4908)')]...
    Recent rewards sample: {'usv_0': np.float64(7.872463700903664), 'usv_1': np.float64(3.3744445641466854)}
    Episode time: 264.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 55860.9
  Targets Detected: 8/101 (5.9%)
  Steps: 2949
  Episode Time: 294.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.94
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.21065616 0.0163992 ] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 699, Avg Reward: 4.166, Episode Reward: 2912.2
    æ£€æµ‹è¿›åº¦: 2/28 (7.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3106)'), ('usv_1', '(251,4123)'), ('usv_2', '(281,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2833078536671267), 'usv_1': np.float64(0.3701564746365298)}
    Episode time: 69.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 1699, Avg Reward: 9.062, Episode Reward: 15396.9
    æ£€æµ‹è¿›åº¦: 1/36 (2.8%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3017)'), ('usv_1', '(294,4098)'), ('usv_2', '(377,5097)')]...
    Recent rewards sample: {'usv_0': np.float64(4.872852660743847), 'usv_1': np.float64(0.37256570086159746)}
    Episode time: 169.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 17780.2
  Targets Detected: 2/42 (2.4%)
  Steps: 1873
  Episode Time: 187.3s
  Termination Reason: no_progress_120s
  Average Reward/Step: 9.49
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 826, Avg Reward: 5.090, Episode Reward: 4204.6
    æ£€æµ‹è¿›åº¦: 3/28 (10.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(291,3091)'), ('usv_1', '(245,4105)'), ('usv_2', '(285,5129)')]...
    Recent rewards sample: {'usv_0': np.float64(282.28879511848777), 'usv_1': np.float64(283.36882041323594)}
    Episode time: 82.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 1826, Avg Reward: 16.130, Episode Reward: 29453.5
    æ£€æµ‹è¿›åº¦: 5/57 (8.8%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(270,3014)'), ('usv_1', '(222,4080)'), ('usv_2', '(347,5066)')]...
    Recent rewards sample: {'usv_0': np.float64(7.872469451171575), 'usv_1': np.float64(3.3701977635270115)}
    Episode time: 182.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 2826, Avg Reward: 19.992, Episode Reward: 56497.9
    æ£€æµ‹è¿›åº¦: 7/81 (8.6%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(208,2954)'), ('usv_1', '(205,4101)'), ('usv_2', '(351,4971)')]...
    Recent rewards sample: {'usv_0': np.float64(7.870799576237928), 'usv_1': np.float64(3.366010905254468)}
    Episode time: 282.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 60930.4
  Targets Detected: 9/83 (8.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.30
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.17279398  0.11417318] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 825, Avg Reward: 13.248, Episode Reward: 10930.0
    æ£€æµ‹è¿›åº¦: 3/28 (10.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3090)'), ('usv_1', '(249,4124)'), ('usv_2', '(318,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(4.285292481925862), 'usv_1': np.float64(3.369009736592319)}
    Episode time: 82.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 1825, Avg Reward: 18.707, Episode Reward: 34140.4
    æ£€æµ‹è¿›åº¦: 4/50 (8.0%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3002)'), ('usv_1', '(236,4097)'), ('usv_2', '(400,5064)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8765441144820425), 'usv_1': np.float64(3.3701603705875804)}
    Episode time: 182.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 2825, Avg Reward: 21.079, Episode Reward: 59547.5
    æ£€æµ‹è¿›åº¦: 10/80 (12.5%), Episode total: 12
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,2941)'), ('usv_1', '(209,4108)'), ('usv_2', '(419,4992)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8764196789932805), 'usv_1': np.float64(3.376695057968294)}
    Episode time: 282.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 64583.0
  Targets Detected: 13/80 (13.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.52
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 824, Avg Reward: 10.606, Episode Reward: 8739.6
    æ£€æµ‹è¿›åº¦: 2/31 (6.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(286,3098)'), ('usv_1', '(241,4106)'), ('usv_2', '(291,5090)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2863250128942565), 'usv_1': np.float64(0.371507027693861)}
    Episode time: 82.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 20722.1
  Targets Detected: 2/55 (3.6%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_161s
  Average Reward/Step: 11.51
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 23, Avg Reward: -3.845, Episode Reward: -88.4
    æ£€æµ‹è¿›åº¦: 0/4 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.733597157637316), 'usv_1': np.float64(-1.6302295347499196)}
    Episode time: 2.3s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.09243938 -0.04067963] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 1023, Avg Reward: -2.027, Episode Reward: -2073.1
    æ£€æµ‹è¿›åº¦: 1/37 (2.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3069)'), ('usv_1', '(264,4107)'), ('usv_2', '(292,5097)')]...
    Recent rewards sample: {'usv_0': np.float64(3.8741492742365238), 'usv_1': np.float64(-0.6297843286317162)}
    Episode time: 102.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 2023, Avg Reward: 10.986, Episode Reward: 22225.0
    æ£€æµ‹è¿›åº¦: 6/72 (8.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(201,2990)'), ('usv_1', '(282,4067)'), ('usv_2', '(302,5017)')]...
    Recent rewards sample: {'usv_0': np.float64(7.868729625358905), 'usv_1': np.float64(3.372074720054769)}
    Episode time: 202.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 44510.2
  Targets Detected: 8/94 (8.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.83
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 22, Avg Reward: -3.927, Episode Reward: -86.4
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(212,3130)'), ('usv_1', '(212,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.737233486588469), 'usv_1': np.float64(-1.633799175830426)}
    Episode time: 2.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 1022, Avg Reward: 3.289, Episode Reward: 3361.6
    æ£€æµ‹è¿›åº¦: 1/26 (3.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3065)'), ('usv_1', '(259,4102)'), ('usv_2', '(315,5061)')]...
    Recent rewards sample: {'usv_0': np.float64(5.8753830744265265), 'usv_1': np.float64(-0.6246054902315317)}
    Episode time: 102.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 2022, Avg Reward: 8.193, Episode Reward: 16565.9
    æ£€æµ‹è¿›åº¦: 3/53 (5.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,2998)'), ('usv_1', '(262,4072)'), ('usv_2', '(288,4961)')]...
    Recent rewards sample: {'usv_0': np.float64(6.8717150532636415), 'usv_1': np.float64(0.37151754324564257)}
    Episode time: 202.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 25957.3
  Targets Detected: 4/59 (5.1%)
  Steps: 2545
  Episode Time: 254.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 10.20
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.00525832 -0.07510707] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 100000, Episode Steps: 477, Avg Reward: -0.474, Episode Reward: -226.3
    æ£€æµ‹è¿›åº¦: 2/12 (16.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,3120)'), ('usv_1', '(231,4119)'), ('usv_2', '(253,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(1.283699995467663), 'usv_1': np.float64(0.372894402503235)}
    Episode time: 47.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 101000, Episode Steps: 1477, Avg Reward: 8.458, Episode Reward: 12492.4
    æ£€æµ‹è¿›åº¦: 4/37 (10.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,3058)'), ('usv_1', '(260,4074)'), ('usv_2', '(352,5115)')]...
    Recent rewards sample: {'usv_0': np.float64(5.8721224736234845), 'usv_1': np.float64(1.370341800191984)}
    Episode time: 147.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 102000, Episode Steps: 2477, Avg Reward: 12.400, Episode Reward: 30715.3
    æ£€æµ‹è¿›åº¦: 4/66 (6.1%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(201,3028)'), ('usv_1', '(247,4030)'), ('usv_2', '(375,5031)')]...
    Recent rewards sample: {'usv_0': np.float64(5.874646300470079), 'usv_1': np.float64(1.3703645730584166)}
    Episode time: 247.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 44069.2
  Targets Detected: 12/76 (10.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.68
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 103000, Episode Steps: 476, Avg Reward: -3.611, Episode Reward: -1718.6
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(257,3111)'), ('usv_1', '(228,4122)'), ('usv_2', '(255,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(0.28059666380784676), 'usv_1': np.float64(-0.6325758705761535)}
    Episode time: 47.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 104000, Episode Steps: 1476, Avg Reward: 11.686, Episode Reward: 17248.7
    æ£€æµ‹è¿›åº¦: 2/39 (5.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(301,3041)'), ('usv_1', '(234,4081)'), ('usv_2', '(364,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(7.874952531968147), 'usv_1': np.float64(1.3742699617161884)}
    Episode time: 147.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.01911592  0.17380459] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 105000, Episode Steps: 2476, Avg Reward: 17.085, Episode Reward: 42301.5
    æ£€æµ‹è¿›åº¦: 6/85 (7.1%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(233,2993)'), ('usv_1', '(201,4056)'), ('usv_2', '(468,5080)')]...
    Recent rewards sample: {'usv_0': np.float64(7.872867050002667), 'usv_1': np.float64(1.3688175690740652)}
    Episode time: 247.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 55294.0
  Targets Detected: 9/97 (7.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.43

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 43087.9
Last 10 episodes average detections: 7.6
Best episode reward so far: 64583.0
Best detection count so far: 13
Learning trend: Improving (43087.9 vs 26694.6)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 106000, Episode Steps: 475, Avg Reward: -3.922, Episode Reward: -1862.9
    æ£€æµ‹è¿›åº¦: 0/30 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3115)'), ('usv_1', '(231,4127)'), ('usv_2', '(252,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7136797441615217), 'usv_1': np.float64(-1.6303736304733398)}
    Episode time: 47.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 107000, Episode Steps: 1475, Avg Reward: -2.508, Episode Reward: -3699.4
    æ£€æµ‹è¿›åº¦: 0/62 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(306,3023)'), ('usv_1', '(247,4080)'), ('usv_2', '(316,5079)')]...
    Recent rewards sample: {'usv_0': np.float64(2.875753416194141), 'usv_1': np.float64(-1.6307209806820824)}
    Episode time: 147.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: -3807.9
  Targets Detected: 0/70 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -2.11
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 108000, Episode Steps: 674, Avg Reward: 7.834, Episode Reward: 5280.0
    æ£€æµ‹è¿›åº¦: 2/20 (10.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3109)'), ('usv_1', '(242,4124)'), ('usv_2', '(293,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(2.28638602492876), 'usv_1': np.float64(1.3684623265566467)}
    Episode time: 67.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 109000, Episode Steps: 1674, Avg Reward: 17.228, Episode Reward: 28839.9
    æ£€æµ‹è¿›åº¦: 5/54 (9.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(322,3036)'), ('usv_1', '(237,4081)'), ('usv_2', '(384,5070)')]...
    Recent rewards sample: {'usv_0': np.float64(7.875577900160076), 'usv_1': np.float64(3.3710348454661663)}
    Episode time: 167.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.06551673 -0.18627733] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 110000, Episode Steps: 2674, Avg Reward: 21.732, Episode Reward: 58110.1
    æ£€æµ‹è¿›åº¦: 11/94 (11.7%), Episode total: 14
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(269,3006)'), ('usv_1', '(200,4073)'), ('usv_2', '(364,4993)')]...
    Recent rewards sample: {'usv_0': np.float64(6.875630060360375), 'usv_1': np.float64(3.3699126681274025)}
    Episode time: 267.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 66415.3
  Targets Detected: 14/101 (10.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 22.13
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 111000, Episode Steps: 673, Avg Reward: 7.569, Episode Reward: 5093.8
    æ£€æµ‹è¿›åº¦: 3/21 (14.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3121)'), ('usv_1', '(236,4111)'), ('usv_2', '(277,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(4.287907282518042), 'usv_1': np.float64(1.370159363709651)}
    Episode time: 67.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 112000, Episode Steps: 1673, Avg Reward: 13.863, Episode Reward: 23192.2
    æ£€æµ‹è¿›åº¦: 3/46 (6.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(328,3053)'), ('usv_1', '(206,4088)'), ('usv_2', '(371,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(5.87576053944188), 'usv_1': np.float64(1.3688784692608125)}
    Episode time: 167.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 25713.6
  Targets Detected: 4/51 (5.9%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_122s
  Average Reward/Step: 14.28
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 113000, Episode Steps: 872, Avg Reward: -1.030, Episode Reward: -898.1
    æ£€æµ‹è¿›åº¦: 1/33 (3.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(303,3091)'), ('usv_1', '(224,4093)'), ('usv_2', '(285,5101)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2958137277853004), 'usv_1': np.float64(-0.6266564441924303)}
    Episode time: 87.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 114000, Episode Steps: 1872, Avg Reward: 3.716, Episode Reward: 6956.2
    æ£€æµ‹è¿›åº¦: 3/54 (5.6%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(302,3013)'), ('usv_1', '(204,4061)'), ('usv_2', '(290,5021)')]...
    Recent rewards sample: {'usv_0': np.float64(5.88071979093626), 'usv_1': np.float64(-0.63256663768539)}
    Episode time: 187.2s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.3072742  0.00283779] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 115000, Episode Steps: 2872, Avg Reward: 8.689, Episode Reward: 24955.7
    æ£€æµ‹è¿›åº¦: 5/86 (5.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(229,3006)'), ('usv_1', '(208,4058)'), ('usv_2', '(218,4970)')]...
    Recent rewards sample: {'usv_0': np.float64(5.883226305154369), 'usv_1': np.float64(3.368089221432953)}
    Episode time: 287.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 27491.5
  Targets Detected: 5/92 (5.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.16
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 116000, Episode Steps: 871, Avg Reward: 13.516, Episode Reward: 11772.4
    æ£€æµ‹è¿›åº¦: 3/32 (9.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3066)'), ('usv_1', '(248,4141)'), ('usv_2', '(286,5102)')]...
    Recent rewards sample: {'usv_0': np.float64(5.871753930508346), 'usv_1': np.float64(1.3699935017625626)}
    Episode time: 87.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 32194.1
  Targets Detected: 4/47 (6.4%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_121s
  Average Reward/Step: 17.88
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 117000, Episode Steps: 70, Avg Reward: -3.897, Episode Reward: -272.8
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(217,3130)'), ('usv_1', '(216,4130)'), ('usv_2', '(221,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7253050633435235), 'usv_1': np.float64(-1.6291828140102096)}
    Episode time: 7.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 118000, Episode Steps: 1070, Avg Reward: 13.592, Episode Reward: 14543.1
    æ£€æµ‹è¿›åº¦: 3/15 (20.0%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,3068)'), ('usv_1', '(224,4092)'), ('usv_2', '(307,5104)')]...
    Recent rewards sample: {'usv_0': np.float64(7.879406152784079), 'usv_1': np.float64(1.367377318666247)}
    Episode time: 107.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 119000, Episode Steps: 2070, Avg Reward: 19.018, Episode Reward: 39367.4
    æ£€æµ‹è¿›åº¦: 7/44 (15.9%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(202,2999)'), ('usv_1', '(205,4073)'), ('usv_2', '(388,5028)')]...
    Recent rewards sample: {'usv_0': np.float64(7.876016143206663), 'usv_1': np.float64(3.371438227819155)}
    Episode time: 207.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 63647.4
  Targets Detected: 12/78 (12.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.21
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.11255759 0.08614702] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 120000, Episode Steps: 69, Avg Reward: -3.899, Episode Reward: -269.0
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3130)'), ('usv_1', '(215,4130)'), ('usv_2', '(222,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7338274821493873), 'usv_1': np.float64(-1.6335742136577291)}
    Episode time: 6.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 121000, Episode Steps: 1069, Avg Reward: -3.316, Episode Reward: -3545.1
    æ£€æµ‹è¿›åº¦: 0/23 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(276,3062)'), ('usv_1', '(246,4120)'), ('usv_2', '(321,5072)')]...
    Recent rewards sample: {'usv_0': np.float64(2.8780316293886012), 'usv_1': np.float64(-1.6312201530207526)}
    Episode time: 106.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 122000, Episode Steps: 2069, Avg Reward: 5.376, Episode Reward: 11122.3
    æ£€æµ‹è¿›åº¦: 3/47 (6.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,2984)'), ('usv_1', '(205,4085)'), ('usv_2', '(303,4979)')]...
    Recent rewards sample: {'usv_0': np.float64(5.872518163922693), 'usv_1': np.float64(3.371324150430558)}
    Episode time: 206.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 33296.6
  Targets Detected: 7/73 (6.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.10
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 123000, Episode Steps: 68, Avg Reward: -3.926, Episode Reward: -267.0
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(218,3130)'), ('usv_1', '(215,4130)'), ('usv_2', '(222,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.731752963968965), 'usv_1': np.float64(-1.6335854115913475)}
    Episode time: 6.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 124000, Episode Steps: 1068, Avg Reward: 4.394, Episode Reward: 4693.2
    æ£€æµ‹è¿›åº¦: 2/40 (5.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3083)'), ('usv_1', '(233,4096)'), ('usv_2', '(322,5117)')]...
    Recent rewards sample: {'usv_0': np.float64(4.877020717946077), 'usv_1': np.float64(0.3680168157825652)}
    Episode time: 106.8s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.36630012 -0.26630789] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 125000, Episode Steps: 2068, Avg Reward: 14.202, Episode Reward: 29369.4
    æ£€æµ‹è¿›åº¦: 7/83 (8.4%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,3115)'), ('usv_1', '(205,4071)'), ('usv_2', '(392,5053)')]...
    Recent rewards sample: {'usv_0': np.float64(2.2693707051272556), 'usv_1': np.float64(3.366333729551723)}
    Episode time: 206.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 47467.6
  Targets Detected: 9/104 (7.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.82
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 126000, Episode Steps: 67, Avg Reward: -4.970, Episode Reward: -333.0
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(224,3130)'), ('usv_1', '(213,4130)'), ('usv_2', '(223,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7276536867326422), 'usv_1': np.float64(-1.6337277379942998)}
    Episode time: 6.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 127000, Episode Steps: 1067, Avg Reward: 6.934, Episode Reward: 7398.5
    æ£€æµ‹è¿›åº¦: 4/36 (11.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3060)'), ('usv_1', '(253,4119)'), ('usv_2', '(310,5100)')]...
    Recent rewards sample: {'usv_0': np.float64(5.875475410835358), 'usv_1': np.float64(3.370114465249742)}
    Episode time: 106.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 128000, Episode Steps: 2067, Avg Reward: 14.446, Episode Reward: 29860.2
    æ£€æµ‹è¿›åº¦: 6/71 (8.5%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(200,2981)'), ('usv_1', '(262,4082)'), ('usv_2', '(371,5032)')]...
    Recent rewards sample: {'usv_0': np.float64(5.8743000993240795), 'usv_1': np.float64(3.3725943390758424)}
    Episode time: 206.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 52461.7
  Targets Detected: 9/95 (6.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.48
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 129000, Episode Steps: 66, Avg Reward: -4.568, Episode Reward: -301.5
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(216,3130)'), ('usv_1', '(214,4130)'), ('usv_2', '(225,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7267410907894724), 'usv_1': np.float64(-1.6336927583715732)}
    Episode time: 6.6s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.36499014 -0.06926267] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 130000, Episode Steps: 1066, Avg Reward: 2.350, Episode Reward: 2504.7
    æ£€æµ‹è¿›åº¦: 1/22 (4.5%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,3072)'), ('usv_1', '(246,4135)'), ('usv_2', '(299,5082)')]...
    Recent rewards sample: {'usv_0': np.float64(3.88653744221977), 'usv_1': np.float64(1.370786026081639)}
    Episode time: 106.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Avg Actor Loss: -0.0708, Avg Critic Loss: 194.3937
    Step 131000, Episode Steps: 2066, Avg Reward: 12.430, Episode Reward: 25681.4
    æ£€æµ‹è¿›åº¦: 5/45 (11.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(263,2984)'), ('usv_1', '(278,4171)'), ('usv_2', '(368,4989)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8858176692751645), 'usv_1': np.float64(3.372452983935581)}
    Episode time: 206.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 48836.5
  Targets Detected: 9/69 (10.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.27

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 39371.7
Last 10 episodes average detections: 7.3
Best episode reward so far: 66415.3
Best detection count so far: 14
Learning trend: Declining (39371.7 vs 43087.9)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 66415.3
Final 10 episodes average: 39371.7
Best detection performance: 14 targets
Average detections (final 10): 7.3
============================================================
{"final_avg_reward": 39371.65882111096, "final_detection_rate": 7.3, "best_episode_reward": 66415.3110201752, "best_detection_count": 14, "total_episodes": 50}
Simulation finished.
