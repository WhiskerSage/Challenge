D:\Anaconda3\envs\lunarlander\lib\site-packages\pygame\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
D:\Anaconda3\envs\lunarlander\lib\site-packages\gymnasium\spaces\box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
pygame 2.6.1 (SDL 2.28.4, Python 3.9.23)
Hello from the pygame community. https://www.pygame.org/contribute.html
MADDPGè®­ç»ƒæ¨¡å¼ï¼šå·²ç¦ç”¨å¯è§†åŒ–æ¸²æŸ“ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
ä½¿ç”¨è®¾å¤‡: cpu
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 1 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
MADDPGåˆå§‹åŒ–å®Œæˆ: 6ä¸ªæ™ºèƒ½ä½“
    MADDPG UPDATING at time_step 1000...
    MADDPG UPDATE finished.
    Step 1000, Episode Steps: 1000, Avg Reward: 2.318, Episode Reward: 2317.9
    æ£€æµ‹è¿›åº¦: 1/5 (20.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(269,3076)'), ('usv_1', '(265,4127)'), ('usv_2', '(211,5167)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9734474549516294), 'usv_1': np.float64(-0.5293941560945137)}
    Episode time: 100.0s, Time penalty=-0.05
------------------------------------------------------------
Episode 1 Summary:
  Total Reward: 7925.7
  Targets Detected: 1/12 (8.3%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_149s
  Average Reward/Step: 4.40
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 2 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 2000...
    MADDPG UPDATE finished.
    Step 2000, Episode Steps: 199, Avg Reward: 7.217, Episode Reward: 1436.1
    æ£€æµ‹è¿›åº¦: 1/7 (14.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(230,3130)'), ('usv_1', '(231,4131)'), ('usv_2', '(224,5132)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3684385167879474), 'usv_1': np.float64(0.4749328424403447)}
    Episode time: 19.9s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 3000...
    MADDPG UPDATE finished.
    Step 3000, Episode Steps: 1199, Avg Reward: 19.757, Episode Reward: 23688.4
    æ£€æµ‹è¿›åº¦: 6/24 (25.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3049)'), ('usv_1', '(277,4146)'), ('usv_2', '(249,5198)')]...
    Recent rewards sample: {'usv_0': np.float64(7.972060675941336), 'usv_1': np.float64(3.478201667246953)}
    Episode time: 119.9s, Time penalty=-0.05
------------------------------------------------------------
Episode 2 Summary:
  Total Reward: 47744.5
  Targets Detected: 7/32 (12.5%)
  Steps: 2144
  Episode Time: 214.4s
  Termination Reason: no_progress_120s
  Average Reward/Step: 22.27
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 3 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 4000...
    MADDPG UPDATE finished.
    Step 4000, Episode Steps: 55, Avg Reward: -3.045, Episode Reward: -167.5
    æ£€æµ‹è¿›åº¦: 0/2 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(213,4130)'), ('usv_2', '(214,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.635185320891851), 'usv_1': np.float64(-1.533757870339731)}
    Episode time: 5.5s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.13632452 -0.31170055] (agent usv_0)
    MADDPG UPDATING at time_step 5000...
    MADDPG UPDATE finished.
    Step 5000, Episode Steps: 1055, Avg Reward: 0.570, Episode Reward: 600.8
    æ£€æµ‹è¿›åº¦: 2/14 (14.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(266,3061)'), ('usv_1', '(272,4141)'), ('usv_2', '(231,5177)')]...
    Recent rewards sample: {'usv_0': np.float64(4.975818227972919), 'usv_1': np.float64(0.4757578238299842)}
    Episode time: 105.5s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 6000...
    MADDPG UPDATE finished.
    Step 6000, Episode Steps: 2055, Avg Reward: 11.802, Episode Reward: 24252.2
    æ£€æµ‹è¿›åº¦: 5/29 (17.2%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3001)'), ('usv_1', '(337,4157)'), ('usv_2', '(201,5152)')]...
    Recent rewards sample: {'usv_0': np.float64(5.971128059455124), 'usv_1': np.float64(1.4760020557409699)}
    Episode time: 205.5s, Time penalty=-0.05
------------------------------------------------------------
Episode 3 Summary:
  Total Reward: 37438.8
  Targets Detected: 5/41 (7.3%)
  Steps: 2681
  Episode Time: 268.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.96
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 4 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 7000...
    MADDPG UPDATE finished.
    Step 7000, Episode Steps: 374, Avg Reward: 9.402, Episode Reward: 3516.5
    æ£€æµ‹è¿›åº¦: 2/12 (16.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3122)'), ('usv_1', '(237,4129)'), ('usv_2', '(236,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(1.370006285689983), 'usv_1': np.float64(0.46895024204659985)}
    Episode time: 37.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 8000...
    MADDPG UPDATE finished.
    Step 8000, Episode Steps: 1374, Avg Reward: 9.160, Episode Reward: 12586.3
    æ£€æµ‹è¿›åº¦: 2/21 (9.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(323,3093)'), ('usv_1', '(307,4143)'), ('usv_2', '(271,5180)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3983479542931347), 'usv_1': np.float64(0.47649706485396837)}
    Episode time: 137.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 4 Summary:
  Total Reward: 17273.4
  Targets Detected: 2/30 (6.7%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_154s
  Average Reward/Step: 9.59
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 5 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 9000...
    MADDPG UPDATE finished.
    Step 9000, Episode Steps: 573, Avg Reward: -3.006, Episode Reward: -1722.4
    æ£€æµ‹è¿›åº¦: 1/5 (20.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(246,3110)'), ('usv_1', '(246,4133)'), ('usv_2', '(229,5152)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6157603065678274), 'usv_1': np.float64(-1.5312081203356804)}
    Episode time: 57.3s, Time penalty=-0.05
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.09455166 -0.09710097] (agent usv_0)
    MADDPG UPDATING at time_step 10000...
    MADDPG UPDATE finished.
    Step 10000, Episode Steps: 1573, Avg Reward: 0.996, Episode Reward: 1567.5
    æ£€æµ‹è¿›åº¦: 2/27 (7.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,3025)'), ('usv_1', '(295,4143)'), ('usv_2', '(202,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(4.972725237319016), 'usv_1': np.float64(0.4725402354955015)}
    Episode time: 157.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 11000...
    MADDPG UPDATE finished.
    Step 11000, Episode Steps: 2573, Avg Reward: 9.794, Episode Reward: 25199.1
    æ£€æµ‹è¿›åº¦: 6/50 (12.0%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,2995)'), ('usv_1', '(355,4140)'), ('usv_2', '(248,5123)')]...
    Recent rewards sample: {'usv_0': np.float64(5.968764146636765), 'usv_1': np.float64(3.4840995468921996)}
    Episode time: 257.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 5 Summary:
  Total Reward: 35834.3
  Targets Detected: 8/59 (8.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.94
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 6 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 12000...
    MADDPG UPDATE finished.
    Step 12000, Episode Steps: 572, Avg Reward: -3.266, Episode Reward: -1867.9
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(277,3123)'), ('usv_1', '(246,4134)'), ('usv_2', '(225,5153)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6087352601452916), 'usv_1': np.float64(-1.5248471436018072)}
    Episode time: 57.2s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 13000...
    MADDPG UPDATE finished.
    Step 13000, Episode Steps: 1572, Avg Reward: 1.856, Episode Reward: 2917.9
    æ£€æµ‹è¿›åº¦: 4/27 (14.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(369,3081)'), ('usv_1', '(303,4125)'), ('usv_2', '(200,5161)')]...
    Recent rewards sample: {'usv_0': np.float64(5.979837117434053), 'usv_1': np.float64(1.4737079066652914)}
    Episode time: 157.2s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 14000...
    MADDPG UPDATE finished.
    Step 14000, Episode Steps: 2572, Avg Reward: 8.988, Episode Reward: 23116.9
    æ£€æµ‹è¿›åº¦: 3/35 (8.6%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(401,2982)'), ('usv_1', '(335,4074)'), ('usv_2', '(212,5107)')]...
    Recent rewards sample: {'usv_0': np.float64(5.983648418643947), 'usv_1': np.float64(3.480106178076001)}
    Episode time: 257.2s, Time penalty=-0.05
------------------------------------------------------------
Episode 6 Summary:
  Total Reward: 27090.4
  Targets Detected: 4/37 (8.1%)
  Steps: 2751
  Episode Time: 275.1s
  Termination Reason: no_progress_120s
  Average Reward/Step: 9.85
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 7 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.23598946 -0.13199408] (agent usv_0)
    MADDPG UPDATING at time_step 15000...
    MADDPG UPDATE finished.
    Step 15000, Episode Steps: 821, Avg Reward: 2.920, Episode Reward: 2397.1
    æ£€æµ‹è¿›åº¦: 1/12 (8.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3104)'), ('usv_1', '(272,4136)'), ('usv_2', '(264,5157)')]...
    Recent rewards sample: {'usv_0': np.float64(0.38477897114454973), 'usv_1': np.float64(1.4707760179901217)}
    Episode time: 82.1s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 16000...
    MADDPG UPDATE finished.
    Step 16000, Episode Steps: 1821, Avg Reward: 8.007, Episode Reward: 14581.3
    æ£€æµ‹è¿›åº¦: 2/22 (9.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(297,3038)'), ('usv_1', '(329,4153)'), ('usv_2', '(258,5196)')]...
    Recent rewards sample: {'usv_0': np.float64(4.9774345841519345), 'usv_1': np.float64(2.4751657434099856)}
    Episode time: 182.1s, Time penalty=-0.05
------------------------------------------------------------
Episode 7 Summary:
  Total Reward: 22813.9
  Targets Detected: 2/27 (3.7%)
  Steps: 2397
  Episode Time: 239.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 9.52
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 8 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 17000...
    MADDPG UPDATE finished.
    Step 17000, Episode Steps: 424, Avg Reward: 2.965, Episode Reward: 1257.0
    æ£€æµ‹è¿›åº¦: 1/14 (7.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(267,3118)'), ('usv_1', '(239,4130)'), ('usv_2', '(243,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(3.385127548280319), 'usv_1': np.float64(0.4682508127625553)}
    Episode time: 42.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 18000...
    MADDPG UPDATE finished.
    Step 18000, Episode Steps: 1424, Avg Reward: 14.105, Episode Reward: 20085.0
    æ£€æµ‹è¿›åº¦: 3/24 (12.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3037)'), ('usv_1', '(294,4113)'), ('usv_2', '(285,5200)')]...
    Recent rewards sample: {'usv_0': np.float64(7.9801749581895525), 'usv_1': np.float64(1.472457633819535)}
    Episode time: 142.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 19000...
    MADDPG UPDATE finished.
    Step 19000, Episode Steps: 2424, Avg Reward: 19.268, Episode Reward: 46705.7
    æ£€æµ‹è¿›åº¦: 6/47 (12.8%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3009)'), ('usv_1', '(343,4081)'), ('usv_2', '(250,5228)')]...
    Recent rewards sample: {'usv_0': np.float64(7.981733238070833), 'usv_1': np.float64(3.476447131702309)}
    Episode time: 242.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 8 Summary:
  Total Reward: 57622.4
  Targets Detected: 9/51 (13.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.20
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 9 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.0415971  -0.19021023] (agent usv_0)
    MADDPG UPDATING at time_step 20000...
    MADDPG UPDATE finished.
    Step 20000, Episode Steps: 423, Avg Reward: 9.684, Episode Reward: 4096.2
    æ£€æµ‹è¿›åº¦: 2/10 (20.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(239,3123)'), ('usv_1', '(238,4140)'), ('usv_2', '(225,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3734692555078576), 'usv_1': np.float64(2.4685934008307755)}
    Episode time: 42.3s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 21000...
    MADDPG UPDATE finished.
    Step 21000, Episode Steps: 1423, Avg Reward: 20.099, Episode Reward: 28601.5
    æ£€æµ‹è¿›åº¦: 7/29 (24.1%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(316,3083)'), ('usv_1', '(296,4181)'), ('usv_2', '(202,5170)')]...
    Recent rewards sample: {'usv_0': np.float64(7.976159291075046), 'usv_1': np.float64(3.4767718613609047)}
    Episode time: 142.3s, Time penalty=-0.05
------------------------------------------------------------
Episode 9 Summary:
  Total Reward: 45310.3
  Targets Detected: 9/34 (20.6%)
  Steps: 2059
  Episode Time: 205.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 22.01
    [Curriculum] Easy mode: è¾¹ç•Œç›®æ ‡ä¸»å¯¼, ä½Žé€Ÿç›®æ ‡, æŽ¢ç´¢å¥–åŠ±å¢žå¼º
--- Episode 10 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 22000...
    MADDPG UPDATE finished.
    Step 22000, Episode Steps: 364, Avg Reward: -3.243, Episode Reward: -1180.6
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(236,3125)'), ('usv_1', '(241,4125)'), ('usv_2', '(225,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6251583960660813), 'usv_1': np.float64(-1.5295644972203173)}
    Episode time: 36.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 23000...
    MADDPG UPDATE finished.
    Step 23000, Episode Steps: 1364, Avg Reward: 6.916, Episode Reward: 9432.8
    æ£€æµ‹è¿›åº¦: 2/25 (8.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(284,3056)'), ('usv_1', '(294,4104)'), ('usv_2', '(214,5184)')]...
    Recent rewards sample: {'usv_0': np.float64(7.981614719731079), 'usv_1': np.float64(3.4725280557228873)}
    Episode time: 136.4s, Time penalty=-0.05
------------------------------------------------------------
    MADDPG UPDATING at time_step 24000...
    MADDPG UPDATE finished.
    Step 24000, Episode Steps: 2364, Avg Reward: 14.122, Episode Reward: 33383.8
    æ£€æµ‹è¿›åº¦: 4/35 (11.4%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3008)'), ('usv_1', '(310,4053)'), ('usv_2', '(224,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(5.976304960825347), 'usv_1': np.float64(3.478288819239892)}
    Episode time: 236.4s, Time penalty=-0.05
------------------------------------------------------------
Episode 10 Summary:
  Total Reward: 46956.4
  Targets Detected: 4/42 (9.5%)
  Steps: 2966
  Episode Time: 296.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.83

==================================================
MADDPG TRAINING PROGRESS - Episode 10
==================================================
Last 10 episodes average reward: 34601.0
Last 10 episodes average detections: 5.1
Best episode reward so far: 57622.4
Best detection count so far: 9
Buffer size: 24602
==================================================

    [Curriculum] Medium mode: ç›®æ ‡ç±»åž‹å¹³è¡¡, é€Ÿåº¦æå‡
--- Episode 11 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.05602553 -0.03417938] (agent usv_0)
    MADDPG UPDATING at time_step 25000...
    MADDPG UPDATE finished.
    Step 25000, Episode Steps: 398, Avg Reward: 0.748, Episode Reward: 297.7
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3123)'), ('usv_1', '(237,4131)'), ('usv_2', '(230,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3283966811302418), 'usv_1': np.float64(-0.5783014983164726)}
    Episode time: 39.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 26000...
    MADDPG UPDATE finished.
    Step 26000, Episode Steps: 1398, Avg Reward: 12.557, Episode Reward: 17555.3
    æ£€æµ‹è¿›åº¦: 3/30 (10.0%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(332,3046)'), ('usv_1', '(302,4134)'), ('usv_2', '(208,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(7.93675560982811), 'usv_1': np.float64(1.4247352986943813)}
    Episode time: 139.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 11 Summary:
  Total Reward: 31388.0
  Targets Detected: 3/37 (2.7%)
  Steps: 2000
  Episode Time: 200.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.69
--- Episode 12 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 27000...
    MADDPG UPDATE finished.
    Step 27000, Episode Steps: 398, Avg Reward: 11.538, Episode Reward: 4592.0
    æ£€æµ‹è¿›åº¦: 2/7 (28.6%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3116)'), ('usv_1', '(236,4128)'), ('usv_2', '(237,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(3.3280172220154274), 'usv_1': np.float64(0.4227993719045313)}
    Episode time: 39.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 28000...
    MADDPG UPDATE finished.
    Step 28000, Episode Steps: 1398, Avg Reward: 16.264, Episode Reward: 22736.7
    æ£€æµ‹è¿›åº¦: 3/19 (15.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(271,3032)'), ('usv_1', '(277,4117)'), ('usv_2', '(257,5211)')]...
    Recent rewards sample: {'usv_0': np.float64(7.927897014755349), 'usv_1': np.float64(3.4214374018620024)}
    Episode time: 139.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 29000...
    MADDPG UPDATE finished.
    Step 29000, Episode Steps: 2398, Avg Reward: 20.233, Episode Reward: 48517.6
    æ£€æµ‹è¿›åº¦: 4/41 (9.8%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(209,3020)'), ('usv_1', '(344,4138)'), ('usv_2', '(200,5237)')]...
    Recent rewards sample: {'usv_0': np.float64(7.923530120459285), 'usv_1': np.float64(3.42719100808002)}
    Episode time: 239.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 12 Summary:
  Total Reward: 64166.9
  Targets Detected: 7/52 (11.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 21.38
--- Episode 13 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.09480926 -0.10969811] (agent usv_0)
    MADDPG UPDATING at time_step 30000...
    MADDPG UPDATE finished.
    Step 30000, Episode Steps: 397, Avg Reward: -3.587, Episode Reward: -1424.1
    æ£€æµ‹è¿›åº¦: 0/10 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3118)'), ('usv_1', '(225,4129)'), ('usv_2', '(250,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6721465566154096), 'usv_1': np.float64(-1.5827822568268541)}
    Episode time: 39.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 31000...
    MADDPG UPDATE finished.
    Step 31000, Episode Steps: 1397, Avg Reward: -0.806, Episode Reward: -1125.6
    æ£€æµ‹è¿›åº¦: 1/26 (3.8%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(301,3042)'), ('usv_1', '(254,4083)'), ('usv_2', '(272,5184)')]...
    Recent rewards sample: {'usv_0': np.float64(3.927467820355283), 'usv_1': np.float64(1.4219149739416115)}
    Episode time: 139.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 32000...
    MADDPG UPDATE finished.
    Step 32000, Episode Steps: 2397, Avg Reward: 6.466, Episode Reward: 15499.1
    æ£€æµ‹è¿›åº¦: 3/34 (8.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(259,2965)'), ('usv_1', '(262,4035)'), ('usv_2', '(230,5209)')]...
    Recent rewards sample: {'usv_0': np.float64(7.938361431621454), 'usv_1': np.float64(3.4269917214465906)}
    Episode time: 239.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 13 Summary:
  Total Reward: 29164.1
  Targets Detected: 4/46 (8.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 9.72
--- Episode 14 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 33000...
    MADDPG UPDATE finished.
    Step 33000, Episode Steps: 396, Avg Reward: -3.589, Episode Reward: -1421.4
    æ£€æµ‹è¿›åº¦: 0/8 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3123)'), ('usv_1', '(233,4139)'), ('usv_2', '(232,5133)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6767379163524981), 'usv_1': np.float64(-1.5821796356643618)}
    Episode time: 39.6s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 34000...
    MADDPG UPDATE finished.
    Step 34000, Episode Steps: 1396, Avg Reward: 7.246, Episode Reward: 10115.1
    æ£€æµ‹è¿›åº¦: 3/33 (9.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(296,3054)'), ('usv_1', '(281,4166)'), ('usv_2', '(209,5174)')]...
    Recent rewards sample: {'usv_0': np.float64(5.929996201201837), 'usv_1': np.float64(1.4234151651752343)}
    Episode time: 139.6s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.16639263 -0.23834118] (agent usv_0)
    MADDPG UPDATING at time_step 35000...
    MADDPG UPDATE finished.
    Step 35000, Episode Steps: 2396, Avg Reward: 12.613, Episode Reward: 30219.9
    æ£€æµ‹è¿›åº¦: 4/52 (7.7%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,2987)'), ('usv_1', '(324,4145)'), ('usv_2', '(210,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(5.932683198658473), 'usv_1': np.float64(1.4247412923938167)}
    Episode time: 239.6s, Time penalty=-0.1
------------------------------------------------------------
Episode 14 Summary:
  Total Reward: 43593.9
  Targets Detected: 8/65 (10.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.53
--- Episode 15 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 36000...
    MADDPG UPDATE finished.
    Step 36000, Episode Steps: 395, Avg Reward: -2.857, Episode Reward: -1128.3
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(241,3129)'), ('usv_1', '(224,4128)'), ('usv_2', '(245,5137)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3202803845568366), 'usv_1': np.float64(1.418069267618118)}
    Episode time: 39.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 37000...
    MADDPG UPDATE finished.
    Step 37000, Episode Steps: 1395, Avg Reward: 6.706, Episode Reward: 9355.3
    æ£€æµ‹è¿›åº¦: 2/32 (6.2%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(300,3064)'), ('usv_1', '(265,4091)'), ('usv_2', '(245,5193)')]...
    Recent rewards sample: {'usv_0': np.float64(4.929708575182838), 'usv_1': np.float64(0.42827059930007527)}
    Episode time: 139.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 38000...
    MADDPG UPDATE finished.
    Step 38000, Episode Steps: 2395, Avg Reward: 10.548, Episode Reward: 25263.3
    æ£€æµ‹è¿›åº¦: 4/68 (5.9%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(286,2969)'), ('usv_1', '(291,4039)'), ('usv_2', '(209,5169)')]...
    Recent rewards sample: {'usv_0': np.float64(5.92740564884535), 'usv_1': np.float64(1.4299011395168737)}
    Episode time: 239.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 15 Summary:
  Total Reward: 38669.2
  Targets Detected: 5/74 (5.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.89
--- Episode 16 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 39000...
    MADDPG UPDATE finished.
    Step 39000, Episode Steps: 394, Avg Reward: 0.962, Episode Reward: 379.0
    æ£€æµ‹è¿›åº¦: 1/13 (7.7%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3128)'), ('usv_1', '(236,4128)'), ('usv_2', '(235,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3231682342721852), 'usv_1': np.float64(-0.5819974561840766)}
    Episode time: 39.4s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.09335372 -0.41306965] (agent usv_0)
    MADDPG UPDATING at time_step 40000...
    MADDPG UPDATE finished.
    Step 40000, Episode Steps: 1394, Avg Reward: 11.491, Episode Reward: 16018.0
    æ£€æµ‹è¿›åº¦: 5/36 (13.9%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(273,3062)'), ('usv_1', '(282,4128)'), ('usv_2', '(220,5177)')]...
    Recent rewards sample: {'usv_0': np.float64(5.921461868040338), 'usv_1': np.float64(1.4226844707618116)}
    Episode time: 139.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 41000...
    MADDPG UPDATE finished.
    Step 41000, Episode Steps: 2394, Avg Reward: 17.178, Episode Reward: 41123.5
    æ£€æµ‹è¿›åº¦: 7/62 (11.3%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(215,3021)'), ('usv_1', '(334,4140)'), ('usv_2', '(203,5151)')]...
    Recent rewards sample: {'usv_0': np.float64(7.919300922895707), 'usv_1': np.float64(3.4275521355080105)}
    Episode time: 239.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 16 Summary:
  Total Reward: 57893.5
  Targets Detected: 9/74 (12.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 19.29
--- Episode 17 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 42000...
    MADDPG UPDATE finished.
    Step 42000, Episode Steps: 393, Avg Reward: -3.567, Episode Reward: -1402.0
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(250,3123)'), ('usv_1', '(229,4129)'), ('usv_2', '(230,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6755241302099356), 'usv_1': np.float64(-1.5824974211743654)}
    Episode time: 39.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 43000...
    MADDPG UPDATE finished.
    Step 43000, Episode Steps: 1393, Avg Reward: 9.761, Episode Reward: 13596.6
    æ£€æµ‹è¿›åº¦: 3/42 (7.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(285,3057)'), ('usv_1', '(281,4132)'), ('usv_2', '(215,5195)')]...
    Recent rewards sample: {'usv_0': np.float64(5.922482011083631), 'usv_1': np.float64(1.421470680287824)}
    Episode time: 139.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 44000...
    MADDPG UPDATE finished.
    Step 44000, Episode Steps: 2393, Avg Reward: 14.979, Episode Reward: 35845.0
    æ£€æµ‹è¿›åº¦: 2/55 (3.6%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(248,2987)'), ('usv_1', '(321,4168)'), ('usv_2', '(218,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(5.921856489494937), 'usv_1': np.float64(1.424684653932022)}
    Episode time: 239.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 17 Summary:
  Total Reward: 39659.6
  Targets Detected: 4/55 (3.6%)
  Steps: 2566
  Episode Time: 256.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.46
--- Episode 18 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.12870124 -0.06477984] (agent usv_0)
    MADDPG UPDATING at time_step 45000...
    MADDPG UPDATE finished.
    Step 45000, Episode Steps: 827, Avg Reward: -3.585, Episode Reward: -2965.2
    æ£€æµ‹è¿›åº¦: 0/27 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(282,3101)'), ('usv_1', '(270,4145)'), ('usv_2', '(222,5161)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6637025229286759), 'usv_1': np.float64(-1.5712314025688074)}
    Episode time: 82.7s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 46000...
    MADDPG UPDATE finished.
    Step 46000, Episode Steps: 1827, Avg Reward: 10.738, Episode Reward: 19617.8
    æ£€æµ‹è¿›åº¦: 4/56 (7.1%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(322,3043)'), ('usv_1', '(306,4148)'), ('usv_2', '(203,5172)')]...
    Recent rewards sample: {'usv_0': np.float64(7.933195089101156), 'usv_1': np.float64(1.4233942093992686)}
    Episode time: 182.7s, Time penalty=-0.1
------------------------------------------------------------
Episode 18 Summary:
  Total Reward: 31358.6
  Targets Detected: 4/69 (5.8%)
  Steps: 2317
  Episode Time: 231.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 13.53
--- Episode 19 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 47000...
    MADDPG UPDATE finished.
    Step 47000, Episode Steps: 510, Avg Reward: 10.503, Episode Reward: 5356.6
    æ£€æµ‹è¿›åº¦: 2/12 (16.7%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3103)'), ('usv_1', '(245,4139)'), ('usv_2', '(222,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(3.336418805112132), 'usv_1': np.float64(0.41927659746299817)}
    Episode time: 51.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 48000...
    MADDPG UPDATE finished.
    Step 48000, Episode Steps: 1510, Avg Reward: 15.179, Episode Reward: 22920.2
    æ£€æµ‹è¿›åº¦: 4/34 (11.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(221,3022)'), ('usv_1', '(280,4168)'), ('usv_2', '(206,5128)')]...
    Recent rewards sample: {'usv_0': np.float64(7.923543002327739), 'usv_1': np.float64(1.4225884342570199)}
    Episode time: 151.0s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 49000...
    MADDPG UPDATE finished.
    Step 49000, Episode Steps: 2510, Avg Reward: 18.640, Episode Reward: 46785.3
    æ£€æµ‹è¿›åº¦: 6/45 (13.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(204,2988)'), ('usv_1', '(284,4213)'), ('usv_2', '(228,5087)')]...
    Recent rewards sample: {'usv_0': np.float64(7.9228610761853), 'usv_1': np.float64(1.4226037499899875)}
    Episode time: 251.0s, Time penalty=-0.1
------------------------------------------------------------
Episode 19 Summary:
  Total Reward: 60455.3
  Targets Detected: 9/56 (16.1%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.15
--- Episode 20 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.12144614  0.07696882] (agent usv_0)
    MADDPG UPDATING at time_step 50000...
    MADDPG UPDATE finished.
    Step 50000, Episode Steps: 509, Avg Reward: 6.835, Episode Reward: 3478.9
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3113)'), ('usv_1', '(238,4114)'), ('usv_2', '(234,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3276572911589462), 'usv_1': np.float64(2.418232781490553)}
    Episode time: 50.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 51000...
    MADDPG UPDATE finished.
    Step 51000, Episode Steps: 1509, Avg Reward: 15.885, Episode Reward: 23970.8
    æ£€æµ‹è¿›åº¦: 4/37 (10.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(290,3035)'), ('usv_1', '(279,4104)'), ('usv_2', '(214,5188)')]...
    Recent rewards sample: {'usv_0': np.float64(7.931029363627028), 'usv_1': np.float64(3.4232818750939957)}
    Episode time: 150.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 52000...
    MADDPG UPDATE finished.
    Step 52000, Episode Steps: 2509, Avg Reward: 19.110, Episode Reward: 47948.2
    æ£€æµ‹è¿›åº¦: 5/55 (9.1%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(225,2986)'), ('usv_1', '(342,4139)'), ('usv_2', '(206,5190)')]...
    Recent rewards sample: {'usv_0': np.float64(7.926836167654915), 'usv_1': np.float64(3.429385668935325)}
    Episode time: 250.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 20 Summary:
  Total Reward: 53163.1
  Targets Detected: 5/57 (8.8%)
  Steps: 2746
  Episode Time: 274.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 19.36

==================================================
MADDPG TRAINING PROGRESS - Episode 20
==================================================
Last 10 episodes average reward: 44951.2
Last 10 episodes average detections: 5.8
Best episode reward so far: 64166.9
Best detection count so far: 9
Learning trend: Improving (44951.2 vs 34601.0)
Buffer size: 50000
==================================================

--- Episode 21 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 53000...
    MADDPG UPDATE finished.
    Step 53000, Episode Steps: 763, Avg Reward: -2.426, Episode Reward: -1850.9
    æ£€æµ‹è¿›åº¦: 1/12 (8.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(266,3103)'), ('usv_1', '(255,4118)'), ('usv_2', '(217,5168)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3369111287205735), 'usv_1': np.float64(-0.5805325736127251)}
    Episode time: 76.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 54000...
    MADDPG UPDATE finished.
    Step 54000, Episode Steps: 1763, Avg Reward: 3.039, Episode Reward: 5357.0
    æ£€æµ‹è¿›åº¦: 1/47 (2.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3022)'), ('usv_1', '(286,4059)'), ('usv_2', '(207,5192)')]...
    Recent rewards sample: {'usv_0': np.float64(3.929125335083945), 'usv_1': np.float64(-0.5774945286799027)}
    Episode time: 176.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 21 Summary:
  Total Reward: 6604.1
  Targets Detected: 1/49 (2.0%)
  Steps: 1919
  Episode Time: 191.9s
  Termination Reason: no_progress_120s
  Average Reward/Step: 3.44
--- Episode 22 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.01897822 -0.03435687] (agent usv_0)
    MADDPG UPDATING at time_step 55000...
    MADDPG UPDATE finished.
    Step 55000, Episode Steps: 844, Avg Reward: 2.706, Episode Reward: 2284.0
    æ£€æµ‹è¿›åº¦: 2/15 (13.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(318,3108)'), ('usv_1', '(267,4135)'), ('usv_2', '(215,5172)')]...
    Recent rewards sample: {'usv_0': np.float64(1.3461033683494847), 'usv_1': np.float64(2.421527812802201)}
    Episode time: 84.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 56000...
    MADDPG UPDATE finished.
    Step 56000, Episode Steps: 1844, Avg Reward: 10.769, Episode Reward: 19857.9
    æ£€æµ‹è¿›åº¦: 3/36 (8.3%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(344,3028)'), ('usv_1', '(319,4101)'), ('usv_2', '(206,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(5.927394037116917), 'usv_1': np.float64(3.431338946005182)}
    Episode time: 184.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 57000...
    MADDPG UPDATE finished.
    Step 57000, Episode Steps: 2844, Avg Reward: 14.854, Episode Reward: 42244.1
    æ£€æµ‹è¿›åº¦: 6/64 (9.4%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(278,2969)'), ('usv_1', '(345,4042)'), ('usv_2', '(256,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(7.925522441532328), 'usv_1': np.float64(3.43364542169075)}
    Episode time: 284.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 22 Summary:
  Total Reward: 43187.2
  Targets Detected: 6/64 (9.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 14.39
--- Episode 23 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 58000...
    MADDPG UPDATE finished.
    Step 58000, Episode Steps: 843, Avg Reward: 8.469, Episode Reward: 7139.6
    æ£€æµ‹è¿›åº¦: 1/30 (3.3%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3086)'), ('usv_1', '(247,4120)'), ('usv_2', '(228,5155)')]...
    Recent rewards sample: {'usv_0': np.float64(4.927577015134124), 'usv_1': np.float64(0.4188433028815288)}
    Episode time: 84.3s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 59000...
    MADDPG UPDATE finished.
    Step 59000, Episode Steps: 1843, Avg Reward: 13.672, Episode Reward: 25197.0
    æ£€æµ‹è¿›åº¦: 3/46 (6.5%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(347,3001)'), ('usv_1', '(280,4078)'), ('usv_2', '(209,5142)')]...
    Recent rewards sample: {'usv_0': np.float64(5.944742676060479), 'usv_1': np.float64(1.4217527043022025)}
    Episode time: 184.3s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.1014929  -0.03557115] (agent usv_0)
    MADDPG UPDATING at time_step 60000...
    MADDPG UPDATE finished.
    Step 60000, Episode Steps: 2843, Avg Reward: 17.783, Episode Reward: 50558.4
    æ£€æµ‹è¿›åº¦: 5/65 (7.7%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(344,2897)'), ('usv_1', '(298,4023)'), ('usv_2', '(226,5073)')]...
    Recent rewards sample: {'usv_0': np.float64(7.93600816913063), 'usv_1': np.float64(3.4251578596460437)}
    Episode time: 284.3s, Time penalty=-0.1
------------------------------------------------------------
Episode 23 Summary:
  Total Reward: 54849.7
  Targets Detected: 8/67 (9.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 18.28
--- Episode 24 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 61000...
    MADDPG UPDATE finished.
    Step 61000, Episode Steps: 842, Avg Reward: 16.194, Episode Reward: 13635.8
    æ£€æµ‹è¿›åº¦: 5/19 (26.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(283,3110)'), ('usv_1', '(251,4116)'), ('usv_2', '(241,5163)')]...
    Recent rewards sample: {'usv_0': np.float64(4.333857057066677), 'usv_1': np.float64(1.4194074457075594)}
    Episode time: 84.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 62000...
    MADDPG UPDATE finished.
    Step 62000, Episode Steps: 1842, Avg Reward: 19.997, Episode Reward: 36834.0
    æ£€æµ‹è¿›åº¦: 8/42 (19.0%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(289,3024)'), ('usv_1', '(299,4083)'), ('usv_2', '(209,5173)')]...
    Recent rewards sample: {'usv_0': np.float64(7.931852494728509), 'usv_1': np.float64(3.4230958366626503)}
    Episode time: 184.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 24 Summary:
  Total Reward: 57607.0
  Targets Detected: 10/56 (14.3%)
  Steps: 2797
  Episode Time: 279.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 20.60
--- Episode 25 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 63000...
    MADDPG UPDATE finished.
    Step 63000, Episode Steps: 45, Avg Reward: -3.786, Episode Reward: -170.4
    æ£€æµ‹è¿›åº¦: 0/3 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(213,3130)'), ('usv_1', '(218,4130)'), ('usv_2', '(213,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.685073593222619), 'usv_1': np.float64(-1.5798556667218837)}
    Episode time: 4.5s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 64000...
    MADDPG UPDATE finished.
    Step 64000, Episode Steps: 1045, Avg Reward: 0.992, Episode Reward: 1036.8
    æ£€æµ‹è¿›åº¦: 1/19 (5.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(274,3079)'), ('usv_1', '(256,4146)'), ('usv_2', '(231,5180)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9212841838693433), 'usv_1': np.float64(-0.575391668170561)}
    Episode time: 104.5s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.22197993 -0.33060456] (agent usv_0)
    MADDPG UPDATING at time_step 65000...
    MADDPG UPDATE finished.
    Step 65000, Episode Steps: 2045, Avg Reward: 5.904, Episode Reward: 12074.4
    æ£€æµ‹è¿›åº¦: 4/45 (8.9%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(261,2984)'), ('usv_1', '(273,4192)'), ('usv_2', '(204,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(7.92286856061498), 'usv_1': np.float64(1.4255806746436348)}
    Episode time: 204.5s, Time penalty=-0.1
------------------------------------------------------------
Episode 25 Summary:
  Total Reward: 33331.3
  Targets Detected: 5/60 (6.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 11.11
--- Episode 26 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 66000...
    MADDPG UPDATE finished.
    Step 66000, Episode Steps: 44, Avg Reward: -3.420, Episode Reward: -150.5
    æ£€æµ‹è¿›åº¦: 0/1 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(214,3130)'), ('usv_1', '(213,4130)'), ('usv_2', '(215,5130)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6809685298599675), 'usv_1': np.float64(-1.5777515140502831)}
    Episode time: 4.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 67000...
    MADDPG UPDATE finished.
    Step 67000, Episode Steps: 1044, Avg Reward: 0.537, Episode Reward: 561.1
    æ£€æµ‹è¿›åº¦: 2/18 (11.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(291,3069)'), ('usv_1', '(260,4111)'), ('usv_2', '(263,5176)')]...
    Recent rewards sample: {'usv_0': np.float64(3.9237319708180944), 'usv_1': np.float64(-0.5801148324280401)}
    Episode time: 104.4s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 68000...
    MADDPG UPDATE finished.
    Step 68000, Episode Steps: 2044, Avg Reward: 10.998, Episode Reward: 22479.1
    æ£€æµ‹è¿›åº¦: 4/37 (10.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(242,2998)'), ('usv_1', '(318,4086)'), ('usv_2', '(230,5202)')]...
    Recent rewards sample: {'usv_0': np.float64(5.927639625079781), 'usv_1': np.float64(1.4244996578823148)}
    Episode time: 204.4s, Time penalty=-0.1
------------------------------------------------------------
Episode 26 Summary:
  Total Reward: 31894.2
  Targets Detected: 4/47 (4.3%)
  Steps: 2655
  Episode Time: 265.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 12.01
--- Episode 27 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 69000...
    MADDPG UPDATE finished.
    Step 69000, Episode Steps: 389, Avg Reward: 4.402, Episode Reward: 1712.4
    æ£€æµ‹è¿›åº¦: 1/11 (9.1%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(243,3133)'), ('usv_1', '(231,4126)'), ('usv_2', '(242,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(0.3238667897579347), 'usv_1': np.float64(-0.5823938328409555)}
    Episode time: 38.9s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.04260069 0.19094564] (agent usv_0)
    MADDPG UPDATING at time_step 70000...
    MADDPG UPDATE finished.
    Step 70000, Episode Steps: 1389, Avg Reward: 7.521, Episode Reward: 10446.6
    æ£€æµ‹è¿›åº¦: 2/33 (6.1%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(321,3142)'), ('usv_1', '(262,4092)'), ('usv_2', '(229,5192)')]...
    Recent rewards sample: {'usv_0': np.float64(1.340185660285607), 'usv_1': np.float64(0.4202375533466174)}
    Episode time: 138.9s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 71000...
    MADDPG UPDATE finished.
    Step 71000, Episode Steps: 2389, Avg Reward: 8.749, Episode Reward: 20900.9
    æ£€æµ‹è¿›åº¦: 3/45 (6.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(410,3096)'), ('usv_1', '(262,4032)'), ('usv_2', '(204,5158)')]...
    Recent rewards sample: {'usv_0': np.float64(4.376599583908875), 'usv_1': np.float64(1.4247344251409184)}
    Episode time: 238.9s, Time penalty=-0.1
------------------------------------------------------------
Episode 27 Summary:
  Total Reward: 32954.3
  Targets Detected: 4/52 (7.7%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.98
--- Episode 28 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 72000...
    MADDPG UPDATE finished.
    Step 72000, Episode Steps: 388, Avg Reward: -5.467, Episode Reward: -2121.3
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3132)'), ('usv_1', '(243,4122)'), ('usv_2', '(230,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.676831592249046), 'usv_1': np.float64(-1.5737807968692672)}
    Episode time: 38.8s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 73000...
    MADDPG UPDATE finished.
    Step 73000, Episode Steps: 1388, Avg Reward: -0.476, Episode Reward: -660.9
    æ£€æµ‹è¿›åº¦: 0/38 (0.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(315,3086)'), ('usv_1', '(309,4080)'), ('usv_2', '(234,5205)')]...
    Recent rewards sample: {'usv_0': np.float64(3.927566228404509), 'usv_1': np.float64(-0.5749987319562615)}
    Episode time: 138.8s, Time penalty=-0.1
------------------------------------------------------------
Episode 28 Summary:
  Total Reward: 7127.6
  Targets Detected: 2/51 (2.0%)
  Steps: 1896
  Episode Time: 189.6s
  Termination Reason: no_progress_120s
  Average Reward/Step: 3.76
--- Episode 29 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 74000...
    MADDPG UPDATE finished.
    Step 74000, Episode Steps: 492, Avg Reward: -3.687, Episode Reward: -1814.1
    æ£€æµ‹è¿›åº¦: 0/6 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3114)'), ('usv_1', '(256,4132)'), ('usv_2', '(240,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6744573529525225), 'usv_1': np.float64(-1.5743245589967745)}
    Episode time: 49.2s, Time penalty=-0.1
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.04406033 -0.15948764] (agent usv_0)
    MADDPG UPDATING at time_step 75000...
    MADDPG UPDATE finished.
    Step 75000, Episode Steps: 1492, Avg Reward: -0.590, Episode Reward: -880.3
    æ£€æµ‹è¿›åº¦: 1/20 (5.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3033)'), ('usv_1', '(316,4154)'), ('usv_2', '(205,5192)')]...
    Recent rewards sample: {'usv_0': np.float64(4.922240913312153), 'usv_1': np.float64(2.431221607440761)}
    Episode time: 149.2s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 76000...
    MADDPG UPDATE finished.
    Step 76000, Episode Steps: 2492, Avg Reward: 8.005, Episode Reward: 19949.1
    æ£€æµ‹è¿›åº¦: 4/49 (8.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(206,3066)'), ('usv_1', '(376,4156)'), ('usv_2', '(229,5175)')]...
    Recent rewards sample: {'usv_0': np.float64(7.924420108350976), 'usv_1': np.float64(3.4358574261009167)}
    Episode time: 249.2s, Time penalty=-0.1
------------------------------------------------------------
Episode 29 Summary:
  Total Reward: 32118.1
  Targets Detected: 5/64 (7.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 10.70
--- Episode 30 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 77000...
    MADDPG UPDATE finished.
    Step 77000, Episode Steps: 491, Avg Reward: -3.597, Episode Reward: -1766.1
    æ£€æµ‹è¿›åº¦: 0/11 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(249,3124)'), ('usv_1', '(240,4113)'), ('usv_2', '(241,5139)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.6680022255403532), 'usv_1': np.float64(-1.5744718933875568)}
    Episode time: 49.1s, Time penalty=-0.1
------------------------------------------------------------
    MADDPG UPDATING at time_step 78000...
    MADDPG UPDATE finished.
    Step 78000, Episode Steps: 1491, Avg Reward: -2.452, Episode Reward: -3656.0
    æ£€æµ‹è¿›åº¦: 0/29 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3031)'), ('usv_1', '(264,4055)'), ('usv_2', '(237,5193)')]...
    Recent rewards sample: {'usv_0': np.float64(2.9306699852789504), 'usv_1': np.float64(-1.579068883356047)}
    Episode time: 149.1s, Time penalty=-0.1
------------------------------------------------------------
Episode 30 Summary:
  Total Reward: -3647.9
  Targets Detected: 0/42 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -2.03

==================================================
MADDPG TRAINING PROGRESS - Episode 30
==================================================
Last 10 episodes average reward: 29602.5
Last 10 episodes average detections: 4.5
Best episode reward so far: 64166.9
Best detection count so far: 10
Learning trend: Declining (29602.5 vs 44951.2)
Buffer size: 50000
==================================================

    [Curriculum] Hard mode: é«˜é€Ÿç›®æ ‡ä¸»å¯¼, æ•ˆçŽ‡ä¼˜å…ˆ
--- Episode 31 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 79000...
    MADDPG UPDATE finished.
    Step 79000, Episode Steps: 690, Avg Reward: -3.908, Episode Reward: -2696.8
    æ£€æµ‹è¿›åº¦: 0/17 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3100)'), ('usv_1', '(247,4130)'), ('usv_2', '(252,5138)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7141947017576304), 'usv_1': np.float64(-1.6247151872905967)}
    Episode time: 69.0s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.15521549 0.35416911] (agent usv_0)
    MADDPG UPDATING at time_step 80000...
    MADDPG UPDATE finished.
    Step 80000, Episode Steps: 1690, Avg Reward: -2.231, Episode Reward: -3769.7
    æ£€æµ‹è¿›åº¦: 0/39 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(253,3018)'), ('usv_1', '(304,4137)'), ('usv_2', '(291,5202)')]...
    Recent rewards sample: {'usv_0': np.float64(2.884814971041916), 'usv_1': np.float64(-1.6142089519497511)}
    Episode time: 169.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 31 Summary:
  Total Reward: -3815.8
  Targets Detected: 0/49 (0.0%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_180s
  Average Reward/Step: -2.12
--- Episode 32 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 81000...
    MADDPG UPDATE finished.
    Step 81000, Episode Steps: 889, Avg Reward: 0.021, Episode Reward: 18.2
    æ£€æµ‹è¿›åº¦: 1/25 (4.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(288,3120)'), ('usv_1', '(262,4130)'), ('usv_2', '(242,5163)')]...
    Recent rewards sample: {'usv_0': np.float64(0.28761717411025567), 'usv_1': np.float64(-0.6299805425058126)}
    Episode time: 88.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 82000...
    MADDPG UPDATE finished.
    Step 82000, Episode Steps: 1889, Avg Reward: 5.176, Episode Reward: 9777.7
    æ£€æµ‹è¿›åº¦: 3/47 (6.4%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(361,3100)'), ('usv_1', '(280,4082)'), ('usv_2', '(206,5179)')]...
    Recent rewards sample: {'usv_0': np.float64(4.305505434453936), 'usv_1': np.float64(3.3750825710567565)}
    Episode time: 188.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 83000...
    MADDPG UPDATE finished.
    Step 83000, Episode Steps: 2889, Avg Reward: 12.415, Episode Reward: 35867.3
    æ£€æµ‹è¿›åº¦: 5/82 (6.1%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(397,3025)'), ('usv_1', '(310,4020)'), ('usv_2', '(224,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(7.889919108683737), 'usv_1': np.float64(3.380116877791332)}
    Episode time: 288.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 32 Summary:
  Total Reward: 38529.7
  Targets Detected: 7/86 (5.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 12.84
--- Episode 33 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 84000...
    MADDPG UPDATE finished.
    Step 84000, Episode Steps: 888, Avg Reward: 1.247, Episode Reward: 1107.0
    æ£€æµ‹è¿›åº¦: 2/29 (6.9%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(297,3121)'), ('usv_1', '(264,4127)'), ('usv_2', '(273,5157)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2956601881863854), 'usv_1': np.float64(0.3701506536538721)}
    Episode time: 88.8s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.15843824 0.33531507] (agent usv_0)
    MADDPG UPDATING at time_step 85000...
    MADDPG UPDATE finished.
    Step 85000, Episode Steps: 1888, Avg Reward: 9.627, Episode Reward: 18176.5
    æ£€æµ‹è¿›åº¦: 5/48 (10.4%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(361,3063)'), ('usv_1', '(311,4114)'), ('usv_2', '(275,5209)')]...
    Recent rewards sample: {'usv_0': np.float64(7.88403775758527), 'usv_1': np.float64(1.3737707283518157)}
    Episode time: 188.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 86000...
    MADDPG UPDATE finished.
    Step 86000, Episode Steps: 2888, Avg Reward: 13.554, Episode Reward: 39144.0
    æ£€æµ‹è¿›åº¦: 7/73 (9.6%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(355,2965)'), ('usv_1', '(308,4060)'), ('usv_2', '(247,5177)')]...
    Recent rewards sample: {'usv_0': np.float64(7.883775625367402), 'usv_1': np.float64(1.3761830502870036)}
    Episode time: 288.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 33 Summary:
  Total Reward: 41602.3
  Targets Detected: 10/74 (9.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.86
--- Episode 34 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 87000...
    MADDPG UPDATE finished.
    Step 87000, Episode Steps: 887, Avg Reward: 8.755, Episode Reward: 7766.1
    æ£€æµ‹è¿›åº¦: 2/19 (10.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,3082)'), ('usv_1', '(258,4139)'), ('usv_2', '(246,5160)')]...
    Recent rewards sample: {'usv_0': np.float64(6.873265461946714), 'usv_1': np.float64(0.3697030488791133)}
    Episode time: 88.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 88000...
    MADDPG UPDATE finished.
    Step 88000, Episode Steps: 1887, Avg Reward: 13.708, Episode Reward: 25867.9
    æ£€æµ‹è¿›åº¦: 4/51 (7.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3009)'), ('usv_1', '(299,4166)'), ('usv_2', '(200,5157)')]...
    Recent rewards sample: {'usv_0': np.float64(5.876558066945556), 'usv_1': np.float64(3.3786349952368875)}
    Episode time: 188.7s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 89000...
    MADDPG UPDATE finished.
    Step 89000, Episode Steps: 2887, Avg Reward: 17.359, Episode Reward: 50115.1
    æ£€æµ‹è¿›åº¦: 5/78 (6.4%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(204,3027)'), ('usv_1', '(313,4211)'), ('usv_2', '(202,5098)')]...
    Recent rewards sample: {'usv_0': np.float64(7.871327697455094), 'usv_1': np.float64(3.381552811314471)}
    Episode time: 288.7s, Time penalty=-0.15
------------------------------------------------------------
Episode 34 Summary:
  Total Reward: 52816.6
  Targets Detected: 6/81 (6.2%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 17.60
--- Episode 35 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.1733757  -0.10180971] (agent usv_0)
    MADDPG UPDATING at time_step 90000...
    MADDPG UPDATE finished.
    Step 90000, Episode Steps: 886, Avg Reward: 1.100, Episode Reward: 974.7
    æ£€æµ‹è¿›åº¦: 1/24 (4.2%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3109)'), ('usv_1', '(265,4121)'), ('usv_2', '(262,5151)')]...
    Recent rewards sample: {'usv_0': np.float64(0.29529201005721417), 'usv_1': np.float64(-0.6297797706837633)}
    Episode time: 88.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 91000...
    MADDPG UPDATE finished.
    Step 91000, Episode Steps: 1886, Avg Reward: 10.979, Episode Reward: 20706.3
    æ£€æµ‹è¿›åº¦: 5/66 (7.6%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(339,3022)'), ('usv_1', '(322,4085)'), ('usv_2', '(212,5166)')]...
    Recent rewards sample: {'usv_0': np.float64(7.877177076558858), 'usv_1': np.float64(3.382612409559128)}
    Episode time: 188.6s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 92000...
    MADDPG UPDATE finished.
    Step 92000, Episode Steps: 2886, Avg Reward: 16.235, Episode Reward: 46854.2
    æ£€æµ‹è¿›åº¦: 8/87 (9.2%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(310,2937)'), ('usv_1', '(371,4086)'), ('usv_2', '(237,5127)')]...
    Recent rewards sample: {'usv_0': np.float64(5.884620149751784), 'usv_1': np.float64(3.3840813875102977)}
    Episode time: 288.6s, Time penalty=-0.15
------------------------------------------------------------
Episode 35 Summary:
  Total Reward: 50500.9
  Targets Detected: 11/90 (8.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.83
--- Episode 36 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 93000...
    MADDPG UPDATE finished.
    Step 93000, Episode Steps: 885, Avg Reward: 11.732, Episode Reward: 10383.2
    æ£€æµ‹è¿›åº¦: 4/28 (14.3%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(290,3103)'), ('usv_1', '(274,4148)'), ('usv_2', '(244,5154)')]...
    Recent rewards sample: {'usv_0': np.float64(4.289896937256434), 'usv_1': np.float64(1.3745479163084546)}
    Episode time: 88.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 94000...
    MADDPG UPDATE finished.
    Step 94000, Episode Steps: 1885, Avg Reward: 17.306, Episode Reward: 32622.5
    æ£€æµ‹è¿›åº¦: 5/60 (8.3%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(284,3034)'), ('usv_1', '(333,4115)'), ('usv_2', '(210,5168)')]...
    Recent rewards sample: {'usv_0': np.float64(7.872870630955473), 'usv_1': np.float64(1.3754908070739869)}
    Episode time: 188.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 36 Summary:
  Total Reward: 45753.7
  Targets Detected: 7/76 (5.3%)
  Steps: 2440
  Episode Time: 244.0s
  Termination Reason: no_progress_120s
  Average Reward/Step: 18.75
--- Episode 37 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.12883198 -0.06314982] (agent usv_0)
    MADDPG UPDATING at time_step 95000...
    MADDPG UPDATE finished.
    Step 95000, Episode Steps: 445, Avg Reward: -4.257, Episode Reward: -1894.2
    æ£€æµ‹è¿›åº¦: 0/16 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(247,3123)'), ('usv_1', '(233,4130)'), ('usv_2', '(231,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.720738392423347), 'usv_1': np.float64(-1.632191321568277)}
    Episode time: 44.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 96000...
    MADDPG UPDATE finished.
    Step 96000, Episode Steps: 1445, Avg Reward: 0.544, Episode Reward: 786.4
    æ£€æµ‹è¿›åº¦: 3/53 (5.7%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(328,3082)'), ('usv_1', '(288,4103)'), ('usv_2', '(205,5144)')]...
    Recent rewards sample: {'usv_0': np.float64(7.875339536413893), 'usv_1': np.float64(1.3720732028235632)}
    Episode time: 144.5s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 97000...
    MADDPG UPDATE finished.
    Step 97000, Episode Steps: 2445, Avg Reward: 11.361, Episode Reward: 27776.9
    æ£€æµ‹è¿›åº¦: 7/83 (8.4%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(314,3002)'), ('usv_1', '(321,4064)'), ('usv_2', '(249,5134)')]...
    Recent rewards sample: {'usv_0': np.float64(7.87587404913203), 'usv_1': np.float64(1.3750483743777289)}
    Episode time: 244.5s, Time penalty=-0.15
------------------------------------------------------------
Episode 37 Summary:
  Total Reward: 41987.1
  Targets Detected: 10/96 (9.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 13.99
--- Episode 38 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 98000...
    MADDPG UPDATE finished.
    Step 98000, Episode Steps: 444, Avg Reward: 3.337, Episode Reward: 1481.7
    æ£€æµ‹è¿›åº¦: 1/10 (10.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,3121)'), ('usv_1', '(224,4130)'), ('usv_2', '(251,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(0.2747562663565287), 'usv_1': np.float64(-0.6312076908239457)}
    Episode time: 44.4s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 99000...
    MADDPG UPDATE finished.
    Step 99000, Episode Steps: 1444, Avg Reward: 14.560, Episode Reward: 21023.9
    æ£€æµ‹è¿›åº¦: 9/53 (17.0%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(265,3045)'), ('usv_1', '(287,4123)'), ('usv_2', '(270,5224)')]...
    Recent rewards sample: {'usv_0': np.float64(7.876267791123519), 'usv_1': np.float64(3.377901598309321)}
    Episode time: 144.4s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.21667319 -0.15025664] (agent usv_0)
    MADDPG UPDATING at time_step 100000...
    MADDPG UPDATE finished.
    Step 100000, Episode Steps: 2444, Avg Reward: 19.068, Episode Reward: 46601.3
    æ£€æµ‹è¿›åº¦: 10/75 (13.3%), Episode total: 12
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(205,3013)'), ('usv_1', '(347,4106)'), ('usv_2', '(220,5238)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8700035314106564), 'usv_1': np.float64(3.376565569448446)}
    Episode time: 244.4s, Time penalty=-0.15
------------------------------------------------------------
Episode 38 Summary:
  Total Reward: 60916.1
  Targets Detected: 12/85 (11.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.30
--- Episode 39 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 101000...
    MADDPG UPDATE finished.
    Step 101000, Episode Steps: 443, Avg Reward: -4.561, Episode Reward: -2020.7
    æ£€æµ‹è¿›åº¦: 0/13 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(244,3123)'), ('usv_1', '(235,4129)'), ('usv_2', '(240,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7257213163931416), 'usv_1': np.float64(-1.6320620992554458)}
    Episode time: 44.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 102000...
    MADDPG UPDATE finished.
    Step 102000, Episode Steps: 1443, Avg Reward: 6.782, Episode Reward: 9786.8
    æ£€æµ‹è¿›åº¦: 1/42 (2.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(310,3077)'), ('usv_1', '(290,4118)'), ('usv_2', '(235,5186)')]...
    Recent rewards sample: {'usv_0': np.float64(4.877868731351045), 'usv_1': np.float64(0.373244733515657)}
    Episode time: 144.3s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 103000...
    MADDPG UPDATE finished.
    Step 103000, Episode Steps: 2443, Avg Reward: 13.712, Episode Reward: 33499.2
    æ£€æµ‹è¿›åº¦: 6/71 (8.5%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(298,2995)'), ('usv_1', '(319,4151)'), ('usv_2', '(228,5125)')]...
    Recent rewards sample: {'usv_0': np.float64(5.881256744191359), 'usv_1': np.float64(1.3743764890139354)}
    Episode time: 244.3s, Time penalty=-0.15
------------------------------------------------------------
Episode 39 Summary:
  Total Reward: 45883.2
  Targets Detected: 9/83 (8.4%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.29
--- Episode 40 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 104000...
    MADDPG UPDATE finished.
    Step 104000, Episode Steps: 442, Avg Reward: -2.909, Episode Reward: -1285.7
    æ£€æµ‹è¿›åº¦: 0/18 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3118)'), ('usv_1', '(243,4130)'), ('usv_2', '(239,5141)')]...
    Recent rewards sample: {'usv_0': np.float64(2.276428667782634), 'usv_1': np.float64(-0.631452576233426)}
    Episode time: 44.2s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.16847422 0.13666888] (agent usv_0)
    MADDPG UPDATING at time_step 105000...
    MADDPG UPDATE finished.
    Step 105000, Episode Steps: 1442, Avg Reward: 7.887, Episode Reward: 11372.7
    æ£€æµ‹è¿›åº¦: 1/41 (2.4%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(305,3048)'), ('usv_1', '(288,4103)'), ('usv_2', '(235,5193)')]...
    Recent rewards sample: {'usv_0': np.float64(5.877110366968701), 'usv_1': np.float64(0.37306384221218836)}
    Episode time: 144.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 106000...
    MADDPG UPDATE finished.
    Step 106000, Episode Steps: 2442, Avg Reward: 14.261, Episode Reward: 34824.6
    æ£€æµ‹è¿›åº¦: 4/67 (6.0%), Episode total: 5
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(289,2961)'), ('usv_1', '(315,4055)'), ('usv_2', '(204,5176)')]...
    Recent rewards sample: {'usv_0': np.float64(7.880043889364599), 'usv_1': np.float64(1.3797261160474767)}
    Episode time: 244.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 40 Summary:
  Total Reward: 47770.2
  Targets Detected: 7/76 (7.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.92

==================================================
MADDPG TRAINING PROGRESS - Episode 40
==================================================
Last 10 episodes average reward: 42194.4
Last 10 episodes average detections: 7.9
Best episode reward so far: 64166.9
Best detection count so far: 12
Learning trend: Improving (42194.4 vs 29602.5)
Buffer size: 50000
==================================================

--- Episode 41 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 107000...
    MADDPG UPDATE finished.
    Step 107000, Episode Steps: 441, Avg Reward: 8.792, Episode Reward: 3877.1
    æ£€æµ‹è¿›åº¦: 2/8 (25.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(226,3118)'), ('usv_1', '(233,4130)'), ('usv_2', '(230,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2719176282068658), 'usv_1': np.float64(0.3678145252000553)}
    Episode time: 44.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 108000...
    MADDPG UPDATE finished.
    Step 108000, Episode Steps: 1441, Avg Reward: 16.836, Episode Reward: 24260.9
    æ£€æµ‹è¿›åº¦: 5/38 (13.2%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(200,3065)'), ('usv_1', '(291,4107)'), ('usv_2', '(203,5185)')]...
    Recent rewards sample: {'usv_0': np.float64(5.866052276310394), 'usv_1': np.float64(1.3804288760977799)}
    Episode time: 144.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 109000...
    MADDPG UPDATE finished.
    Step 109000, Episode Steps: 2441, Avg Reward: 19.821, Episode Reward: 48382.0
    æ£€æµ‹è¿›åº¦: 9/67 (13.4%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(203,3078)'), ('usv_1', '(338,4121)'), ('usv_2', '(201,5162)')]...
    Recent rewards sample: {'usv_0': np.float64(5.865994008355019), 'usv_1': np.float64(3.3811998692923186)}
    Episode time: 244.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 41 Summary:
  Total Reward: 60936.7
  Targets Detected: 12/86 (12.8%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.31
--- Episode 42 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [ 0.06046349 -0.129398  ] (agent usv_0)
    MADDPG UPDATING at time_step 110000...
    MADDPG UPDATE finished.
    Step 110000, Episode Steps: 440, Avg Reward: 6.625, Episode Reward: 2914.9
    æ£€æµ‹è¿›åº¦: 2/20 (10.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(245,3128)'), ('usv_1', '(240,4128)'), ('usv_2', '(229,5143)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2789154092067), 'usv_1': np.float64(0.3682991035705625)}
    Episode time: 44.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 111000...
    MADDPG UPDATE finished.
    Step 111000, Episode Steps: 1440, Avg Reward: 18.181, Episode Reward: 26181.0
    æ£€æµ‹è¿›åº¦: 8/55 (14.5%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(290,3056)'), ('usv_1', '(297,4113)'), ('usv_2', '(208,5185)')]...
    Recent rewards sample: {'usv_0': np.float64(5.874832046049508), 'usv_1': np.float64(3.3733781219920944)}
    Episode time: 144.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 112000...
    MADDPG UPDATE finished.
    Step 112000, Episode Steps: 2440, Avg Reward: 22.488, Episode Reward: 54870.5
    æ£€æµ‹è¿›åº¦: 12/85 (14.1%), Episode total: 14
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(275,2974)'), ('usv_1', '(336,4093)'), ('usv_2', '(218,5154)')]...
    Recent rewards sample: {'usv_0': np.float64(7.883995544013024), 'usv_1': np.float64(3.375896939708011)}
    Episode time: 244.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 42 Summary:
  Total Reward: 70109.1
  Targets Detected: 16/100 (14.0%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 23.36
--- Episode 43 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 113000...
    MADDPG UPDATE finished.
    Step 113000, Episode Steps: 439, Avg Reward: 5.180, Episode Reward: 2273.9
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(252,3120)'), ('usv_1', '(242,4133)'), ('usv_2', '(233,5136)')]...
    Recent rewards sample: {'usv_0': np.float64(0.28336882554338594), 'usv_1': np.float64(-0.6315206715089925)}
    Episode time: 43.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 114000...
    MADDPG UPDATE finished.
    Step 114000, Episode Steps: 1439, Avg Reward: 5.231, Episode Reward: 7527.3
    æ£€æµ‹è¿›åº¦: 3/55 (5.5%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(318,3077)'), ('usv_1', '(292,4122)'), ('usv_2', '(208,5169)')]...
    Recent rewards sample: {'usv_0': np.float64(4.877226086589267), 'usv_1': np.float64(0.37330254373864724)}
    Episode time: 143.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.02155365  0.08534535] (agent usv_0)
    MADDPG UPDATING at time_step 115000...
    MADDPG UPDATE finished.
    Step 115000, Episode Steps: 2439, Avg Reward: 13.219, Episode Reward: 32242.3
    æ£€æµ‹è¿›åº¦: 8/90 (8.9%), Episode total: 10
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(356,2993)'), ('usv_1', '(350,4104)'), ('usv_2', '(211,5119)')]...
    Recent rewards sample: {'usv_0': np.float64(7.883909680679098), 'usv_1': np.float64(3.376799781521667)}
    Episode time: 243.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 43 Summary:
  Total Reward: 47167.1
  Targets Detected: 14/106 (11.3%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 15.72
--- Episode 44 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 116000...
    MADDPG UPDATE finished.
    Step 116000, Episode Steps: 438, Avg Reward: 4.628, Episode Reward: 2027.2
    æ£€æµ‹è¿›åº¦: 1/17 (5.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(255,3126)'), ('usv_1', '(233,4131)'), ('usv_2', '(236,5140)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27933398683593835), 'usv_1': np.float64(1.3677938080599832)}
    Episode time: 43.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 117000...
    MADDPG UPDATE finished.
    Step 117000, Episode Steps: 1438, Avg Reward: 11.604, Episode Reward: 16686.5
    æ£€æµ‹è¿›åº¦: 7/68 (10.3%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(329,3083)'), ('usv_1', '(290,4152)'), ('usv_2', '(216,5208)')]...
    Recent rewards sample: {'usv_0': np.float64(5.876340848127701), 'usv_1': np.float64(3.3721902419582843)}
    Episode time: 143.8s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 118000...
    MADDPG UPDATE finished.
    Step 118000, Episode Steps: 2438, Avg Reward: 15.139, Episode Reward: 36907.8
    æ£€æµ‹è¿›åº¦: 7/83 (8.4%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(368,2993)'), ('usv_1', '(342,4186)'), ('usv_2', '(200,5191)')]...
    Recent rewards sample: {'usv_0': np.float64(5.8834938230928255), 'usv_1': np.float64(3.3810466841060336)}
    Episode time: 243.8s, Time penalty=-0.15
------------------------------------------------------------
Episode 44 Summary:
  Total Reward: 37873.9
  Targets Detected: 8/86 (8.1%)
  Steps: 2487
  Episode Time: 248.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 15.23
--- Episode 45 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 119000...
    MADDPG UPDATE finished.
    Step 119000, Episode Steps: 951, Avg Reward: 21.469, Episode Reward: 20416.7
    æ£€æµ‹è¿›åº¦: 4/27 (14.8%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(280,3073)'), ('usv_1', '(262,4126)'), ('usv_2', '(260,5146)')]...
    Recent rewards sample: {'usv_0': np.float64(5.876805170073726), 'usv_1': np.float64(1.374825575802069)}
    Episode time: 95.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 45 Summary:
  Total Reward: 39406.3
  Targets Detected: 5/48 (8.3%)
  Steps: 1801
  Episode Time: 180.1s
  Termination Reason: no_progress_121s
  Average Reward/Step: 21.88
--- Episode 46 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [0.18204189 0.01610279] (agent usv_0)
    MADDPG UPDATING at time_step 120000...
    MADDPG UPDATE finished.
    Step 120000, Episode Steps: 150, Avg Reward: 3.567, Episode Reward: 535.0
    æ£€æµ‹è¿›åº¦: 1/4 (25.0%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(235,3128)'), ('usv_1', '(223,4130)'), ('usv_2', '(227,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27804406407565974), 'usv_1': np.float64(-0.6319391504631757)}
    Episode time: 15.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 121000...
    MADDPG UPDATE finished.
    Step 121000, Episode Steps: 1150, Avg Reward: 5.436, Episode Reward: 6251.5
    æ£€æµ‹è¿›åº¦: 3/34 (8.8%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(290,3066)'), ('usv_1', '(278,4129)'), ('usv_2', '(239,5179)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8756499606383406), 'usv_1': np.float64(1.3732036250830104)}
    Episode time: 115.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 122000...
    MADDPG UPDATE finished.
    Step 122000, Episode Steps: 2150, Avg Reward: 13.215, Episode Reward: 28412.9
    æ£€æµ‹è¿›åº¦: 6/72 (8.3%), Episode total: 7
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(254,2978)'), ('usv_1', '(322,4086)'), ('usv_2', '(207,5189)')]...
    Recent rewards sample: {'usv_0': np.float64(7.878351680788552), 'usv_1': np.float64(3.3773501353675695)}
    Episode time: 215.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 46 Summary:
  Total Reward: 50149.3
  Targets Detected: 10/93 (7.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.71
--- Episode 47 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 123000...
    MADDPG UPDATE finished.
    Step 123000, Episode Steps: 149, Avg Reward: 8.363, Episode Reward: 1246.1
    æ£€æµ‹è¿›åº¦: 1/3 (33.3%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(227,3129)'), ('usv_1', '(220,4130)'), ('usv_2', '(220,5131)')]...
    Recent rewards sample: {'usv_0': np.float64(0.27078772802834483), 'usv_1': np.float64(-0.633175956593063)}
    Episode time: 14.9s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 124000...
    MADDPG UPDATE finished.
    Step 124000, Episode Steps: 1149, Avg Reward: 9.661, Episode Reward: 11100.1
    æ£€æµ‹è¿›åº¦: 3/37 (8.1%), Episode total: 3
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(272,3069)'), ('usv_1', '(264,4114)'), ('usv_2', '(253,5179)')]...
    Recent rewards sample: {'usv_0': np.float64(7.88125167317419), 'usv_1': np.float64(1.3724130582335379)}
    Episode time: 114.9s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.10826619 -0.09836509] (agent usv_0)
    MADDPG UPDATING at time_step 125000...
    MADDPG UPDATE finished.
    Step 125000, Episode Steps: 2149, Avg Reward: 15.596, Episode Reward: 33516.2
    æ£€æµ‹è¿›åº¦: 2/63 (3.2%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(231,2975)'), ('usv_1', '(322,4106)'), ('usv_2', '(209,5161)')]...
    Recent rewards sample: {'usv_0': np.float64(7.876233472406625), 'usv_1': np.float64(1.378627915824603)}
    Episode time: 214.9s, Time penalty=-0.15
------------------------------------------------------------
Episode 47 Summary:
  Total Reward: 39958.1
  Targets Detected: 5/68 (4.4%)
  Steps: 2397
  Episode Time: 239.7s
  Termination Reason: no_progress_120s
  Average Reward/Step: 16.67
--- Episode 48 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 126000...
    MADDPG UPDATE finished.
    Step 126000, Episode Steps: 752, Avg Reward: 8.655, Episode Reward: 6508.6
    æ£€æµ‹è¿›åº¦: 2/20 (10.0%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(279,3129)'), ('usv_1', '(255,4114)'), ('usv_2', '(231,5159)')]...
    Recent rewards sample: {'usv_0': np.float64(4.289728596166966), 'usv_1': np.float64(1.373213722362153)}
    Episode time: 75.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 127000...
    MADDPG UPDATE finished.
    Step 127000, Episode Steps: 1752, Avg Reward: 17.521, Episode Reward: 30696.9
    æ£€æµ‹è¿›åº¦: 8/48 (16.7%), Episode total: 8
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(358,3073)'), ('usv_1', '(303,4106)'), ('usv_2', '(203,5149)')]...
    Recent rewards sample: {'usv_0': np.float64(7.877677378273328), 'usv_1': np.float64(3.3775335813843252)}
    Episode time: 175.2s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 128000...
    MADDPG UPDATE finished.
    Step 128000, Episode Steps: 2752, Avg Reward: 20.419, Episode Reward: 56193.9
    æ£€æµ‹è¿›åº¦: 8/68 (11.8%), Episode total: 9
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(321,2999)'), ('usv_1', '(354,4077)'), ('usv_2', '(215,5100)')]...
    Recent rewards sample: {'usv_0': np.float64(7.883223232796381), 'usv_1': np.float64(3.3773576473264804)}
    Episode time: 275.2s, Time penalty=-0.15
------------------------------------------------------------
Episode 48 Summary:
  Total Reward: 62379.4
  Targets Detected: 9/71 (9.9%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 20.79
--- Episode 49 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 129000...
    MADDPG UPDATE finished.
    Step 129000, Episode Steps: 751, Avg Reward: 5.161, Episode Reward: 3876.2
    æ£€æµ‹è¿›åº¦: 2/16 (12.5%), Episode total: 2
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(286,3100)'), ('usv_1', '(248,4121)'), ('usv_2', '(241,5145)')]...
    Recent rewards sample: {'usv_0': np.float64(1.2861429235387647), 'usv_1': np.float64(0.3729445253900412)}
    Episode time: 75.1s, Time penalty=-0.15
------------------------------------------------------------
    DEBUG: MADDPG actions shape = (6, 2)
    DEBUG: Sample action = [-0.27161454  0.04696047] (agent usv_0)
    MADDPG UPDATING at time_step 130000...
    MADDPG UPDATE finished.
    Step 130000, Episode Steps: 1751, Avg Reward: 12.084, Episode Reward: 21159.1
    æ£€æµ‹è¿›åº¦: 4/43 (9.3%), Episode total: 4
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(293,3013)'), ('usv_1', '(286,4096)'), ('usv_2', '(208,5179)')]...
    Recent rewards sample: {'usv_0': np.float64(7.875032808889958), 'usv_1': np.float64(1.3759426504984553)}
    Episode time: 175.1s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 131000...
    MADDPG UPDATE finished.
    Step 131000, Episode Steps: 2751, Avg Reward: 15.874, Episode Reward: 43670.4
    æ£€æµ‹è¿›åº¦: 6/72 (8.3%), Episode total: 6
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(210,2988)'), ('usv_1', '(335,4063)'), ('usv_2', '(209,5121)')]...
    Recent rewards sample: {'usv_0': np.float64(7.8712746669888), 'usv_1': np.float64(1.380818700952311)}
    Episode time: 275.1s, Time penalty=-0.15
------------------------------------------------------------
Episode 49 Summary:
  Total Reward: 49482.8
  Targets Detected: 6/80 (7.5%)
  Steps: 3001
  Episode Time: 300.1s
  Termination Reason: time_limit_300s
  Average Reward/Step: 16.49
--- Episode 50 ---
åˆ†é…äº†6ä¸ªæ™ºèƒ½ä½“çš„ä¸“è´£åŒºåŸŸ
    MADDPG UPDATING at time_step 132000...
    MADDPG UPDATE finished.
    Step 132000, Episode Steps: 750, Avg Reward: -4.694, Episode Reward: -3520.6
    æ£€æµ‹è¿›åº¦: 0/19 (0.0%), Episode total: 0
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(272,3110)'), ('usv_1', '(255,4132)'), ('usv_2', '(230,5169)')]...
    Recent rewards sample: {'usv_0': np.float64(-0.7114577449861692), 'usv_1': np.float64(-1.6259202346062809)}
    Episode time: 75.0s, Time penalty=-0.15
------------------------------------------------------------
    MADDPG UPDATING at time_step 133000...
    MADDPG UPDATE finished.
    Step 133000, Episode Steps: 1750, Avg Reward: -0.476, Episode Reward: -833.0
    æ£€æµ‹è¿›åº¦: 1/35 (2.9%), Episode total: 1
    æ™ºèƒ½ä½“ä½ç½®: [('usv_0', '(281,3047)'), ('usv_1', '(299,4149)'), ('usv_2', '(203,5210)')]...
    Recent rewards sample: {'usv_0': np.float64(3.878790765235918), 'usv_1': np.float64(1.3782936068979605)}
    Episode time: 175.0s, Time penalty=-0.15
------------------------------------------------------------
Episode 50 Summary:
  Total Reward: 6765.2
  Targets Detected: 2/52 (1.9%)
  Steps: 2515
  Episode Time: 251.5s
  Termination Reason: no_progress_120s
  Average Reward/Step: 2.69

==================================================
MADDPG TRAINING PROGRESS - Episode 50
==================================================
Last 10 episodes average reward: 46422.8
Last 10 episodes average detections: 8.7
Best episode reward so far: 70109.1
Best detection count so far: 16
Learning trend: Improving (46422.8 vs 42194.4)
Buffer size: 50000
==================================================


=====================TRAINING COMPLETED=====================
Total episodes: 50
Best episode reward: 70109.1
Final 10 episodes average: 46422.8
Best detection performance: 16 targets
Average detections (final 10): 8.7
============================================================
{"final_avg_reward": 46422.801938489065, "final_detection_rate": 8.7, "best_episode_reward": 70109.08202447623, "best_detection_count": 16, "total_episodes": 50}
Simulation finished.
